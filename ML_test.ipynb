{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "#import optuna\n",
    "#from optuna.integration import SklearnSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  patient_nbr             race  gender      age  \\\n",
       "0           0      8222157        Caucasian  Female   [0-10)   \n",
       "1           1     55629189        Caucasian  Female  [10-20)   \n",
       "2           2     86047875  AfricanAmerican  Female  [20-30)   \n",
       "3           3     82442376        Caucasian    Male  [30-40)   \n",
       "4           4     42519267        Caucasian    Male  [40-50)   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  num_lab_procedures  ...  metformin  glimepiride  \\\n",
       "0                 1                  41  ...          0            0   \n",
       "1                 3                  59  ...          0            0   \n",
       "2                 2                  11  ...          0            0   \n",
       "3                 2                  44  ...          0            0   \n",
       "4                 1                  51  ...          0            0   \n",
       "\n",
       "   glipizide  glyburide  pioglitazone rosiglitazone insulin change  \\\n",
       "0          0          0             0             0       0     No   \n",
       "1          0          0             0             0       2     Ch   \n",
       "2          1          0             0             0       0     No   \n",
       "3          0          0             0             0       2     Ch   \n",
       "4          1          0             0             0       1     Ch   \n",
       "\n",
       "   diabetesMed readmitted  \n",
       "0           No         NO  \n",
       "1          Yes        >30  \n",
       "2          Yes         NO  \n",
       "3          Yes         NO  \n",
       "4          Yes         NO  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga la base de datos desde un archivo csv\n",
    "df_0 = pd.read_csv('diabetic_data_modified.csv')\n",
    "df = df_0.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "0        Caucasian  Female   [0-10)                  6   \n",
       "1        Caucasian  Female  [10-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-30)                  1   \n",
       "3        Caucasian    Male  [30-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "0                        25                    1                 1   \n",
       "1                         1                    7                 3   \n",
       "2                         1                    7                 2   \n",
       "3                         1                    7                 2   \n",
       "4                         1                    7                 1   \n",
       "\n",
       "   num_lab_procedures  num_procedures  num_medications  ...  metformin  \\\n",
       "0                  41               0                1  ...          0   \n",
       "1                  59               0               18  ...          0   \n",
       "2                  11               5               13  ...          0   \n",
       "3                  44               1               16  ...          0   \n",
       "4                  51               0                8  ...          0   \n",
       "\n",
       "   glimepiride  glipizide glyburide pioglitazone rosiglitazone  insulin  \\\n",
       "0            0          0         0            0             0        0   \n",
       "1            0          0         0            0             0        2   \n",
       "2            0          1         0            0             0        0   \n",
       "3            0          0         0            0             0        2   \n",
       "4            0          1         0            0             0        1   \n",
       "\n",
       "  change diabetesMed  readmitted  \n",
       "0     No          No          NO  \n",
       "1     Ch         Yes         >30  \n",
       "2     No         Yes          NO  \n",
       "3     Ch         Yes          NO  \n",
       "4     Ch         Yes          NO  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\",\"patient_nbr\",], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>Other</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>Other</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>Other</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Diseases of the circulatory system</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>Neoplasms</td>\n",
       "      <td>Neoplasms</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71513</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>Diseases of the digestive system</td>\n",
       "      <td>Diseases of the digestive system</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>&gt;7</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71514</th>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>Diseases of the genitourinary system</td>\n",
       "      <td>Diseases of the genitourinary system</td>\n",
       "      <td>Diseases of the respiratory system</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>&gt;8</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71515</th>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>Injury and poisoning</td>\n",
       "      <td>Diseases of the genitourinary system</td>\n",
       "      <td>Diseases of the circulatory system</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71516</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71517</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>Diseases of the digestive system</td>\n",
       "      <td>Diseases of the digestive system</td>\n",
       "      <td>Diseases of the digestive system</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>Not taken</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71518 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  race  gender      age                                diag_1  \\\n",
       "0            Caucasian  Female   [0-10)                     Diabetes mellitus   \n",
       "1            Caucasian  Female  [10-20)                                 Other   \n",
       "2      AfricanAmerican  Female  [20-30)                                 Other   \n",
       "3            Caucasian    Male  [30-40)                                 Other   \n",
       "4            Caucasian    Male  [40-50)                             Neoplasms   \n",
       "...                ...     ...      ...                                   ...   \n",
       "71513        Caucasian  Female  [70-80)      Diseases of the digestive system   \n",
       "71514            Other  Female  [40-50)  Diseases of the genitourinary system   \n",
       "71515            Other  Female  [60-70)                  Injury and poisoning   \n",
       "71516        Caucasian  Female  [80-90)                                 Other   \n",
       "71517        Caucasian    Male  [70-80)      Diseases of the digestive system   \n",
       "\n",
       "                                     diag_2  \\\n",
       "0                                     Other   \n",
       "1                         Diabetes mellitus   \n",
       "2                         Diabetes mellitus   \n",
       "3                         Diabetes mellitus   \n",
       "4                                 Neoplasms   \n",
       "...                                     ...   \n",
       "71513      Diseases of the digestive system   \n",
       "71514  Diseases of the genitourinary system   \n",
       "71515  Diseases of the genitourinary system   \n",
       "71516                                 Other   \n",
       "71517      Diseases of the digestive system   \n",
       "\n",
       "                                   diag_3 max_glu_serum  A1Cresult change  \\\n",
       "0                                   Other     Not taken  Not taken     No   \n",
       "1                                   Other     Not taken  Not taken     Ch   \n",
       "2                                   Other     Not taken  Not taken     No   \n",
       "3      Diseases of the circulatory system     Not taken  Not taken     Ch   \n",
       "4                       Diabetes mellitus     Not taken  Not taken     Ch   \n",
       "...                                   ...           ...        ...    ...   \n",
       "71513                   Diabetes mellitus     Not taken         >7     Ch   \n",
       "71514  Diseases of the respiratory system     Not taken         >8     Ch   \n",
       "71515  Diseases of the circulatory system     Not taken  Not taken     No   \n",
       "71516                               Other     Not taken  Not taken     Ch   \n",
       "71517    Diseases of the digestive system     Not taken  Not taken     No   \n",
       "\n",
       "      diabetesMed readmitted  \n",
       "0              No         NO  \n",
       "1             Yes        >30  \n",
       "2             Yes         NO  \n",
       "3             Yes         NO  \n",
       "4             Yes         NO  \n",
       "...           ...        ...  \n",
       "71513         Yes        >30  \n",
       "71514         Yes        >30  \n",
       "71515         Yes        >30  \n",
       "71516         Yes         NO  \n",
       "71517          No         NO  \n",
       "\n",
       "[71518 rows x 11 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=['category', 'object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71514</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71515</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71516</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71517</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71518 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                      6                        25                    1   \n",
       "1                      1                         1                    7   \n",
       "2                      1                         1                    7   \n",
       "3                      1                         1                    7   \n",
       "4                      1                         1                    7   \n",
       "...                  ...                       ...                  ...   \n",
       "71513                  1                         1                    7   \n",
       "71514                  1                         1                    7   \n",
       "71515                  1                         1                    7   \n",
       "71516                  1                         1                    7   \n",
       "71517                  1                         1                    7   \n",
       "\n",
       "       time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0                     1                  41               0                1   \n",
       "1                     3                  59               0               18   \n",
       "2                     2                  11               5               13   \n",
       "3                     2                  44               1               16   \n",
       "4                     1                  51               0                8   \n",
       "...                 ...                 ...             ...              ...   \n",
       "71513                 9                  50               2               33   \n",
       "71514                14                  73               6               26   \n",
       "71515                 2                  46               6               17   \n",
       "71516                 5                  76               1               22   \n",
       "71517                 6                  13               3                3   \n",
       "\n",
       "       number_outpatient  number_emergency  number_inpatient  \\\n",
       "0                      0                 0                 0   \n",
       "1                      0                 0                 0   \n",
       "2                      2                 0                 1   \n",
       "3                      0                 0                 0   \n",
       "4                      0                 0                 0   \n",
       "...                  ...               ...               ...   \n",
       "71513                  0                 0                 0   \n",
       "71514                  0                 1                 0   \n",
       "71515                  1                 1                 1   \n",
       "71516                  0                 1                 0   \n",
       "71517                  0                 0                 0   \n",
       "\n",
       "       number_diagnoses  metformin  glimepiride  glipizide  glyburide  \\\n",
       "0                     1          0            0          0          0   \n",
       "1                     9          0            0          0          0   \n",
       "2                     6          0            0          1          0   \n",
       "3                     7          0            0          0          0   \n",
       "4                     5          0            0          1          0   \n",
       "...                 ...        ...          ...        ...        ...   \n",
       "71513                 9          0            0          0          2   \n",
       "71514                 9          0            0          1          0   \n",
       "71515                 9          0            0          0          0   \n",
       "71516                 9          0            0          0          0   \n",
       "71517                 9          0            0          0          0   \n",
       "\n",
       "       pioglitazone  rosiglitazone  insulin  \n",
       "0                 0              0        0  \n",
       "1                 0              0        2  \n",
       "2                 0              0        0  \n",
       "3                 0              0        2  \n",
       "4                 0              0        1  \n",
       "...             ...            ...      ...  \n",
       "71513             0              0        1  \n",
       "71514             0              0        2  \n",
       "71515             0              0        1  \n",
       "71516             0              0        2  \n",
       "71517             0              0        0  \n",
       "\n",
       "[71518 rows x 18 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=['int', 'float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO', '>30', '<30'], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra los valores unicos de la columna que sera el target\n",
    "valores_unicos = df['readmitted'].unique()\n",
    "valores_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guille\\AppData\\Local\\Temp\\ipykernel_22728\\1913057400.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['readmitted'] = df['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar 'NO' por 0 y cualquier otro valor por 1\n",
    "df['readmitted'] = df['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "0        Caucasian  Female   [0-10)                  6   \n",
       "1        Caucasian  Female  [10-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-30)                  1   \n",
       "3        Caucasian    Male  [30-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "0                        25                    1                 1   \n",
       "1                         1                    7                 3   \n",
       "2                         1                    7                 2   \n",
       "3                         1                    7                 2   \n",
       "4                         1                    7                 1   \n",
       "\n",
       "   num_lab_procedures  num_procedures  num_medications  ...  metformin  \\\n",
       "0                  41               0                1  ...          0   \n",
       "1                  59               0               18  ...          0   \n",
       "2                  11               5               13  ...          0   \n",
       "3                  44               1               16  ...          0   \n",
       "4                  51               0                8  ...          0   \n",
       "\n",
       "   glimepiride  glipizide glyburide pioglitazone rosiglitazone  insulin  \\\n",
       "0            0          0         0            0             0        0   \n",
       "1            0          0         0            0             0        2   \n",
       "2            0          1         0            0             0        0   \n",
       "3            0          0         0            0             0        2   \n",
       "4            0          1         0            0             0        1   \n",
       "\n",
       "  change diabetesMed  readmitted  \n",
       "0     No          No           0  \n",
       "1     Ch         Yes           1  \n",
       "2     No         Yes           0  \n",
       "3     Ch         Yes           0  \n",
       "4     Ch         Yes           0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmitted\n",
      "0    42985\n",
      "1    28533\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readmitted', ylabel='count'>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.readmitted.value_counts())\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='readmitted', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71518, 29)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>...</th>\n",
       "      <th>max_glu_serum_Norm</th>\n",
       "      <th>max_glu_serum_Not taken</th>\n",
       "      <th>A1Cresult_&gt;7</th>\n",
       "      <th>A1Cresult_&gt;8</th>\n",
       "      <th>A1Cresult_Norm</th>\n",
       "      <th>A1Cresult_Not taken</th>\n",
       "      <th>change_Ch</th>\n",
       "      <th>change_No</th>\n",
       "      <th>diabetesMed_No</th>\n",
       "      <th>diabetesMed_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71514</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71515</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71516</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71517</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71518 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                      6                        25                    1   \n",
       "1                      1                         1                    7   \n",
       "2                      1                         1                    7   \n",
       "3                      1                         1                    7   \n",
       "4                      1                         1                    7   \n",
       "...                  ...                       ...                  ...   \n",
       "71513                  1                         1                    7   \n",
       "71514                  1                         1                    7   \n",
       "71515                  1                         1                    7   \n",
       "71516                  1                         1                    7   \n",
       "71517                  1                         1                    7   \n",
       "\n",
       "       time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0                     1                  41               0                1   \n",
       "1                     3                  59               0               18   \n",
       "2                     2                  11               5               13   \n",
       "3                     2                  44               1               16   \n",
       "4                     1                  51               0                8   \n",
       "...                 ...                 ...             ...              ...   \n",
       "71513                 9                  50               2               33   \n",
       "71514                14                  73               6               26   \n",
       "71515                 2                  46               6               17   \n",
       "71516                 5                  76               1               22   \n",
       "71517                 6                  13               3                3   \n",
       "\n",
       "       number_outpatient  number_emergency  number_inpatient  ...  \\\n",
       "0                      0                 0                 0  ...   \n",
       "1                      0                 0                 0  ...   \n",
       "2                      2                 0                 1  ...   \n",
       "3                      0                 0                 0  ...   \n",
       "4                      0                 0                 0  ...   \n",
       "...                  ...               ...               ...  ...   \n",
       "71513                  0                 0                 0  ...   \n",
       "71514                  0                 1                 0  ...   \n",
       "71515                  1                 1                 1  ...   \n",
       "71516                  0                 1                 0  ...   \n",
       "71517                  0                 0                 0  ...   \n",
       "\n",
       "       max_glu_serum_Norm  max_glu_serum_Not taken  A1Cresult_>7  \\\n",
       "0                       0                        1             0   \n",
       "1                       0                        1             0   \n",
       "2                       0                        1             0   \n",
       "3                       0                        1             0   \n",
       "4                       0                        1             0   \n",
       "...                   ...                      ...           ...   \n",
       "71513                   0                        1             1   \n",
       "71514                   0                        1             0   \n",
       "71515                   0                        1             0   \n",
       "71516                   0                        1             0   \n",
       "71517                   0                        1             0   \n",
       "\n",
       "       A1Cresult_>8  A1Cresult_Norm  A1Cresult_Not taken  change_Ch  \\\n",
       "0                 0               0                    1          0   \n",
       "1                 0               0                    1          1   \n",
       "2                 0               0                    1          0   \n",
       "3                 0               0                    1          1   \n",
       "4                 0               0                    1          1   \n",
       "...             ...             ...                  ...        ...   \n",
       "71513             0               0                    0          1   \n",
       "71514             1               0                    0          1   \n",
       "71515             0               0                    1          0   \n",
       "71516             0               0                    1          1   \n",
       "71517             0               0                    1          0   \n",
       "\n",
       "       change_No  diabetesMed_No  diabetesMed_Yes  \n",
       "0              1               1                0  \n",
       "1              0               0                1  \n",
       "2              1               0                1  \n",
       "3              0               0                1  \n",
       "4              0               0                1  \n",
       "...          ...             ...              ...  \n",
       "71513          0               0                1  \n",
       "71514          0               0                1  \n",
       "71515          1               0                1  \n",
       "71516          0               0                1  \n",
       "71517          1               1                0  \n",
       "\n",
       "[71518 rows x 76 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecciona automáticamente las columnas categóricas del DataFrame\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Realiza codificación one-hot manualmente para cada columna categórica\n",
    "encoded_columns = pd.get_dummies(df[categorical_columns])\n",
    "\n",
    "# Convierte las columnas codificadas one-hot en valores numéricos\n",
    "encoded_columns = encoded_columns.astype(int)\n",
    "\n",
    "# Concatena las columnas codificadas one-hot con el DataFrame original\n",
    "df_encoded = pd.concat([df.drop(columns=categorical_columns), encoded_columns], axis=1)\n",
    "\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71518, 76)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
       "       'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
       "       'num_medications', 'number_outpatient', 'number_emergency',\n",
       "       'number_inpatient', 'number_diagnoses', 'metformin', 'glimepiride',\n",
       "       'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin',\n",
       "       'readmitted', 'race_AfricanAmerican', 'race_Asian', 'race_Caucasian',\n",
       "       'race_Hispanic', 'race_Other', 'gender_Female', 'gender_Male',\n",
       "       'gender_Unknown/Invalid', 'age_[0-10)', 'age_[10-20)', 'age_[20-30)',\n",
       "       'age_[30-40)', 'age_[40-50)', 'age_[50-60)', 'age_[60-70)',\n",
       "       'age_[70-80)', 'age_[80-90)', 'age_[90-100)',\n",
       "       'diag_1_Diabetes mellitus', 'diag_1_Diseases of the circulatory system',\n",
       "       'diag_1_Diseases of the digestive system',\n",
       "       'diag_1_Diseases of the genitourinary system',\n",
       "       'diag_1_Diseases of the musculoskeletal system and connective tissue',\n",
       "       'diag_1_Diseases of the respiratory system',\n",
       "       'diag_1_Injury and poisoning', 'diag_1_Neoplasms', 'diag_1_Other',\n",
       "       'diag_2_Diabetes mellitus', 'diag_2_Diseases of the circulatory system',\n",
       "       'diag_2_Diseases of the digestive system',\n",
       "       'diag_2_Diseases of the genitourinary system',\n",
       "       'diag_2_Diseases of the musculoskeletal system and connective tissue',\n",
       "       'diag_2_Diseases of the respiratory system',\n",
       "       'diag_2_Injury and poisoning', 'diag_2_Neoplasms', 'diag_2_Other',\n",
       "       'diag_3_Diabetes mellitus', 'diag_3_Diseases of the circulatory system',\n",
       "       'diag_3_Diseases of the digestive system',\n",
       "       'diag_3_Diseases of the genitourinary system',\n",
       "       'diag_3_Diseases of the musculoskeletal system and connective tissue',\n",
       "       'diag_3_Diseases of the respiratory system',\n",
       "       'diag_3_Injury and poisoning', 'diag_3_Neoplasms', 'diag_3_Other',\n",
       "       'max_glu_serum_>200', 'max_glu_serum_>300', 'max_glu_serum_Norm',\n",
       "       'max_glu_serum_Not taken', 'A1Cresult_>7', 'A1Cresult_>8',\n",
       "       'A1Cresult_Norm', 'A1Cresult_Not taken', 'change_Ch', 'change_No',\n",
       "       'diabetesMed_No', 'diabetesMed_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las features y la variable target\n",
    "X = df_encoded.drop('readmitted', axis=1)  # Features\n",
    "y = df_encoded['readmitted']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa los datos de entrenamiento y evaulacion\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57214, 75)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_neurons=5,input_shape=(X_train.shape[1],)):\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(keras.layers.Dense(n_neurons, activation='relu', input_shape=input_shape))\n",
    "  model.add(keras.layers.Dense(n_neurons, activation='relu' ))\n",
    "  model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guille\\AppData\\Local\\Temp\\ipykernel_22728\\1618677641.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_cs = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, epochs=100, validation_split=0.2)\n"
     ]
    }
   ],
   "source": [
    "# Crea un clasificador de Keras que es compatible con scikit-learn\n",
    "keras_cs = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un pipeline en scikit-learn. Un pipeline es una secuencia de transformaciones y un estimador final. \n",
    "model =  Pipeline([\n",
    "                   ('scale', StandardScaler()), ('ann', keras_cs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1431/1431 [==============================] - 2s 1ms/step - loss: 0.6770 - accuracy: 0.5933 - val_loss: 0.6699 - val_accuracy: 0.6019\n",
      "Epoch 2/100\n",
      "1431/1431 [==============================] - 1s 908us/step - loss: 0.6683 - accuracy: 0.5979 - val_loss: 0.6656 - val_accuracy: 0.6019\n",
      "Epoch 3/100\n",
      "1431/1431 [==============================] - 1s 934us/step - loss: 0.6648 - accuracy: 0.5980 - val_loss: 0.6623 - val_accuracy: 0.6020\n",
      "Epoch 4/100\n",
      "1431/1431 [==============================] - 1s 885us/step - loss: 0.6619 - accuracy: 0.6014 - val_loss: 0.6595 - val_accuracy: 0.6089\n",
      "Epoch 5/100\n",
      "1431/1431 [==============================] - 1s 883us/step - loss: 0.6592 - accuracy: 0.6070 - val_loss: 0.6569 - val_accuracy: 0.6108\n",
      "Epoch 6/100\n",
      "1431/1431 [==============================] - 1s 903us/step - loss: 0.6568 - accuracy: 0.6109 - val_loss: 0.6551 - val_accuracy: 0.6129\n",
      "Epoch 7/100\n",
      "1431/1431 [==============================] - 1s 890us/step - loss: 0.6545 - accuracy: 0.6137 - val_loss: 0.6529 - val_accuracy: 0.6169\n",
      "Epoch 8/100\n",
      "1431/1431 [==============================] - 1s 887us/step - loss: 0.6525 - accuracy: 0.6165 - val_loss: 0.6511 - val_accuracy: 0.6198\n",
      "Epoch 9/100\n",
      "1431/1431 [==============================] - 1s 919us/step - loss: 0.6507 - accuracy: 0.6186 - val_loss: 0.6498 - val_accuracy: 0.6214\n",
      "Epoch 10/100\n",
      "1431/1431 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.6211 - val_loss: 0.6491 - val_accuracy: 0.6229\n",
      "Epoch 11/100\n",
      "1431/1431 [==============================] - 1s 1ms/step - loss: 0.6481 - accuracy: 0.6226 - val_loss: 0.6480 - val_accuracy: 0.6231\n",
      "Epoch 12/100\n",
      "1431/1431 [==============================] - 1s 974us/step - loss: 0.6473 - accuracy: 0.6246 - val_loss: 0.6474 - val_accuracy: 0.6247\n",
      "Epoch 13/100\n",
      "1431/1431 [==============================] - 1s 929us/step - loss: 0.6465 - accuracy: 0.6250 - val_loss: 0.6469 - val_accuracy: 0.6253\n",
      "Epoch 14/100\n",
      "1431/1431 [==============================] - 1s 909us/step - loss: 0.6459 - accuracy: 0.6256 - val_loss: 0.6466 - val_accuracy: 0.6247\n",
      "Epoch 15/100\n",
      "1431/1431 [==============================] - 1s 957us/step - loss: 0.6453 - accuracy: 0.6262 - val_loss: 0.6465 - val_accuracy: 0.6254\n",
      "Epoch 16/100\n",
      "1431/1431 [==============================] - 1s 898us/step - loss: 0.6450 - accuracy: 0.6275 - val_loss: 0.6459 - val_accuracy: 0.6234\n",
      "Epoch 17/100\n",
      "1431/1431 [==============================] - 1s 911us/step - loss: 0.6446 - accuracy: 0.6268 - val_loss: 0.6455 - val_accuracy: 0.6239\n",
      "Epoch 18/100\n",
      "1431/1431 [==============================] - 1s 896us/step - loss: 0.6443 - accuracy: 0.6289 - val_loss: 0.6454 - val_accuracy: 0.6254\n",
      "Epoch 19/100\n",
      "1431/1431 [==============================] - 1s 904us/step - loss: 0.6440 - accuracy: 0.6286 - val_loss: 0.6453 - val_accuracy: 0.6247\n",
      "Epoch 20/100\n",
      "1431/1431 [==============================] - 1s 886us/step - loss: 0.6437 - accuracy: 0.6284 - val_loss: 0.6450 - val_accuracy: 0.6239\n",
      "Epoch 21/100\n",
      "1431/1431 [==============================] - 1s 964us/step - loss: 0.6435 - accuracy: 0.6292 - val_loss: 0.6450 - val_accuracy: 0.6253\n",
      "Epoch 22/100\n",
      "1431/1431 [==============================] - 1s 895us/step - loss: 0.6433 - accuracy: 0.6295 - val_loss: 0.6447 - val_accuracy: 0.6251\n",
      "Epoch 23/100\n",
      "1431/1431 [==============================] - 1s 915us/step - loss: 0.6430 - accuracy: 0.6303 - val_loss: 0.6446 - val_accuracy: 0.6246\n",
      "Epoch 24/100\n",
      "1431/1431 [==============================] - 1s 911us/step - loss: 0.6429 - accuracy: 0.6297 - val_loss: 0.6446 - val_accuracy: 0.6248\n",
      "Epoch 25/100\n",
      "1431/1431 [==============================] - 1s 909us/step - loss: 0.6426 - accuracy: 0.6299 - val_loss: 0.6445 - val_accuracy: 0.6257\n",
      "Epoch 26/100\n",
      "1431/1431 [==============================] - 1s 893us/step - loss: 0.6425 - accuracy: 0.6299 - val_loss: 0.6445 - val_accuracy: 0.6253\n",
      "Epoch 27/100\n",
      "1431/1431 [==============================] - 1s 997us/step - loss: 0.6423 - accuracy: 0.6309 - val_loss: 0.6444 - val_accuracy: 0.6243\n",
      "Epoch 28/100\n",
      "1431/1431 [==============================] - 1s 944us/step - loss: 0.6421 - accuracy: 0.6306 - val_loss: 0.6444 - val_accuracy: 0.6247\n",
      "Epoch 29/100\n",
      "1431/1431 [==============================] - 1s 908us/step - loss: 0.6420 - accuracy: 0.6309 - val_loss: 0.6442 - val_accuracy: 0.6254\n",
      "Epoch 30/100\n",
      "1431/1431 [==============================] - 1s 895us/step - loss: 0.6418 - accuracy: 0.6320 - val_loss: 0.6440 - val_accuracy: 0.6261\n",
      "Epoch 31/100\n",
      "1431/1431 [==============================] - 1s 886us/step - loss: 0.6417 - accuracy: 0.6313 - val_loss: 0.6440 - val_accuracy: 0.6264\n",
      "Epoch 32/100\n",
      "1431/1431 [==============================] - 1s 886us/step - loss: 0.6416 - accuracy: 0.6314 - val_loss: 0.6439 - val_accuracy: 0.6269\n",
      "Epoch 33/100\n",
      "1431/1431 [==============================] - 1s 908us/step - loss: 0.6415 - accuracy: 0.6315 - val_loss: 0.6437 - val_accuracy: 0.6261\n",
      "Epoch 34/100\n",
      "1431/1431 [==============================] - 1s 914us/step - loss: 0.6413 - accuracy: 0.6316 - val_loss: 0.6437 - val_accuracy: 0.6258\n",
      "Epoch 35/100\n",
      "1431/1431 [==============================] - 1s 1ms/step - loss: 0.6412 - accuracy: 0.6317 - val_loss: 0.6437 - val_accuracy: 0.6261\n",
      "Epoch 36/100\n",
      "1431/1431 [==============================] - 1s 922us/step - loss: 0.6411 - accuracy: 0.6321 - val_loss: 0.6436 - val_accuracy: 0.6273\n",
      "Epoch 37/100\n",
      "1431/1431 [==============================] - 1s 952us/step - loss: 0.6410 - accuracy: 0.6334 - val_loss: 0.6437 - val_accuracy: 0.6275\n",
      "Epoch 38/100\n",
      "1431/1431 [==============================] - 1s 904us/step - loss: 0.6408 - accuracy: 0.6335 - val_loss: 0.6435 - val_accuracy: 0.6279\n",
      "Epoch 39/100\n",
      "1431/1431 [==============================] - 1s 957us/step - loss: 0.6407 - accuracy: 0.6333 - val_loss: 0.6434 - val_accuracy: 0.6270\n",
      "Epoch 40/100\n",
      "1431/1431 [==============================] - 1s 915us/step - loss: 0.6406 - accuracy: 0.6331 - val_loss: 0.6435 - val_accuracy: 0.6271\n",
      "Epoch 41/100\n",
      "1431/1431 [==============================] - 1s 907us/step - loss: 0.6404 - accuracy: 0.6342 - val_loss: 0.6435 - val_accuracy: 0.6266\n",
      "Epoch 42/100\n",
      "1431/1431 [==============================] - 1s 898us/step - loss: 0.6402 - accuracy: 0.6340 - val_loss: 0.6435 - val_accuracy: 0.6272\n",
      "Epoch 43/100\n",
      "1431/1431 [==============================] - 1s 905us/step - loss: 0.6402 - accuracy: 0.6342 - val_loss: 0.6434 - val_accuracy: 0.6271\n",
      "Epoch 44/100\n",
      "1431/1431 [==============================] - 1s 895us/step - loss: 0.6401 - accuracy: 0.6343 - val_loss: 0.6433 - val_accuracy: 0.6269\n",
      "Epoch 45/100\n",
      "1431/1431 [==============================] - 1s 965us/step - loss: 0.6400 - accuracy: 0.6348 - val_loss: 0.6438 - val_accuracy: 0.6260\n",
      "Epoch 46/100\n",
      "1431/1431 [==============================] - 1s 899us/step - loss: 0.6399 - accuracy: 0.6347 - val_loss: 0.6434 - val_accuracy: 0.6277\n",
      "Epoch 47/100\n",
      "1431/1431 [==============================] - 1s 909us/step - loss: 0.6398 - accuracy: 0.6349 - val_loss: 0.6433 - val_accuracy: 0.6266\n",
      "Epoch 48/100\n",
      "1431/1431 [==============================] - 1s 917us/step - loss: 0.6397 - accuracy: 0.6354 - val_loss: 0.6431 - val_accuracy: 0.6263\n",
      "Epoch 49/100\n",
      "1431/1431 [==============================] - 1s 887us/step - loss: 0.6396 - accuracy: 0.6359 - val_loss: 0.6432 - val_accuracy: 0.6273\n",
      "Epoch 50/100\n",
      "1431/1431 [==============================] - 1s 887us/step - loss: 0.6396 - accuracy: 0.6356 - val_loss: 0.6430 - val_accuracy: 0.6261\n",
      "Epoch 51/100\n",
      "1431/1431 [==============================] - 1s 961us/step - loss: 0.6395 - accuracy: 0.6356 - val_loss: 0.6431 - val_accuracy: 0.6268\n",
      "Epoch 52/100\n",
      "1431/1431 [==============================] - 1s 918us/step - loss: 0.6394 - accuracy: 0.6363 - val_loss: 0.6430 - val_accuracy: 0.6269\n",
      "Epoch 53/100\n",
      "1431/1431 [==============================] - 1s 907us/step - loss: 0.6394 - accuracy: 0.6357 - val_loss: 0.6430 - val_accuracy: 0.6282\n",
      "Epoch 54/100\n",
      "1431/1431 [==============================] - 1s 900us/step - loss: 0.6393 - accuracy: 0.6365 - val_loss: 0.6429 - val_accuracy: 0.6264\n",
      "Epoch 55/100\n",
      "1431/1431 [==============================] - 1s 907us/step - loss: 0.6392 - accuracy: 0.6365 - val_loss: 0.6429 - val_accuracy: 0.6270\n",
      "Epoch 56/100\n",
      "1431/1431 [==============================] - 1s 914us/step - loss: 0.6392 - accuracy: 0.6363 - val_loss: 0.6431 - val_accuracy: 0.6261\n",
      "Epoch 57/100\n",
      "1431/1431 [==============================] - 1s 955us/step - loss: 0.6390 - accuracy: 0.6367 - val_loss: 0.6428 - val_accuracy: 0.6282\n",
      "Epoch 58/100\n",
      "1431/1431 [==============================] - 1s 906us/step - loss: 0.6390 - accuracy: 0.6366 - val_loss: 0.6430 - val_accuracy: 0.6263\n",
      "Epoch 59/100\n",
      "1431/1431 [==============================] - 1s 906us/step - loss: 0.6390 - accuracy: 0.6371 - val_loss: 0.6429 - val_accuracy: 0.6262\n",
      "Epoch 60/100\n",
      "1431/1431 [==============================] - 1s 936us/step - loss: 0.6389 - accuracy: 0.6372 - val_loss: 0.6429 - val_accuracy: 0.6261\n",
      "Epoch 61/100\n",
      "1431/1431 [==============================] - 1s 907us/step - loss: 0.6389 - accuracy: 0.6372 - val_loss: 0.6428 - val_accuracy: 0.6263\n",
      "Epoch 62/100\n",
      "1431/1431 [==============================] - 1s 911us/step - loss: 0.6388 - accuracy: 0.6374 - val_loss: 0.6428 - val_accuracy: 0.6277\n",
      "Epoch 63/100\n",
      "1431/1431 [==============================] - 1s 961us/step - loss: 0.6387 - accuracy: 0.6377 - val_loss: 0.6428 - val_accuracy: 0.6261\n",
      "Epoch 64/100\n",
      "1431/1431 [==============================] - 1s 908us/step - loss: 0.6386 - accuracy: 0.6374 - val_loss: 0.6427 - val_accuracy: 0.6258\n",
      "Epoch 65/100\n",
      "1431/1431 [==============================] - 1s 901us/step - loss: 0.6385 - accuracy: 0.6382 - val_loss: 0.6427 - val_accuracy: 0.6278\n",
      "Epoch 66/100\n",
      "1431/1431 [==============================] - 1s 998us/step - loss: 0.6385 - accuracy: 0.6378 - val_loss: 0.6426 - val_accuracy: 0.6277\n",
      "Epoch 67/100\n",
      "1431/1431 [==============================] - 1s 901us/step - loss: 0.6383 - accuracy: 0.6380 - val_loss: 0.6430 - val_accuracy: 0.6275\n",
      "Epoch 68/100\n",
      "1431/1431 [==============================] - 1s 980us/step - loss: 0.6383 - accuracy: 0.6383 - val_loss: 0.6428 - val_accuracy: 0.6260\n",
      "Epoch 69/100\n",
      "1431/1431 [==============================] - 1s 909us/step - loss: 0.6383 - accuracy: 0.6379 - val_loss: 0.6428 - val_accuracy: 0.6272\n",
      "Epoch 70/100\n",
      "1431/1431 [==============================] - 1s 912us/step - loss: 0.6382 - accuracy: 0.6381 - val_loss: 0.6428 - val_accuracy: 0.6253\n",
      "Epoch 71/100\n",
      "1431/1431 [==============================] - 1s 928us/step - loss: 0.6381 - accuracy: 0.6376 - val_loss: 0.6431 - val_accuracy: 0.6256\n",
      "Epoch 72/100\n",
      "1431/1431 [==============================] - 1s 1ms/step - loss: 0.6381 - accuracy: 0.6380 - val_loss: 0.6429 - val_accuracy: 0.6292\n",
      "Epoch 73/100\n",
      "1431/1431 [==============================] - 1s 892us/step - loss: 0.6380 - accuracy: 0.6373 - val_loss: 0.6428 - val_accuracy: 0.6258\n",
      "Epoch 74/100\n",
      "1431/1431 [==============================] - 1s 882us/step - loss: 0.6379 - accuracy: 0.6385 - val_loss: 0.6428 - val_accuracy: 0.6258\n",
      "Epoch 75/100\n",
      "1431/1431 [==============================] - 1s 890us/step - loss: 0.6379 - accuracy: 0.6382 - val_loss: 0.6429 - val_accuracy: 0.6247\n",
      "Epoch 76/100\n",
      "1431/1431 [==============================] - 1s 904us/step - loss: 0.6378 - accuracy: 0.6382 - val_loss: 0.6428 - val_accuracy: 0.6275\n",
      "Epoch 77/100\n",
      "1431/1431 [==============================] - 1s 947us/step - loss: 0.6378 - accuracy: 0.6374 - val_loss: 0.6429 - val_accuracy: 0.6268\n",
      "Epoch 78/100\n",
      "1431/1431 [==============================] - 1s 896us/step - loss: 0.6377 - accuracy: 0.6380 - val_loss: 0.6429 - val_accuracy: 0.6261\n",
      "Epoch 79/100\n",
      "1431/1431 [==============================] - 1s 916us/step - loss: 0.6377 - accuracy: 0.6381 - val_loss: 0.6430 - val_accuracy: 0.6251\n",
      "Epoch 80/100\n",
      "1431/1431 [==============================] - 1s 907us/step - loss: 0.6376 - accuracy: 0.6375 - val_loss: 0.6430 - val_accuracy: 0.6254\n",
      "Epoch 81/100\n",
      "1431/1431 [==============================] - 1s 951us/step - loss: 0.6376 - accuracy: 0.6377 - val_loss: 0.6430 - val_accuracy: 0.6247\n",
      "Epoch 82/100\n",
      "1431/1431 [==============================] - 1s 888us/step - loss: 0.6376 - accuracy: 0.6374 - val_loss: 0.6429 - val_accuracy: 0.6241\n",
      "Epoch 83/100\n",
      "1431/1431 [==============================] - 1s 902us/step - loss: 0.6375 - accuracy: 0.6381 - val_loss: 0.6430 - val_accuracy: 0.6260\n",
      "Epoch 84/100\n",
      "1431/1431 [==============================] - 1s 902us/step - loss: 0.6374 - accuracy: 0.6382 - val_loss: 0.6428 - val_accuracy: 0.6263\n",
      "Epoch 85/100\n",
      "1431/1431 [==============================] - 1s 952us/step - loss: 0.6374 - accuracy: 0.6376 - val_loss: 0.6430 - val_accuracy: 0.6262\n",
      "Epoch 86/100\n",
      "1431/1431 [==============================] - 1s 903us/step - loss: 0.6374 - accuracy: 0.6376 - val_loss: 0.6429 - val_accuracy: 0.6252\n",
      "Epoch 87/100\n",
      "1431/1431 [==============================] - 1s 918us/step - loss: 0.6374 - accuracy: 0.6371 - val_loss: 0.6429 - val_accuracy: 0.6259\n",
      "Epoch 88/100\n",
      "1431/1431 [==============================] - 1s 977us/step - loss: 0.6373 - accuracy: 0.6370 - val_loss: 0.6430 - val_accuracy: 0.6257\n",
      "Epoch 89/100\n",
      "1431/1431 [==============================] - 1s 921us/step - loss: 0.6373 - accuracy: 0.6382 - val_loss: 0.6430 - val_accuracy: 0.6261\n",
      "Epoch 90/100\n",
      "1431/1431 [==============================] - 1s 898us/step - loss: 0.6373 - accuracy: 0.6378 - val_loss: 0.6430 - val_accuracy: 0.6261\n",
      "Epoch 91/100\n",
      "1431/1431 [==============================] - 1s 909us/step - loss: 0.6372 - accuracy: 0.6378 - val_loss: 0.6432 - val_accuracy: 0.6259\n",
      "Epoch 92/100\n",
      "1431/1431 [==============================] - 1s 909us/step - loss: 0.6372 - accuracy: 0.6374 - val_loss: 0.6431 - val_accuracy: 0.6259\n",
      "Epoch 93/100\n",
      "1431/1431 [==============================] - 1s 975us/step - loss: 0.6372 - accuracy: 0.6375 - val_loss: 0.6432 - val_accuracy: 0.6249\n",
      "Epoch 94/100\n",
      "1431/1431 [==============================] - 1s 894us/step - loss: 0.6371 - accuracy: 0.6377 - val_loss: 0.6431 - val_accuracy: 0.6263\n",
      "Epoch 95/100\n",
      "1431/1431 [==============================] - 1s 969us/step - loss: 0.6372 - accuracy: 0.6377 - val_loss: 0.6430 - val_accuracy: 0.6256\n",
      "Epoch 96/100\n",
      "1431/1431 [==============================] - 1s 912us/step - loss: 0.6371 - accuracy: 0.6373 - val_loss: 0.6431 - val_accuracy: 0.6260\n",
      "Epoch 97/100\n",
      "1431/1431 [==============================] - 1s 894us/step - loss: 0.6370 - accuracy: 0.6369 - val_loss: 0.6433 - val_accuracy: 0.6252\n",
      "Epoch 98/100\n",
      "1431/1431 [==============================] - 1s 903us/step - loss: 0.6370 - accuracy: 0.6388 - val_loss: 0.6431 - val_accuracy: 0.6261\n",
      "Epoch 99/100\n",
      "1431/1431 [==============================] - 1s 947us/step - loss: 0.6370 - accuracy: 0.6377 - val_loss: 0.6432 - val_accuracy: 0.6265\n",
      "Epoch 100/100\n",
      "1431/1431 [==============================] - 1s 890us/step - loss: 0.6370 - accuracy: 0.6377 - val_loss: 0.6432 - val_accuracy: 0.6260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;ann&#x27;,\n",
       "                 &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB4BA94610&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;ann&#x27;,\n",
       "                 &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB4BA94610&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB4BA94610&gt;</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('ann',\n",
       "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB4BA94610>)])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicia el entrenamiento del modelo de keras\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447/447 [==============================] - 0s 545us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6516    0.8603    0.7416      8732\n",
      "           1     0.5605    0.2793    0.3728      5572\n",
      "\n",
      "    accuracy                         0.6339     14304\n",
      "   macro avg     0.6061    0.5698    0.5572     14304\n",
      "weighted avg     0.6161    0.6339    0.5979     14304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predice según los datos de testeo e imprime los resultados con cuatro decimales\n",
    "y_fit = model.predict(X_test)\n",
    "print(classification_report(y_test, y_fit, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpia el modelo anteior para liberar espacio en memoria\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se procedera a buscar los mejores hiperparametros para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=5, input_shape=(X_train.shape[1],), num_classes=2):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(n_neurons, activation='relu', input_shape=input_shape))\n",
    "\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "\n",
    "    # Capa de salida adaptada para el número de clases\n",
    "    if num_classes == 2:\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid'))  # Clasificación binaria\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        model.add(keras.layers.Dense(num_classes, activation='softmax'))  # Clasificación multiclase\n",
    "        loss = 'categorical_crossentropy'\n",
    "\n",
    "    model.compile(optimizer='sgd', loss=loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guille\\AppData\\Local\\Temp\\ipykernel_22728\\854310640.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_cs = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, epochs=50, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "keras_cs = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Pipeline([\n",
    "                   ('scale', StandardScaler()), ('ann', keras_cs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con los hiperparametros a testear\n",
    "params = {\n",
    "    'ann__n_hidden':[0,1,2,3,4,5],\n",
    "    'ann__n_neurons':np.arange(0,30),\n",
    "    'ann__batch_size':[10,15,20,25,30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search = RandomizedSearchCV(model, params, n_iter=10, cv=3, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "grid_result = rnd_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ann__n_neurons': 25, 'ann__n_hidden': 0, 'ann__batch_size': 30}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params = {\n",
    "    'batch_size':grid_result.best_params_['ann__batch_size'],\n",
    "    'n_hidden': grid_result.best_params_['ann__n_hidden'],\n",
    "    'n_neurons':grid_result.best_params_['ann__n_neurons']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 30, 'n_hidden': 0, 'n_neurons': 25}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guille\\AppData\\Local\\Temp\\ipykernel_22728\\2354317905.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_cs = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, epochs=20, verbose=1, **sk_params )\n"
     ]
    }
   ],
   "source": [
    "keras_cs = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, epochs=20, verbose=1, **sk_params )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Pipeline([\n",
    "                   ('scale', StandardScaler()), ('ann', keras_cs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908/1908 [==============================] - 2s 699us/step - loss: 0.6716 - accuracy: 0.6009\n",
      "Epoch 2/20\n",
      "1908/1908 [==============================] - 1s 727us/step - loss: 0.6519 - accuracy: 0.6220\n",
      "Epoch 3/20\n",
      "1908/1908 [==============================] - 1s 735us/step - loss: 0.6488 - accuracy: 0.6238\n",
      "Epoch 4/20\n",
      "1908/1908 [==============================] - 1s 725us/step - loss: 0.6471 - accuracy: 0.6263\n",
      "Epoch 5/20\n",
      "1908/1908 [==============================] - 1s 756us/step - loss: 0.6457 - accuracy: 0.6276\n",
      "Epoch 6/20\n",
      "1908/1908 [==============================] - 1s 721us/step - loss: 0.6446 - accuracy: 0.6282\n",
      "Epoch 7/20\n",
      "1908/1908 [==============================] - 1s 711us/step - loss: 0.6436 - accuracy: 0.6293\n",
      "Epoch 8/20\n",
      "1908/1908 [==============================] - 1s 722us/step - loss: 0.6429 - accuracy: 0.6296\n",
      "Epoch 9/20\n",
      "1908/1908 [==============================] - 1s 708us/step - loss: 0.6422 - accuracy: 0.6306\n",
      "Epoch 10/20\n",
      "1908/1908 [==============================] - 1s 727us/step - loss: 0.6415 - accuracy: 0.6310\n",
      "Epoch 11/20\n",
      "1908/1908 [==============================] - 1s 771us/step - loss: 0.6409 - accuracy: 0.6321\n",
      "Epoch 12/20\n",
      "1908/1908 [==============================] - 1s 734us/step - loss: 0.6404 - accuracy: 0.6324\n",
      "Epoch 13/20\n",
      "1908/1908 [==============================] - 1s 728us/step - loss: 0.6398 - accuracy: 0.6337\n",
      "Epoch 14/20\n",
      "1908/1908 [==============================] - 1s 725us/step - loss: 0.6393 - accuracy: 0.6331\n",
      "Epoch 15/20\n",
      "1908/1908 [==============================] - 1s 711us/step - loss: 0.6388 - accuracy: 0.6342\n",
      "Epoch 16/20\n",
      "1908/1908 [==============================] - 1s 763us/step - loss: 0.6383 - accuracy: 0.6349\n",
      "Epoch 17/20\n",
      "1908/1908 [==============================] - 1s 732us/step - loss: 0.6379 - accuracy: 0.6348\n",
      "Epoch 18/20\n",
      "1908/1908 [==============================] - 1s 710us/step - loss: 0.6374 - accuracy: 0.6356\n",
      "Epoch 19/20\n",
      "1908/1908 [==============================] - 1s 711us/step - loss: 0.6370 - accuracy: 0.6359\n",
      "Epoch 20/20\n",
      "1908/1908 [==============================] - 1s 745us/step - loss: 0.6365 - accuracy: 0.6367\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;ann&#x27;,\n",
       "                 &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB37CE5190&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;ann&#x27;,\n",
       "                 &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB37CE5190&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB37CE5190&gt;</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('ann',\n",
       "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DB37CE5190>)])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447/447 [==============================] - 0s 540us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6517    0.8559    0.7400      8732\n",
      "           1     0.5563    0.2830    0.3752      5572\n",
      "\n",
      "    accuracy                         0.6328     14304\n",
      "   macro avg     0.6040    0.5695    0.5576     14304\n",
      "weighted avg     0.6145    0.6328    0.5979     14304\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_fit = model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = confusion_matrix(y_test, y_fit)\n",
    "sns.heatmap(conf_matrix, annot=True)  # Utiliza fmt=\".4f\" para imprimir números con 4 decimales\n",
    "b, t = plt.ylim() \n",
    "b += 0.5 \n",
    "t -= 0.5 \n",
    "plt.ylim(b, t)\n",
    "\n",
    "# Imprimir el informe de clasificación con números con 4 decimales\n",
    "print(classification_report(y_test, y_fit, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guille\\AppData\\Local\\Temp\\ipykernel_3624\\3020703118.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['readmitted'] = df['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('diabetic_data_modified.csv')\n",
    "df = df.drop(columns=[\"Unnamed: 0\",\"patient_nbr\",], axis=1)\n",
    "df['readmitted'] = df['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "encoded_columns = pd.get_dummies(df[categorical_columns])\n",
    "encoded_columns = encoded_columns.astype(int)\n",
    "df_encoded = pd.concat([df.drop(columns=categorical_columns), encoded_columns], axis=1)\n",
    "X = df_encoded.drop('readmitted', axis=1)  # Features\n",
    "y = df_encoded['readmitted']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar tus datos\n",
    "X = df_encoded.drop('readmitted', axis=1).values.astype(np.float32)  # Obtener características como matriz numpy\n",
    "y = df_encoded['readmitted'].values.astype(np.float32)       # Obtener etiquetas como matriz numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos en conjuntos de entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).cuda()\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).cuda()\n",
    "\n",
    "# Convertir y_test a un array de NumPy y luego a tensor de PyTorch\n",
    "y_test_np = y_test.astype(int)  # Convertir a tipo int si no lo está\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.long).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).cuda()\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).cuda()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).cuda()\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(df['readmitted'].unique())\n",
    "model = Classifier(input_dim, output_dim).cuda()\n",
    "\n",
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Loss: 0.6963462829589844\n",
      "Epoch [2/10000], Loss: 0.6907228231430054\n",
      "Epoch [3/10000], Loss: 0.6856984496116638\n",
      "Epoch [4/10000], Loss: 0.6812710762023926\n",
      "Epoch [5/10000], Loss: 0.6774320602416992\n",
      "Epoch [6/10000], Loss: 0.6741604208946228\n",
      "Epoch [7/10000], Loss: 0.671421229839325\n",
      "Epoch [8/10000], Loss: 0.6691665053367615\n",
      "Epoch [9/10000], Loss: 0.6673378944396973\n",
      "Epoch [10/10000], Loss: 0.6658646464347839\n",
      "Epoch [11/10000], Loss: 0.6646707653999329\n",
      "Epoch [12/10000], Loss: 0.6636832356452942\n",
      "Epoch [13/10000], Loss: 0.6628350615501404\n",
      "Epoch [14/10000], Loss: 0.6620675921440125\n",
      "Epoch [15/10000], Loss: 0.6613359451293945\n",
      "Epoch [16/10000], Loss: 0.6606107950210571\n",
      "Epoch [17/10000], Loss: 0.6598747968673706\n",
      "Epoch [18/10000], Loss: 0.6591213941574097\n",
      "Epoch [19/10000], Loss: 0.6583519577980042\n",
      "Epoch [20/10000], Loss: 0.6575747132301331\n",
      "Epoch [21/10000], Loss: 0.6567985415458679\n",
      "Epoch [22/10000], Loss: 0.6560366153717041\n",
      "Epoch [23/10000], Loss: 0.6552981734275818\n",
      "Epoch [24/10000], Loss: 0.6545913815498352\n",
      "Epoch [25/10000], Loss: 0.6539217829704285\n",
      "Epoch [26/10000], Loss: 0.6532899141311646\n",
      "Epoch [27/10000], Loss: 0.6526976823806763\n",
      "Epoch [28/10000], Loss: 0.6521420478820801\n",
      "Epoch [29/10000], Loss: 0.6516172289848328\n",
      "Epoch [30/10000], Loss: 0.6511173248291016\n",
      "Epoch [31/10000], Loss: 0.6506357192993164\n",
      "Epoch [32/10000], Loss: 0.6501656174659729\n",
      "Epoch [33/10000], Loss: 0.6497035026550293\n",
      "Epoch [34/10000], Loss: 0.6492474675178528\n",
      "Epoch [35/10000], Loss: 0.6487962007522583\n",
      "Epoch [36/10000], Loss: 0.6483507752418518\n",
      "Epoch [37/10000], Loss: 0.6479102969169617\n",
      "Epoch [38/10000], Loss: 0.6474776864051819\n",
      "Epoch [39/10000], Loss: 0.6470532417297363\n",
      "Epoch [40/10000], Loss: 0.6466398239135742\n",
      "Epoch [41/10000], Loss: 0.6462386846542358\n",
      "Epoch [42/10000], Loss: 0.645850419998169\n",
      "Epoch [43/10000], Loss: 0.6454746127128601\n",
      "Epoch [44/10000], Loss: 0.6451115012168884\n",
      "Epoch [45/10000], Loss: 0.6447584629058838\n",
      "Epoch [46/10000], Loss: 0.6444143652915955\n",
      "Epoch [47/10000], Loss: 0.6440780162811279\n",
      "Epoch [48/10000], Loss: 0.643748939037323\n",
      "Epoch [49/10000], Loss: 0.6434255242347717\n",
      "Epoch [50/10000], Loss: 0.6431075930595398\n",
      "Epoch [51/10000], Loss: 0.6427939534187317\n",
      "Epoch [52/10000], Loss: 0.6424856781959534\n",
      "Epoch [53/10000], Loss: 0.6421828269958496\n",
      "Epoch [54/10000], Loss: 0.6418853402137756\n",
      "Epoch [55/10000], Loss: 0.641593873500824\n",
      "Epoch [56/10000], Loss: 0.6413082480430603\n",
      "Epoch [57/10000], Loss: 0.6410271525382996\n",
      "Epoch [58/10000], Loss: 0.640750527381897\n",
      "Epoch [59/10000], Loss: 0.6404792070388794\n",
      "Epoch [60/10000], Loss: 0.6402131915092468\n",
      "Epoch [61/10000], Loss: 0.6399526596069336\n",
      "Epoch [62/10000], Loss: 0.6396960616111755\n",
      "Epoch [63/10000], Loss: 0.6394430994987488\n",
      "Epoch [64/10000], Loss: 0.639194130897522\n",
      "Epoch [65/10000], Loss: 0.6389486193656921\n",
      "Epoch [66/10000], Loss: 0.638706624507904\n",
      "Epoch [67/10000], Loss: 0.6384680867195129\n",
      "Epoch [68/10000], Loss: 0.6382335424423218\n",
      "Epoch [69/10000], Loss: 0.6380025744438171\n",
      "Epoch [70/10000], Loss: 0.6377745866775513\n",
      "Epoch [71/10000], Loss: 0.637549638748169\n",
      "Epoch [72/10000], Loss: 0.6373279690742493\n",
      "Epoch [73/10000], Loss: 0.6371092796325684\n",
      "Epoch [74/10000], Loss: 0.636893093585968\n",
      "Epoch [75/10000], Loss: 0.636680543422699\n",
      "Epoch [76/10000], Loss: 0.6364709734916687\n",
      "Epoch [77/10000], Loss: 0.636263370513916\n",
      "Epoch [78/10000], Loss: 0.6360573172569275\n",
      "Epoch [79/10000], Loss: 0.635853111743927\n",
      "Epoch [80/10000], Loss: 0.6356508135795593\n",
      "Epoch [81/10000], Loss: 0.6354510188102722\n",
      "Epoch [82/10000], Loss: 0.6352537274360657\n",
      "Epoch [83/10000], Loss: 0.635058581829071\n",
      "Epoch [84/10000], Loss: 0.6348651051521301\n",
      "Epoch [85/10000], Loss: 0.6346737742424011\n",
      "Epoch [86/10000], Loss: 0.6344842910766602\n",
      "Epoch [87/10000], Loss: 0.6342958211898804\n",
      "Epoch [88/10000], Loss: 0.6341089010238647\n",
      "Epoch [89/10000], Loss: 0.6339232325553894\n",
      "Epoch [90/10000], Loss: 0.6337387561798096\n",
      "Epoch [91/10000], Loss: 0.6335551738739014\n",
      "Epoch [92/10000], Loss: 0.6333730816841125\n",
      "Epoch [93/10000], Loss: 0.6331919431686401\n",
      "Epoch [94/10000], Loss: 0.6330121159553528\n",
      "Epoch [95/10000], Loss: 0.6328336596488953\n",
      "Epoch [96/10000], Loss: 0.6326556205749512\n",
      "Epoch [97/10000], Loss: 0.6324775218963623\n",
      "Epoch [98/10000], Loss: 0.6323001980781555\n",
      "Epoch [99/10000], Loss: 0.6321243047714233\n",
      "Epoch [100/10000], Loss: 0.6319484710693359\n",
      "Epoch [101/10000], Loss: 0.6317727565765381\n",
      "Epoch [102/10000], Loss: 0.6315973401069641\n",
      "Epoch [103/10000], Loss: 0.6314226388931274\n",
      "Epoch [104/10000], Loss: 0.6312480568885803\n",
      "Epoch [105/10000], Loss: 0.6310744881629944\n",
      "Epoch [106/10000], Loss: 0.630901575088501\n",
      "Epoch [107/10000], Loss: 0.630729079246521\n",
      "Epoch [108/10000], Loss: 0.6305569410324097\n",
      "Epoch [109/10000], Loss: 0.6303855776786804\n",
      "Epoch [110/10000], Loss: 0.6302152872085571\n",
      "Epoch [111/10000], Loss: 0.6300450563430786\n",
      "Epoch [112/10000], Loss: 0.6298744082450867\n",
      "Epoch [113/10000], Loss: 0.6297041177749634\n",
      "Epoch [114/10000], Loss: 0.6295343041419983\n",
      "Epoch [115/10000], Loss: 0.6293647289276123\n",
      "Epoch [116/10000], Loss: 0.6291957497596741\n",
      "Epoch [117/10000], Loss: 0.6290270686149597\n",
      "Epoch [118/10000], Loss: 0.6288585066795349\n",
      "Epoch [119/10000], Loss: 0.6286900639533997\n",
      "Epoch [120/10000], Loss: 0.6285219192504883\n",
      "Epoch [121/10000], Loss: 0.6283536553382874\n",
      "Epoch [122/10000], Loss: 0.6281847357749939\n",
      "Epoch [123/10000], Loss: 0.6280166506767273\n",
      "Epoch [124/10000], Loss: 0.6278483271598816\n",
      "Epoch [125/10000], Loss: 0.6276798844337463\n",
      "Epoch [126/10000], Loss: 0.6275117993354797\n",
      "Epoch [127/10000], Loss: 0.6273436546325684\n",
      "Epoch [128/10000], Loss: 0.6271752715110779\n",
      "Epoch [129/10000], Loss: 0.627007246017456\n",
      "Epoch [130/10000], Loss: 0.6268391609191895\n",
      "Epoch [131/10000], Loss: 0.6266719698905945\n",
      "Epoch [132/10000], Loss: 0.6265053153038025\n",
      "Epoch [133/10000], Loss: 0.6263394355773926\n",
      "Epoch [134/10000], Loss: 0.6261738538742065\n",
      "Epoch [135/10000], Loss: 0.6260084509849548\n",
      "Epoch [136/10000], Loss: 0.6258438229560852\n",
      "Epoch [137/10000], Loss: 0.625679612159729\n",
      "Epoch [138/10000], Loss: 0.6255156993865967\n",
      "Epoch [139/10000], Loss: 0.6253520846366882\n",
      "Epoch [140/10000], Loss: 0.6251885890960693\n",
      "Epoch [141/10000], Loss: 0.6250245571136475\n",
      "Epoch [142/10000], Loss: 0.6248611211776733\n",
      "Epoch [143/10000], Loss: 0.6246985793113708\n",
      "Epoch [144/10000], Loss: 0.6245368123054504\n",
      "Epoch [145/10000], Loss: 0.6243757009506226\n",
      "Epoch [146/10000], Loss: 0.6242146492004395\n",
      "Epoch [147/10000], Loss: 0.6240543723106384\n",
      "Epoch [148/10000], Loss: 0.6238946914672852\n",
      "Epoch [149/10000], Loss: 0.6237354278564453\n",
      "Epoch [150/10000], Loss: 0.6235763430595398\n",
      "Epoch [151/10000], Loss: 0.6234176754951477\n",
      "Epoch [152/10000], Loss: 0.6232591867446899\n",
      "Epoch [153/10000], Loss: 0.623100757598877\n",
      "Epoch [154/10000], Loss: 0.622942328453064\n",
      "Epoch [155/10000], Loss: 0.6227843761444092\n",
      "Epoch [156/10000], Loss: 0.6226269006729126\n",
      "Epoch [157/10000], Loss: 0.622469961643219\n",
      "Epoch [158/10000], Loss: 0.6223135590553284\n",
      "Epoch [159/10000], Loss: 0.6221573352813721\n",
      "Epoch [160/10000], Loss: 0.6220012307167053\n",
      "Epoch [161/10000], Loss: 0.6218453049659729\n",
      "Epoch [162/10000], Loss: 0.6216908097267151\n",
      "Epoch [163/10000], Loss: 0.6215369701385498\n",
      "Epoch [164/10000], Loss: 0.62138432264328\n",
      "Epoch [165/10000], Loss: 0.6212322115898132\n",
      "Epoch [166/10000], Loss: 0.6210806369781494\n",
      "Epoch [167/10000], Loss: 0.6209291219711304\n",
      "Epoch [168/10000], Loss: 0.620777428150177\n",
      "Epoch [169/10000], Loss: 0.6206258535385132\n",
      "Epoch [170/10000], Loss: 0.6204746961593628\n",
      "Epoch [171/10000], Loss: 0.620324432849884\n",
      "Epoch [172/10000], Loss: 0.6201750636100769\n",
      "Epoch [173/10000], Loss: 0.6200260519981384\n",
      "Epoch [174/10000], Loss: 0.6198775768280029\n",
      "Epoch [175/10000], Loss: 0.6197295188903809\n",
      "Epoch [176/10000], Loss: 0.6195815801620483\n",
      "Epoch [177/10000], Loss: 0.6194345951080322\n",
      "Epoch [178/10000], Loss: 0.6192888617515564\n",
      "Epoch [179/10000], Loss: 0.6191433668136597\n",
      "Epoch [180/10000], Loss: 0.6189978122711182\n",
      "Epoch [181/10000], Loss: 0.6188525557518005\n",
      "Epoch [182/10000], Loss: 0.6187074184417725\n",
      "Epoch [183/10000], Loss: 0.6185629963874817\n",
      "Epoch [184/10000], Loss: 0.6184186935424805\n",
      "Epoch [185/10000], Loss: 0.6182748079299927\n",
      "Epoch [186/10000], Loss: 0.6181309223175049\n",
      "Epoch [187/10000], Loss: 0.6179871559143066\n",
      "Epoch [188/10000], Loss: 0.6178427934646606\n",
      "Epoch [189/10000], Loss: 0.617698073387146\n",
      "Epoch [190/10000], Loss: 0.617553174495697\n",
      "Epoch [191/10000], Loss: 0.6174079775810242\n",
      "Epoch [192/10000], Loss: 0.6172621250152588\n",
      "Epoch [193/10000], Loss: 0.6171169281005859\n",
      "Epoch [194/10000], Loss: 0.6169718503952026\n",
      "Epoch [195/10000], Loss: 0.6168268322944641\n",
      "Epoch [196/10000], Loss: 0.616680920124054\n",
      "Epoch [197/10000], Loss: 0.6165353655815125\n",
      "Epoch [198/10000], Loss: 0.6163901686668396\n",
      "Epoch [199/10000], Loss: 0.6162452697753906\n",
      "Epoch [200/10000], Loss: 0.616100013256073\n",
      "Epoch [201/10000], Loss: 0.6159551739692688\n",
      "Epoch [202/10000], Loss: 0.6158104538917542\n",
      "Epoch [203/10000], Loss: 0.6156660914421082\n",
      "Epoch [204/10000], Loss: 0.6155216097831726\n",
      "Epoch [205/10000], Loss: 0.615376889705658\n",
      "Epoch [206/10000], Loss: 0.6152327656745911\n",
      "Epoch [207/10000], Loss: 0.6150897741317749\n",
      "Epoch [208/10000], Loss: 0.6149476170539856\n",
      "Epoch [209/10000], Loss: 0.6148061752319336\n",
      "Epoch [210/10000], Loss: 0.6146652102470398\n",
      "Epoch [211/10000], Loss: 0.614524781703949\n",
      "Epoch [212/10000], Loss: 0.6143842339515686\n",
      "Epoch [213/10000], Loss: 0.6142445206642151\n",
      "Epoch [214/10000], Loss: 0.614105761051178\n",
      "Epoch [215/10000], Loss: 0.6139678359031677\n",
      "Epoch [216/10000], Loss: 0.6138303279876709\n",
      "Epoch [217/10000], Loss: 0.6136932969093323\n",
      "Epoch [218/10000], Loss: 0.6135561466217041\n",
      "Epoch [219/10000], Loss: 0.6134191155433655\n",
      "Epoch [220/10000], Loss: 0.6132822632789612\n",
      "Epoch [221/10000], Loss: 0.6131460070610046\n",
      "Epoch [222/10000], Loss: 0.6130093336105347\n",
      "Epoch [223/10000], Loss: 0.6128729581832886\n",
      "Epoch [224/10000], Loss: 0.612737238407135\n",
      "Epoch [225/10000], Loss: 0.6126019358634949\n",
      "Epoch [226/10000], Loss: 0.6124671697616577\n",
      "Epoch [227/10000], Loss: 0.612332820892334\n",
      "Epoch [228/10000], Loss: 0.6121987700462341\n",
      "Epoch [229/10000], Loss: 0.6120655536651611\n",
      "Epoch [230/10000], Loss: 0.6119331121444702\n",
      "Epoch [231/10000], Loss: 0.6118012070655823\n",
      "Epoch [232/10000], Loss: 0.6116694808006287\n",
      "Epoch [233/10000], Loss: 0.6115378141403198\n",
      "Epoch [234/10000], Loss: 0.6114063858985901\n",
      "Epoch [235/10000], Loss: 0.6112750172615051\n",
      "Epoch [236/10000], Loss: 0.6111438274383545\n",
      "Epoch [237/10000], Loss: 0.6110128164291382\n",
      "Epoch [238/10000], Loss: 0.6108821034431458\n",
      "Epoch [239/10000], Loss: 0.6107518076896667\n",
      "Epoch [240/10000], Loss: 0.6106220483779907\n",
      "Epoch [241/10000], Loss: 0.6104922294616699\n",
      "Epoch [242/10000], Loss: 0.6103625297546387\n",
      "Epoch [243/10000], Loss: 0.6102326512336731\n",
      "Epoch [244/10000], Loss: 0.6101033687591553\n",
      "Epoch [245/10000], Loss: 0.609974205493927\n",
      "Epoch [246/10000], Loss: 0.6098452806472778\n",
      "Epoch [247/10000], Loss: 0.6097170114517212\n",
      "Epoch [248/10000], Loss: 0.609589695930481\n",
      "Epoch [249/10000], Loss: 0.6094622015953064\n",
      "Epoch [250/10000], Loss: 0.6093347668647766\n",
      "Epoch [251/10000], Loss: 0.6092069149017334\n",
      "Epoch [252/10000], Loss: 0.6090793013572693\n",
      "Epoch [253/10000], Loss: 0.6089529991149902\n",
      "Epoch [254/10000], Loss: 0.6088277697563171\n",
      "Epoch [255/10000], Loss: 0.6087028980255127\n",
      "Epoch [256/10000], Loss: 0.608578622341156\n",
      "Epoch [257/10000], Loss: 0.6084544658660889\n",
      "Epoch [258/10000], Loss: 0.6083305478096008\n",
      "Epoch [259/10000], Loss: 0.6082065105438232\n",
      "Epoch [260/10000], Loss: 0.6080829501152039\n",
      "Epoch [261/10000], Loss: 0.6079608798027039\n",
      "Epoch [262/10000], Loss: 0.6078379154205322\n",
      "Epoch [263/10000], Loss: 0.6077139377593994\n",
      "Epoch [264/10000], Loss: 0.6075904369354248\n",
      "Epoch [265/10000], Loss: 0.6074678897857666\n",
      "Epoch [266/10000], Loss: 0.6073464155197144\n",
      "Epoch [267/10000], Loss: 0.6072260737419128\n",
      "Epoch [268/10000], Loss: 0.60710608959198\n",
      "Epoch [269/10000], Loss: 0.6069863438606262\n",
      "Epoch [270/10000], Loss: 0.6068671345710754\n",
      "Epoch [271/10000], Loss: 0.606748104095459\n",
      "Epoch [272/10000], Loss: 0.606629490852356\n",
      "Epoch [273/10000], Loss: 0.6065117120742798\n",
      "Epoch [274/10000], Loss: 0.6063942909240723\n",
      "Epoch [275/10000], Loss: 0.6062788367271423\n",
      "Epoch [276/10000], Loss: 0.606164276599884\n",
      "Epoch [277/10000], Loss: 0.6060503125190735\n",
      "Epoch [278/10000], Loss: 0.6059357523918152\n",
      "Epoch [279/10000], Loss: 0.6058220267295837\n",
      "Epoch [280/10000], Loss: 0.6057083010673523\n",
      "Epoch [281/10000], Loss: 0.6055946350097656\n",
      "Epoch [282/10000], Loss: 0.6054815649986267\n",
      "Epoch [283/10000], Loss: 0.605369508266449\n",
      "Epoch [284/10000], Loss: 0.6052581071853638\n",
      "Epoch [285/10000], Loss: 0.6051462292671204\n",
      "Epoch [286/10000], Loss: 0.605033814907074\n",
      "Epoch [287/10000], Loss: 0.6049221158027649\n",
      "Epoch [288/10000], Loss: 0.6048114895820618\n",
      "Epoch [289/10000], Loss: 0.6047012805938721\n",
      "Epoch [290/10000], Loss: 0.6045914888381958\n",
      "Epoch [291/10000], Loss: 0.6044818162918091\n",
      "Epoch [292/10000], Loss: 0.6043723821640015\n",
      "Epoch [293/10000], Loss: 0.604263186454773\n",
      "Epoch [294/10000], Loss: 0.6041545867919922\n",
      "Epoch [295/10000], Loss: 0.6040473580360413\n",
      "Epoch [296/10000], Loss: 0.6039404273033142\n",
      "Epoch [297/10000], Loss: 0.6038330793380737\n",
      "Epoch [298/10000], Loss: 0.6037260890007019\n",
      "Epoch [299/10000], Loss: 0.6036196947097778\n",
      "Epoch [300/10000], Loss: 0.6035135984420776\n",
      "Epoch [301/10000], Loss: 0.6034080982208252\n",
      "Epoch [302/10000], Loss: 0.6033030152320862\n",
      "Epoch [303/10000], Loss: 0.6031978726387024\n",
      "Epoch [304/10000], Loss: 0.6030932664871216\n",
      "Epoch [305/10000], Loss: 0.6029888987541199\n",
      "Epoch [306/10000], Loss: 0.6028842926025391\n",
      "Epoch [307/10000], Loss: 0.6027806401252747\n",
      "Epoch [308/10000], Loss: 0.6026774048805237\n",
      "Epoch [309/10000], Loss: 0.6025750637054443\n",
      "Epoch [310/10000], Loss: 0.6024735569953918\n",
      "Epoch [311/10000], Loss: 0.6023721694946289\n",
      "Epoch [312/10000], Loss: 0.6022712588310242\n",
      "Epoch [313/10000], Loss: 0.6021708846092224\n",
      "Epoch [314/10000], Loss: 0.6020704507827759\n",
      "Epoch [315/10000], Loss: 0.6019715070724487\n",
      "Epoch [316/10000], Loss: 0.6018728613853455\n",
      "Epoch [317/10000], Loss: 0.601774275302887\n",
      "Epoch [318/10000], Loss: 0.6016762852668762\n",
      "Epoch [319/10000], Loss: 0.6015778183937073\n",
      "Epoch [320/10000], Loss: 0.6014787554740906\n",
      "Epoch [321/10000], Loss: 0.6013800501823425\n",
      "Epoch [322/10000], Loss: 0.6012810468673706\n",
      "Epoch [323/10000], Loss: 0.601182758808136\n",
      "Epoch [324/10000], Loss: 0.6010853052139282\n",
      "Epoch [325/10000], Loss: 0.6009883284568787\n",
      "Epoch [326/10000], Loss: 0.6008927226066589\n",
      "Epoch [327/10000], Loss: 0.6007968783378601\n",
      "Epoch [328/10000], Loss: 0.6007015705108643\n",
      "Epoch [329/10000], Loss: 0.6006065607070923\n",
      "Epoch [330/10000], Loss: 0.6005114912986755\n",
      "Epoch [331/10000], Loss: 0.6004161834716797\n",
      "Epoch [332/10000], Loss: 0.60032057762146\n",
      "Epoch [333/10000], Loss: 0.6002253890037537\n",
      "Epoch [334/10000], Loss: 0.6001303791999817\n",
      "Epoch [335/10000], Loss: 0.6000358462333679\n",
      "Epoch [336/10000], Loss: 0.5999418497085571\n",
      "Epoch [337/10000], Loss: 0.5998483300209045\n",
      "Epoch [338/10000], Loss: 0.5997548699378967\n",
      "Epoch [339/10000], Loss: 0.5996619462966919\n",
      "Epoch [340/10000], Loss: 0.5995690822601318\n",
      "Epoch [341/10000], Loss: 0.5994757413864136\n",
      "Epoch [342/10000], Loss: 0.5993822813034058\n",
      "Epoch [343/10000], Loss: 0.5992892384529114\n",
      "Epoch [344/10000], Loss: 0.5991974472999573\n",
      "Epoch [345/10000], Loss: 0.5991061329841614\n",
      "Epoch [346/10000], Loss: 0.5990149974822998\n",
      "Epoch [347/10000], Loss: 0.5989235043525696\n",
      "Epoch [348/10000], Loss: 0.5988320112228394\n",
      "Epoch [349/10000], Loss: 0.5987394452095032\n",
      "Epoch [350/10000], Loss: 0.5986460447311401\n",
      "Epoch [351/10000], Loss: 0.5985530614852905\n",
      "Epoch [352/10000], Loss: 0.5984604954719543\n",
      "Epoch [353/10000], Loss: 0.5983688235282898\n",
      "Epoch [354/10000], Loss: 0.5982770919799805\n",
      "Epoch [355/10000], Loss: 0.5981846451759338\n",
      "Epoch [356/10000], Loss: 0.5980915427207947\n",
      "Epoch [357/10000], Loss: 0.5979993343353271\n",
      "Epoch [358/10000], Loss: 0.5979077219963074\n",
      "Epoch [359/10000], Loss: 0.5978164672851562\n",
      "Epoch [360/10000], Loss: 0.5977265238761902\n",
      "Epoch [361/10000], Loss: 0.5976360440254211\n",
      "Epoch [362/10000], Loss: 0.5975459814071655\n",
      "Epoch [363/10000], Loss: 0.5974567532539368\n",
      "Epoch [364/10000], Loss: 0.5973676443099976\n",
      "Epoch [365/10000], Loss: 0.5972787141799927\n",
      "Epoch [366/10000], Loss: 0.5971909165382385\n",
      "Epoch [367/10000], Loss: 0.5971038937568665\n",
      "Epoch [368/10000], Loss: 0.5970182418823242\n",
      "Epoch [369/10000], Loss: 0.5969336628913879\n",
      "Epoch [370/10000], Loss: 0.5968484878540039\n",
      "Epoch [371/10000], Loss: 0.5967623591423035\n",
      "Epoch [372/10000], Loss: 0.5966757535934448\n",
      "Epoch [373/10000], Loss: 0.5965898036956787\n",
      "Epoch [374/10000], Loss: 0.5965025424957275\n",
      "Epoch [375/10000], Loss: 0.5964155197143555\n",
      "Epoch [376/10000], Loss: 0.5963290929794312\n",
      "Epoch [377/10000], Loss: 0.5962418913841248\n",
      "Epoch [378/10000], Loss: 0.5961546897888184\n",
      "Epoch [379/10000], Loss: 0.5960683226585388\n",
      "Epoch [380/10000], Loss: 0.5959828495979309\n",
      "Epoch [381/10000], Loss: 0.5958993434906006\n",
      "Epoch [382/10000], Loss: 0.5958170890808105\n",
      "Epoch [383/10000], Loss: 0.5957350730895996\n",
      "Epoch [384/10000], Loss: 0.5956536531448364\n",
      "Epoch [385/10000], Loss: 0.5955735445022583\n",
      "Epoch [386/10000], Loss: 0.5954920053482056\n",
      "Epoch [387/10000], Loss: 0.5954103469848633\n",
      "Epoch [388/10000], Loss: 0.5953290462493896\n",
      "Epoch [389/10000], Loss: 0.5952484011650085\n",
      "Epoch [390/10000], Loss: 0.5951682925224304\n",
      "Epoch [391/10000], Loss: 0.5950881838798523\n",
      "Epoch [392/10000], Loss: 0.5950078964233398\n",
      "Epoch [393/10000], Loss: 0.5949282646179199\n",
      "Epoch [394/10000], Loss: 0.5948489904403687\n",
      "Epoch [395/10000], Loss: 0.5947699546813965\n",
      "Epoch [396/10000], Loss: 0.594692051410675\n",
      "Epoch [397/10000], Loss: 0.5946152806282043\n",
      "Epoch [398/10000], Loss: 0.5945380926132202\n",
      "Epoch [399/10000], Loss: 0.5944611430168152\n",
      "Epoch [400/10000], Loss: 0.5943832397460938\n",
      "Epoch [401/10000], Loss: 0.5943046808242798\n",
      "Epoch [402/10000], Loss: 0.5942257642745972\n",
      "Epoch [403/10000], Loss: 0.5941470265388489\n",
      "Epoch [404/10000], Loss: 0.59406977891922\n",
      "Epoch [405/10000], Loss: 0.593993067741394\n",
      "Epoch [406/10000], Loss: 0.5939170122146606\n",
      "Epoch [407/10000], Loss: 0.5938412547111511\n",
      "Epoch [408/10000], Loss: 0.5937659740447998\n",
      "Epoch [409/10000], Loss: 0.593692421913147\n",
      "Epoch [410/10000], Loss: 0.593619704246521\n",
      "Epoch [411/10000], Loss: 0.593547523021698\n",
      "Epoch [412/10000], Loss: 0.5934744477272034\n",
      "Epoch [413/10000], Loss: 0.5934011936187744\n",
      "Epoch [414/10000], Loss: 0.5933282971382141\n",
      "Epoch [415/10000], Loss: 0.5932556390762329\n",
      "Epoch [416/10000], Loss: 0.5931837558746338\n",
      "Epoch [417/10000], Loss: 0.5931108593940735\n",
      "Epoch [418/10000], Loss: 0.5930382609367371\n",
      "Epoch [419/10000], Loss: 0.5929660201072693\n",
      "Epoch [420/10000], Loss: 0.5928940176963806\n",
      "Epoch [421/10000], Loss: 0.5928226709365845\n",
      "Epoch [422/10000], Loss: 0.5927520990371704\n",
      "Epoch [423/10000], Loss: 0.5926820039749146\n",
      "Epoch [424/10000], Loss: 0.5926104784011841\n",
      "Epoch [425/10000], Loss: 0.5925384759902954\n",
      "Epoch [426/10000], Loss: 0.592466413974762\n",
      "Epoch [427/10000], Loss: 0.5923938155174255\n",
      "Epoch [428/10000], Loss: 0.5923202633857727\n",
      "Epoch [429/10000], Loss: 0.5922467112541199\n",
      "Epoch [430/10000], Loss: 0.592173159122467\n",
      "Epoch [431/10000], Loss: 0.5920991897583008\n",
      "Epoch [432/10000], Loss: 0.5920255184173584\n",
      "Epoch [433/10000], Loss: 0.5919516682624817\n",
      "Epoch [434/10000], Loss: 0.5918781161308289\n",
      "Epoch [435/10000], Loss: 0.5918046832084656\n",
      "Epoch [436/10000], Loss: 0.5917307138442993\n",
      "Epoch [437/10000], Loss: 0.5916556119918823\n",
      "Epoch [438/10000], Loss: 0.591580331325531\n",
      "Epoch [439/10000], Loss: 0.5915049910545349\n",
      "Epoch [440/10000], Loss: 0.5914312601089478\n",
      "Epoch [441/10000], Loss: 0.5913583636283875\n",
      "Epoch [442/10000], Loss: 0.591285228729248\n",
      "Epoch [443/10000], Loss: 0.5912132859230042\n",
      "Epoch [444/10000], Loss: 0.5911416411399841\n",
      "Epoch [445/10000], Loss: 0.5910699963569641\n",
      "Epoch [446/10000], Loss: 0.590998649597168\n",
      "Epoch [447/10000], Loss: 0.5909277200698853\n",
      "Epoch [448/10000], Loss: 0.5908573269844055\n",
      "Epoch [449/10000], Loss: 0.5907866358757019\n",
      "Epoch [450/10000], Loss: 0.5907163023948669\n",
      "Epoch [451/10000], Loss: 0.590646505355835\n",
      "Epoch [452/10000], Loss: 0.5905765891075134\n",
      "Epoch [453/10000], Loss: 0.5905077457427979\n",
      "Epoch [454/10000], Loss: 0.5904388427734375\n",
      "Epoch [455/10000], Loss: 0.5903705358505249\n",
      "Epoch [456/10000], Loss: 0.5903028249740601\n",
      "Epoch [457/10000], Loss: 0.5902354121208191\n",
      "Epoch [458/10000], Loss: 0.5901684761047363\n",
      "Epoch [459/10000], Loss: 0.5901012420654297\n",
      "Epoch [460/10000], Loss: 0.5900338292121887\n",
      "Epoch [461/10000], Loss: 0.5899666547775269\n",
      "Epoch [462/10000], Loss: 0.5898995399475098\n",
      "Epoch [463/10000], Loss: 0.5898328423500061\n",
      "Epoch [464/10000], Loss: 0.5897671580314636\n",
      "Epoch [465/10000], Loss: 0.5897019505500793\n",
      "Epoch [466/10000], Loss: 0.5896366238594055\n",
      "Epoch [467/10000], Loss: 0.5895706415176392\n",
      "Epoch [468/10000], Loss: 0.5895043611526489\n",
      "Epoch [469/10000], Loss: 0.5894375443458557\n",
      "Epoch [470/10000], Loss: 0.5893710851669312\n",
      "Epoch [471/10000], Loss: 0.5893054604530334\n",
      "Epoch [472/10000], Loss: 0.589240312576294\n",
      "Epoch [473/10000], Loss: 0.5891756415367126\n",
      "Epoch [474/10000], Loss: 0.5891115069389343\n",
      "Epoch [475/10000], Loss: 0.5890465378761292\n",
      "Epoch [476/10000], Loss: 0.5889816284179688\n",
      "Epoch [477/10000], Loss: 0.5889170169830322\n",
      "Epoch [478/10000], Loss: 0.5888519883155823\n",
      "Epoch [479/10000], Loss: 0.5887869596481323\n",
      "Epoch [480/10000], Loss: 0.5887210369110107\n",
      "Epoch [481/10000], Loss: 0.5886550545692444\n",
      "Epoch [482/10000], Loss: 0.5885879397392273\n",
      "Epoch [483/10000], Loss: 0.5885210633277893\n",
      "Epoch [484/10000], Loss: 0.5884544849395752\n",
      "Epoch [485/10000], Loss: 0.5883895754814148\n",
      "Epoch [486/10000], Loss: 0.5883262753486633\n",
      "Epoch [487/10000], Loss: 0.588263988494873\n",
      "Epoch [488/10000], Loss: 0.5882007479667664\n",
      "Epoch [489/10000], Loss: 0.5881375074386597\n",
      "Epoch [490/10000], Loss: 0.5880744457244873\n",
      "Epoch [491/10000], Loss: 0.5880112648010254\n",
      "Epoch [492/10000], Loss: 0.5879484415054321\n",
      "Epoch [493/10000], Loss: 0.5878846645355225\n",
      "Epoch [494/10000], Loss: 0.5878202319145203\n",
      "Epoch [495/10000], Loss: 0.5877557396888733\n",
      "Epoch [496/10000], Loss: 0.5876915454864502\n",
      "Epoch [497/10000], Loss: 0.5876268148422241\n",
      "Epoch [498/10000], Loss: 0.5875619053840637\n",
      "Epoch [499/10000], Loss: 0.5874969363212585\n",
      "Epoch [500/10000], Loss: 0.5874334573745728\n",
      "Epoch [501/10000], Loss: 0.5873721241950989\n",
      "Epoch [502/10000], Loss: 0.5873113870620728\n",
      "Epoch [503/10000], Loss: 0.5872499346733093\n",
      "Epoch [504/10000], Loss: 0.5871884822845459\n",
      "Epoch [505/10000], Loss: 0.5871265530586243\n",
      "Epoch [506/10000], Loss: 0.5870653986930847\n",
      "Epoch [507/10000], Loss: 0.5870035290718079\n",
      "Epoch [508/10000], Loss: 0.5869415402412415\n",
      "Epoch [509/10000], Loss: 0.5868794322013855\n",
      "Epoch [510/10000], Loss: 0.586816132068634\n",
      "Epoch [511/10000], Loss: 0.5867519378662109\n",
      "Epoch [512/10000], Loss: 0.586687445640564\n",
      "Epoch [513/10000], Loss: 0.5866232514381409\n",
      "Epoch [514/10000], Loss: 0.5865592360496521\n",
      "Epoch [515/10000], Loss: 0.5864951610565186\n",
      "Epoch [516/10000], Loss: 0.5864307284355164\n",
      "Epoch [517/10000], Loss: 0.5863656997680664\n",
      "Epoch [518/10000], Loss: 0.5863006711006165\n",
      "Epoch [519/10000], Loss: 0.5862349271774292\n",
      "Epoch [520/10000], Loss: 0.5861697793006897\n",
      "Epoch [521/10000], Loss: 0.5861051082611084\n",
      "Epoch [522/10000], Loss: 0.5860415697097778\n",
      "Epoch [523/10000], Loss: 0.5859780311584473\n",
      "Epoch [524/10000], Loss: 0.5859149098396301\n",
      "Epoch [525/10000], Loss: 0.5858511924743652\n",
      "Epoch [526/10000], Loss: 0.5857875943183899\n",
      "Epoch [527/10000], Loss: 0.5857235193252563\n",
      "Epoch [528/10000], Loss: 0.585659921169281\n",
      "Epoch [529/10000], Loss: 0.5855957865715027\n",
      "Epoch [530/10000], Loss: 0.5855323076248169\n",
      "Epoch [531/10000], Loss: 0.5854694247245789\n",
      "Epoch [532/10000], Loss: 0.5854074358940125\n",
      "Epoch [533/10000], Loss: 0.5853452086448669\n",
      "Epoch [534/10000], Loss: 0.5852818489074707\n",
      "Epoch [535/10000], Loss: 0.5852187275886536\n",
      "Epoch [536/10000], Loss: 0.5851558446884155\n",
      "Epoch [537/10000], Loss: 0.5850930213928223\n",
      "Epoch [538/10000], Loss: 0.5850307941436768\n",
      "Epoch [539/10000], Loss: 0.5849697589874268\n",
      "Epoch [540/10000], Loss: 0.584909200668335\n",
      "Epoch [541/10000], Loss: 0.5848491787910461\n",
      "Epoch [542/10000], Loss: 0.5847893357276917\n",
      "Epoch [543/10000], Loss: 0.5847292542457581\n",
      "Epoch [544/10000], Loss: 0.5846693515777588\n",
      "Epoch [545/10000], Loss: 0.5846089720726013\n",
      "Epoch [546/10000], Loss: 0.58454829454422\n",
      "Epoch [547/10000], Loss: 0.584488034248352\n",
      "Epoch [548/10000], Loss: 0.5844270586967468\n",
      "Epoch [549/10000], Loss: 0.5843656063079834\n",
      "Epoch [550/10000], Loss: 0.5843051075935364\n",
      "Epoch [551/10000], Loss: 0.5842452645301819\n",
      "Epoch [552/10000], Loss: 0.5841867923736572\n",
      "Epoch [553/10000], Loss: 0.5841272473335266\n",
      "Epoch [554/10000], Loss: 0.584067165851593\n",
      "Epoch [555/10000], Loss: 0.5840074419975281\n",
      "Epoch [556/10000], Loss: 0.5839481949806213\n",
      "Epoch [557/10000], Loss: 0.5838895440101624\n",
      "Epoch [558/10000], Loss: 0.5838314294815063\n",
      "Epoch [559/10000], Loss: 0.5837740898132324\n",
      "Epoch [560/10000], Loss: 0.5837159156799316\n",
      "Epoch [561/10000], Loss: 0.5836573243141174\n",
      "Epoch [562/10000], Loss: 0.5835992097854614\n",
      "Epoch [563/10000], Loss: 0.5835414528846741\n",
      "Epoch [564/10000], Loss: 0.5834831595420837\n",
      "Epoch [565/10000], Loss: 0.5834240317344666\n",
      "Epoch [566/10000], Loss: 0.5833646059036255\n",
      "Epoch [567/10000], Loss: 0.5833057761192322\n",
      "Epoch [568/10000], Loss: 0.5832482576370239\n",
      "Epoch [569/10000], Loss: 0.5831900835037231\n",
      "Epoch [570/10000], Loss: 0.5831308960914612\n",
      "Epoch [571/10000], Loss: 0.5830717086791992\n",
      "Epoch [572/10000], Loss: 0.5830129384994507\n",
      "Epoch [573/10000], Loss: 0.5829548239707947\n",
      "Epoch [574/10000], Loss: 0.5828978419303894\n",
      "Epoch [575/10000], Loss: 0.5828417539596558\n",
      "Epoch [576/10000], Loss: 0.5827863216400146\n",
      "Epoch [577/10000], Loss: 0.5827317237854004\n",
      "Epoch [578/10000], Loss: 0.5826769471168518\n",
      "Epoch [579/10000], Loss: 0.5826219320297241\n",
      "Epoch [580/10000], Loss: 0.5825678706169128\n",
      "Epoch [581/10000], Loss: 0.5825146436691284\n",
      "Epoch [582/10000], Loss: 0.5824620723724365\n",
      "Epoch [583/10000], Loss: 0.5824093818664551\n",
      "Epoch [584/10000], Loss: 0.5823565125465393\n",
      "Epoch [585/10000], Loss: 0.5823038816452026\n",
      "Epoch [586/10000], Loss: 0.5822518467903137\n",
      "Epoch [587/10000], Loss: 0.5822000503540039\n",
      "Epoch [588/10000], Loss: 0.5821475386619568\n",
      "Epoch [589/10000], Loss: 0.5820949077606201\n",
      "Epoch [590/10000], Loss: 0.5820412039756775\n",
      "Epoch [591/10000], Loss: 0.5819876194000244\n",
      "Epoch [592/10000], Loss: 0.5819342732429504\n",
      "Epoch [593/10000], Loss: 0.5818818211555481\n",
      "Epoch [594/10000], Loss: 0.5818296074867249\n",
      "Epoch [595/10000], Loss: 0.5817773342132568\n",
      "Epoch [596/10000], Loss: 0.5817258358001709\n",
      "Epoch [597/10000], Loss: 0.5816750526428223\n",
      "Epoch [598/10000], Loss: 0.581623911857605\n",
      "Epoch [599/10000], Loss: 0.5815734267234802\n",
      "Epoch [600/10000], Loss: 0.5815227627754211\n",
      "Epoch [601/10000], Loss: 0.5814722776412964\n",
      "Epoch [602/10000], Loss: 0.5814220905303955\n",
      "Epoch [603/10000], Loss: 0.5813713073730469\n",
      "Epoch [604/10000], Loss: 0.5813202261924744\n",
      "Epoch [605/10000], Loss: 0.5812689661979675\n",
      "Epoch [606/10000], Loss: 0.5812174677848816\n",
      "Epoch [607/10000], Loss: 0.5811657905578613\n",
      "Epoch [608/10000], Loss: 0.5811141133308411\n",
      "Epoch [609/10000], Loss: 0.581062376499176\n",
      "Epoch [610/10000], Loss: 0.5810109376907349\n",
      "Epoch [611/10000], Loss: 0.5809597373008728\n",
      "Epoch [612/10000], Loss: 0.5809081792831421\n",
      "Epoch [613/10000], Loss: 0.5808562636375427\n",
      "Epoch [614/10000], Loss: 0.5808044672012329\n",
      "Epoch [615/10000], Loss: 0.580752968788147\n",
      "Epoch [616/10000], Loss: 0.5807014107704163\n",
      "Epoch [617/10000], Loss: 0.5806494355201721\n",
      "Epoch [618/10000], Loss: 0.5805972218513489\n",
      "Epoch [619/10000], Loss: 0.5805451273918152\n",
      "Epoch [620/10000], Loss: 0.5804941058158875\n",
      "Epoch [621/10000], Loss: 0.5804433822631836\n",
      "Epoch [622/10000], Loss: 0.5803934335708618\n",
      "Epoch [623/10000], Loss: 0.5803436636924744\n",
      "Epoch [624/10000], Loss: 0.5802941918373108\n",
      "Epoch [625/10000], Loss: 0.5802459716796875\n",
      "Epoch [626/10000], Loss: 0.580198347568512\n",
      "Epoch [627/10000], Loss: 0.5801507234573364\n",
      "Epoch [628/10000], Loss: 0.5801025629043579\n",
      "Epoch [629/10000], Loss: 0.5800543427467346\n",
      "Epoch [630/10000], Loss: 0.5800067782402039\n",
      "Epoch [631/10000], Loss: 0.5799599885940552\n",
      "Epoch [632/10000], Loss: 0.5799142122268677\n",
      "Epoch [633/10000], Loss: 0.5798691511154175\n",
      "Epoch [634/10000], Loss: 0.5798242688179016\n",
      "Epoch [635/10000], Loss: 0.5797790288925171\n",
      "Epoch [636/10000], Loss: 0.5797328352928162\n",
      "Epoch [637/10000], Loss: 0.5796870589256287\n",
      "Epoch [638/10000], Loss: 0.5796416997909546\n",
      "Epoch [639/10000], Loss: 0.5795954465866089\n",
      "Epoch [640/10000], Loss: 0.5795478820800781\n",
      "Epoch [641/10000], Loss: 0.5794994831085205\n",
      "Epoch [642/10000], Loss: 0.5794514417648315\n",
      "Epoch [643/10000], Loss: 0.5794035196304321\n",
      "Epoch [644/10000], Loss: 0.5793566107749939\n",
      "Epoch [645/10000], Loss: 0.5793101191520691\n",
      "Epoch [646/10000], Loss: 0.57926344871521\n",
      "Epoch [647/10000], Loss: 0.5792173147201538\n",
      "Epoch [648/10000], Loss: 0.5791711807250977\n",
      "Epoch [649/10000], Loss: 0.5791257619857788\n",
      "Epoch [650/10000], Loss: 0.5790804028511047\n",
      "Epoch [651/10000], Loss: 0.5790347456932068\n",
      "Epoch [652/10000], Loss: 0.5789889693260193\n",
      "Epoch [653/10000], Loss: 0.5789434909820557\n",
      "Epoch [654/10000], Loss: 0.5788972973823547\n",
      "Epoch [655/10000], Loss: 0.578851580619812\n",
      "Epoch [656/10000], Loss: 0.5788061022758484\n",
      "Epoch [657/10000], Loss: 0.5787604451179504\n",
      "Epoch [658/10000], Loss: 0.5787149667739868\n",
      "Epoch [659/10000], Loss: 0.5786688923835754\n",
      "Epoch [660/10000], Loss: 0.5786226987838745\n",
      "Epoch [661/10000], Loss: 0.5785769820213318\n",
      "Epoch [662/10000], Loss: 0.57853102684021\n",
      "Epoch [663/10000], Loss: 0.5784853100776672\n",
      "Epoch [664/10000], Loss: 0.5784409642219543\n",
      "Epoch [665/10000], Loss: 0.5783982872962952\n",
      "Epoch [666/10000], Loss: 0.5783565640449524\n",
      "Epoch [667/10000], Loss: 0.5783159732818604\n",
      "Epoch [668/10000], Loss: 0.5782748460769653\n",
      "Epoch [669/10000], Loss: 0.578233003616333\n",
      "Epoch [670/10000], Loss: 0.5781919360160828\n",
      "Epoch [671/10000], Loss: 0.5781512260437012\n",
      "Epoch [672/10000], Loss: 0.5781108140945435\n",
      "Epoch [673/10000], Loss: 0.5780705809593201\n",
      "Epoch [674/10000], Loss: 0.5780306458473206\n",
      "Epoch [675/10000], Loss: 0.5779907703399658\n",
      "Epoch [676/10000], Loss: 0.5779505372047424\n",
      "Epoch [677/10000], Loss: 0.5779104232788086\n",
      "Epoch [678/10000], Loss: 0.5778700113296509\n",
      "Epoch [679/10000], Loss: 0.5778288841247559\n",
      "Epoch [680/10000], Loss: 0.5777873396873474\n",
      "Epoch [681/10000], Loss: 0.5777456760406494\n",
      "Epoch [682/10000], Loss: 0.5777035355567932\n",
      "Epoch [683/10000], Loss: 0.5776610970497131\n",
      "Epoch [684/10000], Loss: 0.5776193737983704\n",
      "Epoch [685/10000], Loss: 0.5775775909423828\n",
      "Epoch [686/10000], Loss: 0.5775361061096191\n",
      "Epoch [687/10000], Loss: 0.5774960517883301\n",
      "Epoch [688/10000], Loss: 0.5774549841880798\n",
      "Epoch [689/10000], Loss: 0.577414333820343\n",
      "Epoch [690/10000], Loss: 0.5773736834526062\n",
      "Epoch [691/10000], Loss: 0.5773323178291321\n",
      "Epoch [692/10000], Loss: 0.5772920250892639\n",
      "Epoch [693/10000], Loss: 0.5772525072097778\n",
      "Epoch [694/10000], Loss: 0.5772148370742798\n",
      "Epoch [695/10000], Loss: 0.5771776437759399\n",
      "Epoch [696/10000], Loss: 0.5771403312683105\n",
      "Epoch [697/10000], Loss: 0.5770995020866394\n",
      "Epoch [698/10000], Loss: 0.5770542025566101\n",
      "Epoch [699/10000], Loss: 0.5770096182823181\n",
      "Epoch [700/10000], Loss: 0.5769708156585693\n",
      "Epoch [701/10000], Loss: 0.5769355893135071\n",
      "Epoch [702/10000], Loss: 0.5768999457359314\n",
      "Epoch [703/10000], Loss: 0.5768620371818542\n",
      "Epoch [704/10000], Loss: 0.5768235325813293\n",
      "Epoch [705/10000], Loss: 0.5767858624458313\n",
      "Epoch [706/10000], Loss: 0.5767492055892944\n",
      "Epoch [707/10000], Loss: 0.5767120122909546\n",
      "Epoch [708/10000], Loss: 0.5766741633415222\n",
      "Epoch [709/10000], Loss: 0.5766361355781555\n",
      "Epoch [710/10000], Loss: 0.576598584651947\n",
      "Epoch [711/10000], Loss: 0.5765617489814758\n",
      "Epoch [712/10000], Loss: 0.5765261054039001\n",
      "Epoch [713/10000], Loss: 0.5764901638031006\n",
      "Epoch [714/10000], Loss: 0.576453685760498\n",
      "Epoch [715/10000], Loss: 0.5764181613922119\n",
      "Epoch [716/10000], Loss: 0.5763822793960571\n",
      "Epoch [717/10000], Loss: 0.5763454437255859\n",
      "Epoch [718/10000], Loss: 0.576309323310852\n",
      "Epoch [719/10000], Loss: 0.5762745141983032\n",
      "Epoch [720/10000], Loss: 0.5762390494346619\n",
      "Epoch [721/10000], Loss: 0.5762031674385071\n",
      "Epoch [722/10000], Loss: 0.5761670470237732\n",
      "Epoch [723/10000], Loss: 0.5761304497718811\n",
      "Epoch [724/10000], Loss: 0.5760940313339233\n",
      "Epoch [725/10000], Loss: 0.5760579109191895\n",
      "Epoch [726/10000], Loss: 0.5760218501091003\n",
      "Epoch [727/10000], Loss: 0.5759856104850769\n",
      "Epoch [728/10000], Loss: 0.5759494304656982\n",
      "Epoch [729/10000], Loss: 0.5759128928184509\n",
      "Epoch [730/10000], Loss: 0.575876772403717\n",
      "Epoch [731/10000], Loss: 0.5758406519889832\n",
      "Epoch [732/10000], Loss: 0.575805127620697\n",
      "Epoch [733/10000], Loss: 0.5757691860198975\n",
      "Epoch [734/10000], Loss: 0.5757330656051636\n",
      "Epoch [735/10000], Loss: 0.5756974220275879\n",
      "Epoch [736/10000], Loss: 0.5756614804267883\n",
      "Epoch [737/10000], Loss: 0.575624942779541\n",
      "Epoch [738/10000], Loss: 0.5755881071090698\n",
      "Epoch [739/10000], Loss: 0.5755504965782166\n",
      "Epoch [740/10000], Loss: 0.5755122303962708\n",
      "Epoch [741/10000], Loss: 0.5754734873771667\n",
      "Epoch [742/10000], Loss: 0.5754353404045105\n",
      "Epoch [743/10000], Loss: 0.5753973126411438\n",
      "Epoch [744/10000], Loss: 0.5753583908081055\n",
      "Epoch [745/10000], Loss: 0.5753195881843567\n",
      "Epoch [746/10000], Loss: 0.5752809643745422\n",
      "Epoch [747/10000], Loss: 0.5752419829368591\n",
      "Epoch [748/10000], Loss: 0.575203537940979\n",
      "Epoch [749/10000], Loss: 0.5751650333404541\n",
      "Epoch [750/10000], Loss: 0.5751256346702576\n",
      "Epoch [751/10000], Loss: 0.5750867128372192\n",
      "Epoch [752/10000], Loss: 0.5750483274459839\n",
      "Epoch [753/10000], Loss: 0.5750102996826172\n",
      "Epoch [754/10000], Loss: 0.5749726891517639\n",
      "Epoch [755/10000], Loss: 0.5749340057373047\n",
      "Epoch [756/10000], Loss: 0.5748955607414246\n",
      "Epoch [757/10000], Loss: 0.5748564600944519\n",
      "Epoch [758/10000], Loss: 0.5748165845870972\n",
      "Epoch [759/10000], Loss: 0.5747771859169006\n",
      "Epoch [760/10000], Loss: 0.5747380256652832\n",
      "Epoch [761/10000], Loss: 0.5746991038322449\n",
      "Epoch [762/10000], Loss: 0.5746611952781677\n",
      "Epoch [763/10000], Loss: 0.5746233463287354\n",
      "Epoch [764/10000], Loss: 0.5745858550071716\n",
      "Epoch [765/10000], Loss: 0.5745478868484497\n",
      "Epoch [766/10000], Loss: 0.5745097994804382\n",
      "Epoch [767/10000], Loss: 0.5744719505310059\n",
      "Epoch [768/10000], Loss: 0.5744342803955078\n",
      "Epoch [769/10000], Loss: 0.5743969678878784\n",
      "Epoch [770/10000], Loss: 0.5743590593338013\n",
      "Epoch [771/10000], Loss: 0.5743212699890137\n",
      "Epoch [772/10000], Loss: 0.5742835402488708\n",
      "Epoch [773/10000], Loss: 0.5742456912994385\n",
      "Epoch [774/10000], Loss: 0.5742083191871643\n",
      "Epoch [775/10000], Loss: 0.574171245098114\n",
      "Epoch [776/10000], Loss: 0.5741355419158936\n",
      "Epoch [777/10000], Loss: 0.5740999579429626\n",
      "Epoch [778/10000], Loss: 0.5740642547607422\n",
      "Epoch [779/10000], Loss: 0.5740292072296143\n",
      "Epoch [780/10000], Loss: 0.573994517326355\n",
      "Epoch [781/10000], Loss: 0.5739611983299255\n",
      "Epoch [782/10000], Loss: 0.573928952217102\n",
      "Epoch [783/10000], Loss: 0.5738961696624756\n",
      "Epoch [784/10000], Loss: 0.5738635659217834\n",
      "Epoch [785/10000], Loss: 0.5738305449485779\n",
      "Epoch [786/10000], Loss: 0.573794960975647\n",
      "Epoch [787/10000], Loss: 0.5737577676773071\n",
      "Epoch [788/10000], Loss: 0.5737196207046509\n",
      "Epoch [789/10000], Loss: 0.5736826062202454\n",
      "Epoch [790/10000], Loss: 0.5736478567123413\n",
      "Epoch [791/10000], Loss: 0.5736150741577148\n",
      "Epoch [792/10000], Loss: 0.5735824108123779\n",
      "Epoch [793/10000], Loss: 0.5735492706298828\n",
      "Epoch [794/10000], Loss: 0.5735164284706116\n",
      "Epoch [795/10000], Loss: 0.573482096195221\n",
      "Epoch [796/10000], Loss: 0.5734466314315796\n",
      "Epoch [797/10000], Loss: 0.5734125375747681\n",
      "Epoch [798/10000], Loss: 0.5733798146247864\n",
      "Epoch [799/10000], Loss: 0.5733478665351868\n",
      "Epoch [800/10000], Loss: 0.5733159184455872\n",
      "Epoch [801/10000], Loss: 0.5732824802398682\n",
      "Epoch [802/10000], Loss: 0.5732484459877014\n",
      "Epoch [803/10000], Loss: 0.573215126991272\n",
      "Epoch [804/10000], Loss: 0.5731837153434753\n",
      "Epoch [805/10000], Loss: 0.5731528997421265\n",
      "Epoch [806/10000], Loss: 0.5731232166290283\n",
      "Epoch [807/10000], Loss: 0.5730936527252197\n",
      "Epoch [808/10000], Loss: 0.5730648636817932\n",
      "Epoch [809/10000], Loss: 0.573035717010498\n",
      "Epoch [810/10000], Loss: 0.573006272315979\n",
      "Epoch [811/10000], Loss: 0.5729770660400391\n",
      "Epoch [812/10000], Loss: 0.5729489326477051\n",
      "Epoch [813/10000], Loss: 0.5729207992553711\n",
      "Epoch [814/10000], Loss: 0.5728930234909058\n",
      "Epoch [815/10000], Loss: 0.5728650093078613\n",
      "Epoch [816/10000], Loss: 0.5728379487991333\n",
      "Epoch [817/10000], Loss: 0.5728119611740112\n",
      "Epoch [818/10000], Loss: 0.5727860927581787\n",
      "Epoch [819/10000], Loss: 0.5727609395980835\n",
      "Epoch [820/10000], Loss: 0.5727365612983704\n",
      "Epoch [821/10000], Loss: 0.5727120041847229\n",
      "Epoch [822/10000], Loss: 0.5726865530014038\n",
      "Epoch [823/10000], Loss: 0.5726608633995056\n",
      "Epoch [824/10000], Loss: 0.5726351141929626\n",
      "Epoch [825/10000], Loss: 0.5726094841957092\n",
      "Epoch [826/10000], Loss: 0.5725841522216797\n",
      "Epoch [827/10000], Loss: 0.5725588798522949\n",
      "Epoch [828/10000], Loss: 0.5725336074829102\n",
      "Epoch [829/10000], Loss: 0.5725080370903015\n",
      "Epoch [830/10000], Loss: 0.5724828243255615\n",
      "Epoch [831/10000], Loss: 0.5724586248397827\n",
      "Epoch [832/10000], Loss: 0.5724347233772278\n",
      "Epoch [833/10000], Loss: 0.5724102854728699\n",
      "Epoch [834/10000], Loss: 0.5723860263824463\n",
      "Epoch [835/10000], Loss: 0.5723623633384705\n",
      "Epoch [836/10000], Loss: 0.5723382830619812\n",
      "Epoch [837/10000], Loss: 0.5723143815994263\n",
      "Epoch [838/10000], Loss: 0.5722903609275818\n",
      "Epoch [839/10000], Loss: 0.5722664594650269\n",
      "Epoch [840/10000], Loss: 0.5722423791885376\n",
      "Epoch [841/10000], Loss: 0.5722184777259827\n",
      "Epoch [842/10000], Loss: 0.5721951127052307\n",
      "Epoch [843/10000], Loss: 0.5721719264984131\n",
      "Epoch [844/10000], Loss: 0.5721486806869507\n",
      "Epoch [845/10000], Loss: 0.5721263885498047\n",
      "Epoch [846/10000], Loss: 0.5721043348312378\n",
      "Epoch [847/10000], Loss: 0.5720824599266052\n",
      "Epoch [848/10000], Loss: 0.5720615386962891\n",
      "Epoch [849/10000], Loss: 0.5720401406288147\n",
      "Epoch [850/10000], Loss: 0.5720171928405762\n",
      "Epoch [851/10000], Loss: 0.5719932913780212\n",
      "Epoch [852/10000], Loss: 0.5719688534736633\n",
      "Epoch [853/10000], Loss: 0.5719448924064636\n",
      "Epoch [854/10000], Loss: 0.5719221830368042\n",
      "Epoch [855/10000], Loss: 0.5719004273414612\n",
      "Epoch [856/10000], Loss: 0.5718793869018555\n",
      "Epoch [857/10000], Loss: 0.571858286857605\n",
      "Epoch [858/10000], Loss: 0.5718370079994202\n",
      "Epoch [859/10000], Loss: 0.5718144774436951\n",
      "Epoch [860/10000], Loss: 0.5717909336090088\n",
      "Epoch [861/10000], Loss: 0.5717669129371643\n",
      "Epoch [862/10000], Loss: 0.5717427134513855\n",
      "Epoch [863/10000], Loss: 0.5717189311981201\n",
      "Epoch [864/10000], Loss: 0.5716949701309204\n",
      "Epoch [865/10000], Loss: 0.5716709494590759\n",
      "Epoch [866/10000], Loss: 0.5716480016708374\n",
      "Epoch [867/10000], Loss: 0.5716239213943481\n",
      "Epoch [868/10000], Loss: 0.571599543094635\n",
      "Epoch [869/10000], Loss: 0.5715753436088562\n",
      "Epoch [870/10000], Loss: 0.5715512037277222\n",
      "Epoch [871/10000], Loss: 0.5715267062187195\n",
      "Epoch [872/10000], Loss: 0.5715023279190063\n",
      "Epoch [873/10000], Loss: 0.5714789628982544\n",
      "Epoch [874/10000], Loss: 0.5714558362960815\n",
      "Epoch [875/10000], Loss: 0.5714333057403564\n",
      "Epoch [876/10000], Loss: 0.5714116096496582\n",
      "Epoch [877/10000], Loss: 0.5713906288146973\n",
      "Epoch [878/10000], Loss: 0.5713695287704468\n",
      "Epoch [879/10000], Loss: 0.571346640586853\n",
      "Epoch [880/10000], Loss: 0.5713232755661011\n",
      "Epoch [881/10000], Loss: 0.5712997317314148\n",
      "Epoch [882/10000], Loss: 0.5712766647338867\n",
      "Epoch [883/10000], Loss: 0.5712532997131348\n",
      "Epoch [884/10000], Loss: 0.5712295174598694\n",
      "Epoch [885/10000], Loss: 0.5712054371833801\n",
      "Epoch [886/10000], Loss: 0.5711815357208252\n",
      "Epoch [887/10000], Loss: 0.5711572170257568\n",
      "Epoch [888/10000], Loss: 0.571132242679596\n",
      "Epoch [889/10000], Loss: 0.5711074471473694\n",
      "Epoch [890/10000], Loss: 0.5710834860801697\n",
      "Epoch [891/10000], Loss: 0.571060061454773\n",
      "Epoch [892/10000], Loss: 0.5710362792015076\n",
      "Epoch [893/10000], Loss: 0.5710129737854004\n",
      "Epoch [894/10000], Loss: 0.570991039276123\n",
      "Epoch [895/10000], Loss: 0.5709690451622009\n",
      "Epoch [896/10000], Loss: 0.5709465742111206\n",
      "Epoch [897/10000], Loss: 0.5709242224693298\n",
      "Epoch [898/10000], Loss: 0.5709013342857361\n",
      "Epoch [899/10000], Loss: 0.5708779096603394\n",
      "Epoch [900/10000], Loss: 0.5708542466163635\n",
      "Epoch [901/10000], Loss: 0.5708306431770325\n",
      "Epoch [902/10000], Loss: 0.5708069205284119\n",
      "Epoch [903/10000], Loss: 0.5707837343215942\n",
      "Epoch [904/10000], Loss: 0.5707601308822632\n",
      "Epoch [905/10000], Loss: 0.5707359313964844\n",
      "Epoch [906/10000], Loss: 0.5707123279571533\n",
      "Epoch [907/10000], Loss: 0.5706890225410461\n",
      "Epoch [908/10000], Loss: 0.5706647038459778\n",
      "Epoch [909/10000], Loss: 0.5706400275230408\n",
      "Epoch [910/10000], Loss: 0.5706154108047485\n",
      "Epoch [911/10000], Loss: 0.5705897808074951\n",
      "Epoch [912/10000], Loss: 0.5705638527870178\n",
      "Epoch [913/10000], Loss: 0.5705388188362122\n",
      "Epoch [914/10000], Loss: 0.570514976978302\n",
      "Epoch [915/10000], Loss: 0.5704917311668396\n",
      "Epoch [916/10000], Loss: 0.5704688429832458\n",
      "Epoch [917/10000], Loss: 0.570446252822876\n",
      "Epoch [918/10000], Loss: 0.5704235434532166\n",
      "Epoch [919/10000], Loss: 0.5704018473625183\n",
      "Epoch [920/10000], Loss: 0.5703800320625305\n",
      "Epoch [921/10000], Loss: 0.5703586339950562\n",
      "Epoch [922/10000], Loss: 0.5703372359275818\n",
      "Epoch [923/10000], Loss: 0.5703161358833313\n",
      "Epoch [924/10000], Loss: 0.5702954530715942\n",
      "Epoch [925/10000], Loss: 0.5702748894691467\n",
      "Epoch [926/10000], Loss: 0.5702541470527649\n",
      "Epoch [927/10000], Loss: 0.5702334046363831\n",
      "Epoch [928/10000], Loss: 0.5702123641967773\n",
      "Epoch [929/10000], Loss: 0.570190966129303\n",
      "Epoch [930/10000], Loss: 0.5701689124107361\n",
      "Epoch [931/10000], Loss: 0.5701457858085632\n",
      "Epoch [932/10000], Loss: 0.5701233744621277\n",
      "Epoch [933/10000], Loss: 0.5701009631156921\n",
      "Epoch [934/10000], Loss: 0.5700782537460327\n",
      "Epoch [935/10000], Loss: 0.5700551271438599\n",
      "Epoch [936/10000], Loss: 0.5700319409370422\n",
      "Epoch [937/10000], Loss: 0.5700089335441589\n",
      "Epoch [938/10000], Loss: 0.5699867010116577\n",
      "Epoch [939/10000], Loss: 0.5699652433395386\n",
      "Epoch [940/10000], Loss: 0.5699447393417358\n",
      "Epoch [941/10000], Loss: 0.56992506980896\n",
      "Epoch [942/10000], Loss: 0.5699055194854736\n",
      "Epoch [943/10000], Loss: 0.5698859691619873\n",
      "Epoch [944/10000], Loss: 0.5698662400245667\n",
      "Epoch [945/10000], Loss: 0.5698462724685669\n",
      "Epoch [946/10000], Loss: 0.569827139377594\n",
      "Epoch [947/10000], Loss: 0.5698080062866211\n",
      "Epoch [948/10000], Loss: 0.5697889924049377\n",
      "Epoch [949/10000], Loss: 0.5697695016860962\n",
      "Epoch [950/10000], Loss: 0.5697495937347412\n",
      "Epoch [951/10000], Loss: 0.5697301626205444\n",
      "Epoch [952/10000], Loss: 0.5697115659713745\n",
      "Epoch [953/10000], Loss: 0.5696930289268494\n",
      "Epoch [954/10000], Loss: 0.5696742534637451\n",
      "Epoch [955/10000], Loss: 0.5696558952331543\n",
      "Epoch [956/10000], Loss: 0.5696375966072083\n",
      "Epoch [957/10000], Loss: 0.5696189403533936\n",
      "Epoch [958/10000], Loss: 0.5696001648902893\n",
      "Epoch [959/10000], Loss: 0.5695821642875671\n",
      "Epoch [960/10000], Loss: 0.5695648193359375\n",
      "Epoch [961/10000], Loss: 0.5695481300354004\n",
      "Epoch [962/10000], Loss: 0.5695313811302185\n",
      "Epoch [963/10000], Loss: 0.5695145130157471\n",
      "Epoch [964/10000], Loss: 0.5694975256919861\n",
      "Epoch [965/10000], Loss: 0.5694806575775146\n",
      "Epoch [966/10000], Loss: 0.5694646239280701\n",
      "Epoch [967/10000], Loss: 0.569448709487915\n",
      "Epoch [968/10000], Loss: 0.5694324374198914\n",
      "Epoch [969/10000], Loss: 0.569415807723999\n",
      "Epoch [970/10000], Loss: 0.5693982243537903\n",
      "Epoch [971/10000], Loss: 0.5693803429603577\n",
      "Epoch [972/10000], Loss: 0.5693621635437012\n",
      "Epoch [973/10000], Loss: 0.5693445205688477\n",
      "Epoch [974/10000], Loss: 0.5693268179893494\n",
      "Epoch [975/10000], Loss: 0.5693095326423645\n",
      "Epoch [976/10000], Loss: 0.5692922472953796\n",
      "Epoch [977/10000], Loss: 0.5692753195762634\n",
      "Epoch [978/10000], Loss: 0.5692582130432129\n",
      "Epoch [979/10000], Loss: 0.5692406892776489\n",
      "Epoch [980/10000], Loss: 0.5692236423492432\n",
      "Epoch [981/10000], Loss: 0.5692070126533508\n",
      "Epoch [982/10000], Loss: 0.5691899061203003\n",
      "Epoch [983/10000], Loss: 0.5691721439361572\n",
      "Epoch [984/10000], Loss: 0.5691551566123962\n",
      "Epoch [985/10000], Loss: 0.5691381096839905\n",
      "Epoch [986/10000], Loss: 0.5691220760345459\n",
      "Epoch [987/10000], Loss: 0.5691057443618774\n",
      "Epoch [988/10000], Loss: 0.5690885782241821\n",
      "Epoch [989/10000], Loss: 0.5690715909004211\n",
      "Epoch [990/10000], Loss: 0.5690552592277527\n",
      "Epoch [991/10000], Loss: 0.569038987159729\n",
      "Epoch [992/10000], Loss: 0.5690224170684814\n",
      "Epoch [993/10000], Loss: 0.5690056681632996\n",
      "Epoch [994/10000], Loss: 0.5689888000488281\n",
      "Epoch [995/10000], Loss: 0.5689724683761597\n",
      "Epoch [996/10000], Loss: 0.5689554810523987\n",
      "Epoch [997/10000], Loss: 0.5689387321472168\n",
      "Epoch [998/10000], Loss: 0.5689220428466797\n",
      "Epoch [999/10000], Loss: 0.5689049363136292\n",
      "Epoch [1000/10000], Loss: 0.5688880681991577\n",
      "Epoch [1001/10000], Loss: 0.5688713192939758\n",
      "Epoch [1002/10000], Loss: 0.5688554048538208\n",
      "Epoch [1003/10000], Loss: 0.5688388347625732\n",
      "Epoch [1004/10000], Loss: 0.568821907043457\n",
      "Epoch [1005/10000], Loss: 0.5688049793243408\n",
      "Epoch [1006/10000], Loss: 0.5687880516052246\n",
      "Epoch [1007/10000], Loss: 0.5687716007232666\n",
      "Epoch [1008/10000], Loss: 0.5687553882598877\n",
      "Epoch [1009/10000], Loss: 0.5687394738197327\n",
      "Epoch [1010/10000], Loss: 0.5687242150306702\n",
      "Epoch [1011/10000], Loss: 0.5687092542648315\n",
      "Epoch [1012/10000], Loss: 0.5686940550804138\n",
      "Epoch [1013/10000], Loss: 0.568678081035614\n",
      "Epoch [1014/10000], Loss: 0.5686621069908142\n",
      "Epoch [1015/10000], Loss: 0.5686463713645935\n",
      "Epoch [1016/10000], Loss: 0.5686296224594116\n",
      "Epoch [1017/10000], Loss: 0.5686127543449402\n",
      "Epoch [1018/10000], Loss: 0.5685958862304688\n",
      "Epoch [1019/10000], Loss: 0.5685787796974182\n",
      "Epoch [1020/10000], Loss: 0.5685626864433289\n",
      "Epoch [1021/10000], Loss: 0.5685471892356873\n",
      "Epoch [1022/10000], Loss: 0.5685311555862427\n",
      "Epoch [1023/10000], Loss: 0.5685158371925354\n",
      "Epoch [1024/10000], Loss: 0.5685015320777893\n",
      "Epoch [1025/10000], Loss: 0.5684874057769775\n",
      "Epoch [1026/10000], Loss: 0.5684719085693359\n",
      "Epoch [1027/10000], Loss: 0.568454384803772\n",
      "Epoch [1028/10000], Loss: 0.5684351921081543\n",
      "Epoch [1029/10000], Loss: 0.5684146881103516\n",
      "Epoch [1030/10000], Loss: 0.5683959722518921\n",
      "Epoch [1031/10000], Loss: 0.5683797597885132\n",
      "Epoch [1032/10000], Loss: 0.5683653354644775\n",
      "Epoch [1033/10000], Loss: 0.5683513879776001\n",
      "Epoch [1034/10000], Loss: 0.5683366656303406\n",
      "Epoch [1035/10000], Loss: 0.5683211088180542\n",
      "Epoch [1036/10000], Loss: 0.5683049559593201\n",
      "Epoch [1037/10000], Loss: 0.5682880878448486\n",
      "Epoch [1038/10000], Loss: 0.5682708024978638\n",
      "Epoch [1039/10000], Loss: 0.5682547688484192\n",
      "Epoch [1040/10000], Loss: 0.5682401061058044\n",
      "Epoch [1041/10000], Loss: 0.5682270526885986\n",
      "Epoch [1042/10000], Loss: 0.5682145357131958\n",
      "Epoch [1043/10000], Loss: 0.56820148229599\n",
      "Epoch [1044/10000], Loss: 0.5681876540184021\n",
      "Epoch [1045/10000], Loss: 0.568173348903656\n",
      "Epoch [1046/10000], Loss: 0.5681599378585815\n",
      "Epoch [1047/10000], Loss: 0.568147599697113\n",
      "Epoch [1048/10000], Loss: 0.5681360363960266\n",
      "Epoch [1049/10000], Loss: 0.5681244730949402\n",
      "Epoch [1050/10000], Loss: 0.5681135058403015\n",
      "Epoch [1051/10000], Loss: 0.5681032538414001\n",
      "Epoch [1052/10000], Loss: 0.568092942237854\n",
      "Epoch [1053/10000], Loss: 0.5680822730064392\n",
      "Epoch [1054/10000], Loss: 0.5680713653564453\n",
      "Epoch [1055/10000], Loss: 0.5680608749389648\n",
      "Epoch [1056/10000], Loss: 0.5680512189865112\n",
      "Epoch [1057/10000], Loss: 0.5680425763130188\n",
      "Epoch [1058/10000], Loss: 0.5680341720581055\n",
      "Epoch [1059/10000], Loss: 0.5680252909660339\n",
      "Epoch [1060/10000], Loss: 0.5680159330368042\n",
      "Epoch [1061/10000], Loss: 0.5680053234100342\n",
      "Epoch [1062/10000], Loss: 0.5679934620857239\n",
      "Epoch [1063/10000], Loss: 0.5679806470870972\n",
      "Epoch [1064/10000], Loss: 0.5679685473442078\n",
      "Epoch [1065/10000], Loss: 0.5679576992988586\n",
      "Epoch [1066/10000], Loss: 0.5679476261138916\n",
      "Epoch [1067/10000], Loss: 0.5679391622543335\n",
      "Epoch [1068/10000], Loss: 0.5679318904876709\n",
      "Epoch [1069/10000], Loss: 0.5679245591163635\n",
      "Epoch [1070/10000], Loss: 0.5679165124893188\n",
      "Epoch [1071/10000], Loss: 0.5679079294204712\n",
      "Epoch [1072/10000], Loss: 0.5678987503051758\n",
      "Epoch [1073/10000], Loss: 0.5678887963294983\n",
      "Epoch [1074/10000], Loss: 0.5678784251213074\n",
      "Epoch [1075/10000], Loss: 0.5678682327270508\n",
      "Epoch [1076/10000], Loss: 0.5678583979606628\n",
      "Epoch [1077/10000], Loss: 0.567848801612854\n",
      "Epoch [1078/10000], Loss: 0.5678402185440063\n",
      "Epoch [1079/10000], Loss: 0.5678310990333557\n",
      "Epoch [1080/10000], Loss: 0.5678228139877319\n",
      "Epoch [1081/10000], Loss: 0.5678142309188843\n",
      "Epoch [1082/10000], Loss: 0.5678051114082336\n",
      "Epoch [1083/10000], Loss: 0.5677958726882935\n",
      "Epoch [1084/10000], Loss: 0.5677862763404846\n",
      "Epoch [1085/10000], Loss: 0.5677765607833862\n",
      "Epoch [1086/10000], Loss: 0.5677664875984192\n",
      "Epoch [1087/10000], Loss: 0.5677564740180969\n",
      "Epoch [1088/10000], Loss: 0.567746639251709\n",
      "Epoch [1089/10000], Loss: 0.5677369236946106\n",
      "Epoch [1090/10000], Loss: 0.5677278637886047\n",
      "Epoch [1091/10000], Loss: 0.567718505859375\n",
      "Epoch [1092/10000], Loss: 0.5677098631858826\n",
      "Epoch [1093/10000], Loss: 0.5677008628845215\n",
      "Epoch [1094/10000], Loss: 0.5676912665367126\n",
      "Epoch [1095/10000], Loss: 0.5676811933517456\n",
      "Epoch [1096/10000], Loss: 0.5676702260971069\n",
      "Epoch [1097/10000], Loss: 0.5676594376564026\n",
      "Epoch [1098/10000], Loss: 0.56764817237854\n",
      "Epoch [1099/10000], Loss: 0.5676369071006775\n",
      "Epoch [1100/10000], Loss: 0.5676255822181702\n",
      "Epoch [1101/10000], Loss: 0.5676137804985046\n",
      "Epoch [1102/10000], Loss: 0.5676020979881287\n",
      "Epoch [1103/10000], Loss: 0.5675908327102661\n",
      "Epoch [1104/10000], Loss: 0.5675800442695618\n",
      "Epoch [1105/10000], Loss: 0.5675693154335022\n",
      "Epoch [1106/10000], Loss: 0.5675588846206665\n",
      "Epoch [1107/10000], Loss: 0.5675491690635681\n",
      "Epoch [1108/10000], Loss: 0.5675402283668518\n",
      "Epoch [1109/10000], Loss: 0.5675316452980042\n",
      "Epoch [1110/10000], Loss: 0.5675228834152222\n",
      "Epoch [1111/10000], Loss: 0.5675140619277954\n",
      "Epoch [1112/10000], Loss: 0.567505419254303\n",
      "Epoch [1113/10000], Loss: 0.5674958825111389\n",
      "Epoch [1114/10000], Loss: 0.5674859285354614\n",
      "Epoch [1115/10000], Loss: 0.5674751400947571\n",
      "Epoch [1116/10000], Loss: 0.5674643516540527\n",
      "Epoch [1117/10000], Loss: 0.5674541592597961\n",
      "Epoch [1118/10000], Loss: 0.5674440264701843\n",
      "Epoch [1119/10000], Loss: 0.5674336552619934\n",
      "Epoch [1120/10000], Loss: 0.5674241781234741\n",
      "Epoch [1121/10000], Loss: 0.5674149990081787\n",
      "Epoch [1122/10000], Loss: 0.5674057602882385\n",
      "Epoch [1123/10000], Loss: 0.5673967003822327\n",
      "Epoch [1124/10000], Loss: 0.5673877596855164\n",
      "Epoch [1125/10000], Loss: 0.5673789978027344\n",
      "Epoch [1126/10000], Loss: 0.5673704743385315\n",
      "Epoch [1127/10000], Loss: 0.56736159324646\n",
      "Epoch [1128/10000], Loss: 0.5673531889915466\n",
      "Epoch [1129/10000], Loss: 0.5673450827598572\n",
      "Epoch [1130/10000], Loss: 0.5673365592956543\n",
      "Epoch [1131/10000], Loss: 0.5673279762268066\n",
      "Epoch [1132/10000], Loss: 0.5673192739486694\n",
      "Epoch [1133/10000], Loss: 0.5673105120658875\n",
      "Epoch [1134/10000], Loss: 0.5673012733459473\n",
      "Epoch [1135/10000], Loss: 0.5672923922538757\n",
      "Epoch [1136/10000], Loss: 0.5672836899757385\n",
      "Epoch [1137/10000], Loss: 0.5672740936279297\n",
      "Epoch [1138/10000], Loss: 0.5672649145126343\n",
      "Epoch [1139/10000], Loss: 0.5672546625137329\n",
      "Epoch [1140/10000], Loss: 0.5672434568405151\n",
      "Epoch [1141/10000], Loss: 0.5672320127487183\n",
      "Epoch [1142/10000], Loss: 0.5672197937965393\n",
      "Epoch [1143/10000], Loss: 0.5672078132629395\n",
      "Epoch [1144/10000], Loss: 0.5671961307525635\n",
      "Epoch [1145/10000], Loss: 0.5671849250793457\n",
      "Epoch [1146/10000], Loss: 0.5671747922897339\n",
      "Epoch [1147/10000], Loss: 0.5671653747558594\n",
      "Epoch [1148/10000], Loss: 0.5671564340591431\n",
      "Epoch [1149/10000], Loss: 0.5671463012695312\n",
      "Epoch [1150/10000], Loss: 0.5671366453170776\n",
      "Epoch [1151/10000], Loss: 0.5671270489692688\n",
      "Epoch [1152/10000], Loss: 0.5671170949935913\n",
      "Epoch [1153/10000], Loss: 0.567107081413269\n",
      "Epoch [1154/10000], Loss: 0.5670966506004333\n",
      "Epoch [1155/10000], Loss: 0.5670868754386902\n",
      "Epoch [1156/10000], Loss: 0.5670764446258545\n",
      "Epoch [1157/10000], Loss: 0.5670651793479919\n",
      "Epoch [1158/10000], Loss: 0.5670540928840637\n",
      "Epoch [1159/10000], Loss: 0.5670431852340698\n",
      "Epoch [1160/10000], Loss: 0.5670326352119446\n",
      "Epoch [1161/10000], Loss: 0.5670214295387268\n",
      "Epoch [1162/10000], Loss: 0.567010223865509\n",
      "Epoch [1163/10000], Loss: 0.5669992566108704\n",
      "Epoch [1164/10000], Loss: 0.5669880509376526\n",
      "Epoch [1165/10000], Loss: 0.5669769644737244\n",
      "Epoch [1166/10000], Loss: 0.5669655203819275\n",
      "Epoch [1167/10000], Loss: 0.5669543147087097\n",
      "Epoch [1168/10000], Loss: 0.5669432878494263\n",
      "Epoch [1169/10000], Loss: 0.5669333338737488\n",
      "Epoch [1170/10000], Loss: 0.5669236183166504\n",
      "Epoch [1171/10000], Loss: 0.5669146776199341\n",
      "Epoch [1172/10000], Loss: 0.56690514087677\n",
      "Epoch [1173/10000], Loss: 0.5668954253196716\n",
      "Epoch [1174/10000], Loss: 0.5668858289718628\n",
      "Epoch [1175/10000], Loss: 0.5668757557868958\n",
      "Epoch [1176/10000], Loss: 0.5668660998344421\n",
      "Epoch [1177/10000], Loss: 0.5668563842773438\n",
      "Epoch [1178/10000], Loss: 0.5668461918830872\n",
      "Epoch [1179/10000], Loss: 0.5668363571166992\n",
      "Epoch [1180/10000], Loss: 0.5668256282806396\n",
      "Epoch [1181/10000], Loss: 0.5668148994445801\n",
      "Epoch [1182/10000], Loss: 0.5668041706085205\n",
      "Epoch [1183/10000], Loss: 0.5667936205863953\n",
      "Epoch [1184/10000], Loss: 0.566783607006073\n",
      "Epoch [1185/10000], Loss: 0.5667738914489746\n",
      "Epoch [1186/10000], Loss: 0.5667639970779419\n",
      "Epoch [1187/10000], Loss: 0.5667537450790405\n",
      "Epoch [1188/10000], Loss: 0.5667430758476257\n",
      "Epoch [1189/10000], Loss: 0.5667321681976318\n",
      "Epoch [1190/10000], Loss: 0.566721498966217\n",
      "Epoch [1191/10000], Loss: 0.5667113065719604\n",
      "Epoch [1192/10000], Loss: 0.5667011141777039\n",
      "Epoch [1193/10000], Loss: 0.5666908621788025\n",
      "Epoch [1194/10000], Loss: 0.5666804313659668\n",
      "Epoch [1195/10000], Loss: 0.5666696429252625\n",
      "Epoch [1196/10000], Loss: 0.5666584372520447\n",
      "Epoch [1197/10000], Loss: 0.5666475892066956\n",
      "Epoch [1198/10000], Loss: 0.5666365623474121\n",
      "Epoch [1199/10000], Loss: 0.5666248798370361\n",
      "Epoch [1200/10000], Loss: 0.5666130185127258\n",
      "Epoch [1201/10000], Loss: 0.566601574420929\n",
      "Epoch [1202/10000], Loss: 0.5665904879570007\n",
      "Epoch [1203/10000], Loss: 0.5665797591209412\n",
      "Epoch [1204/10000], Loss: 0.5665689706802368\n",
      "Epoch [1205/10000], Loss: 0.566558301448822\n",
      "Epoch [1206/10000], Loss: 0.5665478706359863\n",
      "Epoch [1207/10000], Loss: 0.5665372014045715\n",
      "Epoch [1208/10000], Loss: 0.5665263533592224\n",
      "Epoch [1209/10000], Loss: 0.5665160417556763\n",
      "Epoch [1210/10000], Loss: 0.5665053725242615\n",
      "Epoch [1211/10000], Loss: 0.5664944052696228\n",
      "Epoch [1212/10000], Loss: 0.5664831399917603\n",
      "Epoch [1213/10000], Loss: 0.566471517086029\n",
      "Epoch [1214/10000], Loss: 0.5664600133895874\n",
      "Epoch [1215/10000], Loss: 0.5664492845535278\n",
      "Epoch [1216/10000], Loss: 0.5664383769035339\n",
      "Epoch [1217/10000], Loss: 0.5664276480674744\n",
      "Epoch [1218/10000], Loss: 0.5664174556732178\n",
      "Epoch [1219/10000], Loss: 0.5664078593254089\n",
      "Epoch [1220/10000], Loss: 0.5663987398147583\n",
      "Epoch [1221/10000], Loss: 0.5663893222808838\n",
      "Epoch [1222/10000], Loss: 0.5663797855377197\n",
      "Epoch [1223/10000], Loss: 0.5663707256317139\n",
      "Epoch [1224/10000], Loss: 0.5663618445396423\n",
      "Epoch [1225/10000], Loss: 0.5663536190986633\n",
      "Epoch [1226/10000], Loss: 0.56634521484375\n",
      "Epoch [1227/10000], Loss: 0.5663363933563232\n",
      "Epoch [1228/10000], Loss: 0.5663283467292786\n",
      "Epoch [1229/10000], Loss: 0.5663201808929443\n",
      "Epoch [1230/10000], Loss: 0.566311776638031\n",
      "Epoch [1231/10000], Loss: 0.5663030743598938\n",
      "Epoch [1232/10000], Loss: 0.5662944912910461\n",
      "Epoch [1233/10000], Loss: 0.5662863850593567\n",
      "Epoch [1234/10000], Loss: 0.566278874874115\n",
      "Epoch [1235/10000], Loss: 0.5662714838981628\n",
      "Epoch [1236/10000], Loss: 0.5662639141082764\n",
      "Epoch [1237/10000], Loss: 0.5662561655044556\n",
      "Epoch [1238/10000], Loss: 0.5662484169006348\n",
      "Epoch [1239/10000], Loss: 0.566240131855011\n",
      "Epoch [1240/10000], Loss: 0.5662304162979126\n",
      "Epoch [1241/10000], Loss: 0.5662209987640381\n",
      "Epoch [1242/10000], Loss: 0.5662121176719666\n",
      "Epoch [1243/10000], Loss: 0.5662038922309875\n",
      "Epoch [1244/10000], Loss: 0.5661960244178772\n",
      "Epoch [1245/10000], Loss: 0.5661889314651489\n",
      "Epoch [1246/10000], Loss: 0.5661821365356445\n",
      "Epoch [1247/10000], Loss: 0.5661758780479431\n",
      "Epoch [1248/10000], Loss: 0.566170334815979\n",
      "Epoch [1249/10000], Loss: 0.5661665201187134\n",
      "Epoch [1250/10000], Loss: 0.5661619901657104\n",
      "Epoch [1251/10000], Loss: 0.5661577582359314\n",
      "Epoch [1252/10000], Loss: 0.5661529302597046\n",
      "Epoch [1253/10000], Loss: 0.5661472678184509\n",
      "Epoch [1254/10000], Loss: 0.5661394596099854\n",
      "Epoch [1255/10000], Loss: 0.5661292672157288\n",
      "Epoch [1256/10000], Loss: 0.5661174058914185\n",
      "Epoch [1257/10000], Loss: 0.5661051273345947\n",
      "Epoch [1258/10000], Loss: 0.5660930275917053\n",
      "Epoch [1259/10000], Loss: 0.5660822987556458\n",
      "Epoch [1260/10000], Loss: 0.5660735964775085\n",
      "Epoch [1261/10000], Loss: 0.5660667419433594\n",
      "Epoch [1262/10000], Loss: 0.5660606622695923\n",
      "Epoch [1263/10000], Loss: 0.5660549998283386\n",
      "Epoch [1264/10000], Loss: 0.5660495758056641\n",
      "Epoch [1265/10000], Loss: 0.5660445094108582\n",
      "Epoch [1266/10000], Loss: 0.5660383105278015\n",
      "Epoch [1267/10000], Loss: 0.5660313963890076\n",
      "Epoch [1268/10000], Loss: 0.5660229921340942\n",
      "Epoch [1269/10000], Loss: 0.5660141110420227\n",
      "Epoch [1270/10000], Loss: 0.5660050511360168\n",
      "Epoch [1271/10000], Loss: 0.5659970045089722\n",
      "Epoch [1272/10000], Loss: 0.5659888386726379\n",
      "Epoch [1273/10000], Loss: 0.5659811496734619\n",
      "Epoch [1274/10000], Loss: 0.5659738779067993\n",
      "Epoch [1275/10000], Loss: 0.5659679770469666\n",
      "Epoch [1276/10000], Loss: 0.5659622550010681\n",
      "Epoch [1277/10000], Loss: 0.5659571290016174\n",
      "Epoch [1278/10000], Loss: 0.5659515261650085\n",
      "Epoch [1279/10000], Loss: 0.5659451484680176\n",
      "Epoch [1280/10000], Loss: 0.5659383535385132\n",
      "Epoch [1281/10000], Loss: 0.5659318566322327\n",
      "Epoch [1282/10000], Loss: 0.5659248232841492\n",
      "Epoch [1283/10000], Loss: 0.5659177303314209\n",
      "Epoch [1284/10000], Loss: 0.5659109950065613\n",
      "Epoch [1285/10000], Loss: 0.565904974937439\n",
      "Epoch [1286/10000], Loss: 0.5658989548683167\n",
      "Epoch [1287/10000], Loss: 0.5658929347991943\n",
      "Epoch [1288/10000], Loss: 0.5658871531486511\n",
      "Epoch [1289/10000], Loss: 0.5658815503120422\n",
      "Epoch [1290/10000], Loss: 0.565875768661499\n",
      "Epoch [1291/10000], Loss: 0.5658701658248901\n",
      "Epoch [1292/10000], Loss: 0.5658643841743469\n",
      "Epoch [1293/10000], Loss: 0.5658585429191589\n",
      "Epoch [1294/10000], Loss: 0.5658528804779053\n",
      "Epoch [1295/10000], Loss: 0.5658481121063232\n",
      "Epoch [1296/10000], Loss: 0.565843403339386\n",
      "Epoch [1297/10000], Loss: 0.5658386945724487\n",
      "Epoch [1298/10000], Loss: 0.5658342242240906\n",
      "Epoch [1299/10000], Loss: 0.5658297538757324\n",
      "Epoch [1300/10000], Loss: 0.5658254027366638\n",
      "Epoch [1301/10000], Loss: 0.5658208727836609\n",
      "Epoch [1302/10000], Loss: 0.5658158659934998\n",
      "Epoch [1303/10000], Loss: 0.5658103823661804\n",
      "Epoch [1304/10000], Loss: 0.5658047199249268\n",
      "Epoch [1305/10000], Loss: 0.5657985806465149\n",
      "Epoch [1306/10000], Loss: 0.5657926201820374\n",
      "Epoch [1307/10000], Loss: 0.565786600112915\n",
      "Epoch [1308/10000], Loss: 0.5657806992530823\n",
      "Epoch [1309/10000], Loss: 0.5657746195793152\n",
      "Epoch [1310/10000], Loss: 0.5657689571380615\n",
      "Epoch [1311/10000], Loss: 0.5657636523246765\n",
      "Epoch [1312/10000], Loss: 0.565758228302002\n",
      "Epoch [1313/10000], Loss: 0.5657534003257751\n",
      "Epoch [1314/10000], Loss: 0.565748393535614\n",
      "Epoch [1315/10000], Loss: 0.565743625164032\n",
      "Epoch [1316/10000], Loss: 0.5657393932342529\n",
      "Epoch [1317/10000], Loss: 0.5657356381416321\n",
      "Epoch [1318/10000], Loss: 0.5657321214675903\n",
      "Epoch [1319/10000], Loss: 0.565728485584259\n",
      "Epoch [1320/10000], Loss: 0.5657250285148621\n",
      "Epoch [1321/10000], Loss: 0.5657217502593994\n",
      "Epoch [1322/10000], Loss: 0.5657179355621338\n",
      "Epoch [1323/10000], Loss: 0.5657137036323547\n",
      "Epoch [1324/10000], Loss: 0.5657082796096802\n",
      "Epoch [1325/10000], Loss: 0.5657015442848206\n",
      "Epoch [1326/10000], Loss: 0.5656943321228027\n",
      "Epoch [1327/10000], Loss: 0.5656870007514954\n",
      "Epoch [1328/10000], Loss: 0.5656796097755432\n",
      "Epoch [1329/10000], Loss: 0.5656722187995911\n",
      "Epoch [1330/10000], Loss: 0.5656654238700867\n",
      "Epoch [1331/10000], Loss: 0.5656598210334778\n",
      "Epoch [1332/10000], Loss: 0.5656545162200928\n",
      "Epoch [1333/10000], Loss: 0.5656493306159973\n",
      "Epoch [1334/10000], Loss: 0.5656449794769287\n",
      "Epoch [1335/10000], Loss: 0.5656402707099915\n",
      "Epoch [1336/10000], Loss: 0.5656358003616333\n",
      "Epoch [1337/10000], Loss: 0.5656312108039856\n",
      "Epoch [1338/10000], Loss: 0.5656270980834961\n",
      "Epoch [1339/10000], Loss: 0.565622091293335\n",
      "Epoch [1340/10000], Loss: 0.565617024898529\n",
      "Epoch [1341/10000], Loss: 0.5656110644340515\n",
      "Epoch [1342/10000], Loss: 0.5656047463417053\n",
      "Epoch [1343/10000], Loss: 0.5655984282493591\n",
      "Epoch [1344/10000], Loss: 0.5655909776687622\n",
      "Epoch [1345/10000], Loss: 0.5655832886695862\n",
      "Epoch [1346/10000], Loss: 0.565575361251831\n",
      "Epoch [1347/10000], Loss: 0.5655673742294312\n",
      "Epoch [1348/10000], Loss: 0.565559983253479\n",
      "Epoch [1349/10000], Loss: 0.5655534863471985\n",
      "Epoch [1350/10000], Loss: 0.5655473470687866\n",
      "Epoch [1351/10000], Loss: 0.5655418038368225\n",
      "Epoch [1352/10000], Loss: 0.5655356049537659\n",
      "Epoch [1353/10000], Loss: 0.565529465675354\n",
      "Epoch [1354/10000], Loss: 0.5655235052108765\n",
      "Epoch [1355/10000], Loss: 0.5655175447463989\n",
      "Epoch [1356/10000], Loss: 0.5655120015144348\n",
      "Epoch [1357/10000], Loss: 0.5655064582824707\n",
      "Epoch [1358/10000], Loss: 0.5655014514923096\n",
      "Epoch [1359/10000], Loss: 0.5654954314231873\n",
      "Epoch [1360/10000], Loss: 0.5654897093772888\n",
      "Epoch [1361/10000], Loss: 0.5654844045639038\n",
      "Epoch [1362/10000], Loss: 0.5654790997505188\n",
      "Epoch [1363/10000], Loss: 0.5654736161231995\n",
      "Epoch [1364/10000], Loss: 0.5654685497283936\n",
      "Epoch [1365/10000], Loss: 0.5654633045196533\n",
      "Epoch [1366/10000], Loss: 0.5654581785202026\n",
      "Epoch [1367/10000], Loss: 0.565453052520752\n",
      "Epoch [1368/10000], Loss: 0.5654477477073669\n",
      "Epoch [1369/10000], Loss: 0.5654424428939819\n",
      "Epoch [1370/10000], Loss: 0.565437376499176\n",
      "Epoch [1371/10000], Loss: 0.5654325485229492\n",
      "Epoch [1372/10000], Loss: 0.5654271841049194\n",
      "Epoch [1373/10000], Loss: 0.5654215812683105\n",
      "Epoch [1374/10000], Loss: 0.5654162168502808\n",
      "Epoch [1375/10000], Loss: 0.5654114484786987\n",
      "Epoch [1376/10000], Loss: 0.5654062628746033\n",
      "Epoch [1377/10000], Loss: 0.5654006600379944\n",
      "Epoch [1378/10000], Loss: 0.5653948783874512\n",
      "Epoch [1379/10000], Loss: 0.5653889179229736\n",
      "Epoch [1380/10000], Loss: 0.5653835535049438\n",
      "Epoch [1381/10000], Loss: 0.565377950668335\n",
      "Epoch [1382/10000], Loss: 0.5653725266456604\n",
      "Epoch [1383/10000], Loss: 0.5653668642044067\n",
      "Epoch [1384/10000], Loss: 0.5653610825538635\n",
      "Epoch [1385/10000], Loss: 0.5653553009033203\n",
      "Epoch [1386/10000], Loss: 0.5653498768806458\n",
      "Epoch [1387/10000], Loss: 0.565344512462616\n",
      "Epoch [1388/10000], Loss: 0.5653393268585205\n",
      "Epoch [1389/10000], Loss: 0.5653339624404907\n",
      "Epoch [1390/10000], Loss: 0.5653286576271057\n",
      "Epoch [1391/10000], Loss: 0.5653239488601685\n",
      "Epoch [1392/10000], Loss: 0.5653197765350342\n",
      "Epoch [1393/10000], Loss: 0.565316915512085\n",
      "Epoch [1394/10000], Loss: 0.5653141736984253\n",
      "Epoch [1395/10000], Loss: 0.5653120875358582\n",
      "Epoch [1396/10000], Loss: 0.5653094053268433\n",
      "Epoch [1397/10000], Loss: 0.5653051733970642\n",
      "Epoch [1398/10000], Loss: 0.5652981996536255\n",
      "Epoch [1399/10000], Loss: 0.5652883648872375\n",
      "Epoch [1400/10000], Loss: 0.5652775168418884\n",
      "Epoch [1401/10000], Loss: 0.5652683973312378\n",
      "Epoch [1402/10000], Loss: 0.56526118516922\n",
      "Epoch [1403/10000], Loss: 0.5652562379837036\n",
      "Epoch [1404/10000], Loss: 0.5652518272399902\n",
      "Epoch [1405/10000], Loss: 0.5652475953102112\n",
      "Epoch [1406/10000], Loss: 0.5652416348457336\n",
      "Epoch [1407/10000], Loss: 0.5652336478233337\n",
      "Epoch [1408/10000], Loss: 0.5652256011962891\n",
      "Epoch [1409/10000], Loss: 0.5652177333831787\n",
      "Epoch [1410/10000], Loss: 0.5652113556861877\n",
      "Epoch [1411/10000], Loss: 0.5652069449424744\n",
      "Epoch [1412/10000], Loss: 0.5652039051055908\n",
      "Epoch [1413/10000], Loss: 0.5652011632919312\n",
      "Epoch [1414/10000], Loss: 0.5651972889900208\n",
      "Epoch [1415/10000], Loss: 0.5651922821998596\n",
      "Epoch [1416/10000], Loss: 0.5651863813400269\n",
      "Epoch [1417/10000], Loss: 0.565179705619812\n",
      "Epoch [1418/10000], Loss: 0.5651732683181763\n",
      "Epoch [1419/10000], Loss: 0.5651677250862122\n",
      "Epoch [1420/10000], Loss: 0.5651629567146301\n",
      "Epoch [1421/10000], Loss: 0.5651592016220093\n",
      "Epoch [1422/10000], Loss: 0.5651552677154541\n",
      "Epoch [1423/10000], Loss: 0.5651505589485168\n",
      "Epoch [1424/10000], Loss: 0.5651448965072632\n",
      "Epoch [1425/10000], Loss: 0.5651389956474304\n",
      "Epoch [1426/10000], Loss: 0.5651332139968872\n",
      "Epoch [1427/10000], Loss: 0.5651280283927917\n",
      "Epoch [1428/10000], Loss: 0.5651230216026306\n",
      "Epoch [1429/10000], Loss: 0.5651180744171143\n",
      "Epoch [1430/10000], Loss: 0.5651136636734009\n",
      "Epoch [1431/10000], Loss: 0.5651089549064636\n",
      "Epoch [1432/10000], Loss: 0.5651048421859741\n",
      "Epoch [1433/10000], Loss: 0.5651009678840637\n",
      "Epoch [1434/10000], Loss: 0.5650966763496399\n",
      "Epoch [1435/10000], Loss: 0.5650926232337952\n",
      "Epoch [1436/10000], Loss: 0.5650888681411743\n",
      "Epoch [1437/10000], Loss: 0.5650852918624878\n",
      "Epoch [1438/10000], Loss: 0.565081775188446\n",
      "Epoch [1439/10000], Loss: 0.5650787949562073\n",
      "Epoch [1440/10000], Loss: 0.5650764107704163\n",
      "Epoch [1441/10000], Loss: 0.5650736093521118\n",
      "Epoch [1442/10000], Loss: 0.5650705695152283\n",
      "Epoch [1443/10000], Loss: 0.5650676488876343\n",
      "Epoch [1444/10000], Loss: 0.5650641322135925\n",
      "Epoch [1445/10000], Loss: 0.5650608539581299\n",
      "Epoch [1446/10000], Loss: 0.565056562423706\n",
      "Epoch [1447/10000], Loss: 0.565051257610321\n",
      "Epoch [1448/10000], Loss: 0.5650454759597778\n",
      "Epoch [1449/10000], Loss: 0.5650399923324585\n",
      "Epoch [1450/10000], Loss: 0.565034806728363\n",
      "Epoch [1451/10000], Loss: 0.5650294423103333\n",
      "Epoch [1452/10000], Loss: 0.5650247931480408\n",
      "Epoch [1453/10000], Loss: 0.5650205016136169\n",
      "Epoch [1454/10000], Loss: 0.565015971660614\n",
      "Epoch [1455/10000], Loss: 0.5650118589401245\n",
      "Epoch [1456/10000], Loss: 0.5650076270103455\n",
      "Epoch [1457/10000], Loss: 0.5650038719177246\n",
      "Epoch [1458/10000], Loss: 0.5649996995925903\n",
      "Epoch [1459/10000], Loss: 0.5649962425231934\n",
      "Epoch [1460/10000], Loss: 0.5649928450584412\n",
      "Epoch [1461/10000], Loss: 0.5649893879890442\n",
      "Epoch [1462/10000], Loss: 0.564985454082489\n",
      "Epoch [1463/10000], Loss: 0.5649816989898682\n",
      "Epoch [1464/10000], Loss: 0.564978301525116\n",
      "Epoch [1465/10000], Loss: 0.5649749040603638\n",
      "Epoch [1466/10000], Loss: 0.5649715662002563\n",
      "Epoch [1467/10000], Loss: 0.5649688839912415\n",
      "Epoch [1468/10000], Loss: 0.5649664402008057\n",
      "Epoch [1469/10000], Loss: 0.5649639368057251\n",
      "Epoch [1470/10000], Loss: 0.5649616718292236\n",
      "Epoch [1471/10000], Loss: 0.5649594664573669\n",
      "Epoch [1472/10000], Loss: 0.5649574995040894\n",
      "Epoch [1473/10000], Loss: 0.56495600938797\n",
      "Epoch [1474/10000], Loss: 0.5649541020393372\n",
      "Epoch [1475/10000], Loss: 0.5649510622024536\n",
      "Epoch [1476/10000], Loss: 0.5649466514587402\n",
      "Epoch [1477/10000], Loss: 0.5649410486221313\n",
      "Epoch [1478/10000], Loss: 0.5649347305297852\n",
      "Epoch [1479/10000], Loss: 0.5649275779724121\n",
      "Epoch [1480/10000], Loss: 0.5649210214614868\n",
      "Epoch [1481/10000], Loss: 0.564915120601654\n",
      "Epoch [1482/10000], Loss: 0.5649095177650452\n",
      "Epoch [1483/10000], Loss: 0.5649045705795288\n",
      "Epoch [1484/10000], Loss: 0.5648996233940125\n",
      "Epoch [1485/10000], Loss: 0.56489497423172\n",
      "Epoch [1486/10000], Loss: 0.56489098072052\n",
      "Epoch [1487/10000], Loss: 0.5648873448371887\n",
      "Epoch [1488/10000], Loss: 0.5648837685585022\n",
      "Epoch [1489/10000], Loss: 0.5648799538612366\n",
      "Epoch [1490/10000], Loss: 0.5648766160011292\n",
      "Epoch [1491/10000], Loss: 0.5648731589317322\n",
      "Epoch [1492/10000], Loss: 0.5648701190948486\n",
      "Epoch [1493/10000], Loss: 0.5648667812347412\n",
      "Epoch [1494/10000], Loss: 0.564863920211792\n",
      "Epoch [1495/10000], Loss: 0.5648610591888428\n",
      "Epoch [1496/10000], Loss: 0.5648583173751831\n",
      "Epoch [1497/10000], Loss: 0.5648559331893921\n",
      "Epoch [1498/10000], Loss: 0.564853310585022\n",
      "Epoch [1499/10000], Loss: 0.5648505687713623\n",
      "Epoch [1500/10000], Loss: 0.5648480653762817\n",
      "Epoch [1501/10000], Loss: 0.5648454427719116\n",
      "Epoch [1502/10000], Loss: 0.5648433566093445\n",
      "Epoch [1503/10000], Loss: 0.56484055519104\n",
      "Epoch [1504/10000], Loss: 0.5648366808891296\n",
      "Epoch [1505/10000], Loss: 0.5648327469825745\n",
      "Epoch [1506/10000], Loss: 0.5648278594017029\n",
      "Epoch [1507/10000], Loss: 0.5648234486579895\n",
      "Epoch [1508/10000], Loss: 0.5648187398910522\n",
      "Epoch [1509/10000], Loss: 0.5648137927055359\n",
      "Epoch [1510/10000], Loss: 0.564809262752533\n",
      "Epoch [1511/10000], Loss: 0.5648049116134644\n",
      "Epoch [1512/10000], Loss: 0.5648008584976196\n",
      "Epoch [1513/10000], Loss: 0.5647966265678406\n",
      "Epoch [1514/10000], Loss: 0.5647931694984436\n",
      "Epoch [1515/10000], Loss: 0.5647897124290466\n",
      "Epoch [1516/10000], Loss: 0.5647861957550049\n",
      "Epoch [1517/10000], Loss: 0.5647827982902527\n",
      "Epoch [1518/10000], Loss: 0.5647792816162109\n",
      "Epoch [1519/10000], Loss: 0.5647757053375244\n",
      "Epoch [1520/10000], Loss: 0.564772367477417\n",
      "Epoch [1521/10000], Loss: 0.5647688508033752\n",
      "Epoch [1522/10000], Loss: 0.5647653341293335\n",
      "Epoch [1523/10000], Loss: 0.5647621154785156\n",
      "Epoch [1524/10000], Loss: 0.5647594332695007\n",
      "Epoch [1525/10000], Loss: 0.5647565722465515\n",
      "Epoch [1526/10000], Loss: 0.5647538304328918\n",
      "Epoch [1527/10000], Loss: 0.5647516846656799\n",
      "Epoch [1528/10000], Loss: 0.5647494196891785\n",
      "Epoch [1529/10000], Loss: 0.5647478103637695\n",
      "Epoch [1530/10000], Loss: 0.5647463202476501\n",
      "Epoch [1531/10000], Loss: 0.5647438764572144\n",
      "Epoch [1532/10000], Loss: 0.5647416710853577\n",
      "Epoch [1533/10000], Loss: 0.5647388696670532\n",
      "Epoch [1534/10000], Loss: 0.5647363662719727\n",
      "Epoch [1535/10000], Loss: 0.5647333264350891\n",
      "Epoch [1536/10000], Loss: 0.5647305846214294\n",
      "Epoch [1537/10000], Loss: 0.5647276043891907\n",
      "Epoch [1538/10000], Loss: 0.5647239685058594\n",
      "Epoch [1539/10000], Loss: 0.5647205114364624\n",
      "Epoch [1540/10000], Loss: 0.5647175312042236\n",
      "Epoch [1541/10000], Loss: 0.5647141933441162\n",
      "Epoch [1542/10000], Loss: 0.564711332321167\n",
      "Epoch [1543/10000], Loss: 0.5647079348564148\n",
      "Epoch [1544/10000], Loss: 0.5647035837173462\n",
      "Epoch [1545/10000], Loss: 0.5646987557411194\n",
      "Epoch [1546/10000], Loss: 0.5646935701370239\n",
      "Epoch [1547/10000], Loss: 0.5646893978118896\n",
      "Epoch [1548/10000], Loss: 0.5646851062774658\n",
      "Epoch [1549/10000], Loss: 0.5646817684173584\n",
      "Epoch [1550/10000], Loss: 0.5646787881851196\n",
      "Epoch [1551/10000], Loss: 0.56467604637146\n",
      "Epoch [1552/10000], Loss: 0.5646735429763794\n",
      "Epoch [1553/10000], Loss: 0.5646711587905884\n",
      "Epoch [1554/10000], Loss: 0.5646696090698242\n",
      "Epoch [1555/10000], Loss: 0.5646677613258362\n",
      "Epoch [1556/10000], Loss: 0.5646663904190063\n",
      "Epoch [1557/10000], Loss: 0.5646643042564392\n",
      "Epoch [1558/10000], Loss: 0.5646612644195557\n",
      "Epoch [1559/10000], Loss: 0.5646572709083557\n",
      "Epoch [1560/10000], Loss: 0.5646526217460632\n",
      "Epoch [1561/10000], Loss: 0.5646477937698364\n",
      "Epoch [1562/10000], Loss: 0.5646432638168335\n",
      "Epoch [1563/10000], Loss: 0.5646388530731201\n",
      "Epoch [1564/10000], Loss: 0.5646349191665649\n",
      "Epoch [1565/10000], Loss: 0.564631462097168\n",
      "Epoch [1566/10000], Loss: 0.5646281242370605\n",
      "Epoch [1567/10000], Loss: 0.564625084400177\n",
      "Epoch [1568/10000], Loss: 0.5646217465400696\n",
      "Epoch [1569/10000], Loss: 0.5646182298660278\n",
      "Epoch [1570/10000], Loss: 0.5646147131919861\n",
      "Epoch [1571/10000], Loss: 0.5646113753318787\n",
      "Epoch [1572/10000], Loss: 0.5646081566810608\n",
      "Epoch [1573/10000], Loss: 0.5646046996116638\n",
      "Epoch [1574/10000], Loss: 0.5646011233329773\n",
      "Epoch [1575/10000], Loss: 0.5645983219146729\n",
      "Epoch [1576/10000], Loss: 0.5645954012870789\n",
      "Epoch [1577/10000], Loss: 0.5645923614501953\n",
      "Epoch [1578/10000], Loss: 0.5645895600318909\n",
      "Epoch [1579/10000], Loss: 0.5645860433578491\n",
      "Epoch [1580/10000], Loss: 0.5645830631256104\n",
      "Epoch [1581/10000], Loss: 0.564579427242279\n",
      "Epoch [1582/10000], Loss: 0.564575731754303\n",
      "Epoch [1583/10000], Loss: 0.5645716786384583\n",
      "Epoch [1584/10000], Loss: 0.5645673871040344\n",
      "Epoch [1585/10000], Loss: 0.5645631551742554\n",
      "Epoch [1586/10000], Loss: 0.5645590424537659\n",
      "Epoch [1587/10000], Loss: 0.5645555853843689\n",
      "Epoch [1588/10000], Loss: 0.5645521283149719\n",
      "Epoch [1589/10000], Loss: 0.564548909664154\n",
      "Epoch [1590/10000], Loss: 0.5645459890365601\n",
      "Epoch [1591/10000], Loss: 0.5645434260368347\n",
      "Epoch [1592/10000], Loss: 0.5645412802696228\n",
      "Epoch [1593/10000], Loss: 0.5645396113395691\n",
      "Epoch [1594/10000], Loss: 0.5645385980606079\n",
      "Epoch [1595/10000], Loss: 0.5645372867584229\n",
      "Epoch [1596/10000], Loss: 0.5645362734794617\n",
      "Epoch [1597/10000], Loss: 0.5645352005958557\n",
      "Epoch [1598/10000], Loss: 0.5645328164100647\n",
      "Epoch [1599/10000], Loss: 0.5645290613174438\n",
      "Epoch [1600/10000], Loss: 0.5645235776901245\n",
      "Epoch [1601/10000], Loss: 0.5645175576210022\n",
      "Epoch [1602/10000], Loss: 0.5645103454589844\n",
      "Epoch [1603/10000], Loss: 0.5645036697387695\n",
      "Epoch [1604/10000], Loss: 0.5644975900650024\n",
      "Epoch [1605/10000], Loss: 0.564492404460907\n",
      "Epoch [1606/10000], Loss: 0.564488410949707\n",
      "Epoch [1607/10000], Loss: 0.5644852519035339\n",
      "Epoch [1608/10000], Loss: 0.5644828081130981\n",
      "Epoch [1609/10000], Loss: 0.5644806623458862\n",
      "Epoch [1610/10000], Loss: 0.5644773840904236\n",
      "Epoch [1611/10000], Loss: 0.5644738674163818\n",
      "Epoch [1612/10000], Loss: 0.5644707679748535\n",
      "Epoch [1613/10000], Loss: 0.5644671320915222\n",
      "Epoch [1614/10000], Loss: 0.5644639730453491\n",
      "Epoch [1615/10000], Loss: 0.5644609332084656\n",
      "Epoch [1616/10000], Loss: 0.5644569993019104\n",
      "Epoch [1617/10000], Loss: 0.5644528865814209\n",
      "Epoch [1618/10000], Loss: 0.5644484162330627\n",
      "Epoch [1619/10000], Loss: 0.5644437670707703\n",
      "Epoch [1620/10000], Loss: 0.5644396543502808\n",
      "Epoch [1621/10000], Loss: 0.5644357204437256\n",
      "Epoch [1622/10000], Loss: 0.5644319653511047\n",
      "Epoch [1623/10000], Loss: 0.56442791223526\n",
      "Epoch [1624/10000], Loss: 0.564424455165863\n",
      "Epoch [1625/10000], Loss: 0.5644212961196899\n",
      "Epoch [1626/10000], Loss: 0.5644180178642273\n",
      "Epoch [1627/10000], Loss: 0.5644150376319885\n",
      "Epoch [1628/10000], Loss: 0.564411997795105\n",
      "Epoch [1629/10000], Loss: 0.5644094347953796\n",
      "Epoch [1630/10000], Loss: 0.5644067525863647\n",
      "Epoch [1631/10000], Loss: 0.5644041299819946\n",
      "Epoch [1632/10000], Loss: 0.5644016265869141\n",
      "Epoch [1633/10000], Loss: 0.5643990635871887\n",
      "Epoch [1634/10000], Loss: 0.5643959641456604\n",
      "Epoch [1635/10000], Loss: 0.5643929243087769\n",
      "Epoch [1636/10000], Loss: 0.564389169216156\n",
      "Epoch [1637/10000], Loss: 0.5643855929374695\n",
      "Epoch [1638/10000], Loss: 0.5643818974494934\n",
      "Epoch [1639/10000], Loss: 0.5643782019615173\n",
      "Epoch [1640/10000], Loss: 0.5643753409385681\n",
      "Epoch [1641/10000], Loss: 0.5643722414970398\n",
      "Epoch [1642/10000], Loss: 0.564369261264801\n",
      "Epoch [1643/10000], Loss: 0.564366340637207\n",
      "Epoch [1644/10000], Loss: 0.5643638968467712\n",
      "Epoch [1645/10000], Loss: 0.5643614530563354\n",
      "Epoch [1646/10000], Loss: 0.5643594264984131\n",
      "Epoch [1647/10000], Loss: 0.5643579959869385\n",
      "Epoch [1648/10000], Loss: 0.5643565654754639\n",
      "Epoch [1649/10000], Loss: 0.5643557906150818\n",
      "Epoch [1650/10000], Loss: 0.5643544793128967\n",
      "Epoch [1651/10000], Loss: 0.5643530488014221\n",
      "Epoch [1652/10000], Loss: 0.5643517374992371\n",
      "Epoch [1653/10000], Loss: 0.5643500089645386\n",
      "Epoch [1654/10000], Loss: 0.5643471479415894\n",
      "Epoch [1655/10000], Loss: 0.5643436312675476\n",
      "Epoch [1656/10000], Loss: 0.5643393993377686\n",
      "Epoch [1657/10000], Loss: 0.564334511756897\n",
      "Epoch [1658/10000], Loss: 0.5643289089202881\n",
      "Epoch [1659/10000], Loss: 0.5643243193626404\n",
      "Epoch [1660/10000], Loss: 0.5643199682235718\n",
      "Epoch [1661/10000], Loss: 0.564315915107727\n",
      "Epoch [1662/10000], Loss: 0.5643128156661987\n",
      "Epoch [1663/10000], Loss: 0.5643104910850525\n",
      "Epoch [1664/10000], Loss: 0.564309298992157\n",
      "Epoch [1665/10000], Loss: 0.5643086433410645\n",
      "Epoch [1666/10000], Loss: 0.5643084645271301\n",
      "Epoch [1667/10000], Loss: 0.5643078088760376\n",
      "Epoch [1668/10000], Loss: 0.5643069744110107\n",
      "Epoch [1669/10000], Loss: 0.5643048882484436\n",
      "Epoch [1670/10000], Loss: 0.5643010139465332\n",
      "Epoch [1671/10000], Loss: 0.5642962455749512\n",
      "Epoch [1672/10000], Loss: 0.5642906427383423\n",
      "Epoch [1673/10000], Loss: 0.5642848014831543\n",
      "Epoch [1674/10000], Loss: 0.5642796158790588\n",
      "Epoch [1675/10000], Loss: 0.5642753839492798\n",
      "Epoch [1676/10000], Loss: 0.5642715096473694\n",
      "Epoch [1677/10000], Loss: 0.5642682313919067\n",
      "Epoch [1678/10000], Loss: 0.5642655491828918\n",
      "Epoch [1679/10000], Loss: 0.5642631649971008\n",
      "Epoch [1680/10000], Loss: 0.5642615556716919\n",
      "Epoch [1681/10000], Loss: 0.5642596483230591\n",
      "Epoch [1682/10000], Loss: 0.5642580986022949\n",
      "Epoch [1683/10000], Loss: 0.5642558336257935\n",
      "Epoch [1684/10000], Loss: 0.5642532110214233\n",
      "Epoch [1685/10000], Loss: 0.5642504096031189\n",
      "Epoch [1686/10000], Loss: 0.5642473697662354\n",
      "Epoch [1687/10000], Loss: 0.5642439126968384\n",
      "Epoch [1688/10000], Loss: 0.5642403364181519\n",
      "Epoch [1689/10000], Loss: 0.5642368197441101\n",
      "Epoch [1690/10000], Loss: 0.564233124256134\n",
      "Epoch [1691/10000], Loss: 0.5642294883728027\n",
      "Epoch [1692/10000], Loss: 0.5642262697219849\n",
      "Epoch [1693/10000], Loss: 0.5642232298851013\n",
      "Epoch [1694/10000], Loss: 0.5642203688621521\n",
      "Epoch [1695/10000], Loss: 0.5642176270484924\n",
      "Epoch [1696/10000], Loss: 0.5642149448394775\n",
      "Epoch [1697/10000], Loss: 0.5642120242118835\n",
      "Epoch [1698/10000], Loss: 0.5642091631889343\n",
      "Epoch [1699/10000], Loss: 0.5642066597938538\n",
      "Epoch [1700/10000], Loss: 0.5642039775848389\n",
      "Epoch [1701/10000], Loss: 0.5642016530036926\n",
      "Epoch [1702/10000], Loss: 0.5641997456550598\n",
      "Epoch [1703/10000], Loss: 0.5641978979110718\n",
      "Epoch [1704/10000], Loss: 0.5641964673995972\n",
      "Epoch [1705/10000], Loss: 0.5641947984695435\n",
      "Epoch [1706/10000], Loss: 0.564193069934845\n",
      "Epoch [1707/10000], Loss: 0.5641910433769226\n",
      "Epoch [1708/10000], Loss: 0.5641881227493286\n",
      "Epoch [1709/10000], Loss: 0.5641844868659973\n",
      "Epoch [1710/10000], Loss: 0.5641802549362183\n",
      "Epoch [1711/10000], Loss: 0.5641754865646362\n",
      "Epoch [1712/10000], Loss: 0.5641706585884094\n",
      "Epoch [1713/10000], Loss: 0.564166247844696\n",
      "Epoch [1714/10000], Loss: 0.5641621351242065\n",
      "Epoch [1715/10000], Loss: 0.564158022403717\n",
      "Epoch [1716/10000], Loss: 0.5641545057296753\n",
      "Epoch [1717/10000], Loss: 0.5641517043113708\n",
      "Epoch [1718/10000], Loss: 0.5641486048698425\n",
      "Epoch [1719/10000], Loss: 0.5641451478004456\n",
      "Epoch [1720/10000], Loss: 0.5641417503356934\n",
      "Epoch [1721/10000], Loss: 0.5641379952430725\n",
      "Epoch [1722/10000], Loss: 0.5641335844993591\n",
      "Epoch [1723/10000], Loss: 0.5641293525695801\n",
      "Epoch [1724/10000], Loss: 0.5641251802444458\n",
      "Epoch [1725/10000], Loss: 0.564120888710022\n",
      "Epoch [1726/10000], Loss: 0.5641173720359802\n",
      "Epoch [1727/10000], Loss: 0.5641140937805176\n",
      "Epoch [1728/10000], Loss: 0.5641112923622131\n",
      "Epoch [1729/10000], Loss: 0.5641086101531982\n",
      "Epoch [1730/10000], Loss: 0.5641056299209595\n",
      "Epoch [1731/10000], Loss: 0.5641030073165894\n",
      "Epoch [1732/10000], Loss: 0.5641005635261536\n",
      "Epoch [1733/10000], Loss: 0.564098596572876\n",
      "Epoch [1734/10000], Loss: 0.5640965104103088\n",
      "Epoch [1735/10000], Loss: 0.5640950202941895\n",
      "Epoch [1736/10000], Loss: 0.5640936493873596\n",
      "Epoch [1737/10000], Loss: 0.564092755317688\n",
      "Epoch [1738/10000], Loss: 0.564091145992279\n",
      "Epoch [1739/10000], Loss: 0.564088761806488\n",
      "Epoch [1740/10000], Loss: 0.564084529876709\n",
      "Epoch [1741/10000], Loss: 0.5640796422958374\n",
      "Epoch [1742/10000], Loss: 0.5640732049942017\n",
      "Epoch [1743/10000], Loss: 0.5640662312507629\n",
      "Epoch [1744/10000], Loss: 0.5640584826469421\n",
      "Epoch [1745/10000], Loss: 0.5640514492988586\n",
      "Epoch [1746/10000], Loss: 0.5640453100204468\n",
      "Epoch [1747/10000], Loss: 0.5640400648117065\n",
      "Epoch [1748/10000], Loss: 0.5640349984169006\n",
      "Epoch [1749/10000], Loss: 0.5640303492546082\n",
      "Epoch [1750/10000], Loss: 0.5640259981155396\n",
      "Epoch [1751/10000], Loss: 0.564021646976471\n",
      "Epoch [1752/10000], Loss: 0.5640177130699158\n",
      "Epoch [1753/10000], Loss: 0.5640134811401367\n",
      "Epoch [1754/10000], Loss: 0.5640097260475159\n",
      "Epoch [1755/10000], Loss: 0.5640062093734741\n",
      "Epoch [1756/10000], Loss: 0.5640025734901428\n",
      "Epoch [1757/10000], Loss: 0.5639981031417847\n",
      "Epoch [1758/10000], Loss: 0.5639936923980713\n",
      "Epoch [1759/10000], Loss: 0.5639886856079102\n",
      "Epoch [1760/10000], Loss: 0.563983678817749\n",
      "Epoch [1761/10000], Loss: 0.5639787316322327\n",
      "Epoch [1762/10000], Loss: 0.5639745593070984\n",
      "Epoch [1763/10000], Loss: 0.563970685005188\n",
      "Epoch [1764/10000], Loss: 0.5639672875404358\n",
      "Epoch [1765/10000], Loss: 0.5639638304710388\n",
      "Epoch [1766/10000], Loss: 0.5639604330062866\n",
      "Epoch [1767/10000], Loss: 0.563957154750824\n",
      "Epoch [1768/10000], Loss: 0.5639535784721375\n",
      "Epoch [1769/10000], Loss: 0.5639509558677673\n",
      "Epoch [1770/10000], Loss: 0.5639479756355286\n",
      "Epoch [1771/10000], Loss: 0.5639446973800659\n",
      "Epoch [1772/10000], Loss: 0.5639416575431824\n",
      "Epoch [1773/10000], Loss: 0.5639384984970093\n",
      "Epoch [1774/10000], Loss: 0.5639350414276123\n",
      "Epoch [1775/10000], Loss: 0.5639320015907288\n",
      "Epoch [1776/10000], Loss: 0.5639283061027527\n",
      "Epoch [1777/10000], Loss: 0.5639240145683289\n",
      "Epoch [1778/10000], Loss: 0.5639201402664185\n",
      "Epoch [1779/10000], Loss: 0.5639166831970215\n",
      "Epoch [1780/10000], Loss: 0.5639128684997559\n",
      "Epoch [1781/10000], Loss: 0.5639088749885559\n",
      "Epoch [1782/10000], Loss: 0.5639045834541321\n",
      "Epoch [1783/10000], Loss: 0.563900351524353\n",
      "Epoch [1784/10000], Loss: 0.5638958811759949\n",
      "Epoch [1785/10000], Loss: 0.563891589641571\n",
      "Epoch [1786/10000], Loss: 0.563887357711792\n",
      "Epoch [1787/10000], Loss: 0.5638822317123413\n",
      "Epoch [1788/10000], Loss: 0.5638775825500488\n",
      "Epoch [1789/10000], Loss: 0.5638732314109802\n",
      "Epoch [1790/10000], Loss: 0.563868522644043\n",
      "Epoch [1791/10000], Loss: 0.5638638138771057\n",
      "Epoch [1792/10000], Loss: 0.5638598799705505\n",
      "Epoch [1793/10000], Loss: 0.5638558864593506\n",
      "Epoch [1794/10000], Loss: 0.5638524293899536\n",
      "Epoch [1795/10000], Loss: 0.563848614692688\n",
      "Epoch [1796/10000], Loss: 0.5638450980186462\n",
      "Epoch [1797/10000], Loss: 0.5638414025306702\n",
      "Epoch [1798/10000], Loss: 0.563837468624115\n",
      "Epoch [1799/10000], Loss: 0.5638339519500732\n",
      "Epoch [1800/10000], Loss: 0.5638308525085449\n",
      "Epoch [1801/10000], Loss: 0.5638276934623718\n",
      "Epoch [1802/10000], Loss: 0.5638248920440674\n",
      "Epoch [1803/10000], Loss: 0.5638220906257629\n",
      "Epoch [1804/10000], Loss: 0.5638195276260376\n",
      "Epoch [1805/10000], Loss: 0.5638166666030884\n",
      "Epoch [1806/10000], Loss: 0.5638135075569153\n",
      "Epoch [1807/10000], Loss: 0.5638102293014526\n",
      "Epoch [1808/10000], Loss: 0.5638062357902527\n",
      "Epoch [1809/10000], Loss: 0.563801646232605\n",
      "Epoch [1810/10000], Loss: 0.5637967586517334\n",
      "Epoch [1811/10000], Loss: 0.5637924671173096\n",
      "Epoch [1812/10000], Loss: 0.5637878179550171\n",
      "Epoch [1813/10000], Loss: 0.5637830495834351\n",
      "Epoch [1814/10000], Loss: 0.5637784004211426\n",
      "Epoch [1815/10000], Loss: 0.563774049282074\n",
      "Epoch [1816/10000], Loss: 0.563770055770874\n",
      "Epoch [1817/10000], Loss: 0.5637661218643188\n",
      "Epoch [1818/10000], Loss: 0.5637627243995667\n",
      "Epoch [1819/10000], Loss: 0.563759982585907\n",
      "Epoch [1820/10000], Loss: 0.5637577772140503\n",
      "Epoch [1821/10000], Loss: 0.5637568235397339\n",
      "Epoch [1822/10000], Loss: 0.5637561082839966\n",
      "Epoch [1823/10000], Loss: 0.5637558102607727\n",
      "Epoch [1824/10000], Loss: 0.5637557506561279\n",
      "Epoch [1825/10000], Loss: 0.5637549757957458\n",
      "Epoch [1826/10000], Loss: 0.5637533068656921\n",
      "Epoch [1827/10000], Loss: 0.5637482404708862\n",
      "Epoch [1828/10000], Loss: 0.5637416243553162\n",
      "Epoch [1829/10000], Loss: 0.5637344121932983\n",
      "Epoch [1830/10000], Loss: 0.5637279152870178\n",
      "Epoch [1831/10000], Loss: 0.5637214779853821\n",
      "Epoch [1832/10000], Loss: 0.5637165307998657\n",
      "Epoch [1833/10000], Loss: 0.5637127161026001\n",
      "Epoch [1834/10000], Loss: 0.5637100338935852\n",
      "Epoch [1835/10000], Loss: 0.5637086629867554\n",
      "Epoch [1836/10000], Loss: 0.5637074708938599\n",
      "Epoch [1837/10000], Loss: 0.563706636428833\n",
      "Epoch [1838/10000], Loss: 0.5637060403823853\n",
      "Epoch [1839/10000], Loss: 0.5637051463127136\n",
      "Epoch [1840/10000], Loss: 0.5637027621269226\n",
      "Epoch [1841/10000], Loss: 0.5636997222900391\n",
      "Epoch [1842/10000], Loss: 0.5636957287788391\n",
      "Epoch [1843/10000], Loss: 0.5636907815933228\n",
      "Epoch [1844/10000], Loss: 0.5636867880821228\n",
      "Epoch [1845/10000], Loss: 0.5636827945709229\n",
      "Epoch [1846/10000], Loss: 0.5636795163154602\n",
      "Epoch [1847/10000], Loss: 0.5636768341064453\n",
      "Epoch [1848/10000], Loss: 0.5636745691299438\n",
      "Epoch [1849/10000], Loss: 0.5636725425720215\n",
      "Epoch [1850/10000], Loss: 0.5636706352233887\n",
      "Epoch [1851/10000], Loss: 0.5636693835258484\n",
      "Epoch [1852/10000], Loss: 0.5636687278747559\n",
      "Epoch [1853/10000], Loss: 0.5636672973632812\n",
      "Epoch [1854/10000], Loss: 0.5636661648750305\n",
      "Epoch [1855/10000], Loss: 0.5636648535728455\n",
      "Epoch [1856/10000], Loss: 0.5636630654335022\n",
      "Epoch [1857/10000], Loss: 0.5636609196662903\n",
      "Epoch [1858/10000], Loss: 0.5636586546897888\n",
      "Epoch [1859/10000], Loss: 0.5636565089225769\n",
      "Epoch [1860/10000], Loss: 0.5636546015739441\n",
      "Epoch [1861/10000], Loss: 0.5636526942253113\n",
      "Epoch [1862/10000], Loss: 0.5636508464813232\n",
      "Epoch [1863/10000], Loss: 0.5636483430862427\n",
      "Epoch [1864/10000], Loss: 0.5636448860168457\n",
      "Epoch [1865/10000], Loss: 0.5636411905288696\n",
      "Epoch [1866/10000], Loss: 0.5636366009712219\n",
      "Epoch [1867/10000], Loss: 0.5636322498321533\n",
      "Epoch [1868/10000], Loss: 0.5636278390884399\n",
      "Epoch [1869/10000], Loss: 0.5636239051818848\n",
      "Epoch [1870/10000], Loss: 0.5636202096939087\n",
      "Epoch [1871/10000], Loss: 0.5636169910430908\n",
      "Epoch [1872/10000], Loss: 0.563614010810852\n",
      "Epoch [1873/10000], Loss: 0.5636109709739685\n",
      "Epoch [1874/10000], Loss: 0.5636084079742432\n",
      "Epoch [1875/10000], Loss: 0.5636059641838074\n",
      "Epoch [1876/10000], Loss: 0.5636040568351746\n",
      "Epoch [1877/10000], Loss: 0.5636019110679626\n",
      "Epoch [1878/10000], Loss: 0.563599705696106\n",
      "Epoch [1879/10000], Loss: 0.5635982751846313\n",
      "Epoch [1880/10000], Loss: 0.5635966062545776\n",
      "Epoch [1881/10000], Loss: 0.5635948181152344\n",
      "Epoch [1882/10000], Loss: 0.563592255115509\n",
      "Epoch [1883/10000], Loss: 0.5635892748832703\n",
      "Epoch [1884/10000], Loss: 0.5635855793952942\n",
      "Epoch [1885/10000], Loss: 0.5635813474655151\n",
      "Epoch [1886/10000], Loss: 0.5635764598846436\n",
      "Epoch [1887/10000], Loss: 0.5635720491409302\n",
      "Epoch [1888/10000], Loss: 0.5635679364204407\n",
      "Epoch [1889/10000], Loss: 0.5635644793510437\n",
      "Epoch [1890/10000], Loss: 0.5635611414909363\n",
      "Epoch [1891/10000], Loss: 0.563558042049408\n",
      "Epoch [1892/10000], Loss: 0.5635555386543274\n",
      "Epoch [1893/10000], Loss: 0.5635530948638916\n",
      "Epoch [1894/10000], Loss: 0.5635501146316528\n",
      "Epoch [1895/10000], Loss: 0.5635469555854797\n",
      "Epoch [1896/10000], Loss: 0.5635433197021484\n",
      "Epoch [1897/10000], Loss: 0.5635395646095276\n",
      "Epoch [1898/10000], Loss: 0.5635353326797485\n",
      "Epoch [1899/10000], Loss: 0.5635311007499695\n",
      "Epoch [1900/10000], Loss: 0.5635267496109009\n",
      "Epoch [1901/10000], Loss: 0.5635231733322144\n",
      "Epoch [1902/10000], Loss: 0.5635203719139099\n",
      "Epoch [1903/10000], Loss: 0.5635181665420532\n",
      "Epoch [1904/10000], Loss: 0.5635163187980652\n",
      "Epoch [1905/10000], Loss: 0.5635139346122742\n",
      "Epoch [1906/10000], Loss: 0.5635120272636414\n",
      "Epoch [1907/10000], Loss: 0.5635099411010742\n",
      "Epoch [1908/10000], Loss: 0.5635074973106384\n",
      "Epoch [1909/10000], Loss: 0.5635051727294922\n",
      "Epoch [1910/10000], Loss: 0.5635021328926086\n",
      "Epoch [1911/10000], Loss: 0.5634986758232117\n",
      "Epoch [1912/10000], Loss: 0.5634959936141968\n",
      "Epoch [1913/10000], Loss: 0.5634933114051819\n",
      "Epoch [1914/10000], Loss: 0.563490092754364\n",
      "Epoch [1915/10000], Loss: 0.5634869337081909\n",
      "Epoch [1916/10000], Loss: 0.5634836554527283\n",
      "Epoch [1917/10000], Loss: 0.5634803771972656\n",
      "Epoch [1918/10000], Loss: 0.5634779334068298\n",
      "Epoch [1919/10000], Loss: 0.5634755492210388\n",
      "Epoch [1920/10000], Loss: 0.5634726881980896\n",
      "Epoch [1921/10000], Loss: 0.5634694695472717\n",
      "Epoch [1922/10000], Loss: 0.5634653568267822\n",
      "Epoch [1923/10000], Loss: 0.5634604692459106\n",
      "Epoch [1924/10000], Loss: 0.5634558200836182\n",
      "Epoch [1925/10000], Loss: 0.5634509325027466\n",
      "Epoch [1926/10000], Loss: 0.5634453892707825\n",
      "Epoch [1927/10000], Loss: 0.5634401440620422\n",
      "Epoch [1928/10000], Loss: 0.5634348392486572\n",
      "Epoch [1929/10000], Loss: 0.5634299516677856\n",
      "Epoch [1930/10000], Loss: 0.5634254813194275\n",
      "Epoch [1931/10000], Loss: 0.5634210109710693\n",
      "Epoch [1932/10000], Loss: 0.5634163618087769\n",
      "Epoch [1933/10000], Loss: 0.5634123682975769\n",
      "Epoch [1934/10000], Loss: 0.5634085536003113\n",
      "Epoch [1935/10000], Loss: 0.56340491771698\n",
      "Epoch [1936/10000], Loss: 0.5634016990661621\n",
      "Epoch [1937/10000], Loss: 0.5633982419967651\n",
      "Epoch [1938/10000], Loss: 0.56339430809021\n",
      "Epoch [1939/10000], Loss: 0.5633906126022339\n",
      "Epoch [1940/10000], Loss: 0.5633867979049683\n",
      "Epoch [1941/10000], Loss: 0.5633834600448608\n",
      "Epoch [1942/10000], Loss: 0.5633800625801086\n",
      "Epoch [1943/10000], Loss: 0.5633763670921326\n",
      "Epoch [1944/10000], Loss: 0.5633724331855774\n",
      "Epoch [1945/10000], Loss: 0.5633692145347595\n",
      "Epoch [1946/10000], Loss: 0.5633652806282043\n",
      "Epoch [1947/10000], Loss: 0.5633611679077148\n",
      "Epoch [1948/10000], Loss: 0.5633568167686462\n",
      "Epoch [1949/10000], Loss: 0.5633527040481567\n",
      "Epoch [1950/10000], Loss: 0.563348650932312\n",
      "Epoch [1951/10000], Loss: 0.5633454322814941\n",
      "Epoch [1952/10000], Loss: 0.5633419156074524\n",
      "Epoch [1953/10000], Loss: 0.5633386969566345\n",
      "Epoch [1954/10000], Loss: 0.5633351802825928\n",
      "Epoch [1955/10000], Loss: 0.5633320808410645\n",
      "Epoch [1956/10000], Loss: 0.5633288621902466\n",
      "Epoch [1957/10000], Loss: 0.5633257627487183\n",
      "Epoch [1958/10000], Loss: 0.5633227229118347\n",
      "Epoch [1959/10000], Loss: 0.5633201003074646\n",
      "Epoch [1960/10000], Loss: 0.5633176565170288\n",
      "Epoch [1961/10000], Loss: 0.5633150339126587\n",
      "Epoch [1962/10000], Loss: 0.5633119940757751\n",
      "Epoch [1963/10000], Loss: 0.5633086562156677\n",
      "Epoch [1964/10000], Loss: 0.5633055567741394\n",
      "Epoch [1965/10000], Loss: 0.5633020997047424\n",
      "Epoch [1966/10000], Loss: 0.5632985830307007\n",
      "Epoch [1967/10000], Loss: 0.5632945895195007\n",
      "Epoch [1968/10000], Loss: 0.5632902979850769\n",
      "Epoch [1969/10000], Loss: 0.5632860660552979\n",
      "Epoch [1970/10000], Loss: 0.5632821917533875\n",
      "Epoch [1971/10000], Loss: 0.5632781386375427\n",
      "Epoch [1972/10000], Loss: 0.5632739067077637\n",
      "Epoch [1973/10000], Loss: 0.563270092010498\n",
      "Epoch [1974/10000], Loss: 0.5632654428482056\n",
      "Epoch [1975/10000], Loss: 0.5632613897323608\n",
      "Epoch [1976/10000], Loss: 0.5632571578025818\n",
      "Epoch [1977/10000], Loss: 0.5632532238960266\n",
      "Epoch [1978/10000], Loss: 0.5632492899894714\n",
      "Epoch [1979/10000], Loss: 0.5632447600364685\n",
      "Epoch [1980/10000], Loss: 0.5632405281066895\n",
      "Epoch [1981/10000], Loss: 0.5632372498512268\n",
      "Epoch [1982/10000], Loss: 0.5632338523864746\n",
      "Epoch [1983/10000], Loss: 0.5632308125495911\n",
      "Epoch [1984/10000], Loss: 0.5632279515266418\n",
      "Epoch [1985/10000], Loss: 0.5632251501083374\n",
      "Epoch [1986/10000], Loss: 0.5632219910621643\n",
      "Epoch [1987/10000], Loss: 0.5632189512252808\n",
      "Epoch [1988/10000], Loss: 0.5632160305976868\n",
      "Epoch [1989/10000], Loss: 0.5632123351097107\n",
      "Epoch [1990/10000], Loss: 0.5632092356681824\n",
      "Epoch [1991/10000], Loss: 0.563205897808075\n",
      "Epoch [1992/10000], Loss: 0.5632020831108093\n",
      "Epoch [1993/10000], Loss: 0.5631988048553467\n",
      "Epoch [1994/10000], Loss: 0.5631955862045288\n",
      "Epoch [1995/10000], Loss: 0.5631920099258423\n",
      "Epoch [1996/10000], Loss: 0.5631887912750244\n",
      "Epoch [1997/10000], Loss: 0.56318598985672\n",
      "Epoch [1998/10000], Loss: 0.5631838440895081\n",
      "Epoch [1999/10000], Loss: 0.5631813406944275\n",
      "Epoch [2000/10000], Loss: 0.5631784200668335\n",
      "Epoch [2001/10000], Loss: 0.56317538022995\n",
      "Epoch [2002/10000], Loss: 0.5631721019744873\n",
      "Epoch [2003/10000], Loss: 0.5631682872772217\n",
      "Epoch [2004/10000], Loss: 0.5631648898124695\n",
      "Epoch [2005/10000], Loss: 0.5631614923477173\n",
      "Epoch [2006/10000], Loss: 0.5631584525108337\n",
      "Epoch [2007/10000], Loss: 0.5631555318832397\n",
      "Epoch [2008/10000], Loss: 0.5631529688835144\n",
      "Epoch [2009/10000], Loss: 0.5631508827209473\n",
      "Epoch [2010/10000], Loss: 0.5631496906280518\n",
      "Epoch [2011/10000], Loss: 0.5631488561630249\n",
      "Epoch [2012/10000], Loss: 0.5631481409072876\n",
      "Epoch [2013/10000], Loss: 0.5631470084190369\n",
      "Epoch [2014/10000], Loss: 0.5631462335586548\n",
      "Epoch [2015/10000], Loss: 0.5631439685821533\n",
      "Epoch [2016/10000], Loss: 0.5631409287452698\n",
      "Epoch [2017/10000], Loss: 0.5631369352340698\n",
      "Epoch [2018/10000], Loss: 0.5631316900253296\n",
      "Epoch [2019/10000], Loss: 0.5631251931190491\n",
      "Epoch [2020/10000], Loss: 0.5631182789802551\n",
      "Epoch [2021/10000], Loss: 0.5631110668182373\n",
      "Epoch [2022/10000], Loss: 0.5631051659584045\n",
      "Epoch [2023/10000], Loss: 0.5631008744239807\n",
      "Epoch [2024/10000], Loss: 0.5630978941917419\n",
      "Epoch [2025/10000], Loss: 0.5630952715873718\n",
      "Epoch [2026/10000], Loss: 0.5630931258201599\n",
      "Epoch [2027/10000], Loss: 0.5630912184715271\n",
      "Epoch [2028/10000], Loss: 0.5630900263786316\n",
      "Epoch [2029/10000], Loss: 0.5630886554718018\n",
      "Epoch [2030/10000], Loss: 0.5630866885185242\n",
      "Epoch [2031/10000], Loss: 0.5630843043327332\n",
      "Epoch [2032/10000], Loss: 0.5630815625190735\n",
      "Epoch [2033/10000], Loss: 0.5630781054496765\n",
      "Epoch [2034/10000], Loss: 0.5630737543106079\n",
      "Epoch [2035/10000], Loss: 0.5630690455436707\n",
      "Epoch [2036/10000], Loss: 0.5630643367767334\n",
      "Epoch [2037/10000], Loss: 0.5630606412887573\n",
      "Epoch [2038/10000], Loss: 0.5630565881729126\n",
      "Epoch [2039/10000], Loss: 0.5630531907081604\n",
      "Epoch [2040/10000], Loss: 0.5630504488945007\n",
      "Epoch [2041/10000], Loss: 0.5630477070808411\n",
      "Epoch [2042/10000], Loss: 0.563045084476471\n",
      "Epoch [2043/10000], Loss: 0.5630427002906799\n",
      "Epoch [2044/10000], Loss: 0.5630406141281128\n",
      "Epoch [2045/10000], Loss: 0.5630382299423218\n",
      "Epoch [2046/10000], Loss: 0.5630361437797546\n",
      "Epoch [2047/10000], Loss: 0.5630339980125427\n",
      "Epoch [2048/10000], Loss: 0.5630314350128174\n",
      "Epoch [2049/10000], Loss: 0.5630284547805786\n",
      "Epoch [2050/10000], Loss: 0.5630244016647339\n",
      "Epoch [2051/10000], Loss: 0.5630201697349548\n",
      "Epoch [2052/10000], Loss: 0.5630156993865967\n",
      "Epoch [2053/10000], Loss: 0.563011646270752\n",
      "Epoch [2054/10000], Loss: 0.5630077123641968\n",
      "Epoch [2055/10000], Loss: 0.5630043745040894\n",
      "Epoch [2056/10000], Loss: 0.5630010962486267\n",
      "Epoch [2057/10000], Loss: 0.562998354434967\n",
      "Epoch [2058/10000], Loss: 0.5629957914352417\n",
      "Epoch [2059/10000], Loss: 0.5629929304122925\n",
      "Epoch [2060/10000], Loss: 0.562990128993988\n",
      "Epoch [2061/10000], Loss: 0.5629876852035522\n",
      "Epoch [2062/10000], Loss: 0.5629857182502747\n",
      "Epoch [2063/10000], Loss: 0.5629845857620239\n",
      "Epoch [2064/10000], Loss: 0.5629833936691284\n",
      "Epoch [2065/10000], Loss: 0.5629823803901672\n",
      "Epoch [2066/10000], Loss: 0.5629813075065613\n",
      "Epoch [2067/10000], Loss: 0.5629794001579285\n",
      "Epoch [2068/10000], Loss: 0.5629768371582031\n",
      "Epoch [2069/10000], Loss: 0.562973141670227\n",
      "Epoch [2070/10000], Loss: 0.5629689693450928\n",
      "Epoch [2071/10000], Loss: 0.5629642605781555\n",
      "Epoch [2072/10000], Loss: 0.5629592537879944\n",
      "Epoch [2073/10000], Loss: 0.5629538297653198\n",
      "Epoch [2074/10000], Loss: 0.5629482865333557\n",
      "Epoch [2075/10000], Loss: 0.5629435181617737\n",
      "Epoch [2076/10000], Loss: 0.5629392862319946\n",
      "Epoch [2077/10000], Loss: 0.5629350543022156\n",
      "Epoch [2078/10000], Loss: 0.5629307627677917\n",
      "Epoch [2079/10000], Loss: 0.56292724609375\n",
      "Epoch [2080/10000], Loss: 0.5629234910011292\n",
      "Epoch [2081/10000], Loss: 0.562919557094574\n",
      "Epoch [2082/10000], Loss: 0.5629159808158875\n",
      "Epoch [2083/10000], Loss: 0.5629122257232666\n",
      "Epoch [2084/10000], Loss: 0.5629082918167114\n",
      "Epoch [2085/10000], Loss: 0.5629048347473145\n",
      "Epoch [2086/10000], Loss: 0.5629017353057861\n",
      "Epoch [2087/10000], Loss: 0.5628983974456787\n",
      "Epoch [2088/10000], Loss: 0.5628949999809265\n",
      "Epoch [2089/10000], Loss: 0.5628920793533325\n",
      "Epoch [2090/10000], Loss: 0.5628896355628967\n",
      "Epoch [2091/10000], Loss: 0.5628868341445923\n",
      "Epoch [2092/10000], Loss: 0.5628843307495117\n",
      "Epoch [2093/10000], Loss: 0.5628814101219177\n",
      "Epoch [2094/10000], Loss: 0.5628786087036133\n",
      "Epoch [2095/10000], Loss: 0.5628756880760193\n",
      "Epoch [2096/10000], Loss: 0.5628728866577148\n",
      "Epoch [2097/10000], Loss: 0.5628700256347656\n",
      "Epoch [2098/10000], Loss: 0.5628674030303955\n",
      "Epoch [2099/10000], Loss: 0.5628647804260254\n",
      "Epoch [2100/10000], Loss: 0.5628618597984314\n",
      "Epoch [2101/10000], Loss: 0.5628597140312195\n",
      "Epoch [2102/10000], Loss: 0.5628575682640076\n",
      "Epoch [2103/10000], Loss: 0.5628551840782166\n",
      "Epoch [2104/10000], Loss: 0.5628533363342285\n",
      "Epoch [2105/10000], Loss: 0.5628513693809509\n",
      "Epoch [2106/10000], Loss: 0.562850296497345\n",
      "Epoch [2107/10000], Loss: 0.562849760055542\n",
      "Epoch [2108/10000], Loss: 0.5628495216369629\n",
      "Epoch [2109/10000], Loss: 0.5628499984741211\n",
      "Epoch [2110/10000], Loss: 0.5628505349159241\n",
      "Epoch [2111/10000], Loss: 0.562851071357727\n",
      "Epoch [2112/10000], Loss: 0.5628519654273987\n",
      "Epoch [2113/10000], Loss: 0.5628517270088196\n",
      "Epoch [2114/10000], Loss: 0.5628500580787659\n",
      "Epoch [2115/10000], Loss: 0.5628460645675659\n",
      "Epoch [2116/10000], Loss: 0.5628403425216675\n",
      "Epoch [2117/10000], Loss: 0.562833845615387\n",
      "Epoch [2118/10000], Loss: 0.5628272891044617\n",
      "Epoch [2119/10000], Loss: 0.5628213882446289\n",
      "Epoch [2120/10000], Loss: 0.5628171563148499\n",
      "Epoch [2121/10000], Loss: 0.5628140568733215\n",
      "Epoch [2122/10000], Loss: 0.5628117322921753\n",
      "Epoch [2123/10000], Loss: 0.5628108382225037\n",
      "Epoch [2124/10000], Loss: 0.5628102421760559\n",
      "Epoch [2125/10000], Loss: 0.5628100633621216\n",
      "Epoch [2126/10000], Loss: 0.5628100037574768\n",
      "Epoch [2127/10000], Loss: 0.562809407711029\n",
      "Epoch [2128/10000], Loss: 0.5628077387809753\n",
      "Epoch [2129/10000], Loss: 0.5628051161766052\n",
      "Epoch [2130/10000], Loss: 0.5628013014793396\n",
      "Epoch [2131/10000], Loss: 0.5627975463867188\n",
      "Epoch [2132/10000], Loss: 0.5627941489219666\n",
      "Epoch [2133/10000], Loss: 0.5627911686897278\n",
      "Epoch [2134/10000], Loss: 0.5627884268760681\n",
      "Epoch [2135/10000], Loss: 0.5627866387367249\n",
      "Epoch [2136/10000], Loss: 0.5627852082252502\n",
      "Epoch [2137/10000], Loss: 0.5627843141555786\n",
      "Epoch [2138/10000], Loss: 0.5627835988998413\n",
      "Epoch [2139/10000], Loss: 0.5627830028533936\n",
      "Epoch [2140/10000], Loss: 0.5627822279930115\n",
      "Epoch [2141/10000], Loss: 0.5627803802490234\n",
      "Epoch [2142/10000], Loss: 0.5627778172492981\n",
      "Epoch [2143/10000], Loss: 0.5627744793891907\n",
      "Epoch [2144/10000], Loss: 0.5627709031105042\n",
      "Epoch [2145/10000], Loss: 0.5627681016921997\n",
      "Epoch [2146/10000], Loss: 0.5627657771110535\n",
      "Epoch [2147/10000], Loss: 0.5627637505531311\n",
      "Epoch [2148/10000], Loss: 0.5627620816230774\n",
      "Epoch [2149/10000], Loss: 0.5627602934837341\n",
      "Epoch [2150/10000], Loss: 0.5627589821815491\n",
      "Epoch [2151/10000], Loss: 0.5627579092979431\n",
      "Epoch [2152/10000], Loss: 0.5627567172050476\n",
      "Epoch [2153/10000], Loss: 0.5627555251121521\n",
      "Epoch [2154/10000], Loss: 0.5627541542053223\n",
      "Epoch [2155/10000], Loss: 0.5627532005310059\n",
      "Epoch [2156/10000], Loss: 0.5627521276473999\n",
      "Epoch [2157/10000], Loss: 0.5627507567405701\n",
      "Epoch [2158/10000], Loss: 0.5627495646476746\n",
      "Epoch [2159/10000], Loss: 0.5627484917640686\n",
      "Epoch [2160/10000], Loss: 0.5627469420433044\n",
      "Epoch [2161/10000], Loss: 0.5627448558807373\n",
      "Epoch [2162/10000], Loss: 0.5627431273460388\n",
      "Epoch [2163/10000], Loss: 0.562741219997406\n",
      "Epoch [2164/10000], Loss: 0.5627390146255493\n",
      "Epoch [2165/10000], Loss: 0.562737226486206\n",
      "Epoch [2166/10000], Loss: 0.5627359747886658\n",
      "Epoch [2167/10000], Loss: 0.5627344250679016\n",
      "Epoch [2168/10000], Loss: 0.5627334117889404\n",
      "Epoch [2169/10000], Loss: 0.5627328157424927\n",
      "Epoch [2170/10000], Loss: 0.5627321004867554\n",
      "Epoch [2171/10000], Loss: 0.5627313852310181\n",
      "Epoch [2172/10000], Loss: 0.5627292990684509\n",
      "Epoch [2173/10000], Loss: 0.5627269148826599\n",
      "Epoch [2174/10000], Loss: 0.5627236366271973\n",
      "Epoch [2175/10000], Loss: 0.5627201199531555\n",
      "Epoch [2176/10000], Loss: 0.5627167224884033\n",
      "Epoch [2177/10000], Loss: 0.5627139210700989\n",
      "Epoch [2178/10000], Loss: 0.5627109408378601\n",
      "Epoch [2179/10000], Loss: 0.5627086162567139\n",
      "Epoch [2180/10000], Loss: 0.562706708908081\n",
      "Epoch [2181/10000], Loss: 0.5627049803733826\n",
      "Epoch [2182/10000], Loss: 0.5627037286758423\n",
      "Epoch [2183/10000], Loss: 0.5627025961875916\n",
      "Epoch [2184/10000], Loss: 0.5627009272575378\n",
      "Epoch [2185/10000], Loss: 0.5626989006996155\n",
      "Epoch [2186/10000], Loss: 0.5626967549324036\n",
      "Epoch [2187/10000], Loss: 0.562694787979126\n",
      "Epoch [2188/10000], Loss: 0.5626935362815857\n",
      "Epoch [2189/10000], Loss: 0.5626922845840454\n",
      "Epoch [2190/10000], Loss: 0.5626906752586365\n",
      "Epoch [2191/10000], Loss: 0.5626895427703857\n",
      "Epoch [2192/10000], Loss: 0.562688410282135\n",
      "Epoch [2193/10000], Loss: 0.5626870393753052\n",
      "Epoch [2194/10000], Loss: 0.5626856088638306\n",
      "Epoch [2195/10000], Loss: 0.5626844763755798\n",
      "Epoch [2196/10000], Loss: 0.5626833438873291\n",
      "Epoch [2197/10000], Loss: 0.5626821517944336\n",
      "Epoch [2198/10000], Loss: 0.5626802444458008\n",
      "Epoch [2199/10000], Loss: 0.5626786351203918\n",
      "Epoch [2200/10000], Loss: 0.562676191329956\n",
      "Epoch [2201/10000], Loss: 0.5626735687255859\n",
      "Epoch [2202/10000], Loss: 0.5626705288887024\n",
      "Epoch [2203/10000], Loss: 0.5626667737960815\n",
      "Epoch [2204/10000], Loss: 0.5626629590988159\n",
      "Epoch [2205/10000], Loss: 0.562659502029419\n",
      "Epoch [2206/10000], Loss: 0.5626570582389832\n",
      "Epoch [2207/10000], Loss: 0.5626546144485474\n",
      "Epoch [2208/10000], Loss: 0.5626518130302429\n",
      "Epoch [2209/10000], Loss: 0.5626497864723206\n",
      "Epoch [2210/10000], Loss: 0.56264728307724\n",
      "Epoch [2211/10000], Loss: 0.5626451373100281\n",
      "Epoch [2212/10000], Loss: 0.5626429319381714\n",
      "Epoch [2213/10000], Loss: 0.5626413822174072\n",
      "Epoch [2214/10000], Loss: 0.5626393556594849\n",
      "Epoch [2215/10000], Loss: 0.5626375675201416\n",
      "Epoch [2216/10000], Loss: 0.562636137008667\n",
      "Epoch [2217/10000], Loss: 0.5626350045204163\n",
      "Epoch [2218/10000], Loss: 0.5626338124275208\n",
      "Epoch [2219/10000], Loss: 0.5626331567764282\n",
      "Epoch [2220/10000], Loss: 0.5626327991485596\n",
      "Epoch [2221/10000], Loss: 0.5626328587532043\n",
      "Epoch [2222/10000], Loss: 0.5626327991485596\n",
      "Epoch [2223/10000], Loss: 0.5626324415206909\n",
      "Epoch [2224/10000], Loss: 0.5626328587532043\n",
      "Epoch [2225/10000], Loss: 0.5626329183578491\n",
      "Epoch [2226/10000], Loss: 0.5626318454742432\n",
      "Epoch [2227/10000], Loss: 0.5626298785209656\n",
      "Epoch [2228/10000], Loss: 0.562626838684082\n",
      "Epoch [2229/10000], Loss: 0.5626236200332642\n",
      "Epoch [2230/10000], Loss: 0.562620997428894\n",
      "Epoch [2231/10000], Loss: 0.562618613243103\n",
      "Epoch [2232/10000], Loss: 0.5626171827316284\n",
      "Epoch [2233/10000], Loss: 0.5626165866851807\n",
      "Epoch [2234/10000], Loss: 0.562616765499115\n",
      "Epoch [2235/10000], Loss: 0.5626165270805359\n",
      "Epoch [2236/10000], Loss: 0.5626164078712463\n",
      "Epoch [2237/10000], Loss: 0.5626153349876404\n",
      "Epoch [2238/10000], Loss: 0.5626137256622314\n",
      "Epoch [2239/10000], Loss: 0.5626119375228882\n",
      "Epoch [2240/10000], Loss: 0.5626102685928345\n",
      "Epoch [2241/10000], Loss: 0.5626087784767151\n",
      "Epoch [2242/10000], Loss: 0.5626075863838196\n",
      "Epoch [2243/10000], Loss: 0.562606155872345\n",
      "Epoch [2244/10000], Loss: 0.5626049041748047\n",
      "Epoch [2245/10000], Loss: 0.5626033544540405\n",
      "Epoch [2246/10000], Loss: 0.5626017451286316\n",
      "Epoch [2247/10000], Loss: 0.5625996589660645\n",
      "Epoch [2248/10000], Loss: 0.562597930431366\n",
      "Epoch [2249/10000], Loss: 0.5625964403152466\n",
      "Epoch [2250/10000], Loss: 0.5625949501991272\n",
      "Epoch [2251/10000], Loss: 0.5625937581062317\n",
      "Epoch [2252/10000], Loss: 0.5625930428504944\n",
      "Epoch [2253/10000], Loss: 0.5625924468040466\n",
      "Epoch [2254/10000], Loss: 0.5625911951065063\n",
      "Epoch [2255/10000], Loss: 0.5625900030136108\n",
      "Epoch [2256/10000], Loss: 0.5625887513160706\n",
      "Epoch [2257/10000], Loss: 0.5625863671302795\n",
      "Epoch [2258/10000], Loss: 0.5625837445259094\n",
      "Epoch [2259/10000], Loss: 0.5625812411308289\n",
      "Epoch [2260/10000], Loss: 0.5625789165496826\n",
      "Epoch [2261/10000], Loss: 0.5625770092010498\n",
      "Epoch [2262/10000], Loss: 0.5625756978988647\n",
      "Epoch [2263/10000], Loss: 0.5625743269920349\n",
      "Epoch [2264/10000], Loss: 0.5625731945037842\n",
      "Epoch [2265/10000], Loss: 0.5625723600387573\n",
      "Epoch [2266/10000], Loss: 0.5625714659690857\n",
      "Epoch [2267/10000], Loss: 0.5625705718994141\n",
      "Epoch [2268/10000], Loss: 0.5625704526901245\n",
      "Epoch [2269/10000], Loss: 0.5625700950622559\n",
      "Epoch [2270/10000], Loss: 0.5625697374343872\n",
      "Epoch [2271/10000], Loss: 0.5625697374343872\n",
      "Epoch [2272/10000], Loss: 0.5625697374343872\n",
      "Epoch [2273/10000], Loss: 0.5625696182250977\n",
      "Epoch [2274/10000], Loss: 0.5625690817832947\n",
      "Epoch [2275/10000], Loss: 0.562567949295044\n",
      "Epoch [2276/10000], Loss: 0.5625662803649902\n",
      "Epoch [2277/10000], Loss: 0.5625647306442261\n",
      "Epoch [2278/10000], Loss: 0.5625631213188171\n",
      "Epoch [2279/10000], Loss: 0.5625624060630798\n",
      "Epoch [2280/10000], Loss: 0.5625632405281067\n",
      "Epoch [2281/10000], Loss: 0.562564492225647\n",
      "Epoch [2282/10000], Loss: 0.5625664591789246\n",
      "Epoch [2283/10000], Loss: 0.5625689029693604\n",
      "Epoch [2284/10000], Loss: 0.5625713467597961\n",
      "Epoch [2285/10000], Loss: 0.562572717666626\n",
      "Epoch [2286/10000], Loss: 0.5625717043876648\n",
      "Epoch [2287/10000], Loss: 0.5625689029693604\n",
      "Epoch [2288/10000], Loss: 0.5625647306442261\n",
      "Epoch [2289/10000], Loss: 0.5625597834587097\n",
      "Epoch [2290/10000], Loss: 0.5625550150871277\n",
      "Epoch [2291/10000], Loss: 0.5625513792037964\n",
      "Epoch [2292/10000], Loss: 0.5625497102737427\n",
      "Epoch [2293/10000], Loss: 0.5625487565994263\n",
      "Epoch [2294/10000], Loss: 0.5625483989715576\n",
      "Epoch [2295/10000], Loss: 0.5625479817390442\n",
      "Epoch [2296/10000], Loss: 0.5625472068786621\n",
      "Epoch [2297/10000], Loss: 0.5625454187393188\n",
      "Epoch [2298/10000], Loss: 0.5625426769256592\n",
      "Epoch [2299/10000], Loss: 0.5625404715538025\n",
      "Epoch [2300/10000], Loss: 0.5625385642051697\n",
      "Epoch [2301/10000], Loss: 0.5625371336936951\n",
      "Epoch [2302/10000], Loss: 0.5625369548797607\n",
      "Epoch [2303/10000], Loss: 0.5625370740890503\n",
      "Epoch [2304/10000], Loss: 0.5625370144844055\n",
      "Epoch [2305/10000], Loss: 0.5625372529029846\n",
      "Epoch [2306/10000], Loss: 0.5625373721122742\n",
      "Epoch [2307/10000], Loss: 0.5625367164611816\n",
      "Epoch [2308/10000], Loss: 0.5625349283218384\n",
      "Epoch [2309/10000], Loss: 0.5625331997871399\n",
      "Epoch [2310/10000], Loss: 0.562531054019928\n",
      "Epoch [2311/10000], Loss: 0.562528669834137\n",
      "Epoch [2312/10000], Loss: 0.5625264644622803\n",
      "Epoch [2313/10000], Loss: 0.5625243782997131\n",
      "Epoch [2314/10000], Loss: 0.5625221729278564\n",
      "Epoch [2315/10000], Loss: 0.5625200867652893\n",
      "Epoch [2316/10000], Loss: 0.5625184178352356\n",
      "Epoch [2317/10000], Loss: 0.5625168085098267\n",
      "Epoch [2318/10000], Loss: 0.562515139579773\n",
      "Epoch [2319/10000], Loss: 0.562513530254364\n",
      "Epoch [2320/10000], Loss: 0.5625120997428894\n",
      "Epoch [2321/10000], Loss: 0.5625110268592834\n",
      "Epoch [2322/10000], Loss: 0.5625101327896118\n",
      "Epoch [2323/10000], Loss: 0.5625090003013611\n",
      "Epoch [2324/10000], Loss: 0.5625082850456238\n",
      "Epoch [2325/10000], Loss: 0.562507152557373\n",
      "Epoch [2326/10000], Loss: 0.5625061988830566\n",
      "Epoch [2327/10000], Loss: 0.5625049471855164\n",
      "Epoch [2328/10000], Loss: 0.5625041127204895\n",
      "Epoch [2329/10000], Loss: 0.5625038743019104\n",
      "Epoch [2330/10000], Loss: 0.5625036358833313\n",
      "Epoch [2331/10000], Loss: 0.5625036954879761\n",
      "Epoch [2332/10000], Loss: 0.562503457069397\n",
      "Epoch [2333/10000], Loss: 0.562503457069397\n",
      "Epoch [2334/10000], Loss: 0.5625036358833313\n",
      "Epoch [2335/10000], Loss: 0.5625035762786865\n",
      "Epoch [2336/10000], Loss: 0.5625030994415283\n",
      "Epoch [2337/10000], Loss: 0.5625022649765015\n",
      "Epoch [2338/10000], Loss: 0.5625011324882507\n",
      "Epoch [2339/10000], Loss: 0.562499463558197\n",
      "Epoch [2340/10000], Loss: 0.5624969601631165\n",
      "Epoch [2341/10000], Loss: 0.5624944567680359\n",
      "Epoch [2342/10000], Loss: 0.5624916553497314\n",
      "Epoch [2343/10000], Loss: 0.5624886155128479\n",
      "Epoch [2344/10000], Loss: 0.5624860525131226\n",
      "Epoch [2345/10000], Loss: 0.5624842047691345\n",
      "Epoch [2346/10000], Loss: 0.5624819397926331\n",
      "Epoch [2347/10000], Loss: 0.5624798536300659\n",
      "Epoch [2348/10000], Loss: 0.562478244304657\n",
      "Epoch [2349/10000], Loss: 0.562476634979248\n",
      "Epoch [2350/10000], Loss: 0.5624750256538391\n",
      "Epoch [2351/10000], Loss: 0.5624737739562988\n",
      "Epoch [2352/10000], Loss: 0.5624725222587585\n",
      "Epoch [2353/10000], Loss: 0.5624713897705078\n",
      "Epoch [2354/10000], Loss: 0.5624703764915466\n",
      "Epoch [2355/10000], Loss: 0.5624692440032959\n",
      "Epoch [2356/10000], Loss: 0.5624683499336243\n",
      "Epoch [2357/10000], Loss: 0.5624667406082153\n",
      "Epoch [2358/10000], Loss: 0.562465488910675\n",
      "Epoch [2359/10000], Loss: 0.5624637007713318\n",
      "Epoch [2360/10000], Loss: 0.5624625086784363\n",
      "Epoch [2361/10000], Loss: 0.5624613761901855\n",
      "Epoch [2362/10000], Loss: 0.5624597668647766\n",
      "Epoch [2363/10000], Loss: 0.5624582767486572\n",
      "Epoch [2364/10000], Loss: 0.5624565482139587\n",
      "Epoch [2365/10000], Loss: 0.5624549388885498\n",
      "Epoch [2366/10000], Loss: 0.5624532699584961\n",
      "Epoch [2367/10000], Loss: 0.5624517798423767\n",
      "Epoch [2368/10000], Loss: 0.5624505281448364\n",
      "Epoch [2369/10000], Loss: 0.5624487996101379\n",
      "Epoch [2370/10000], Loss: 0.5624473094940186\n",
      "Epoch [2371/10000], Loss: 0.5624458193778992\n",
      "Epoch [2372/10000], Loss: 0.5624440908432007\n",
      "Epoch [2373/10000], Loss: 0.5624423027038574\n",
      "Epoch [2374/10000], Loss: 0.5624409317970276\n",
      "Epoch [2375/10000], Loss: 0.562439501285553\n",
      "Epoch [2376/10000], Loss: 0.5624380707740784\n",
      "Epoch [2377/10000], Loss: 0.5624368786811829\n",
      "Epoch [2378/10000], Loss: 0.5624359846115112\n",
      "Epoch [2379/10000], Loss: 0.5624351501464844\n",
      "Epoch [2380/10000], Loss: 0.5624350905418396\n",
      "Epoch [2381/10000], Loss: 0.5624348521232605\n",
      "Epoch [2382/10000], Loss: 0.5624348521232605\n",
      "Epoch [2383/10000], Loss: 0.5624353289604187\n",
      "Epoch [2384/10000], Loss: 0.5624351501464844\n",
      "Epoch [2385/10000], Loss: 0.5624344348907471\n",
      "Epoch [2386/10000], Loss: 0.5624325275421143\n",
      "Epoch [2387/10000], Loss: 0.562429666519165\n",
      "Epoch [2388/10000], Loss: 0.5624260306358337\n",
      "Epoch [2389/10000], Loss: 0.5624217987060547\n",
      "Epoch [2390/10000], Loss: 0.5624172687530518\n",
      "Epoch [2391/10000], Loss: 0.5624132752418518\n",
      "Epoch [2392/10000], Loss: 0.562409520149231\n",
      "Epoch [2393/10000], Loss: 0.5624064803123474\n",
      "Epoch [2394/10000], Loss: 0.5624034404754639\n",
      "Epoch [2395/10000], Loss: 0.5624005198478699\n",
      "Epoch [2396/10000], Loss: 0.5623984932899475\n",
      "Epoch [2397/10000], Loss: 0.5623969435691833\n",
      "Epoch [2398/10000], Loss: 0.562395453453064\n",
      "Epoch [2399/10000], Loss: 0.5623940825462341\n",
      "Epoch [2400/10000], Loss: 0.5623927116394043\n",
      "Epoch [2401/10000], Loss: 0.5623916983604431\n",
      "Epoch [2402/10000], Loss: 0.562390923500061\n",
      "Epoch [2403/10000], Loss: 0.5623900890350342\n",
      "Epoch [2404/10000], Loss: 0.5623895525932312\n",
      "Epoch [2405/10000], Loss: 0.5623881816864014\n",
      "Epoch [2406/10000], Loss: 0.5623868107795715\n",
      "Epoch [2407/10000], Loss: 0.5623852610588074\n",
      "Epoch [2408/10000], Loss: 0.5623826384544373\n",
      "Epoch [2409/10000], Loss: 0.5623805522918701\n",
      "Epoch [2410/10000], Loss: 0.5623783469200134\n",
      "Epoch [2411/10000], Loss: 0.5623765587806702\n",
      "Epoch [2412/10000], Loss: 0.5623742938041687\n",
      "Epoch [2413/10000], Loss: 0.5623719692230225\n",
      "Epoch [2414/10000], Loss: 0.5623701810836792\n",
      "Epoch [2415/10000], Loss: 0.562369167804718\n",
      "Epoch [2416/10000], Loss: 0.5623682737350464\n",
      "Epoch [2417/10000], Loss: 0.5623681545257568\n",
      "Epoch [2418/10000], Loss: 0.5623681545257568\n",
      "Epoch [2419/10000], Loss: 0.5623684525489807\n",
      "Epoch [2420/10000], Loss: 0.5623683929443359\n",
      "Epoch [2421/10000], Loss: 0.5623679161071777\n",
      "Epoch [2422/10000], Loss: 0.5623658895492554\n",
      "Epoch [2423/10000], Loss: 0.5623638033866882\n",
      "Epoch [2424/10000], Loss: 0.5623608827590942\n",
      "Epoch [2425/10000], Loss: 0.5623579025268555\n",
      "Epoch [2426/10000], Loss: 0.5623553395271301\n",
      "Epoch [2427/10000], Loss: 0.5623531341552734\n",
      "Epoch [2428/10000], Loss: 0.5623511075973511\n",
      "Epoch [2429/10000], Loss: 0.5623494386672974\n",
      "Epoch [2430/10000], Loss: 0.5623481869697571\n",
      "Epoch [2431/10000], Loss: 0.5623471736907959\n",
      "Epoch [2432/10000], Loss: 0.5623461008071899\n",
      "Epoch [2433/10000], Loss: 0.5623449683189392\n",
      "Epoch [2434/10000], Loss: 0.562344491481781\n",
      "Epoch [2435/10000], Loss: 0.5623429417610168\n",
      "Epoch [2436/10000], Loss: 0.562341034412384\n",
      "Epoch [2437/10000], Loss: 0.5623393058776855\n",
      "Epoch [2438/10000], Loss: 0.5623371601104736\n",
      "Epoch [2439/10000], Loss: 0.5623355507850647\n",
      "Epoch [2440/10000], Loss: 0.5623340010643005\n",
      "Epoch [2441/10000], Loss: 0.5623326301574707\n",
      "Epoch [2442/10000], Loss: 0.5623319149017334\n",
      "Epoch [2443/10000], Loss: 0.56233149766922\n",
      "Epoch [2444/10000], Loss: 0.5623311400413513\n",
      "Epoch [2445/10000], Loss: 0.5623297691345215\n",
      "Epoch [2446/10000], Loss: 0.5623277425765991\n",
      "Epoch [2447/10000], Loss: 0.5623248815536499\n",
      "Epoch [2448/10000], Loss: 0.562321662902832\n",
      "Epoch [2449/10000], Loss: 0.5623174905776978\n",
      "Epoch [2450/10000], Loss: 0.562313973903656\n",
      "Epoch [2451/10000], Loss: 0.5623108148574829\n",
      "Epoch [2452/10000], Loss: 0.5623078942298889\n",
      "Epoch [2453/10000], Loss: 0.5623055100440979\n",
      "Epoch [2454/10000], Loss: 0.5623036623001099\n",
      "Epoch [2455/10000], Loss: 0.5623023509979248\n",
      "Epoch [2456/10000], Loss: 0.5623018145561218\n",
      "Epoch [2457/10000], Loss: 0.562301516532898\n",
      "Epoch [2458/10000], Loss: 0.5623006820678711\n",
      "Epoch [2459/10000], Loss: 0.5622984766960144\n",
      "Epoch [2460/10000], Loss: 0.5622954964637756\n",
      "Epoch [2461/10000], Loss: 0.5622923970222473\n",
      "Epoch [2462/10000], Loss: 0.5622899532318115\n",
      "Epoch [2463/10000], Loss: 0.5622875690460205\n",
      "Epoch [2464/10000], Loss: 0.5622861981391907\n",
      "Epoch [2465/10000], Loss: 0.5622852444648743\n",
      "Epoch [2466/10000], Loss: 0.5622841119766235\n",
      "Epoch [2467/10000], Loss: 0.562283456325531\n",
      "Epoch [2468/10000], Loss: 0.5622825026512146\n",
      "Epoch [2469/10000], Loss: 0.5622819662094116\n",
      "Epoch [2470/10000], Loss: 0.5622814297676086\n",
      "Epoch [2471/10000], Loss: 0.5622808933258057\n",
      "Epoch [2472/10000], Loss: 0.5622802376747131\n",
      "Epoch [2473/10000], Loss: 0.5622791051864624\n",
      "Epoch [2474/10000], Loss: 0.5622774362564087\n",
      "Epoch [2475/10000], Loss: 0.5622759461402893\n",
      "Epoch [2476/10000], Loss: 0.5622742772102356\n",
      "Epoch [2477/10000], Loss: 0.5622724890708923\n",
      "Epoch [2478/10000], Loss: 0.5622707605361938\n",
      "Epoch [2479/10000], Loss: 0.5622693300247192\n",
      "Epoch [2480/10000], Loss: 0.5622680187225342\n",
      "Epoch [2481/10000], Loss: 0.5622670650482178\n",
      "Epoch [2482/10000], Loss: 0.5622664093971252\n",
      "Epoch [2483/10000], Loss: 0.5622656345367432\n",
      "Epoch [2484/10000], Loss: 0.5622650980949402\n",
      "Epoch [2485/10000], Loss: 0.5622644424438477\n",
      "Epoch [2486/10000], Loss: 0.5622642636299133\n",
      "Epoch [2487/10000], Loss: 0.5622645020484924\n",
      "Epoch [2488/10000], Loss: 0.5622652173042297\n",
      "Epoch [2489/10000], Loss: 0.5622673034667969\n",
      "Epoch [2490/10000], Loss: 0.562269926071167\n",
      "Epoch [2491/10000], Loss: 0.5622725486755371\n",
      "Epoch [2492/10000], Loss: 0.5622749924659729\n",
      "Epoch [2493/10000], Loss: 0.5622757077217102\n",
      "Epoch [2494/10000], Loss: 0.5622740983963013\n",
      "Epoch [2495/10000], Loss: 0.5622689723968506\n",
      "Epoch [2496/10000], Loss: 0.5622622966766357\n",
      "Epoch [2497/10000], Loss: 0.5622541904449463\n",
      "Epoch [2498/10000], Loss: 0.5622469782829285\n",
      "Epoch [2499/10000], Loss: 0.5622423887252808\n",
      "Epoch [2500/10000], Loss: 0.5622400045394897\n",
      "Epoch [2501/10000], Loss: 0.562239408493042\n",
      "Epoch [2502/10000], Loss: 0.5622401237487793\n",
      "Epoch [2503/10000], Loss: 0.5622414946556091\n",
      "Epoch [2504/10000], Loss: 0.5622424483299255\n",
      "Epoch [2505/10000], Loss: 0.5622432827949524\n",
      "Epoch [2506/10000], Loss: 0.5622429251670837\n",
      "Epoch [2507/10000], Loss: 0.5622417330741882\n",
      "Epoch [2508/10000], Loss: 0.5622386336326599\n",
      "Epoch [2509/10000], Loss: 0.5622347593307495\n",
      "Epoch [2510/10000], Loss: 0.5622305870056152\n",
      "Epoch [2511/10000], Loss: 0.5622274279594421\n",
      "Epoch [2512/10000], Loss: 0.5622250437736511\n",
      "Epoch [2513/10000], Loss: 0.5622234344482422\n",
      "Epoch [2514/10000], Loss: 0.5622232556343079\n",
      "Epoch [2515/10000], Loss: 0.5622230172157288\n",
      "Epoch [2516/10000], Loss: 0.5622231364250183\n",
      "Epoch [2517/10000], Loss: 0.5622232556343079\n",
      "Epoch [2518/10000], Loss: 0.5622227787971497\n",
      "Epoch [2519/10000], Loss: 0.5622216463088989\n",
      "Epoch [2520/10000], Loss: 0.5622202754020691\n",
      "Epoch [2521/10000], Loss: 0.562218427658081\n",
      "Epoch [2522/10000], Loss: 0.5622162222862244\n",
      "Epoch [2523/10000], Loss: 0.5622144937515259\n",
      "Epoch [2524/10000], Loss: 0.5622128844261169\n",
      "Epoch [2525/10000], Loss: 0.5622116327285767\n",
      "Epoch [2526/10000], Loss: 0.5622106790542603\n",
      "Epoch [2527/10000], Loss: 0.5622104406356812\n",
      "Epoch [2528/10000], Loss: 0.5622105002403259\n",
      "Epoch [2529/10000], Loss: 0.5622114539146423\n",
      "Epoch [2530/10000], Loss: 0.5622117519378662\n",
      "Epoch [2531/10000], Loss: 0.5622116923332214\n",
      "Epoch [2532/10000], Loss: 0.5622114539146423\n",
      "Epoch [2533/10000], Loss: 0.5622103214263916\n",
      "Epoch [2534/10000], Loss: 0.5622084140777588\n",
      "Epoch [2535/10000], Loss: 0.5622063279151917\n",
      "Epoch [2536/10000], Loss: 0.5622037053108215\n",
      "Epoch [2537/10000], Loss: 0.5622014999389648\n",
      "Epoch [2538/10000], Loss: 0.5621993541717529\n",
      "Epoch [2539/10000], Loss: 0.5621981024742126\n",
      "Epoch [2540/10000], Loss: 0.5621972680091858\n",
      "Epoch [2541/10000], Loss: 0.5621969103813171\n",
      "Epoch [2542/10000], Loss: 0.5621964335441589\n",
      "Epoch [2543/10000], Loss: 0.5621962547302246\n",
      "Epoch [2544/10000], Loss: 0.5621962547302246\n",
      "Epoch [2545/10000], Loss: 0.5621959567070007\n",
      "Epoch [2546/10000], Loss: 0.5621952414512634\n",
      "Epoch [2547/10000], Loss: 0.5621945858001709\n",
      "Epoch [2548/10000], Loss: 0.5621933937072754\n",
      "Epoch [2549/10000], Loss: 0.5621924996376038\n",
      "Epoch [2550/10000], Loss: 0.5621914267539978\n",
      "Epoch [2551/10000], Loss: 0.5621907114982605\n",
      "Epoch [2552/10000], Loss: 0.5621898770332336\n",
      "Epoch [2553/10000], Loss: 0.5621892213821411\n",
      "Epoch [2554/10000], Loss: 0.5621886253356934\n",
      "Epoch [2555/10000], Loss: 0.5621882677078247\n",
      "Epoch [2556/10000], Loss: 0.562187671661377\n",
      "Epoch [2557/10000], Loss: 0.5621872544288635\n",
      "Epoch [2558/10000], Loss: 0.5621862411499023\n",
      "Epoch [2559/10000], Loss: 0.5621855854988098\n",
      "Epoch [2560/10000], Loss: 0.5621848106384277\n",
      "Epoch [2561/10000], Loss: 0.5621836185455322\n",
      "Epoch [2562/10000], Loss: 0.562182605266571\n",
      "Epoch [2563/10000], Loss: 0.5621817111968994\n",
      "Epoch [2564/10000], Loss: 0.5621811151504517\n",
      "Epoch [2565/10000], Loss: 0.562179684638977\n",
      "Epoch [2566/10000], Loss: 0.5621781945228577\n",
      "Epoch [2567/10000], Loss: 0.5621773600578308\n",
      "Epoch [2568/10000], Loss: 0.5621764659881592\n",
      "Epoch [2569/10000], Loss: 0.5621764063835144\n",
      "Epoch [2570/10000], Loss: 0.5621757507324219\n",
      "Epoch [2571/10000], Loss: 0.5621750950813293\n",
      "Epoch [2572/10000], Loss: 0.5621742010116577\n",
      "Epoch [2573/10000], Loss: 0.5621732473373413\n",
      "Epoch [2574/10000], Loss: 0.5621724128723145\n",
      "Epoch [2575/10000], Loss: 0.562171220779419\n",
      "Epoch [2576/10000], Loss: 0.5621699094772339\n",
      "Epoch [2577/10000], Loss: 0.5621688365936279\n",
      "Epoch [2578/10000], Loss: 0.5621684789657593\n",
      "Epoch [2579/10000], Loss: 0.5621677041053772\n",
      "Epoch [2580/10000], Loss: 0.5621678233146667\n",
      "Epoch [2581/10000], Loss: 0.5621681213378906\n",
      "Epoch [2582/10000], Loss: 0.5621684789657593\n",
      "Epoch [2583/10000], Loss: 0.5621688961982727\n",
      "Epoch [2584/10000], Loss: 0.5621700882911682\n",
      "Epoch [2585/10000], Loss: 0.5621703267097473\n",
      "Epoch [2586/10000], Loss: 0.5621703267097473\n",
      "Epoch [2587/10000], Loss: 0.5621702075004578\n",
      "Epoch [2588/10000], Loss: 0.5621696710586548\n",
      "Epoch [2589/10000], Loss: 0.5621682405471802\n",
      "Epoch [2590/10000], Loss: 0.5621663331985474\n",
      "Epoch [2591/10000], Loss: 0.562164306640625\n",
      "Epoch [2592/10000], Loss: 0.5621616244316101\n",
      "Epoch [2593/10000], Loss: 0.5621577501296997\n",
      "Epoch [2594/10000], Loss: 0.5621537566184998\n",
      "Epoch [2595/10000], Loss: 0.5621495246887207\n",
      "Epoch [2596/10000], Loss: 0.5621457099914551\n",
      "Epoch [2597/10000], Loss: 0.5621428489685059\n",
      "Epoch [2598/10000], Loss: 0.5621405243873596\n",
      "Epoch [2599/10000], Loss: 0.5621394515037537\n",
      "Epoch [2600/10000], Loss: 0.5621392130851746\n",
      "Epoch [2601/10000], Loss: 0.562139093875885\n",
      "Epoch [2602/10000], Loss: 0.5621398091316223\n",
      "Epoch [2603/10000], Loss: 0.562140941619873\n",
      "Epoch [2604/10000], Loss: 0.5621415972709656\n",
      "Epoch [2605/10000], Loss: 0.5621405243873596\n",
      "Epoch [2606/10000], Loss: 0.5621377229690552\n",
      "Epoch [2607/10000], Loss: 0.562133252620697\n",
      "Epoch [2608/10000], Loss: 0.5621290802955627\n",
      "Epoch [2609/10000], Loss: 0.5621249675750732\n",
      "Epoch [2610/10000], Loss: 0.5621208548545837\n",
      "Epoch [2611/10000], Loss: 0.5621176958084106\n",
      "Epoch [2612/10000], Loss: 0.5621148943901062\n",
      "Epoch [2613/10000], Loss: 0.5621121525764465\n",
      "Epoch [2614/10000], Loss: 0.5621097683906555\n",
      "Epoch [2615/10000], Loss: 0.5621072053909302\n",
      "Epoch [2616/10000], Loss: 0.5621044635772705\n",
      "Epoch [2617/10000], Loss: 0.5621020197868347\n",
      "Epoch [2618/10000], Loss: 0.562099814414978\n",
      "Epoch [2619/10000], Loss: 0.5620981454849243\n",
      "Epoch [2620/10000], Loss: 0.562096893787384\n",
      "Epoch [2621/10000], Loss: 0.5620955228805542\n",
      "Epoch [2622/10000], Loss: 0.5620949864387512\n",
      "Epoch [2623/10000], Loss: 0.5620940923690796\n",
      "Epoch [2624/10000], Loss: 0.5620926022529602\n",
      "Epoch [2625/10000], Loss: 0.5620907545089722\n",
      "Epoch [2626/10000], Loss: 0.5620881915092468\n",
      "Epoch [2627/10000], Loss: 0.5620858669281006\n",
      "Epoch [2628/10000], Loss: 0.56208336353302\n",
      "Epoch [2629/10000], Loss: 0.5620802044868469\n",
      "Epoch [2630/10000], Loss: 0.5620773434638977\n",
      "Epoch [2631/10000], Loss: 0.5620747804641724\n",
      "Epoch [2632/10000], Loss: 0.5620715618133545\n",
      "Epoch [2633/10000], Loss: 0.562068521976471\n",
      "Epoch [2634/10000], Loss: 0.5620659589767456\n",
      "Epoch [2635/10000], Loss: 0.5620635747909546\n",
      "Epoch [2636/10000], Loss: 0.5620614886283875\n",
      "Epoch [2637/10000], Loss: 0.5620602369308472\n",
      "Epoch [2638/10000], Loss: 0.5620590448379517\n",
      "Epoch [2639/10000], Loss: 0.56205815076828\n",
      "Epoch [2640/10000], Loss: 0.5620576739311218\n",
      "Epoch [2641/10000], Loss: 0.5620570182800293\n",
      "Epoch [2642/10000], Loss: 0.5620566606521606\n",
      "Epoch [2643/10000], Loss: 0.5620563626289368\n",
      "Epoch [2644/10000], Loss: 0.5620565414428711\n",
      "Epoch [2645/10000], Loss: 0.5620569586753845\n",
      "Epoch [2646/10000], Loss: 0.5620567798614502\n",
      "Epoch [2647/10000], Loss: 0.5620558261871338\n",
      "Epoch [2648/10000], Loss: 0.5620542764663696\n",
      "Epoch [2649/10000], Loss: 0.5620514154434204\n",
      "Epoch [2650/10000], Loss: 0.5620478391647339\n",
      "Epoch [2651/10000], Loss: 0.5620439648628235\n",
      "Epoch [2652/10000], Loss: 0.5620396733283997\n",
      "Epoch [2653/10000], Loss: 0.5620355606079102\n",
      "Epoch [2654/10000], Loss: 0.5620312690734863\n",
      "Epoch [2655/10000], Loss: 0.5620272159576416\n",
      "Epoch [2656/10000], Loss: 0.5620235204696655\n",
      "Epoch [2657/10000], Loss: 0.5620204210281372\n",
      "Epoch [2658/10000], Loss: 0.5620176792144775\n",
      "Epoch [2659/10000], Loss: 0.5620154738426208\n",
      "Epoch [2660/10000], Loss: 0.5620136260986328\n",
      "Epoch [2661/10000], Loss: 0.5620114803314209\n",
      "Epoch [2662/10000], Loss: 0.562009334564209\n",
      "Epoch [2663/10000], Loss: 0.5620073080062866\n",
      "Epoch [2664/10000], Loss: 0.5620055198669434\n",
      "Epoch [2665/10000], Loss: 0.5620030760765076\n",
      "Epoch [2666/10000], Loss: 0.562000572681427\n",
      "Epoch [2667/10000], Loss: 0.5619984269142151\n",
      "Epoch [2668/10000], Loss: 0.5619953274726868\n",
      "Epoch [2669/10000], Loss: 0.5619921088218689\n",
      "Epoch [2670/10000], Loss: 0.5619889497756958\n",
      "Epoch [2671/10000], Loss: 0.5619860887527466\n",
      "Epoch [2672/10000], Loss: 0.5619831085205078\n",
      "Epoch [2673/10000], Loss: 0.561980128288269\n",
      "Epoch [2674/10000], Loss: 0.5619775056838989\n",
      "Epoch [2675/10000], Loss: 0.5619747042655945\n",
      "Epoch [2676/10000], Loss: 0.5619715452194214\n",
      "Epoch [2677/10000], Loss: 0.5619685649871826\n",
      "Epoch [2678/10000], Loss: 0.5619658827781677\n",
      "Epoch [2679/10000], Loss: 0.5619630813598633\n",
      "Epoch [2680/10000], Loss: 0.5619606971740723\n",
      "Epoch [2681/10000], Loss: 0.5619581937789917\n",
      "Epoch [2682/10000], Loss: 0.5619555115699768\n",
      "Epoch [2683/10000], Loss: 0.5619527101516724\n",
      "Epoch [2684/10000], Loss: 0.5619502067565918\n",
      "Epoch [2685/10000], Loss: 0.5619474649429321\n",
      "Epoch [2686/10000], Loss: 0.5619450807571411\n",
      "Epoch [2687/10000], Loss: 0.5619428753852844\n",
      "Epoch [2688/10000], Loss: 0.5619407296180725\n",
      "Epoch [2689/10000], Loss: 0.5619387626647949\n",
      "Epoch [2690/10000], Loss: 0.5619369149208069\n",
      "Epoch [2691/10000], Loss: 0.5619354844093323\n",
      "Epoch [2692/10000], Loss: 0.5619338154792786\n",
      "Epoch [2693/10000], Loss: 0.5619322061538696\n",
      "Epoch [2694/10000], Loss: 0.5619309544563293\n",
      "Epoch [2695/10000], Loss: 0.5619295835494995\n",
      "Epoch [2696/10000], Loss: 0.5619285106658936\n",
      "Epoch [2697/10000], Loss: 0.5619279742240906\n",
      "Epoch [2698/10000], Loss: 0.5619268417358398\n",
      "Epoch [2699/10000], Loss: 0.5619251728057861\n",
      "Epoch [2700/10000], Loss: 0.5619237422943115\n",
      "Epoch [2701/10000], Loss: 0.5619221925735474\n",
      "Epoch [2702/10000], Loss: 0.5619204044342041\n",
      "Epoch [2703/10000], Loss: 0.5619184374809265\n",
      "Epoch [2704/10000], Loss: 0.5619159936904907\n",
      "Epoch [2705/10000], Loss: 0.5619136095046997\n",
      "Epoch [2706/10000], Loss: 0.5619115829467773\n",
      "Epoch [2707/10000], Loss: 0.5619094371795654\n",
      "Epoch [2708/10000], Loss: 0.5619077086448669\n",
      "Epoch [2709/10000], Loss: 0.561906099319458\n",
      "Epoch [2710/10000], Loss: 0.5619049668312073\n",
      "Epoch [2711/10000], Loss: 0.5619035959243774\n",
      "Epoch [2712/10000], Loss: 0.5619028806686401\n",
      "Epoch [2713/10000], Loss: 0.5619028806686401\n",
      "Epoch [2714/10000], Loss: 0.5619032382965088\n",
      "Epoch [2715/10000], Loss: 0.5619032382965088\n",
      "Epoch [2716/10000], Loss: 0.5619030594825745\n",
      "Epoch [2717/10000], Loss: 0.5619016885757446\n",
      "Epoch [2718/10000], Loss: 0.5618993639945984\n",
      "Epoch [2719/10000], Loss: 0.5618958473205566\n",
      "Epoch [2720/10000], Loss: 0.5618919730186462\n",
      "Epoch [2721/10000], Loss: 0.5618881583213806\n",
      "Epoch [2722/10000], Loss: 0.5618844628334045\n",
      "Epoch [2723/10000], Loss: 0.5618811845779419\n",
      "Epoch [2724/10000], Loss: 0.56187903881073\n",
      "Epoch [2725/10000], Loss: 0.5618771910667419\n",
      "Epoch [2726/10000], Loss: 0.5618760585784912\n",
      "Epoch [2727/10000], Loss: 0.5618747472763062\n",
      "Epoch [2728/10000], Loss: 0.5618736743927002\n",
      "Epoch [2729/10000], Loss: 0.5618725419044495\n",
      "Epoch [2730/10000], Loss: 0.5618714094161987\n",
      "Epoch [2731/10000], Loss: 0.5618706345558167\n",
      "Epoch [2732/10000], Loss: 0.5618699789047241\n",
      "Epoch [2733/10000], Loss: 0.5618699193000793\n",
      "Epoch [2734/10000], Loss: 0.5618700981140137\n",
      "Epoch [2735/10000], Loss: 0.5618705153465271\n",
      "Epoch [2736/10000], Loss: 0.5618708729743958\n",
      "Epoch [2737/10000], Loss: 0.5618708729743958\n",
      "Epoch [2738/10000], Loss: 0.5618699193000793\n",
      "Epoch [2739/10000], Loss: 0.5618677735328674\n",
      "Epoch [2740/10000], Loss: 0.5618650317192078\n",
      "Epoch [2741/10000], Loss: 0.5618617534637451\n",
      "Epoch [2742/10000], Loss: 0.5618587732315063\n",
      "Epoch [2743/10000], Loss: 0.5618560314178467\n",
      "Epoch [2744/10000], Loss: 0.5618536472320557\n",
      "Epoch [2745/10000], Loss: 0.5618519186973572\n",
      "Epoch [2746/10000], Loss: 0.5618505477905273\n",
      "Epoch [2747/10000], Loss: 0.5618501901626587\n",
      "Epoch [2748/10000], Loss: 0.5618503093719482\n",
      "Epoch [2749/10000], Loss: 0.5618510842323303\n",
      "Epoch [2750/10000], Loss: 0.561851978302002\n",
      "Epoch [2751/10000], Loss: 0.5618523955345154\n",
      "Epoch [2752/10000], Loss: 0.5618525147438049\n",
      "Epoch [2753/10000], Loss: 0.5618513822555542\n",
      "Epoch [2754/10000], Loss: 0.5618489384651184\n",
      "Epoch [2755/10000], Loss: 0.5618457794189453\n",
      "Epoch [2756/10000], Loss: 0.5618430376052856\n",
      "Epoch [2757/10000], Loss: 0.5618410110473633\n",
      "Epoch [2758/10000], Loss: 0.5618395209312439\n",
      "Epoch [2759/10000], Loss: 0.5618382692337036\n",
      "Epoch [2760/10000], Loss: 0.5618371963500977\n",
      "Epoch [2761/10000], Loss: 0.5618364214897156\n",
      "Epoch [2762/10000], Loss: 0.5618352890014648\n",
      "Epoch [2763/10000], Loss: 0.5618336796760559\n",
      "Epoch [2764/10000], Loss: 0.5618317127227783\n",
      "Epoch [2765/10000], Loss: 0.5618293285369873\n",
      "Epoch [2766/10000], Loss: 0.5618273615837097\n",
      "Epoch [2767/10000], Loss: 0.5618254542350769\n",
      "Epoch [2768/10000], Loss: 0.5618231892585754\n",
      "Epoch [2769/10000], Loss: 0.5618211627006531\n",
      "Epoch [2770/10000], Loss: 0.561819851398468\n",
      "Epoch [2771/10000], Loss: 0.5618187785148621\n",
      "Epoch [2772/10000], Loss: 0.5618178248405457\n",
      "Epoch [2773/10000], Loss: 0.5618170499801636\n",
      "Epoch [2774/10000], Loss: 0.5618167519569397\n",
      "Epoch [2775/10000], Loss: 0.5618176460266113\n",
      "Epoch [2776/10000], Loss: 0.561818540096283\n",
      "Epoch [2777/10000], Loss: 0.5618197917938232\n",
      "Epoch [2778/10000], Loss: 0.5618215799331665\n",
      "Epoch [2779/10000], Loss: 0.5618227124214172\n",
      "Epoch [2780/10000], Loss: 0.5618221163749695\n",
      "Epoch [2781/10000], Loss: 0.5618197917938232\n",
      "Epoch [2782/10000], Loss: 0.5618164539337158\n",
      "Epoch [2783/10000], Loss: 0.561812162399292\n",
      "Epoch [2784/10000], Loss: 0.561808168888092\n",
      "Epoch [2785/10000], Loss: 0.5618054270744324\n",
      "Epoch [2786/10000], Loss: 0.561802864074707\n",
      "Epoch [2787/10000], Loss: 0.5618014335632324\n",
      "Epoch [2788/10000], Loss: 0.561800479888916\n",
      "Epoch [2789/10000], Loss: 0.5618001818656921\n",
      "Epoch [2790/10000], Loss: 0.5618001818656921\n",
      "Epoch [2791/10000], Loss: 0.5618006587028503\n",
      "Epoch [2792/10000], Loss: 0.5618016123771667\n",
      "Epoch [2793/10000], Loss: 0.5618024468421936\n",
      "Epoch [2794/10000], Loss: 0.5618036985397339\n",
      "Epoch [2795/10000], Loss: 0.561803936958313\n",
      "Epoch [2796/10000], Loss: 0.5618023872375488\n",
      "Epoch [2797/10000], Loss: 0.5617997050285339\n",
      "Epoch [2798/10000], Loss: 0.561796247959137\n",
      "Epoch [2799/10000], Loss: 0.5617923140525818\n",
      "Epoch [2800/10000], Loss: 0.5617897510528564\n",
      "Epoch [2801/10000], Loss: 0.561788022518158\n",
      "Epoch [2802/10000], Loss: 0.5617865920066833\n",
      "Epoch [2803/10000], Loss: 0.5617855191230774\n",
      "Epoch [2804/10000], Loss: 0.5617851614952087\n",
      "Epoch [2805/10000], Loss: 0.5617847442626953\n",
      "Epoch [2806/10000], Loss: 0.561784565448761\n",
      "Epoch [2807/10000], Loss: 0.5617848038673401\n",
      "Epoch [2808/10000], Loss: 0.5617852210998535\n",
      "Epoch [2809/10000], Loss: 0.5617851614952087\n",
      "Epoch [2810/10000], Loss: 0.561784565448761\n",
      "Epoch [2811/10000], Loss: 0.5617832541465759\n",
      "Epoch [2812/10000], Loss: 0.5617812871932983\n",
      "Epoch [2813/10000], Loss: 0.5617788434028625\n",
      "Epoch [2814/10000], Loss: 0.5617769360542297\n",
      "Epoch [2815/10000], Loss: 0.5617752075195312\n",
      "Epoch [2816/10000], Loss: 0.5617740154266357\n",
      "Epoch [2817/10000], Loss: 0.5617733001708984\n",
      "Epoch [2818/10000], Loss: 0.5617729425430298\n",
      "Epoch [2819/10000], Loss: 0.5617733001708984\n",
      "Epoch [2820/10000], Loss: 0.5617738962173462\n",
      "Epoch [2821/10000], Loss: 0.5617746114730835\n",
      "Epoch [2822/10000], Loss: 0.5617750883102417\n",
      "Epoch [2823/10000], Loss: 0.5617755055427551\n",
      "Epoch [2824/10000], Loss: 0.561776340007782\n",
      "Epoch [2825/10000], Loss: 0.5617774724960327\n",
      "Epoch [2826/10000], Loss: 0.5617796182632446\n",
      "Epoch [2827/10000], Loss: 0.5617834329605103\n",
      "Epoch [2828/10000], Loss: 0.5617889165878296\n",
      "Epoch [2829/10000], Loss: 0.5617948174476624\n",
      "Epoch [2830/10000], Loss: 0.5617995858192444\n",
      "Epoch [2831/10000], Loss: 0.5618007779121399\n",
      "Epoch [2832/10000], Loss: 0.5617973804473877\n",
      "Epoch [2833/10000], Loss: 0.5617876648902893\n",
      "Epoch [2834/10000], Loss: 0.5617750287055969\n",
      "Epoch [2835/10000], Loss: 0.5617621541023254\n",
      "Epoch [2836/10000], Loss: 0.5617538690567017\n",
      "Epoch [2837/10000], Loss: 0.5617517828941345\n",
      "Epoch [2838/10000], Loss: 0.5617542862892151\n",
      "Epoch [2839/10000], Loss: 0.5617583990097046\n",
      "Epoch [2840/10000], Loss: 0.5617616772651672\n",
      "Epoch [2841/10000], Loss: 0.561761736869812\n",
      "Epoch [2842/10000], Loss: 0.561758279800415\n",
      "Epoch [2843/10000], Loss: 0.5617536902427673\n",
      "Epoch [2844/10000], Loss: 0.5617486238479614\n",
      "Epoch [2845/10000], Loss: 0.5617453455924988\n",
      "Epoch [2846/10000], Loss: 0.5617439150810242\n",
      "Epoch [2847/10000], Loss: 0.5617433786392212\n",
      "Epoch [2848/10000], Loss: 0.5617429614067078\n",
      "Epoch [2849/10000], Loss: 0.561741828918457\n",
      "Epoch [2850/10000], Loss: 0.5617399215698242\n",
      "Epoch [2851/10000], Loss: 0.5617380142211914\n",
      "Epoch [2852/10000], Loss: 0.5617365837097168\n",
      "Epoch [2853/10000], Loss: 0.5617354512214661\n",
      "Epoch [2854/10000], Loss: 0.5617354512214661\n",
      "Epoch [2855/10000], Loss: 0.5617357492446899\n",
      "Epoch [2856/10000], Loss: 0.5617356896400452\n",
      "Epoch [2857/10000], Loss: 0.5617348551750183\n",
      "Epoch [2858/10000], Loss: 0.561733067035675\n",
      "Epoch [2859/10000], Loss: 0.5617305040359497\n",
      "Epoch [2860/10000], Loss: 0.5617283582687378\n",
      "Epoch [2861/10000], Loss: 0.5617272257804871\n",
      "Epoch [2862/10000], Loss: 0.5617261528968811\n",
      "Epoch [2863/10000], Loss: 0.5617256760597229\n",
      "Epoch [2864/10000], Loss: 0.5617254376411438\n",
      "Epoch [2865/10000], Loss: 0.5617253184318542\n",
      "Epoch [2866/10000], Loss: 0.5617256760597229\n",
      "Epoch [2867/10000], Loss: 0.5617255568504333\n",
      "Epoch [2868/10000], Loss: 0.5617251992225647\n",
      "Epoch [2869/10000], Loss: 0.5617243051528931\n",
      "Epoch [2870/10000], Loss: 0.5617240071296692\n",
      "Epoch [2871/10000], Loss: 0.5617225766181946\n",
      "Epoch [2872/10000], Loss: 0.561721682548523\n",
      "Epoch [2873/10000], Loss: 0.5617213845252991\n",
      "Epoch [2874/10000], Loss: 0.5617208480834961\n",
      "Epoch [2875/10000], Loss: 0.5617204904556274\n",
      "Epoch [2876/10000], Loss: 0.5617199540138245\n",
      "Epoch [2877/10000], Loss: 0.5617188215255737\n",
      "Epoch [2878/10000], Loss: 0.5617178678512573\n",
      "Epoch [2879/10000], Loss: 0.5617165565490723\n",
      "Epoch [2880/10000], Loss: 0.5617153644561768\n",
      "Epoch [2881/10000], Loss: 0.5617142915725708\n",
      "Epoch [2882/10000], Loss: 0.561713457107544\n",
      "Epoch [2883/10000], Loss: 0.5617126822471619\n",
      "Epoch [2884/10000], Loss: 0.561711311340332\n",
      "Epoch [2885/10000], Loss: 0.5617105960845947\n",
      "Epoch [2886/10000], Loss: 0.5617097020149231\n",
      "Epoch [2887/10000], Loss: 0.5617086291313171\n",
      "Epoch [2888/10000], Loss: 0.5617077946662903\n",
      "Epoch [2889/10000], Loss: 0.56170654296875\n",
      "Epoch [2890/10000], Loss: 0.5617056488990784\n",
      "Epoch [2891/10000], Loss: 0.5617045164108276\n",
      "Epoch [2892/10000], Loss: 0.5617038607597351\n",
      "Epoch [2893/10000], Loss: 0.5617029070854187\n",
      "Epoch [2894/10000], Loss: 0.5617027282714844\n",
      "Epoch [2895/10000], Loss: 0.5617029070854187\n",
      "Epoch [2896/10000], Loss: 0.5617029666900635\n",
      "Epoch [2897/10000], Loss: 0.5617032051086426\n",
      "Epoch [2898/10000], Loss: 0.5617033243179321\n",
      "Epoch [2899/10000], Loss: 0.5617037415504456\n",
      "Epoch [2900/10000], Loss: 0.5617032647132874\n",
      "Epoch [2901/10000], Loss: 0.5617021322250366\n",
      "Epoch [2902/10000], Loss: 0.5617011785507202\n",
      "Epoch [2903/10000], Loss: 0.561699628829956\n",
      "Epoch [2904/10000], Loss: 0.561697781085968\n",
      "Epoch [2905/10000], Loss: 0.5616961121559143\n",
      "Epoch [2906/10000], Loss: 0.5616948008537292\n",
      "Epoch [2907/10000], Loss: 0.5616934895515442\n",
      "Epoch [2908/10000], Loss: 0.561692476272583\n",
      "Epoch [2909/10000], Loss: 0.5616918802261353\n",
      "Epoch [2910/10000], Loss: 0.5616913437843323\n",
      "Epoch [2911/10000], Loss: 0.5616909265518188\n",
      "Epoch [2912/10000], Loss: 0.561690628528595\n",
      "Epoch [2913/10000], Loss: 0.561690092086792\n",
      "Epoch [2914/10000], Loss: 0.5616901516914368\n",
      "Epoch [2915/10000], Loss: 0.5616902112960815\n",
      "Epoch [2916/10000], Loss: 0.5616903901100159\n",
      "Epoch [2917/10000], Loss: 0.5616906881332397\n",
      "Epoch [2918/10000], Loss: 0.5616910457611084\n",
      "Epoch [2919/10000], Loss: 0.561691164970398\n",
      "Epoch [2920/10000], Loss: 0.561691164970398\n",
      "Epoch [2921/10000], Loss: 0.561690628528595\n",
      "Epoch [2922/10000], Loss: 0.5616901516914368\n",
      "Epoch [2923/10000], Loss: 0.5616896748542786\n",
      "Epoch [2924/10000], Loss: 0.5616888403892517\n",
      "Epoch [2925/10000], Loss: 0.5616883635520935\n",
      "Epoch [2926/10000], Loss: 0.5616880059242249\n",
      "Epoch [2927/10000], Loss: 0.5616881847381592\n",
      "Epoch [2928/10000], Loss: 0.5616887211799622\n",
      "Epoch [2929/10000], Loss: 0.5616896748542786\n",
      "Epoch [2930/10000], Loss: 0.5616911053657532\n",
      "Epoch [2931/10000], Loss: 0.5616922974586487\n",
      "Epoch [2932/10000], Loss: 0.5616922378540039\n",
      "Epoch [2933/10000], Loss: 0.5616912245750427\n",
      "Epoch [2934/10000], Loss: 0.5616888403892517\n",
      "Epoch [2935/10000], Loss: 0.5616849660873413\n",
      "Epoch [2936/10000], Loss: 0.5616807341575623\n",
      "Epoch [2937/10000], Loss: 0.5616775751113892\n",
      "Epoch [2938/10000], Loss: 0.5616753697395325\n",
      "Epoch [2939/10000], Loss: 0.5616739392280579\n",
      "Epoch [2940/10000], Loss: 0.5616735219955444\n",
      "Epoch [2941/10000], Loss: 0.5616742372512817\n",
      "Epoch [2942/10000], Loss: 0.5616750121116638\n",
      "Epoch [2943/10000], Loss: 0.5616754293441772\n",
      "Epoch [2944/10000], Loss: 0.5616765022277832\n",
      "Epoch [2945/10000], Loss: 0.5616766810417175\n",
      "Epoch [2946/10000], Loss: 0.5616757273674011\n",
      "Epoch [2947/10000], Loss: 0.5616745352745056\n",
      "Epoch [2948/10000], Loss: 0.561672568321228\n",
      "Epoch [2949/10000], Loss: 0.5616706609725952\n",
      "Epoch [2950/10000], Loss: 0.5616694092750549\n",
      "Epoch [2951/10000], Loss: 0.561668872833252\n",
      "Epoch [2952/10000], Loss: 0.5616679191589355\n",
      "Epoch [2953/10000], Loss: 0.5616675615310669\n",
      "Epoch [2954/10000], Loss: 0.5616679787635803\n",
      "Epoch [2955/10000], Loss: 0.5616674423217773\n",
      "Epoch [2956/10000], Loss: 0.5616676211357117\n",
      "Epoch [2957/10000], Loss: 0.5616677403450012\n",
      "Epoch [2958/10000], Loss: 0.5616673827171326\n",
      "Epoch [2959/10000], Loss: 0.5616669058799744\n",
      "Epoch [2960/10000], Loss: 0.5616663694381714\n",
      "Epoch [2961/10000], Loss: 0.5616664886474609\n",
      "Epoch [2962/10000], Loss: 0.5616663098335266\n",
      "Epoch [2963/10000], Loss: 0.5616663694381714\n",
      "Epoch [2964/10000], Loss: 0.5616664886474609\n",
      "Epoch [2965/10000], Loss: 0.56166672706604\n",
      "Epoch [2966/10000], Loss: 0.5616661310195923\n",
      "Epoch [2967/10000], Loss: 0.5616657137870789\n",
      "Epoch [2968/10000], Loss: 0.561665415763855\n",
      "Epoch [2969/10000], Loss: 0.561664879322052\n",
      "Epoch [2970/10000], Loss: 0.561664342880249\n",
      "Epoch [2971/10000], Loss: 0.5616642236709595\n",
      "Epoch [2972/10000], Loss: 0.5616641640663147\n",
      "Epoch [2973/10000], Loss: 0.5616648197174072\n",
      "Epoch [2974/10000], Loss: 0.5616652369499207\n",
      "Epoch [2975/10000], Loss: 0.5616655349731445\n",
      "Epoch [2976/10000], Loss: 0.5616663098335266\n",
      "Epoch [2977/10000], Loss: 0.5616671442985535\n",
      "Epoch [2978/10000], Loss: 0.561668336391449\n",
      "Epoch [2979/10000], Loss: 0.5616694688796997\n",
      "Epoch [2980/10000], Loss: 0.5616701245307922\n",
      "Epoch [2981/10000], Loss: 0.561671257019043\n",
      "Epoch [2982/10000], Loss: 0.5616708993911743\n",
      "Epoch [2983/10000], Loss: 0.5616701245307922\n",
      "Epoch [2984/10000], Loss: 0.5616682171821594\n",
      "Epoch [2985/10000], Loss: 0.5616657137870789\n",
      "Epoch [2986/10000], Loss: 0.5616626739501953\n",
      "Epoch [2987/10000], Loss: 0.5616596937179565\n",
      "Epoch [2988/10000], Loss: 0.5616573095321655\n",
      "Epoch [2989/10000], Loss: 0.561655580997467\n",
      "Epoch [2990/10000], Loss: 0.5616544485092163\n",
      "Epoch [2991/10000], Loss: 0.5616535544395447\n",
      "Epoch [2992/10000], Loss: 0.561652421951294\n",
      "Epoch [2993/10000], Loss: 0.5616509318351746\n",
      "Epoch [2994/10000], Loss: 0.5616496801376343\n",
      "Epoch [2995/10000], Loss: 0.5616483688354492\n",
      "Epoch [2996/10000], Loss: 0.5616471767425537\n",
      "Epoch [2997/10000], Loss: 0.5616462826728821\n",
      "Epoch [2998/10000], Loss: 0.5616461038589478\n",
      "Epoch [2999/10000], Loss: 0.5616464614868164\n",
      "Epoch [3000/10000], Loss: 0.5616472959518433\n",
      "Epoch [3001/10000], Loss: 0.5616477727890015\n",
      "Epoch [3002/10000], Loss: 0.5616485476493835\n",
      "Epoch [3003/10000], Loss: 0.5616486668586731\n",
      "Epoch [3004/10000], Loss: 0.5616479516029358\n",
      "Epoch [3005/10000], Loss: 0.5616464018821716\n",
      "Epoch [3006/10000], Loss: 0.561644971370697\n",
      "Epoch [3007/10000], Loss: 0.5616435408592224\n",
      "Epoch [3008/10000], Loss: 0.5616427063941956\n",
      "Epoch [3009/10000], Loss: 0.5616417527198792\n",
      "Epoch [3010/10000], Loss: 0.5616409778594971\n",
      "Epoch [3011/10000], Loss: 0.5616400241851807\n",
      "Epoch [3012/10000], Loss: 0.5616391897201538\n",
      "Epoch [3013/10000], Loss: 0.5616382956504822\n",
      "Epoch [3014/10000], Loss: 0.5616375803947449\n",
      "Epoch [3015/10000], Loss: 0.561636745929718\n",
      "Epoch [3016/10000], Loss: 0.5616360902786255\n",
      "Epoch [3017/10000], Loss: 0.5616351962089539\n",
      "Epoch [3018/10000], Loss: 0.5616350769996643\n",
      "Epoch [3019/10000], Loss: 0.5616347789764404\n",
      "Epoch [3020/10000], Loss: 0.5616344809532166\n",
      "Epoch [3021/10000], Loss: 0.5616345405578613\n",
      "Epoch [3022/10000], Loss: 0.5616344809532166\n",
      "Epoch [3023/10000], Loss: 0.561633825302124\n",
      "Epoch [3024/10000], Loss: 0.5616322755813599\n",
      "Epoch [3025/10000], Loss: 0.5616312623023987\n",
      "Epoch [3026/10000], Loss: 0.5616302490234375\n",
      "Epoch [3027/10000], Loss: 0.5616294145584106\n",
      "Epoch [3028/10000], Loss: 0.5616286993026733\n",
      "Epoch [3029/10000], Loss: 0.5616278052330017\n",
      "Epoch [3030/10000], Loss: 0.5616275668144226\n",
      "Epoch [3031/10000], Loss: 0.5616276860237122\n",
      "Epoch [3032/10000], Loss: 0.5616273283958435\n",
      "Epoch [3033/10000], Loss: 0.5616268515586853\n",
      "Epoch [3034/10000], Loss: 0.5616270303726196\n",
      "Epoch [3035/10000], Loss: 0.5616270899772644\n",
      "Epoch [3036/10000], Loss: 0.5616268515586853\n",
      "Epoch [3037/10000], Loss: 0.561626672744751\n",
      "Epoch [3038/10000], Loss: 0.5616263747215271\n",
      "Epoch [3039/10000], Loss: 0.5616263151168823\n",
      "Epoch [3040/10000], Loss: 0.5616261959075928\n",
      "Epoch [3041/10000], Loss: 0.5616263151168823\n",
      "Epoch [3042/10000], Loss: 0.5616263747215271\n",
      "Epoch [3043/10000], Loss: 0.5616263151168823\n",
      "Epoch [3044/10000], Loss: 0.561626136302948\n",
      "Epoch [3045/10000], Loss: 0.5616254806518555\n",
      "Epoch [3046/10000], Loss: 0.5616241097450256\n",
      "Epoch [3047/10000], Loss: 0.5616223216056824\n",
      "Epoch [3048/10000], Loss: 0.5616204738616943\n",
      "Epoch [3049/10000], Loss: 0.5616188049316406\n",
      "Epoch [3050/10000], Loss: 0.561617374420166\n",
      "Epoch [3051/10000], Loss: 0.5616158246994019\n",
      "Epoch [3052/10000], Loss: 0.561614453792572\n",
      "Epoch [3053/10000], Loss: 0.561613142490387\n",
      "Epoch [3054/10000], Loss: 0.5616118311882019\n",
      "Epoch [3055/10000], Loss: 0.561610758304596\n",
      "Epoch [3056/10000], Loss: 0.5616099834442139\n",
      "Epoch [3057/10000], Loss: 0.5616092681884766\n",
      "Epoch [3058/10000], Loss: 0.561608612537384\n",
      "Epoch [3059/10000], Loss: 0.5616081953048706\n",
      "Epoch [3060/10000], Loss: 0.5616076588630676\n",
      "Epoch [3061/10000], Loss: 0.5616070032119751\n",
      "Epoch [3062/10000], Loss: 0.5616066455841064\n",
      "Epoch [3063/10000], Loss: 0.5616064071655273\n",
      "Epoch [3064/10000], Loss: 0.5616059303283691\n",
      "Epoch [3065/10000], Loss: 0.56160569190979\n",
      "Epoch [3066/10000], Loss: 0.5616059899330139\n",
      "Epoch [3067/10000], Loss: 0.5616068243980408\n",
      "Epoch [3068/10000], Loss: 0.5616084933280945\n",
      "Epoch [3069/10000], Loss: 0.561610758304596\n",
      "Epoch [3070/10000], Loss: 0.5616119503974915\n",
      "Epoch [3071/10000], Loss: 0.5616122484207153\n",
      "Epoch [3072/10000], Loss: 0.5616111755371094\n",
      "Epoch [3073/10000], Loss: 0.5616093277931213\n",
      "Epoch [3074/10000], Loss: 0.5616067051887512\n",
      "Epoch [3075/10000], Loss: 0.5616042613983154\n",
      "Epoch [3076/10000], Loss: 0.5616018772125244\n",
      "Epoch [3077/10000], Loss: 0.561600387096405\n",
      "Epoch [3078/10000], Loss: 0.56159907579422\n",
      "Epoch [3079/10000], Loss: 0.5615981221199036\n",
      "Epoch [3080/10000], Loss: 0.5615972280502319\n",
      "Epoch [3081/10000], Loss: 0.5615963935852051\n",
      "Epoch [3082/10000], Loss: 0.5615964531898499\n",
      "Epoch [3083/10000], Loss: 0.5615965723991394\n",
      "Epoch [3084/10000], Loss: 0.5615965127944946\n",
      "Epoch [3085/10000], Loss: 0.5615970492362976\n",
      "Epoch [3086/10000], Loss: 0.5615970492362976\n",
      "Epoch [3087/10000], Loss: 0.5615971684455872\n",
      "Epoch [3088/10000], Loss: 0.5615966320037842\n",
      "Epoch [3089/10000], Loss: 0.5615956783294678\n",
      "Epoch [3090/10000], Loss: 0.5615944266319275\n",
      "Epoch [3091/10000], Loss: 0.5615927577018738\n",
      "Epoch [3092/10000], Loss: 0.5615921020507812\n",
      "Epoch [3093/10000], Loss: 0.5615918636322021\n",
      "Epoch [3094/10000], Loss: 0.5615925192832947\n",
      "Epoch [3095/10000], Loss: 0.5615938305854797\n",
      "Epoch [3096/10000], Loss: 0.5615957379341125\n",
      "Epoch [3097/10000], Loss: 0.5615982413291931\n",
      "Epoch [3098/10000], Loss: 0.5616000890731812\n",
      "Epoch [3099/10000], Loss: 0.5616016983985901\n",
      "Epoch [3100/10000], Loss: 0.5616019368171692\n",
      "Epoch [3101/10000], Loss: 0.5616007447242737\n",
      "Epoch [3102/10000], Loss: 0.5615973472595215\n",
      "Epoch [3103/10000], Loss: 0.5615936517715454\n",
      "Epoch [3104/10000], Loss: 0.561588704586029\n",
      "Epoch [3105/10000], Loss: 0.5615838766098022\n",
      "Epoch [3106/10000], Loss: 0.5615792870521545\n",
      "Epoch [3107/10000], Loss: 0.5615763664245605\n",
      "Epoch [3108/10000], Loss: 0.5615742206573486\n",
      "Epoch [3109/10000], Loss: 0.5615737438201904\n",
      "Epoch [3110/10000], Loss: 0.56157386302948\n",
      "Epoch [3111/10000], Loss: 0.561574399471283\n",
      "Epoch [3112/10000], Loss: 0.5615742802619934\n",
      "Epoch [3113/10000], Loss: 0.5615739226341248\n",
      "Epoch [3114/10000], Loss: 0.5615730285644531\n",
      "Epoch [3115/10000], Loss: 0.5615706443786621\n",
      "Epoch [3116/10000], Loss: 0.5615679621696472\n",
      "Epoch [3117/10000], Loss: 0.5615657567977905\n",
      "Epoch [3118/10000], Loss: 0.561564564704895\n",
      "Epoch [3119/10000], Loss: 0.5615633726119995\n",
      "Epoch [3120/10000], Loss: 0.5615638494491577\n",
      "Epoch [3121/10000], Loss: 0.5615643858909607\n",
      "Epoch [3122/10000], Loss: 0.5615652799606323\n",
      "Epoch [3123/10000], Loss: 0.5615648031234741\n",
      "Epoch [3124/10000], Loss: 0.5615637898445129\n",
      "Epoch [3125/10000], Loss: 0.5615617632865906\n",
      "Epoch [3126/10000], Loss: 0.5615595579147339\n",
      "Epoch [3127/10000], Loss: 0.5615572333335876\n",
      "Epoch [3128/10000], Loss: 0.5615555047988892\n",
      "Epoch [3129/10000], Loss: 0.561553955078125\n",
      "Epoch [3130/10000], Loss: 0.561552882194519\n",
      "Epoch [3131/10000], Loss: 0.5615521669387817\n",
      "Epoch [3132/10000], Loss: 0.5615516304969788\n",
      "Epoch [3133/10000], Loss: 0.5615513920783997\n",
      "Epoch [3134/10000], Loss: 0.5615513920783997\n",
      "Epoch [3135/10000], Loss: 0.5615516901016235\n",
      "Epoch [3136/10000], Loss: 0.5615516901016235\n",
      "Epoch [3137/10000], Loss: 0.5615508556365967\n",
      "Epoch [3138/10000], Loss: 0.5615493059158325\n",
      "Epoch [3139/10000], Loss: 0.5615472793579102\n",
      "Epoch [3140/10000], Loss: 0.5615453124046326\n",
      "Epoch [3141/10000], Loss: 0.5615435242652893\n",
      "Epoch [3142/10000], Loss: 0.5615427494049072\n",
      "Epoch [3143/10000], Loss: 0.5615418553352356\n",
      "Epoch [3144/10000], Loss: 0.5615415573120117\n",
      "Epoch [3145/10000], Loss: 0.5615415573120117\n",
      "Epoch [3146/10000], Loss: 0.5615417957305908\n",
      "Epoch [3147/10000], Loss: 0.561542272567749\n",
      "Epoch [3148/10000], Loss: 0.5615427494049072\n",
      "Epoch [3149/10000], Loss: 0.561542809009552\n",
      "Epoch [3150/10000], Loss: 0.5615428686141968\n",
      "Epoch [3151/10000], Loss: 0.5615423917770386\n",
      "Epoch [3152/10000], Loss: 0.5615415573120117\n",
      "Epoch [3153/10000], Loss: 0.5615397095680237\n",
      "Epoch [3154/10000], Loss: 0.5615374445915222\n",
      "Epoch [3155/10000], Loss: 0.561535656452179\n",
      "Epoch [3156/10000], Loss: 0.5615342855453491\n",
      "Epoch [3157/10000], Loss: 0.5615335702896118\n",
      "Epoch [3158/10000], Loss: 0.5615325570106506\n",
      "Epoch [3159/10000], Loss: 0.5615312457084656\n",
      "Epoch [3160/10000], Loss: 0.5615299344062805\n",
      "Epoch [3161/10000], Loss: 0.5615277290344238\n",
      "Epoch [3162/10000], Loss: 0.5615255236625671\n",
      "Epoch [3163/10000], Loss: 0.5615226626396179\n",
      "Epoch [3164/10000], Loss: 0.561520516872406\n",
      "Epoch [3165/10000], Loss: 0.5615181922912598\n",
      "Epoch [3166/10000], Loss: 0.5615167617797852\n",
      "Epoch [3167/10000], Loss: 0.5615151524543762\n",
      "Epoch [3168/10000], Loss: 0.5615138411521912\n",
      "Epoch [3169/10000], Loss: 0.5615131855010986\n",
      "Epoch [3170/10000], Loss: 0.5615124106407166\n",
      "Epoch [3171/10000], Loss: 0.5615120530128479\n",
      "Epoch [3172/10000], Loss: 0.5615112781524658\n",
      "Epoch [3173/10000], Loss: 0.5615103244781494\n",
      "Epoch [3174/10000], Loss: 0.5615094304084778\n",
      "Epoch [3175/10000], Loss: 0.5615081191062927\n",
      "Epoch [3176/10000], Loss: 0.5615062713623047\n",
      "Epoch [3177/10000], Loss: 0.5615047216415405\n",
      "Epoch [3178/10000], Loss: 0.5615033507347107\n",
      "Epoch [3179/10000], Loss: 0.5615020990371704\n",
      "Epoch [3180/10000], Loss: 0.5615007281303406\n",
      "Epoch [3181/10000], Loss: 0.5614997148513794\n",
      "Epoch [3182/10000], Loss: 0.5614989399909973\n",
      "Epoch [3183/10000], Loss: 0.5614984035491943\n",
      "Epoch [3184/10000], Loss: 0.5614984631538391\n",
      "Epoch [3185/10000], Loss: 0.5614989399909973\n",
      "Epoch [3186/10000], Loss: 0.5614999532699585\n",
      "Epoch [3187/10000], Loss: 0.5615008473396301\n",
      "Epoch [3188/10000], Loss: 0.5615018010139465\n",
      "Epoch [3189/10000], Loss: 0.5615023970603943\n",
      "Epoch [3190/10000], Loss: 0.5615028142929077\n",
      "Epoch [3191/10000], Loss: 0.5615028142929077\n",
      "Epoch [3192/10000], Loss: 0.5615018010139465\n",
      "Epoch [3193/10000], Loss: 0.5615003108978271\n",
      "Epoch [3194/10000], Loss: 0.5614978075027466\n",
      "Epoch [3195/10000], Loss: 0.561494767665863\n",
      "Epoch [3196/10000], Loss: 0.5614913702011108\n",
      "Epoch [3197/10000], Loss: 0.5614880919456482\n",
      "Epoch [3198/10000], Loss: 0.5614852905273438\n",
      "Epoch [3199/10000], Loss: 0.5614827871322632\n",
      "Epoch [3200/10000], Loss: 0.5614808797836304\n",
      "Epoch [3201/10000], Loss: 0.5614791512489319\n",
      "Epoch [3202/10000], Loss: 0.5614776015281677\n",
      "Epoch [3203/10000], Loss: 0.5614766478538513\n",
      "Epoch [3204/10000], Loss: 0.561475396156311\n",
      "Epoch [3205/10000], Loss: 0.5614738464355469\n",
      "Epoch [3206/10000], Loss: 0.5614727139472961\n",
      "Epoch [3207/10000], Loss: 0.5614714026451111\n",
      "Epoch [3208/10000], Loss: 0.5614704489707947\n",
      "Epoch [3209/10000], Loss: 0.5614693760871887\n",
      "Epoch [3210/10000], Loss: 0.5614686012268066\n",
      "Epoch [3211/10000], Loss: 0.5614675283432007\n",
      "Epoch [3212/10000], Loss: 0.5614663362503052\n",
      "Epoch [3213/10000], Loss: 0.5614650845527649\n",
      "Epoch [3214/10000], Loss: 0.5614643692970276\n",
      "Epoch [3215/10000], Loss: 0.5614636540412903\n",
      "Epoch [3216/10000], Loss: 0.56146240234375\n",
      "Epoch [3217/10000], Loss: 0.5614610314369202\n",
      "Epoch [3218/10000], Loss: 0.5614596605300903\n",
      "Epoch [3219/10000], Loss: 0.5614583492279053\n",
      "Epoch [3220/10000], Loss: 0.5614570379257202\n",
      "Epoch [3221/10000], Loss: 0.5614557862281799\n",
      "Epoch [3222/10000], Loss: 0.5614545345306396\n",
      "Epoch [3223/10000], Loss: 0.5614532232284546\n",
      "Epoch [3224/10000], Loss: 0.5614516735076904\n",
      "Epoch [3225/10000], Loss: 0.5614505410194397\n",
      "Epoch [3226/10000], Loss: 0.5614490509033203\n",
      "Epoch [3227/10000], Loss: 0.5614475607872009\n",
      "Epoch [3228/10000], Loss: 0.5614458918571472\n",
      "Epoch [3229/10000], Loss: 0.5614448189735413\n",
      "Epoch [3230/10000], Loss: 0.5614437460899353\n",
      "Epoch [3231/10000], Loss: 0.5614425539970398\n",
      "Epoch [3232/10000], Loss: 0.5614416599273682\n",
      "Epoch [3233/10000], Loss: 0.5614408850669861\n",
      "Epoch [3234/10000], Loss: 0.5614400506019592\n",
      "Epoch [3235/10000], Loss: 0.5614395141601562\n",
      "Epoch [3236/10000], Loss: 0.5614391565322876\n",
      "Epoch [3237/10000], Loss: 0.5614389181137085\n",
      "Epoch [3238/10000], Loss: 0.5614390969276428\n",
      "Epoch [3239/10000], Loss: 0.5614396929740906\n",
      "Epoch [3240/10000], Loss: 0.5614402294158936\n",
      "Epoch [3241/10000], Loss: 0.5614409446716309\n",
      "Epoch [3242/10000], Loss: 0.56144118309021\n",
      "Epoch [3243/10000], Loss: 0.5614402294158936\n",
      "Epoch [3244/10000], Loss: 0.5614380836486816\n",
      "Epoch [3245/10000], Loss: 0.5614352822303772\n",
      "Epoch [3246/10000], Loss: 0.5614327192306519\n",
      "Epoch [3247/10000], Loss: 0.5614302158355713\n",
      "Epoch [3248/10000], Loss: 0.5614278316497803\n",
      "Epoch [3249/10000], Loss: 0.5614266395568848\n",
      "Epoch [3250/10000], Loss: 0.5614251494407654\n",
      "Epoch [3251/10000], Loss: 0.5614239573478699\n",
      "Epoch [3252/10000], Loss: 0.5614228248596191\n",
      "Epoch [3253/10000], Loss: 0.5614224076271057\n",
      "Epoch [3254/10000], Loss: 0.5614221692085266\n",
      "Epoch [3255/10000], Loss: 0.5614216327667236\n",
      "Epoch [3256/10000], Loss: 0.5614209175109863\n",
      "Epoch [3257/10000], Loss: 0.5614202618598938\n",
      "Epoch [3258/10000], Loss: 0.5614190101623535\n",
      "Epoch [3259/10000], Loss: 0.5614175200462341\n",
      "Epoch [3260/10000], Loss: 0.56141597032547\n",
      "Epoch [3261/10000], Loss: 0.5614140033721924\n",
      "Epoch [3262/10000], Loss: 0.5614116787910461\n",
      "Epoch [3263/10000], Loss: 0.5614092350006104\n",
      "Epoch [3264/10000], Loss: 0.5614075660705566\n",
      "Epoch [3265/10000], Loss: 0.5614058375358582\n",
      "Epoch [3266/10000], Loss: 0.5614038109779358\n",
      "Epoch [3267/10000], Loss: 0.5614029169082642\n",
      "Epoch [3268/10000], Loss: 0.5614016056060791\n",
      "Epoch [3269/10000], Loss: 0.5614007711410522\n",
      "Epoch [3270/10000], Loss: 0.5613999366760254\n",
      "Epoch [3271/10000], Loss: 0.5613994002342224\n",
      "Epoch [3272/10000], Loss: 0.5613985061645508\n",
      "Epoch [3273/10000], Loss: 0.5613979697227478\n",
      "Epoch [3274/10000], Loss: 0.5613975524902344\n",
      "Epoch [3275/10000], Loss: 0.5613971948623657\n",
      "Epoch [3276/10000], Loss: 0.5613973140716553\n",
      "Epoch [3277/10000], Loss: 0.5613977909088135\n",
      "Epoch [3278/10000], Loss: 0.5613981485366821\n",
      "Epoch [3279/10000], Loss: 0.5613988637924194\n",
      "Epoch [3280/10000], Loss: 0.5613991022109985\n",
      "Epoch [3281/10000], Loss: 0.5613996386528015\n",
      "Epoch [3282/10000], Loss: 0.5614006519317627\n",
      "Epoch [3283/10000], Loss: 0.5614010095596313\n",
      "Epoch [3284/10000], Loss: 0.561400830745697\n",
      "Epoch [3285/10000], Loss: 0.5614005327224731\n",
      "Epoch [3286/10000], Loss: 0.5613996386528015\n",
      "Epoch [3287/10000], Loss: 0.5613982677459717\n",
      "Epoch [3288/10000], Loss: 0.5613971948623657\n",
      "Epoch [3289/10000], Loss: 0.5613961219787598\n",
      "Epoch [3290/10000], Loss: 0.5613951086997986\n",
      "Epoch [3291/10000], Loss: 0.5613941550254822\n",
      "Epoch [3292/10000], Loss: 0.5613935589790344\n",
      "Epoch [3293/10000], Loss: 0.5613932609558105\n",
      "Epoch [3294/10000], Loss: 0.5613928437232971\n",
      "Epoch [3295/10000], Loss: 0.5613917708396912\n",
      "Epoch [3296/10000], Loss: 0.5613903999328613\n",
      "Epoch [3297/10000], Loss: 0.5613875389099121\n",
      "Epoch [3298/10000], Loss: 0.5613842606544495\n",
      "Epoch [3299/10000], Loss: 0.5613815188407898\n",
      "Epoch [3300/10000], Loss: 0.5613791942596436\n",
      "Epoch [3301/10000], Loss: 0.5613775849342346\n",
      "Epoch [3302/10000], Loss: 0.5613768696784973\n",
      "Epoch [3303/10000], Loss: 0.5613766312599182\n",
      "Epoch [3304/10000], Loss: 0.5613760948181152\n",
      "Epoch [3305/10000], Loss: 0.5613754987716675\n",
      "Epoch [3306/10000], Loss: 0.5613752007484436\n",
      "Epoch [3307/10000], Loss: 0.561374306678772\n",
      "Epoch [3308/10000], Loss: 0.5613730549812317\n",
      "Epoch [3309/10000], Loss: 0.5613717436790466\n",
      "Epoch [3310/10000], Loss: 0.5613701343536377\n",
      "Epoch [3311/10000], Loss: 0.5613688826560974\n",
      "Epoch [3312/10000], Loss: 0.5613684058189392\n",
      "Epoch [3313/10000], Loss: 0.5613679885864258\n",
      "Epoch [3314/10000], Loss: 0.561367928981781\n",
      "Epoch [3315/10000], Loss: 0.5613682866096497\n",
      "Epoch [3316/10000], Loss: 0.5613691806793213\n",
      "Epoch [3317/10000], Loss: 0.5613701939582825\n",
      "Epoch [3318/10000], Loss: 0.5613707900047302\n",
      "Epoch [3319/10000], Loss: 0.5613707304000854\n",
      "Epoch [3320/10000], Loss: 0.5613695383071899\n",
      "Epoch [3321/10000], Loss: 0.5613671541213989\n",
      "Epoch [3322/10000], Loss: 0.561364471912384\n",
      "Epoch [3323/10000], Loss: 0.5613619089126587\n",
      "Epoch [3324/10000], Loss: 0.5613598227500916\n",
      "Epoch [3325/10000], Loss: 0.5613583922386169\n",
      "Epoch [3326/10000], Loss: 0.5613576769828796\n",
      "Epoch [3327/10000], Loss: 0.5613577961921692\n",
      "Epoch [3328/10000], Loss: 0.5613576769828796\n",
      "Epoch [3329/10000], Loss: 0.5613576769828796\n",
      "Epoch [3330/10000], Loss: 0.5613577961921692\n",
      "Epoch [3331/10000], Loss: 0.5613582730293274\n",
      "Epoch [3332/10000], Loss: 0.5613583326339722\n",
      "Epoch [3333/10000], Loss: 0.5613582730293274\n",
      "Epoch [3334/10000], Loss: 0.5613576173782349\n",
      "Epoch [3335/10000], Loss: 0.5613563656806946\n",
      "Epoch [3336/10000], Loss: 0.5613549947738647\n",
      "Epoch [3337/10000], Loss: 0.5613534450531006\n",
      "Epoch [3338/10000], Loss: 0.5613519549369812\n",
      "Epoch [3339/10000], Loss: 0.5613508224487305\n",
      "Epoch [3340/10000], Loss: 0.5613497495651245\n",
      "Epoch [3341/10000], Loss: 0.5613495111465454\n",
      "Epoch [3342/10000], Loss: 0.561349630355835\n",
      "Epoch [3343/10000], Loss: 0.56135094165802\n",
      "Epoch [3344/10000], Loss: 0.5613532066345215\n",
      "Epoch [3345/10000], Loss: 0.5613551735877991\n",
      "Epoch [3346/10000], Loss: 0.5613560080528259\n",
      "Epoch [3347/10000], Loss: 0.561355710029602\n",
      "Epoch [3348/10000], Loss: 0.5613539218902588\n",
      "Epoch [3349/10000], Loss: 0.5613505840301514\n",
      "Epoch [3350/10000], Loss: 0.5613470673561096\n",
      "Epoch [3351/10000], Loss: 0.5613440275192261\n",
      "Epoch [3352/10000], Loss: 0.5613424777984619\n",
      "Epoch [3353/10000], Loss: 0.5613412261009216\n",
      "Epoch [3354/10000], Loss: 0.5613409280776978\n",
      "Epoch [3355/10000], Loss: 0.5613403916358948\n",
      "Epoch [3356/10000], Loss: 0.5613393783569336\n",
      "Epoch [3357/10000], Loss: 0.5613383054733276\n",
      "Epoch [3358/10000], Loss: 0.5613368153572083\n",
      "Epoch [3359/10000], Loss: 0.5613350868225098\n",
      "Epoch [3360/10000], Loss: 0.5613332986831665\n",
      "Epoch [3361/10000], Loss: 0.5613316893577576\n",
      "Epoch [3362/10000], Loss: 0.5613305568695068\n",
      "Epoch [3363/10000], Loss: 0.5613298416137695\n",
      "Epoch [3364/10000], Loss: 0.5613299608230591\n",
      "Epoch [3365/10000], Loss: 0.5613306164741516\n",
      "Epoch [3366/10000], Loss: 0.5613316297531128\n",
      "Epoch [3367/10000], Loss: 0.5613324046134949\n",
      "Epoch [3368/10000], Loss: 0.5613330006599426\n",
      "Epoch [3369/10000], Loss: 0.5613329410552979\n",
      "Epoch [3370/10000], Loss: 0.5613325834274292\n",
      "Epoch [3371/10000], Loss: 0.5613313317298889\n",
      "Epoch [3372/10000], Loss: 0.5613293051719666\n",
      "Epoch [3373/10000], Loss: 0.5613270998001099\n",
      "Epoch [3374/10000], Loss: 0.5613245964050293\n",
      "Epoch [3375/10000], Loss: 0.5613222718238831\n",
      "Epoch [3376/10000], Loss: 0.5613203048706055\n",
      "Epoch [3377/10000], Loss: 0.5613186359405518\n",
      "Epoch [3378/10000], Loss: 0.5613165497779846\n",
      "Epoch [3379/10000], Loss: 0.5613152980804443\n",
      "Epoch [3380/10000], Loss: 0.5613139271736145\n",
      "Epoch [3381/10000], Loss: 0.561312198638916\n",
      "Epoch [3382/10000], Loss: 0.5613104701042175\n",
      "Epoch [3383/10000], Loss: 0.5613085627555847\n",
      "Epoch [3384/10000], Loss: 0.5613072514533997\n",
      "Epoch [3385/10000], Loss: 0.5613057613372803\n",
      "Epoch [3386/10000], Loss: 0.5613046288490295\n",
      "Epoch [3387/10000], Loss: 0.5613036751747131\n",
      "Epoch [3388/10000], Loss: 0.561302900314331\n",
      "Epoch [3389/10000], Loss: 0.5613024234771729\n",
      "Epoch [3390/10000], Loss: 0.5613018274307251\n",
      "Epoch [3391/10000], Loss: 0.5613014698028564\n",
      "Epoch [3392/10000], Loss: 0.5613011121749878\n",
      "Epoch [3393/10000], Loss: 0.5613009333610535\n",
      "Epoch [3394/10000], Loss: 0.56130051612854\n",
      "Epoch [3395/10000], Loss: 0.5613000988960266\n",
      "Epoch [3396/10000], Loss: 0.561299741268158\n",
      "Epoch [3397/10000], Loss: 0.5612993836402893\n",
      "Epoch [3398/10000], Loss: 0.5612990856170654\n",
      "Epoch [3399/10000], Loss: 0.5612990260124207\n",
      "Epoch [3400/10000], Loss: 0.5612990260124207\n",
      "Epoch [3401/10000], Loss: 0.5612983107566833\n",
      "Epoch [3402/10000], Loss: 0.561297595500946\n",
      "Epoch [3403/10000], Loss: 0.561296820640564\n",
      "Epoch [3404/10000], Loss: 0.5612958669662476\n",
      "Epoch [3405/10000], Loss: 0.5612951517105103\n",
      "Epoch [3406/10000], Loss: 0.5612943768501282\n",
      "Epoch [3407/10000], Loss: 0.5612938404083252\n",
      "Epoch [3408/10000], Loss: 0.5612926483154297\n",
      "Epoch [3409/10000], Loss: 0.5612923502922058\n",
      "Epoch [3410/10000], Loss: 0.5612919926643372\n",
      "Epoch [3411/10000], Loss: 0.5612917542457581\n",
      "Epoch [3412/10000], Loss: 0.5612923502922058\n",
      "Epoch [3413/10000], Loss: 0.5612928867340088\n",
      "Epoch [3414/10000], Loss: 0.5612934827804565\n",
      "Epoch [3415/10000], Loss: 0.5612941980361938\n",
      "Epoch [3416/10000], Loss: 0.561294674873352\n",
      "Epoch [3417/10000], Loss: 0.5612953305244446\n",
      "Epoch [3418/10000], Loss: 0.5612950325012207\n",
      "Epoch [3419/10000], Loss: 0.5612937808036804\n",
      "Epoch [3420/10000], Loss: 0.5612914562225342\n",
      "Epoch [3421/10000], Loss: 0.5612887740135193\n",
      "Epoch [3422/10000], Loss: 0.5612860321998596\n",
      "Epoch [3423/10000], Loss: 0.5612829327583313\n",
      "Epoch [3424/10000], Loss: 0.5612807869911194\n",
      "Epoch [3425/10000], Loss: 0.5612791776657104\n",
      "Epoch [3426/10000], Loss: 0.5612778663635254\n",
      "Epoch [3427/10000], Loss: 0.5612768530845642\n",
      "Epoch [3428/10000], Loss: 0.5612757802009583\n",
      "Epoch [3429/10000], Loss: 0.5612754821777344\n",
      "Epoch [3430/10000], Loss: 0.561275064945221\n",
      "Epoch [3431/10000], Loss: 0.5612750053405762\n",
      "Epoch [3432/10000], Loss: 0.5612753629684448\n",
      "Epoch [3433/10000], Loss: 0.5612765550613403\n",
      "Epoch [3434/10000], Loss: 0.5612778067588806\n",
      "Epoch [3435/10000], Loss: 0.561278760433197\n",
      "Epoch [3436/10000], Loss: 0.5612797141075134\n",
      "Epoch [3437/10000], Loss: 0.5612791776657104\n",
      "Epoch [3438/10000], Loss: 0.5612778663635254\n",
      "Epoch [3439/10000], Loss: 0.5612760782241821\n",
      "Epoch [3440/10000], Loss: 0.5612738132476807\n",
      "Epoch [3441/10000], Loss: 0.5612712502479553\n",
      "Epoch [3442/10000], Loss: 0.5612688660621643\n",
      "Epoch [3443/10000], Loss: 0.5612669587135315\n",
      "Epoch [3444/10000], Loss: 0.5612655878067017\n",
      "Epoch [3445/10000], Loss: 0.5612648725509644\n",
      "Epoch [3446/10000], Loss: 0.5612643361091614\n",
      "Epoch [3447/10000], Loss: 0.5612640380859375\n",
      "Epoch [3448/10000], Loss: 0.5612643361091614\n",
      "Epoch [3449/10000], Loss: 0.5612654685974121\n",
      "Epoch [3450/10000], Loss: 0.5612661242485046\n",
      "Epoch [3451/10000], Loss: 0.5612671971321106\n",
      "Epoch [3452/10000], Loss: 0.5612677335739136\n",
      "Epoch [3453/10000], Loss: 0.5612677335739136\n",
      "Epoch [3454/10000], Loss: 0.5612671971321106\n",
      "Epoch [3455/10000], Loss: 0.5612653493881226\n",
      "Epoch [3456/10000], Loss: 0.561263382434845\n",
      "Epoch [3457/10000], Loss: 0.5612616539001465\n",
      "Epoch [3458/10000], Loss: 0.5612599849700928\n",
      "Epoch [3459/10000], Loss: 0.5612598061561584\n",
      "Epoch [3460/10000], Loss: 0.561259925365448\n",
      "Epoch [3461/10000], Loss: 0.5612603425979614\n",
      "Epoch [3462/10000], Loss: 0.5612609386444092\n",
      "Epoch [3463/10000], Loss: 0.5612611770629883\n",
      "Epoch [3464/10000], Loss: 0.5612608194351196\n",
      "Epoch [3465/10000], Loss: 0.5612593293190002\n",
      "Epoch [3466/10000], Loss: 0.5612568855285645\n",
      "Epoch [3467/10000], Loss: 0.5612539052963257\n",
      "Epoch [3468/10000], Loss: 0.561250627040863\n",
      "Epoch [3469/10000], Loss: 0.5612477660179138\n",
      "Epoch [3470/10000], Loss: 0.5612455606460571\n",
      "Epoch [3471/10000], Loss: 0.5612434148788452\n",
      "Epoch [3472/10000], Loss: 0.5612415075302124\n",
      "Epoch [3473/10000], Loss: 0.561240017414093\n",
      "Epoch [3474/10000], Loss: 0.5612385869026184\n",
      "Epoch [3475/10000], Loss: 0.5612375140190125\n",
      "Epoch [3476/10000], Loss: 0.5612366795539856\n",
      "Epoch [3477/10000], Loss: 0.5612362027168274\n",
      "Epoch [3478/10000], Loss: 0.5612353086471558\n",
      "Epoch [3479/10000], Loss: 0.5612345933914185\n",
      "Epoch [3480/10000], Loss: 0.5612334609031677\n",
      "Epoch [3481/10000], Loss: 0.5612327456474304\n",
      "Epoch [3482/10000], Loss: 0.5612325072288513\n",
      "Epoch [3483/10000], Loss: 0.561231791973114\n",
      "Epoch [3484/10000], Loss: 0.5612305998802185\n",
      "Epoch [3485/10000], Loss: 0.561229407787323\n",
      "Epoch [3486/10000], Loss: 0.5612286925315857\n",
      "Epoch [3487/10000], Loss: 0.5612278580665588\n",
      "Epoch [3488/10000], Loss: 0.5612269043922424\n",
      "Epoch [3489/10000], Loss: 0.5612270832061768\n",
      "Epoch [3490/10000], Loss: 0.5612272620201111\n",
      "Epoch [3491/10000], Loss: 0.5612273216247559\n",
      "Epoch [3492/10000], Loss: 0.5612273216247559\n",
      "Epoch [3493/10000], Loss: 0.5612270832061768\n",
      "Epoch [3494/10000], Loss: 0.5612265467643738\n",
      "Epoch [3495/10000], Loss: 0.5612263679504395\n",
      "Epoch [3496/10000], Loss: 0.5612263083457947\n",
      "Epoch [3497/10000], Loss: 0.5612255334854126\n",
      "Epoch [3498/10000], Loss: 0.5612245202064514\n",
      "Epoch [3499/10000], Loss: 0.5612225532531738\n",
      "Epoch [3500/10000], Loss: 0.5612207651138306\n",
      "Epoch [3501/10000], Loss: 0.5612194538116455\n",
      "Epoch [3502/10000], Loss: 0.5612185597419739\n",
      "Epoch [3503/10000], Loss: 0.5612174868583679\n",
      "Epoch [3504/10000], Loss: 0.5612165927886963\n",
      "Epoch [3505/10000], Loss: 0.5612155795097351\n",
      "Epoch [3506/10000], Loss: 0.5612146258354187\n",
      "Epoch [3507/10000], Loss: 0.5612131357192993\n",
      "Epoch [3508/10000], Loss: 0.5612118244171143\n",
      "Epoch [3509/10000], Loss: 0.5612096190452576\n",
      "Epoch [3510/10000], Loss: 0.5612078309059143\n",
      "Epoch [3511/10000], Loss: 0.5612064599990845\n",
      "Epoch [3512/10000], Loss: 0.5612049102783203\n",
      "Epoch [3513/10000], Loss: 0.5612034201622009\n",
      "Epoch [3514/10000], Loss: 0.5612024068832397\n",
      "Epoch [3515/10000], Loss: 0.5612013339996338\n",
      "Epoch [3516/10000], Loss: 0.5612003803253174\n",
      "Epoch [3517/10000], Loss: 0.5611994862556458\n",
      "Epoch [3518/10000], Loss: 0.5611991286277771\n",
      "Epoch [3519/10000], Loss: 0.5611988306045532\n",
      "Epoch [3520/10000], Loss: 0.5611992478370667\n",
      "Epoch [3521/10000], Loss: 0.5611997842788696\n",
      "Epoch [3522/10000], Loss: 0.5612003207206726\n",
      "Epoch [3523/10000], Loss: 0.561201274394989\n",
      "Epoch [3524/10000], Loss: 0.5612019300460815\n",
      "Epoch [3525/10000], Loss: 0.5612016916275024\n",
      "Epoch [3526/10000], Loss: 0.5612000226974487\n",
      "Epoch [3527/10000], Loss: 0.5611972808837891\n",
      "Epoch [3528/10000], Loss: 0.5611945390701294\n",
      "Epoch [3529/10000], Loss: 0.5611922144889832\n",
      "Epoch [3530/10000], Loss: 0.5611909031867981\n",
      "Epoch [3531/10000], Loss: 0.5611900091171265\n",
      "Epoch [3532/10000], Loss: 0.5611892342567444\n",
      "Epoch [3533/10000], Loss: 0.5611890554428101\n",
      "Epoch [3534/10000], Loss: 0.5611883997917175\n",
      "Epoch [3535/10000], Loss: 0.5611865520477295\n",
      "Epoch [3536/10000], Loss: 0.5611851811408997\n",
      "Epoch [3537/10000], Loss: 0.5611832737922668\n",
      "Epoch [3538/10000], Loss: 0.5611815452575684\n",
      "Epoch [3539/10000], Loss: 0.561179518699646\n",
      "Epoch [3540/10000], Loss: 0.5611773133277893\n",
      "Epoch [3541/10000], Loss: 0.5611753463745117\n",
      "Epoch [3542/10000], Loss: 0.5611739158630371\n",
      "Epoch [3543/10000], Loss: 0.5611724853515625\n",
      "Epoch [3544/10000], Loss: 0.5611717104911804\n",
      "Epoch [3545/10000], Loss: 0.5611714124679565\n",
      "Epoch [3546/10000], Loss: 0.5611714720726013\n",
      "Epoch [3547/10000], Loss: 0.5611708164215088\n",
      "Epoch [3548/10000], Loss: 0.561170756816864\n",
      "Epoch [3549/10000], Loss: 0.5611704587936401\n",
      "Epoch [3550/10000], Loss: 0.5611698627471924\n",
      "Epoch [3551/10000], Loss: 0.5611690878868103\n",
      "Epoch [3552/10000], Loss: 0.5611678957939148\n",
      "Epoch [3553/10000], Loss: 0.5611664652824402\n",
      "Epoch [3554/10000], Loss: 0.561164915561676\n",
      "Epoch [3555/10000], Loss: 0.5611634254455566\n",
      "Epoch [3556/10000], Loss: 0.5611623525619507\n",
      "Epoch [3557/10000], Loss: 0.5611617565155029\n",
      "Epoch [3558/10000], Loss: 0.5611615180969238\n",
      "Epoch [3559/10000], Loss: 0.5611615777015686\n",
      "Epoch [3560/10000], Loss: 0.5611616373062134\n",
      "Epoch [3561/10000], Loss: 0.5611616969108582\n",
      "Epoch [3562/10000], Loss: 0.5611618161201477\n",
      "Epoch [3563/10000], Loss: 0.561161994934082\n",
      "Epoch [3564/10000], Loss: 0.5611623525619507\n",
      "Epoch [3565/10000], Loss: 0.5611630082130432\n",
      "Epoch [3566/10000], Loss: 0.5611633658409119\n",
      "Epoch [3567/10000], Loss: 0.5611639022827148\n",
      "Epoch [3568/10000], Loss: 0.5611656308174133\n",
      "Epoch [3569/10000], Loss: 0.5611668825149536\n",
      "Epoch [3570/10000], Loss: 0.5611695647239685\n",
      "Epoch [3571/10000], Loss: 0.561171293258667\n",
      "Epoch [3572/10000], Loss: 0.5611733198165894\n",
      "Epoch [3573/10000], Loss: 0.5611744523048401\n",
      "Epoch [3574/10000], Loss: 0.561174750328064\n",
      "Epoch [3575/10000], Loss: 0.5611719489097595\n",
      "Epoch [3576/10000], Loss: 0.561167299747467\n",
      "Epoch [3577/10000], Loss: 0.5611613988876343\n",
      "Epoch [3578/10000], Loss: 0.5611562132835388\n",
      "Epoch [3579/10000], Loss: 0.5611523389816284\n",
      "Epoch [3580/10000], Loss: 0.5611499547958374\n",
      "Epoch [3581/10000], Loss: 0.5611494779586792\n",
      "Epoch [3582/10000], Loss: 0.561149537563324\n",
      "Epoch [3583/10000], Loss: 0.5611495971679688\n",
      "Epoch [3584/10000], Loss: 0.561149537563324\n",
      "Epoch [3585/10000], Loss: 0.5611492991447449\n",
      "Epoch [3586/10000], Loss: 0.5611490607261658\n",
      "Epoch [3587/10000], Loss: 0.5611488223075867\n",
      "Epoch [3588/10000], Loss: 0.5611478686332703\n",
      "Epoch [3589/10000], Loss: 0.5611467957496643\n",
      "Epoch [3590/10000], Loss: 0.5611454844474792\n",
      "Epoch [3591/10000], Loss: 0.5611437559127808\n",
      "Epoch [3592/10000], Loss: 0.5611414313316345\n",
      "Epoch [3593/10000], Loss: 0.5611398220062256\n",
      "Epoch [3594/10000], Loss: 0.5611383318901062\n",
      "Epoch [3595/10000], Loss: 0.5611379742622375\n",
      "Epoch [3596/10000], Loss: 0.561138391494751\n",
      "Epoch [3597/10000], Loss: 0.5611392259597778\n",
      "Epoch [3598/10000], Loss: 0.561139702796936\n",
      "Epoch [3599/10000], Loss: 0.5611409544944763\n",
      "Epoch [3600/10000], Loss: 0.5611419081687927\n",
      "Epoch [3601/10000], Loss: 0.5611414313316345\n",
      "Epoch [3602/10000], Loss: 0.5611397624015808\n",
      "Epoch [3603/10000], Loss: 0.5611382722854614\n",
      "Epoch [3604/10000], Loss: 0.5611363053321838\n",
      "Epoch [3605/10000], Loss: 0.5611340403556824\n",
      "Epoch [3606/10000], Loss: 0.56113201379776\n",
      "Epoch [3607/10000], Loss: 0.5611297488212585\n",
      "Epoch [3608/10000], Loss: 0.5611283779144287\n",
      "Epoch [3609/10000], Loss: 0.5611271858215332\n",
      "Epoch [3610/10000], Loss: 0.5611264705657959\n",
      "Epoch [3611/10000], Loss: 0.5611260533332825\n",
      "Epoch [3612/10000], Loss: 0.5611258149147034\n",
      "Epoch [3613/10000], Loss: 0.5611259341239929\n",
      "Epoch [3614/10000], Loss: 0.5611259341239929\n",
      "Epoch [3615/10000], Loss: 0.5611260533332825\n",
      "Epoch [3616/10000], Loss: 0.5611264109611511\n",
      "Epoch [3617/10000], Loss: 0.5611268877983093\n",
      "Epoch [3618/10000], Loss: 0.5611273050308228\n",
      "Epoch [3619/10000], Loss: 0.5611274838447571\n",
      "Epoch [3620/10000], Loss: 0.5611271858215332\n",
      "Epoch [3621/10000], Loss: 0.5611264705657959\n",
      "Epoch [3622/10000], Loss: 0.5611253976821899\n",
      "Epoch [3623/10000], Loss: 0.5611239075660706\n",
      "Epoch [3624/10000], Loss: 0.561121940612793\n",
      "Epoch [3625/10000], Loss: 0.5611198544502258\n",
      "Epoch [3626/10000], Loss: 0.5611184239387512\n",
      "Epoch [3627/10000], Loss: 0.5611168742179871\n",
      "Epoch [3628/10000], Loss: 0.5611155033111572\n",
      "Epoch [3629/10000], Loss: 0.5611149072647095\n",
      "Epoch [3630/10000], Loss: 0.5611139535903931\n",
      "Epoch [3631/10000], Loss: 0.5611132979393005\n",
      "Epoch [3632/10000], Loss: 0.5611128807067871\n",
      "Epoch [3633/10000], Loss: 0.5611124038696289\n",
      "Epoch [3634/10000], Loss: 0.5611121654510498\n",
      "Epoch [3635/10000], Loss: 0.5611117482185364\n",
      "Epoch [3636/10000], Loss: 0.5611115097999573\n",
      "Epoch [3637/10000], Loss: 0.5611110329627991\n",
      "Epoch [3638/10000], Loss: 0.5611107349395752\n",
      "Epoch [3639/10000], Loss: 0.5611104369163513\n",
      "Epoch [3640/10000], Loss: 0.5611109137535095\n",
      "Epoch [3641/10000], Loss: 0.5611118078231812\n",
      "Epoch [3642/10000], Loss: 0.561112642288208\n",
      "Epoch [3643/10000], Loss: 0.5611135959625244\n",
      "Epoch [3644/10000], Loss: 0.5611138343811035\n",
      "Epoch [3645/10000], Loss: 0.561113178730011\n",
      "Epoch [3646/10000], Loss: 0.5611124038696289\n",
      "Epoch [3647/10000], Loss: 0.561112105846405\n",
      "Epoch [3648/10000], Loss: 0.5611116886138916\n",
      "Epoch [3649/10000], Loss: 0.561112105846405\n",
      "Epoch [3650/10000], Loss: 0.5611127614974976\n",
      "Epoch [3651/10000], Loss: 0.5611128807067871\n",
      "Epoch [3652/10000], Loss: 0.5611125230789185\n",
      "Epoch [3653/10000], Loss: 0.5611116290092468\n",
      "Epoch [3654/10000], Loss: 0.5611100196838379\n",
      "Epoch [3655/10000], Loss: 0.5611084699630737\n",
      "Epoch [3656/10000], Loss: 0.5611066818237305\n",
      "Epoch [3657/10000], Loss: 0.5611055493354797\n",
      "Epoch [3658/10000], Loss: 0.5611048936843872\n",
      "Epoch [3659/10000], Loss: 0.5611048340797424\n",
      "Epoch [3660/10000], Loss: 0.5611056089401245\n",
      "Epoch [3661/10000], Loss: 0.561107337474823\n",
      "Epoch [3662/10000], Loss: 0.5611093044281006\n",
      "Epoch [3663/10000], Loss: 0.5611100792884827\n",
      "Epoch [3664/10000], Loss: 0.5611100196838379\n",
      "Epoch [3665/10000], Loss: 0.5611083507537842\n",
      "Epoch [3666/10000], Loss: 0.5611052513122559\n",
      "Epoch [3667/10000], Loss: 0.5611006617546082\n",
      "Epoch [3668/10000], Loss: 0.5610964894294739\n",
      "Epoch [3669/10000], Loss: 0.5610931515693665\n",
      "Epoch [3670/10000], Loss: 0.5610915422439575\n",
      "Epoch [3671/10000], Loss: 0.5610908269882202\n",
      "Epoch [3672/10000], Loss: 0.5610910654067993\n",
      "Epoch [3673/10000], Loss: 0.5610918402671814\n",
      "Epoch [3674/10000], Loss: 0.5610925555229187\n",
      "Epoch [3675/10000], Loss: 0.5610930919647217\n",
      "Epoch [3676/10000], Loss: 0.5610931515693665\n",
      "Epoch [3677/10000], Loss: 0.561092734336853\n",
      "Epoch [3678/10000], Loss: 0.5610917806625366\n",
      "Epoch [3679/10000], Loss: 0.5610905885696411\n",
      "Epoch [3680/10000], Loss: 0.5610896348953247\n",
      "Epoch [3681/10000], Loss: 0.561089038848877\n",
      "Epoch [3682/10000], Loss: 0.5610887408256531\n",
      "Epoch [3683/10000], Loss: 0.5610882639884949\n",
      "Epoch [3684/10000], Loss: 0.5610877275466919\n",
      "Epoch [3685/10000], Loss: 0.5610868334770203\n",
      "Epoch [3686/10000], Loss: 0.5610858798027039\n",
      "Epoch [3687/10000], Loss: 0.5610843300819397\n",
      "Epoch [3688/10000], Loss: 0.5610826015472412\n",
      "Epoch [3689/10000], Loss: 0.5610811114311218\n",
      "Epoch [3690/10000], Loss: 0.5610796809196472\n",
      "Epoch [3691/10000], Loss: 0.561079204082489\n",
      "Epoch [3692/10000], Loss: 0.5610787272453308\n",
      "Epoch [3693/10000], Loss: 0.5610783100128174\n",
      "Epoch [3694/10000], Loss: 0.5610775351524353\n",
      "Epoch [3695/10000], Loss: 0.5610771179199219\n",
      "Epoch [3696/10000], Loss: 0.5610768795013428\n",
      "Epoch [3697/10000], Loss: 0.5610769391059875\n",
      "Epoch [3698/10000], Loss: 0.5610769391059875\n",
      "Epoch [3699/10000], Loss: 0.5610768795013428\n",
      "Epoch [3700/10000], Loss: 0.5610771775245667\n",
      "Epoch [3701/10000], Loss: 0.5610775947570801\n",
      "Epoch [3702/10000], Loss: 0.5610777735710144\n",
      "Epoch [3703/10000], Loss: 0.5610784292221069\n",
      "Epoch [3704/10000], Loss: 0.5610790848731995\n",
      "Epoch [3705/10000], Loss: 0.5610799193382263\n",
      "Epoch [3706/10000], Loss: 0.5610813498497009\n",
      "Epoch [3707/10000], Loss: 0.5610828399658203\n",
      "Epoch [3708/10000], Loss: 0.5610834360122681\n",
      "Epoch [3709/10000], Loss: 0.5610833764076233\n",
      "Epoch [3710/10000], Loss: 0.5610828399658203\n",
      "Epoch [3711/10000], Loss: 0.5610817670822144\n",
      "Epoch [3712/10000], Loss: 0.5610805153846741\n",
      "Epoch [3713/10000], Loss: 0.5610798001289368\n",
      "Epoch [3714/10000], Loss: 0.561079740524292\n",
      "Epoch [3715/10000], Loss: 0.561080813407898\n",
      "Epoch [3716/10000], Loss: 0.5610827207565308\n",
      "Epoch [3717/10000], Loss: 0.5610849857330322\n",
      "Epoch [3718/10000], Loss: 0.5610869526863098\n",
      "Epoch [3719/10000], Loss: 0.5610876679420471\n",
      "Epoch [3720/10000], Loss: 0.5610871911048889\n",
      "Epoch [3721/10000], Loss: 0.561084508895874\n",
      "Epoch [3722/10000], Loss: 0.5610806941986084\n",
      "Epoch [3723/10000], Loss: 0.5610762238502502\n",
      "Epoch [3724/10000], Loss: 0.5610719323158264\n",
      "Epoch [3725/10000], Loss: 0.5610688328742981\n",
      "Epoch [3726/10000], Loss: 0.5610668063163757\n",
      "Epoch [3727/10000], Loss: 0.5610653758049011\n",
      "Epoch [3728/10000], Loss: 0.5610649585723877\n",
      "Epoch [3729/10000], Loss: 0.5610657334327698\n",
      "Epoch [3730/10000], Loss: 0.5610659718513489\n",
      "Epoch [3731/10000], Loss: 0.5610660910606384\n",
      "Epoch [3732/10000], Loss: 0.5610659122467041\n",
      "Epoch [3733/10000], Loss: 0.5610644817352295\n",
      "Epoch [3734/10000], Loss: 0.561062753200531\n",
      "Epoch [3735/10000], Loss: 0.5610607266426086\n",
      "Epoch [3736/10000], Loss: 0.5610589385032654\n",
      "Epoch [3737/10000], Loss: 0.5610575675964355\n",
      "Epoch [3738/10000], Loss: 0.5610567331314087\n",
      "Epoch [3739/10000], Loss: 0.5610565543174744\n",
      "Epoch [3740/10000], Loss: 0.5610560178756714\n",
      "Epoch [3741/10000], Loss: 0.5610558390617371\n",
      "Epoch [3742/10000], Loss: 0.5610551238059998\n",
      "Epoch [3743/10000], Loss: 0.561055064201355\n",
      "Epoch [3744/10000], Loss: 0.5610549449920654\n",
      "Epoch [3745/10000], Loss: 0.5610551238059998\n",
      "Epoch [3746/10000], Loss: 0.5610557794570923\n",
      "Epoch [3747/10000], Loss: 0.5610560774803162\n",
      "Epoch [3748/10000], Loss: 0.5610567927360535\n",
      "Epoch [3749/10000], Loss: 0.5610567927360535\n",
      "Epoch [3750/10000], Loss: 0.5610570311546326\n",
      "Epoch [3751/10000], Loss: 0.561056911945343\n",
      "Epoch [3752/10000], Loss: 0.5610566139221191\n",
      "Epoch [3753/10000], Loss: 0.5610566735267639\n",
      "Epoch [3754/10000], Loss: 0.5610564351081848\n",
      "Epoch [3755/10000], Loss: 0.5610564351081848\n",
      "Epoch [3756/10000], Loss: 0.5610565543174744\n",
      "Epoch [3757/10000], Loss: 0.5610563158988953\n",
      "Epoch [3758/10000], Loss: 0.5610557198524475\n",
      "Epoch [3759/10000], Loss: 0.5610552430152893\n",
      "Epoch [3760/10000], Loss: 0.5610557794570923\n",
      "Epoch [3761/10000], Loss: 0.5610557794570923\n",
      "Epoch [3762/10000], Loss: 0.5610551834106445\n",
      "Epoch [3763/10000], Loss: 0.5610548257827759\n",
      "Epoch [3764/10000], Loss: 0.561053454875946\n",
      "Epoch [3765/10000], Loss: 0.5610518455505371\n",
      "Epoch [3766/10000], Loss: 0.5610501170158386\n",
      "Epoch [3767/10000], Loss: 0.5610479712486267\n",
      "Epoch [3768/10000], Loss: 0.5610462427139282\n",
      "Epoch [3769/10000], Loss: 0.5610454082489014\n",
      "Epoch [3770/10000], Loss: 0.5610449314117432\n",
      "Epoch [3771/10000], Loss: 0.5610449910163879\n",
      "Epoch [3772/10000], Loss: 0.5610455274581909\n",
      "Epoch [3773/10000], Loss: 0.5610466599464417\n",
      "Epoch [3774/10000], Loss: 0.5610476732254028\n",
      "Epoch [3775/10000], Loss: 0.5610483884811401\n",
      "Epoch [3776/10000], Loss: 0.5610484480857849\n",
      "Epoch [3777/10000], Loss: 0.561047375202179\n",
      "Epoch [3778/10000], Loss: 0.561045229434967\n",
      "Epoch [3779/10000], Loss: 0.5610429048538208\n",
      "Epoch [3780/10000], Loss: 0.5610412955284119\n",
      "Epoch [3781/10000], Loss: 0.5610401630401611\n",
      "Epoch [3782/10000], Loss: 0.5610395073890686\n",
      "Epoch [3783/10000], Loss: 0.5610398054122925\n",
      "Epoch [3784/10000], Loss: 0.5610398054122925\n",
      "Epoch [3785/10000], Loss: 0.5610398054122925\n",
      "Epoch [3786/10000], Loss: 0.561039924621582\n",
      "Epoch [3787/10000], Loss: 0.5610401630401611\n",
      "Epoch [3788/10000], Loss: 0.5610406994819641\n",
      "Epoch [3789/10000], Loss: 0.5610416531562805\n",
      "Epoch [3790/10000], Loss: 0.5610424876213074\n",
      "Epoch [3791/10000], Loss: 0.5610435009002686\n",
      "Epoch [3792/10000], Loss: 0.5610442757606506\n",
      "Epoch [3793/10000], Loss: 0.5610445141792297\n",
      "Epoch [3794/10000], Loss: 0.5610440969467163\n",
      "Epoch [3795/10000], Loss: 0.5610440373420715\n",
      "Epoch [3796/10000], Loss: 0.5610443949699402\n",
      "Epoch [3797/10000], Loss: 0.5610456466674805\n",
      "Epoch [3798/10000], Loss: 0.561047375202179\n",
      "Epoch [3799/10000], Loss: 0.561049222946167\n",
      "Epoch [3800/10000], Loss: 0.5610504746437073\n",
      "Epoch [3801/10000], Loss: 0.5610511898994446\n",
      "Epoch [3802/10000], Loss: 0.5610507726669312\n",
      "Epoch [3803/10000], Loss: 0.5610495209693909\n",
      "Epoch [3804/10000], Loss: 0.5610471367835999\n",
      "Epoch [3805/10000], Loss: 0.5610436201095581\n",
      "Epoch [3806/10000], Loss: 0.561040461063385\n",
      "Epoch [3807/10000], Loss: 0.5610370635986328\n",
      "Epoch [3808/10000], Loss: 0.5610345602035522\n",
      "Epoch [3809/10000], Loss: 0.5610332489013672\n",
      "Epoch [3810/10000], Loss: 0.5610324144363403\n",
      "Epoch [3811/10000], Loss: 0.5610317587852478\n",
      "Epoch [3812/10000], Loss: 0.5610316395759583\n",
      "Epoch [3813/10000], Loss: 0.5610315799713135\n",
      "Epoch [3814/10000], Loss: 0.5610315203666687\n",
      "Epoch [3815/10000], Loss: 0.5610321760177612\n",
      "Epoch [3816/10000], Loss: 0.561032772064209\n",
      "Epoch [3817/10000], Loss: 0.561033308506012\n",
      "Epoch [3818/10000], Loss: 0.5610343813896179\n",
      "Epoch [3819/10000], Loss: 0.5610349178314209\n",
      "Epoch [3820/10000], Loss: 0.5610354542732239\n",
      "Epoch [3821/10000], Loss: 0.5610352158546448\n",
      "Epoch [3822/10000], Loss: 0.5610343217849731\n",
      "Epoch [3823/10000], Loss: 0.561032772064209\n",
      "Epoch [3824/10000], Loss: 0.5610310435295105\n",
      "Epoch [3825/10000], Loss: 0.5610293745994568\n",
      "Epoch [3826/10000], Loss: 0.5610286593437195\n",
      "Epoch [3827/10000], Loss: 0.5610283017158508\n",
      "Epoch [3828/10000], Loss: 0.5610281825065613\n",
      "Epoch [3829/10000], Loss: 0.5610278248786926\n",
      "Epoch [3830/10000], Loss: 0.5610279440879822\n",
      "Epoch [3831/10000], Loss: 0.5610283613204956\n",
      "Epoch [3832/10000], Loss: 0.5610285401344299\n",
      "Epoch [3833/10000], Loss: 0.5610286593437195\n",
      "Epoch [3834/10000], Loss: 0.5610283613204956\n",
      "Epoch [3835/10000], Loss: 0.5610278248786926\n",
      "Epoch [3836/10000], Loss: 0.5610277056694031\n",
      "Epoch [3837/10000], Loss: 0.5610274076461792\n",
      "Epoch [3838/10000], Loss: 0.5610268712043762\n",
      "Epoch [3839/10000], Loss: 0.5610266327857971\n",
      "Epoch [3840/10000], Loss: 0.5610264539718628\n",
      "Epoch [3841/10000], Loss: 0.5610257983207703\n",
      "Epoch [3842/10000], Loss: 0.5610255599021912\n",
      "Epoch [3843/10000], Loss: 0.5610253214836121\n",
      "Epoch [3844/10000], Loss: 0.5610253214836121\n",
      "Epoch [3845/10000], Loss: 0.5610253810882568\n",
      "Epoch [3846/10000], Loss: 0.5610259175300598\n",
      "Epoch [3847/10000], Loss: 0.5610259771347046\n",
      "Epoch [3848/10000], Loss: 0.5610265135765076\n",
      "Epoch [3849/10000], Loss: 0.5610266327857971\n",
      "Epoch [3850/10000], Loss: 0.5610266327857971\n",
      "Epoch [3851/10000], Loss: 0.5610265135765076\n",
      "Epoch [3852/10000], Loss: 0.5610264539718628\n",
      "Epoch [3853/10000], Loss: 0.5610261559486389\n",
      "Epoch [3854/10000], Loss: 0.5610260367393494\n",
      "Epoch [3855/10000], Loss: 0.5610252618789673\n",
      "Epoch [3856/10000], Loss: 0.5610246658325195\n",
      "Epoch [3857/10000], Loss: 0.5610238909721375\n",
      "Epoch [3858/10000], Loss: 0.5610232353210449\n",
      "Epoch [3859/10000], Loss: 0.5610225200653076\n",
      "Epoch [3860/10000], Loss: 0.5610222816467285\n",
      "Epoch [3861/10000], Loss: 0.561022162437439\n",
      "Epoch [3862/10000], Loss: 0.561022162437439\n",
      "Epoch [3863/10000], Loss: 0.5610224604606628\n",
      "Epoch [3864/10000], Loss: 0.5610222816467285\n",
      "Epoch [3865/10000], Loss: 0.5610222220420837\n",
      "Epoch [3866/10000], Loss: 0.5610222220420837\n",
      "Epoch [3867/10000], Loss: 0.5610215067863464\n",
      "Epoch [3868/10000], Loss: 0.5610201954841614\n",
      "Epoch [3869/10000], Loss: 0.5610181093215942\n",
      "Epoch [3870/10000], Loss: 0.5610165596008301\n",
      "Epoch [3871/10000], Loss: 0.5610154271125793\n",
      "Epoch [3872/10000], Loss: 0.5610147714614868\n",
      "Epoch [3873/10000], Loss: 0.5610138177871704\n",
      "Epoch [3874/10000], Loss: 0.5610136389732361\n",
      "Epoch [3875/10000], Loss: 0.5610136389732361\n",
      "Epoch [3876/10000], Loss: 0.5610138177871704\n",
      "Epoch [3877/10000], Loss: 0.5610140562057495\n",
      "Epoch [3878/10000], Loss: 0.5610147714614868\n",
      "Epoch [3879/10000], Loss: 0.5610153079032898\n",
      "Epoch [3880/10000], Loss: 0.5610159039497375\n",
      "Epoch [3881/10000], Loss: 0.5610169172286987\n",
      "Epoch [3882/10000], Loss: 0.5610173344612122\n",
      "Epoch [3883/10000], Loss: 0.5610172152519226\n",
      "Epoch [3884/10000], Loss: 0.5610166192054749\n",
      "Epoch [3885/10000], Loss: 0.5610155463218689\n",
      "Epoch [3886/10000], Loss: 0.5610144138336182\n",
      "Epoch [3887/10000], Loss: 0.5610132813453674\n",
      "Epoch [3888/10000], Loss: 0.5610126852989197\n",
      "Epoch [3889/10000], Loss: 0.5610121488571167\n",
      "Epoch [3890/10000], Loss: 0.5610118508338928\n",
      "Epoch [3891/10000], Loss: 0.5610114932060242\n",
      "Epoch [3892/10000], Loss: 0.5610117316246033\n",
      "Epoch [3893/10000], Loss: 0.561012327671051\n",
      "Epoch [3894/10000], Loss: 0.5610125660896301\n",
      "Epoch [3895/10000], Loss: 0.5610131621360779\n",
      "Epoch [3896/10000], Loss: 0.5610131621360779\n",
      "Epoch [3897/10000], Loss: 0.5610132813453674\n",
      "Epoch [3898/10000], Loss: 0.5610129237174988\n",
      "Epoch [3899/10000], Loss: 0.5610129237174988\n",
      "Epoch [3900/10000], Loss: 0.5610130429267883\n",
      "Epoch [3901/10000], Loss: 0.5610131621360779\n",
      "Epoch [3902/10000], Loss: 0.5610135197639465\n",
      "Epoch [3903/10000], Loss: 0.5610150694847107\n",
      "Epoch [3904/10000], Loss: 0.5610171556472778\n",
      "Epoch [3905/10000], Loss: 0.5610194802284241\n",
      "Epoch [3906/10000], Loss: 0.5610226988792419\n",
      "Epoch [3907/10000], Loss: 0.5610259175300598\n",
      "Epoch [3908/10000], Loss: 0.5610290169715881\n",
      "Epoch [3909/10000], Loss: 0.561031699180603\n",
      "Epoch [3910/10000], Loss: 0.5610328316688538\n",
      "Epoch [3911/10000], Loss: 0.5610325932502747\n",
      "Epoch [3912/10000], Loss: 0.5610292553901672\n",
      "Epoch [3913/10000], Loss: 0.5610243082046509\n",
      "Epoch [3914/10000], Loss: 0.5610182881355286\n",
      "Epoch [3915/10000], Loss: 0.561013400554657\n",
      "Epoch [3916/10000], Loss: 0.561009407043457\n",
      "Epoch [3917/10000], Loss: 0.5610079169273376\n",
      "Epoch [3918/10000], Loss: 0.5610077977180481\n",
      "Epoch [3919/10000], Loss: 0.5610089898109436\n",
      "Epoch [3920/10000], Loss: 0.5610111951828003\n",
      "Epoch [3921/10000], Loss: 0.5610131621360779\n",
      "Epoch [3922/10000], Loss: 0.5610139966011047\n",
      "Epoch [3923/10000], Loss: 0.5610135793685913\n",
      "Epoch [3924/10000], Loss: 0.5610119104385376\n",
      "Epoch [3925/10000], Loss: 0.5610095858573914\n",
      "Epoch [3926/10000], Loss: 0.5610079169273376\n",
      "Epoch [3927/10000], Loss: 0.5610063672065735\n",
      "Epoch [3928/10000], Loss: 0.5610054135322571\n",
      "Epoch [3929/10000], Loss: 0.5610049962997437\n",
      "Epoch [3930/10000], Loss: 0.5610048174858093\n",
      "Epoch [3931/10000], Loss: 0.5610048174858093\n",
      "Epoch [3932/10000], Loss: 0.5610044598579407\n",
      "Epoch [3933/10000], Loss: 0.5610041618347168\n",
      "Epoch [3934/10000], Loss: 0.5610036849975586\n",
      "Epoch [3935/10000], Loss: 0.5610028505325317\n",
      "Epoch [3936/10000], Loss: 0.5610023736953735\n",
      "Epoch [3937/10000], Loss: 0.5610021352767944\n",
      "Epoch [3938/10000], Loss: 0.561002254486084\n",
      "Epoch [3939/10000], Loss: 0.5610026121139526\n",
      "Epoch [3940/10000], Loss: 0.5610033869743347\n",
      "Epoch [3941/10000], Loss: 0.5610044002532959\n",
      "Epoch [3942/10000], Loss: 0.5610055923461914\n",
      "Epoch [3943/10000], Loss: 0.5610066056251526\n",
      "Epoch [3944/10000], Loss: 0.5610065460205078\n",
      "Epoch [3945/10000], Loss: 0.5610060095787048\n",
      "Epoch [3946/10000], Loss: 0.5610051155090332\n",
      "Epoch [3947/10000], Loss: 0.5610038638114929\n",
      "Epoch [3948/10000], Loss: 0.5610029101371765\n",
      "Epoch [3949/10000], Loss: 0.5610024929046631\n",
      "Epoch [3950/10000], Loss: 0.5610027313232422\n",
      "Epoch [3951/10000], Loss: 0.5610030293464661\n",
      "Epoch [3952/10000], Loss: 0.5610030889511108\n",
      "Epoch [3953/10000], Loss: 0.5610023140907288\n",
      "Epoch [3954/10000], Loss: 0.5610020756721497\n",
      "Epoch [3955/10000], Loss: 0.5610009431838989\n",
      "Epoch [3956/10000], Loss: 0.5610001087188721\n",
      "Epoch [3957/10000], Loss: 0.5609995126724243\n",
      "Epoch [3958/10000], Loss: 0.5609986186027527\n",
      "Epoch [3959/10000], Loss: 0.5609983205795288\n",
      "Epoch [3960/10000], Loss: 0.5609979033470154\n",
      "Epoch [3961/10000], Loss: 0.5609976053237915\n",
      "Epoch [3962/10000], Loss: 0.5609977841377258\n",
      "Epoch [3963/10000], Loss: 0.5609980821609497\n",
      "Epoch [3964/10000], Loss: 0.5609986782073975\n",
      "Epoch [3965/10000], Loss: 0.5609992742538452\n",
      "Epoch [3966/10000], Loss: 0.5610005855560303\n",
      "Epoch [3967/10000], Loss: 0.5610018968582153\n",
      "Epoch [3968/10000], Loss: 0.5610033273696899\n",
      "Epoch [3969/10000], Loss: 0.5610043406486511\n",
      "Epoch [3970/10000], Loss: 0.5610043406486511\n",
      "Epoch [3971/10000], Loss: 0.5610037446022034\n",
      "Epoch [3972/10000], Loss: 0.5610026121139526\n",
      "Epoch [3973/10000], Loss: 0.5610001683235168\n",
      "Epoch [3974/10000], Loss: 0.560997724533081\n",
      "Epoch [3975/10000], Loss: 0.5609955191612244\n",
      "Epoch [3976/10000], Loss: 0.5609940886497498\n",
      "Epoch [3977/10000], Loss: 0.5609931945800781\n",
      "Epoch [3978/10000], Loss: 0.5609933733940125\n",
      "Epoch [3979/10000], Loss: 0.5609939694404602\n",
      "Epoch [3980/10000], Loss: 0.5609952807426453\n",
      "Epoch [3981/10000], Loss: 0.5609975457191467\n",
      "Epoch [3982/10000], Loss: 0.5609989762306213\n",
      "Epoch [3983/10000], Loss: 0.56099933385849\n",
      "Epoch [3984/10000], Loss: 0.5609985589981079\n",
      "Epoch [3985/10000], Loss: 0.5609968900680542\n",
      "Epoch [3986/10000], Loss: 0.5609946846961975\n",
      "Epoch [3987/10000], Loss: 0.5609924793243408\n",
      "Epoch [3988/10000], Loss: 0.5609911680221558\n",
      "Epoch [3989/10000], Loss: 0.560990571975708\n",
      "Epoch [3990/10000], Loss: 0.560990571975708\n",
      "Epoch [3991/10000], Loss: 0.560990571975708\n",
      "Epoch [3992/10000], Loss: 0.5609909892082214\n",
      "Epoch [3993/10000], Loss: 0.5609915256500244\n",
      "Epoch [3994/10000], Loss: 0.5609924793243408\n",
      "Epoch [3995/10000], Loss: 0.560992956161499\n",
      "Epoch [3996/10000], Loss: 0.5609933733940125\n",
      "Epoch [3997/10000], Loss: 0.5609933733940125\n",
      "Epoch [3998/10000], Loss: 0.5609936118125916\n",
      "Epoch [3999/10000], Loss: 0.5609935522079468\n",
      "Epoch [4000/10000], Loss: 0.5609931349754333\n",
      "Epoch [4001/10000], Loss: 0.5609928965568542\n",
      "Epoch [4002/10000], Loss: 0.5609926581382751\n",
      "Epoch [4003/10000], Loss: 0.5609927177429199\n",
      "Epoch [4004/10000], Loss: 0.5609931945800781\n",
      "Epoch [4005/10000], Loss: 0.5609931945800781\n",
      "Epoch [4006/10000], Loss: 0.560992956161499\n",
      "Epoch [4007/10000], Loss: 0.5609919428825378\n",
      "Epoch [4008/10000], Loss: 0.5609906911849976\n",
      "Epoch [4009/10000], Loss: 0.5609892010688782\n",
      "Epoch [4010/10000], Loss: 0.5609883666038513\n",
      "Epoch [4011/10000], Loss: 0.5609878897666931\n",
      "Epoch [4012/10000], Loss: 0.5609885454177856\n",
      "Epoch [4013/10000], Loss: 0.560989499092102\n",
      "Epoch [4014/10000], Loss: 0.5609903931617737\n",
      "Epoch [4015/10000], Loss: 0.5609903931617737\n",
      "Epoch [4016/10000], Loss: 0.560990035533905\n",
      "Epoch [4017/10000], Loss: 0.5609884858131409\n",
      "Epoch [4018/10000], Loss: 0.5609864592552185\n",
      "Epoch [4019/10000], Loss: 0.5609848499298096\n",
      "Epoch [4020/10000], Loss: 0.5609834790229797\n",
      "Epoch [4021/10000], Loss: 0.560981810092926\n",
      "Epoch [4022/10000], Loss: 0.5609806180000305\n",
      "Epoch [4023/10000], Loss: 0.560979962348938\n",
      "Epoch [4024/10000], Loss: 0.5609793663024902\n",
      "Epoch [4025/10000], Loss: 0.5609790086746216\n",
      "Epoch [4026/10000], Loss: 0.5609785914421082\n",
      "Epoch [4027/10000], Loss: 0.5609789490699768\n",
      "Epoch [4028/10000], Loss: 0.5609790086746216\n",
      "Epoch [4029/10000], Loss: 0.5609791278839111\n",
      "Epoch [4030/10000], Loss: 0.5609794855117798\n",
      "Epoch [4031/10000], Loss: 0.5609797239303589\n",
      "Epoch [4032/10000], Loss: 0.5609797835350037\n",
      "Epoch [4033/10000], Loss: 0.5609792470932007\n",
      "Epoch [4034/10000], Loss: 0.5609787106513977\n",
      "Epoch [4035/10000], Loss: 0.560978353023529\n",
      "Epoch [4036/10000], Loss: 0.5609774589538574\n",
      "Epoch [4037/10000], Loss: 0.5609760284423828\n",
      "Epoch [4038/10000], Loss: 0.5609748959541321\n",
      "Epoch [4039/10000], Loss: 0.5609738230705261\n",
      "Epoch [4040/10000], Loss: 0.5609731674194336\n",
      "Epoch [4041/10000], Loss: 0.5609727501869202\n",
      "Epoch [4042/10000], Loss: 0.5609726309776306\n",
      "Epoch [4043/10000], Loss: 0.5609726905822754\n",
      "Epoch [4044/10000], Loss: 0.5609731078147888\n",
      "Epoch [4045/10000], Loss: 0.5609737038612366\n",
      "Epoch [4046/10000], Loss: 0.560974657535553\n",
      "Epoch [4047/10000], Loss: 0.5609763860702515\n",
      "Epoch [4048/10000], Loss: 0.5609786510467529\n",
      "Epoch [4049/10000], Loss: 0.5609816312789917\n",
      "Epoch [4050/10000], Loss: 0.5609850883483887\n",
      "Epoch [4051/10000], Loss: 0.5609870553016663\n",
      "Epoch [4052/10000], Loss: 0.5609884858131409\n",
      "Epoch [4053/10000], Loss: 0.5609883069992065\n",
      "Epoch [4054/10000], Loss: 0.5609878301620483\n",
      "Epoch [4055/10000], Loss: 0.5609862804412842\n",
      "Epoch [4056/10000], Loss: 0.5609842538833618\n",
      "Epoch [4057/10000], Loss: 0.560981810092926\n",
      "Epoch [4058/10000], Loss: 0.5609787702560425\n",
      "Epoch [4059/10000], Loss: 0.5609750747680664\n",
      "Epoch [4060/10000], Loss: 0.5609715580940247\n",
      "Epoch [4061/10000], Loss: 0.5609681010246277\n",
      "Epoch [4062/10000], Loss: 0.5609654784202576\n",
      "Epoch [4063/10000], Loss: 0.5609642863273621\n",
      "Epoch [4064/10000], Loss: 0.5609642863273621\n",
      "Epoch [4065/10000], Loss: 0.5609647631645203\n",
      "Epoch [4066/10000], Loss: 0.5609656572341919\n",
      "Epoch [4067/10000], Loss: 0.560966968536377\n",
      "Epoch [4068/10000], Loss: 0.5609675645828247\n",
      "Epoch [4069/10000], Loss: 0.560967743396759\n",
      "Epoch [4070/10000], Loss: 0.560967206954956\n",
      "Epoch [4071/10000], Loss: 0.5609657168388367\n",
      "Epoch [4072/10000], Loss: 0.5609637498855591\n",
      "Epoch [4073/10000], Loss: 0.5609613656997681\n",
      "Epoch [4074/10000], Loss: 0.5609590411186218\n",
      "Epoch [4075/10000], Loss: 0.5609571933746338\n",
      "Epoch [4076/10000], Loss: 0.5609562397003174\n",
      "Epoch [4077/10000], Loss: 0.5609555840492249\n",
      "Epoch [4078/10000], Loss: 0.5609548687934875\n",
      "Epoch [4079/10000], Loss: 0.5609540343284607\n",
      "Epoch [4080/10000], Loss: 0.560953676700592\n",
      "Epoch [4081/10000], Loss: 0.5609533786773682\n",
      "Epoch [4082/10000], Loss: 0.5609531998634338\n",
      "Epoch [4083/10000], Loss: 0.5609529614448547\n",
      "Epoch [4084/10000], Loss: 0.5609528422355652\n",
      "Epoch [4085/10000], Loss: 0.5609535574913025\n",
      "Epoch [4086/10000], Loss: 0.5609542727470398\n",
      "Epoch [4087/10000], Loss: 0.5609549283981323\n",
      "Epoch [4088/10000], Loss: 0.5609558820724487\n",
      "Epoch [4089/10000], Loss: 0.5609562993049622\n",
      "Epoch [4090/10000], Loss: 0.5609562993049622\n",
      "Epoch [4091/10000], Loss: 0.560955286026001\n",
      "Epoch [4092/10000], Loss: 0.5609537363052368\n",
      "Epoch [4093/10000], Loss: 0.5609521865844727\n",
      "Epoch [4094/10000], Loss: 0.5609505772590637\n",
      "Epoch [4095/10000], Loss: 0.5609490275382996\n",
      "Epoch [4096/10000], Loss: 0.5609483122825623\n",
      "Epoch [4097/10000], Loss: 0.560947835445404\n",
      "Epoch [4098/10000], Loss: 0.5609473586082458\n",
      "Epoch [4099/10000], Loss: 0.560947060585022\n",
      "Epoch [4100/10000], Loss: 0.5609468221664429\n",
      "Epoch [4101/10000], Loss: 0.5609464049339294\n",
      "Epoch [4102/10000], Loss: 0.560945987701416\n",
      "Epoch [4103/10000], Loss: 0.5609457492828369\n",
      "Epoch [4104/10000], Loss: 0.5609460473060608\n",
      "Epoch [4105/10000], Loss: 0.560946524143219\n",
      "Epoch [4106/10000], Loss: 0.5609472393989563\n",
      "Epoch [4107/10000], Loss: 0.5609485507011414\n",
      "Epoch [4108/10000], Loss: 0.560950517654419\n",
      "Epoch [4109/10000], Loss: 0.5609520077705383\n",
      "Epoch [4110/10000], Loss: 0.5609523057937622\n",
      "Epoch [4111/10000], Loss: 0.560951828956604\n",
      "Epoch [4112/10000], Loss: 0.5609500408172607\n",
      "Epoch [4113/10000], Loss: 0.5609481334686279\n",
      "Epoch [4114/10000], Loss: 0.5609461069107056\n",
      "Epoch [4115/10000], Loss: 0.5609449744224548\n",
      "Epoch [4116/10000], Loss: 0.560943603515625\n",
      "Epoch [4117/10000], Loss: 0.5609425902366638\n",
      "Epoch [4118/10000], Loss: 0.5609420537948608\n",
      "Epoch [4119/10000], Loss: 0.560941755771637\n",
      "Epoch [4120/10000], Loss: 0.5609412789344788\n",
      "Epoch [4121/10000], Loss: 0.5609407424926758\n",
      "Epoch [4122/10000], Loss: 0.5609406232833862\n",
      "Epoch [4123/10000], Loss: 0.5609405636787415\n",
      "Epoch [4124/10000], Loss: 0.5609409213066101\n",
      "Epoch [4125/10000], Loss: 0.5609412789344788\n",
      "Epoch [4126/10000], Loss: 0.5609419941902161\n",
      "Epoch [4127/10000], Loss: 0.5609431266784668\n",
      "Epoch [4128/10000], Loss: 0.5609448552131653\n",
      "Epoch [4129/10000], Loss: 0.5609467625617981\n",
      "Epoch [4130/10000], Loss: 0.5609495043754578\n",
      "Epoch [4131/10000], Loss: 0.5609512329101562\n",
      "Epoch [4132/10000], Loss: 0.5609517693519592\n",
      "Epoch [4133/10000], Loss: 0.5609500408172607\n",
      "Epoch [4134/10000], Loss: 0.5609472990036011\n",
      "Epoch [4135/10000], Loss: 0.5609446167945862\n",
      "Epoch [4136/10000], Loss: 0.5609415173530579\n",
      "Epoch [4137/10000], Loss: 0.560939371585846\n",
      "Epoch [4138/10000], Loss: 0.5609382390975952\n",
      "Epoch [4139/10000], Loss: 0.5609380006790161\n",
      "Epoch [4140/10000], Loss: 0.5609383583068848\n",
      "Epoch [4141/10000], Loss: 0.5609395503997803\n",
      "Epoch [4142/10000], Loss: 0.5609402656555176\n",
      "Epoch [4143/10000], Loss: 0.560940682888031\n",
      "Epoch [4144/10000], Loss: 0.5609408617019653\n",
      "Epoch [4145/10000], Loss: 0.5609407424926758\n",
      "Epoch [4146/10000], Loss: 0.5609405636787415\n",
      "Epoch [4147/10000], Loss: 0.5609399080276489\n",
      "Epoch [4148/10000], Loss: 0.560939371585846\n",
      "Epoch [4149/10000], Loss: 0.5609384179115295\n",
      "Epoch [4150/10000], Loss: 0.5609375238418579\n",
      "Epoch [4151/10000], Loss: 0.5609366297721863\n",
      "Epoch [4152/10000], Loss: 0.5609358549118042\n",
      "Epoch [4153/10000], Loss: 0.560935378074646\n",
      "Epoch [4154/10000], Loss: 0.5609345436096191\n",
      "Epoch [4155/10000], Loss: 0.5609344840049744\n",
      "Epoch [4156/10000], Loss: 0.5609342455863953\n",
      "Epoch [4157/10000], Loss: 0.5609338283538818\n",
      "Epoch [4158/10000], Loss: 0.5609343647956848\n",
      "Epoch [4159/10000], Loss: 0.5609345436096191\n",
      "Epoch [4160/10000], Loss: 0.5609349012374878\n",
      "Epoch [4161/10000], Loss: 0.5609358549118042\n",
      "Epoch [4162/10000], Loss: 0.5609369874000549\n",
      "Epoch [4163/10000], Loss: 0.5609384179115295\n",
      "Epoch [4164/10000], Loss: 0.5609394907951355\n",
      "Epoch [4165/10000], Loss: 0.5609403252601624\n",
      "Epoch [4166/10000], Loss: 0.5609410405158997\n",
      "Epoch [4167/10000], Loss: 0.5609405040740967\n",
      "Epoch [4168/10000], Loss: 0.5609400272369385\n",
      "Epoch [4169/10000], Loss: 0.560939610004425\n",
      "Epoch [4170/10000], Loss: 0.5609396696090698\n",
      "Epoch [4171/10000], Loss: 0.5609410405158997\n",
      "Epoch [4172/10000], Loss: 0.5609438419342041\n",
      "Epoch [4173/10000], Loss: 0.5609472393989563\n",
      "Epoch [4174/10000], Loss: 0.5609520673751831\n",
      "Epoch [4175/10000], Loss: 0.5609562993049622\n",
      "Epoch [4176/10000], Loss: 0.5609583854675293\n",
      "Epoch [4177/10000], Loss: 0.5609584450721741\n",
      "Epoch [4178/10000], Loss: 0.5609560012817383\n",
      "Epoch [4179/10000], Loss: 0.5609506368637085\n",
      "Epoch [4180/10000], Loss: 0.5609443187713623\n",
      "Epoch [4181/10000], Loss: 0.5609380006790161\n",
      "Epoch [4182/10000], Loss: 0.5609332919120789\n",
      "Epoch [4183/10000], Loss: 0.5609307885169983\n",
      "Epoch [4184/10000], Loss: 0.5609306693077087\n",
      "Epoch [4185/10000], Loss: 0.5609315633773804\n",
      "Epoch [4186/10000], Loss: 0.5609320402145386\n",
      "Epoch [4187/10000], Loss: 0.5609325766563416\n",
      "Epoch [4188/10000], Loss: 0.5609323978424072\n",
      "Epoch [4189/10000], Loss: 0.5609315037727356\n",
      "Epoch [4190/10000], Loss: 0.5609309077262878\n",
      "Epoch [4191/10000], Loss: 0.5609303712844849\n",
      "Epoch [4192/10000], Loss: 0.5609310269355774\n",
      "Epoch [4193/10000], Loss: 0.5609311461448669\n",
      "Epoch [4194/10000], Loss: 0.5609306693077087\n",
      "Epoch [4195/10000], Loss: 0.5609292984008789\n",
      "Epoch [4196/10000], Loss: 0.5609274506568909\n",
      "Epoch [4197/10000], Loss: 0.560926079750061\n",
      "Epoch [4198/10000], Loss: 0.5609250664710999\n",
      "Epoch [4199/10000], Loss: 0.5609244108200073\n",
      "Epoch [4200/10000], Loss: 0.56092369556427\n",
      "Epoch [4201/10000], Loss: 0.5609232187271118\n",
      "Epoch [4202/10000], Loss: 0.5609232783317566\n",
      "Epoch [4203/10000], Loss: 0.5609240531921387\n",
      "Epoch [4204/10000], Loss: 0.5609247088432312\n",
      "Epoch [4205/10000], Loss: 0.5609257221221924\n",
      "Epoch [4206/10000], Loss: 0.5609266757965088\n",
      "Epoch [4207/10000], Loss: 0.5609267950057983\n",
      "Epoch [4208/10000], Loss: 0.5609258413314819\n",
      "Epoch [4209/10000], Loss: 0.5609246492385864\n",
      "Epoch [4210/10000], Loss: 0.5609232187271118\n",
      "Epoch [4211/10000], Loss: 0.5609222054481506\n",
      "Epoch [4212/10000], Loss: 0.5609214305877686\n",
      "Epoch [4213/10000], Loss: 0.5609212517738342\n",
      "Epoch [4214/10000], Loss: 0.5609210133552551\n",
      "Epoch [4215/10000], Loss: 0.5609206557273865\n",
      "Epoch [4216/10000], Loss: 0.5609208345413208\n",
      "Epoch [4217/10000], Loss: 0.5609210133552551\n",
      "Epoch [4218/10000], Loss: 0.5609216690063477\n",
      "Epoch [4219/10000], Loss: 0.5609220862388611\n",
      "Epoch [4220/10000], Loss: 0.5609227418899536\n",
      "Epoch [4221/10000], Loss: 0.5609232783317566\n",
      "Epoch [4222/10000], Loss: 0.5609242916107178\n",
      "Epoch [4223/10000], Loss: 0.5609248280525208\n",
      "Epoch [4224/10000], Loss: 0.5609249472618103\n",
      "Epoch [4225/10000], Loss: 0.560924768447876\n",
      "Epoch [4226/10000], Loss: 0.5609234571456909\n",
      "Epoch [4227/10000], Loss: 0.560921847820282\n",
      "Epoch [4228/10000], Loss: 0.5609198808670044\n",
      "Epoch [4229/10000], Loss: 0.5609186291694641\n",
      "Epoch [4230/10000], Loss: 0.5609176754951477\n",
      "Epoch [4231/10000], Loss: 0.5609172582626343\n",
      "Epoch [4232/10000], Loss: 0.5609164237976074\n",
      "Epoch [4233/10000], Loss: 0.5609162449836731\n",
      "Epoch [4234/10000], Loss: 0.5609164237976074\n",
      "Epoch [4235/10000], Loss: 0.5609164834022522\n",
      "Epoch [4236/10000], Loss: 0.5609171390533447\n",
      "Epoch [4237/10000], Loss: 0.5609181523323059\n",
      "Epoch [4238/10000], Loss: 0.5609195232391357\n",
      "Epoch [4239/10000], Loss: 0.5609214901924133\n",
      "Epoch [4240/10000], Loss: 0.5609235167503357\n",
      "Epoch [4241/10000], Loss: 0.5609242916107178\n",
      "Epoch [4242/10000], Loss: 0.5609240531921387\n",
      "Epoch [4243/10000], Loss: 0.5609221458435059\n",
      "Epoch [4244/10000], Loss: 0.5609197616577148\n",
      "Epoch [4245/10000], Loss: 0.5609177350997925\n",
      "Epoch [4246/10000], Loss: 0.5609166026115417\n",
      "Epoch [4247/10000], Loss: 0.5609159469604492\n",
      "Epoch [4248/10000], Loss: 0.5609161853790283\n",
      "Epoch [4249/10000], Loss: 0.5609176158905029\n",
      "Epoch [4250/10000], Loss: 0.560919463634491\n",
      "Epoch [4251/10000], Loss: 0.5609208941459656\n",
      "Epoch [4252/10000], Loss: 0.5609217286109924\n",
      "Epoch [4253/10000], Loss: 0.5609217882156372\n",
      "Epoch [4254/10000], Loss: 0.5609208345413208\n",
      "Epoch [4255/10000], Loss: 0.560919463634491\n",
      "Epoch [4256/10000], Loss: 0.5609184503555298\n",
      "Epoch [4257/10000], Loss: 0.5609177350997925\n",
      "Epoch [4258/10000], Loss: 0.5609175562858582\n",
      "Epoch [4259/10000], Loss: 0.5609183311462402\n",
      "Epoch [4260/10000], Loss: 0.5609202980995178\n",
      "Epoch [4261/10000], Loss: 0.5609223246574402\n",
      "Epoch [4262/10000], Loss: 0.560924768447876\n",
      "Epoch [4263/10000], Loss: 0.5609265565872192\n",
      "Epoch [4264/10000], Loss: 0.5609273910522461\n",
      "Epoch [4265/10000], Loss: 0.5609265565872192\n",
      "Epoch [4266/10000], Loss: 0.5609234571456909\n",
      "Epoch [4267/10000], Loss: 0.5609199404716492\n",
      "Epoch [4268/10000], Loss: 0.5609170198440552\n",
      "Epoch [4269/10000], Loss: 0.5609151721000671\n",
      "Epoch [4270/10000], Loss: 0.5609136819839478\n",
      "Epoch [4271/10000], Loss: 0.5609128475189209\n",
      "Epoch [4272/10000], Loss: 0.5609121918678284\n",
      "Epoch [4273/10000], Loss: 0.5609116554260254\n",
      "Epoch [4274/10000], Loss: 0.5609118342399597\n",
      "Epoch [4275/10000], Loss: 0.5609118938446045\n",
      "Epoch [4276/10000], Loss: 0.5609122514724731\n",
      "Epoch [4277/10000], Loss: 0.5609126687049866\n",
      "Epoch [4278/10000], Loss: 0.5609130859375\n",
      "Epoch [4279/10000], Loss: 0.5609136819839478\n",
      "Epoch [4280/10000], Loss: 0.560914158821106\n",
      "Epoch [4281/10000], Loss: 0.5609144568443298\n",
      "Epoch [4282/10000], Loss: 0.5609148144721985\n",
      "Epoch [4283/10000], Loss: 0.5609147548675537\n",
      "Epoch [4284/10000], Loss: 0.5609142184257507\n",
      "Epoch [4285/10000], Loss: 0.5609133839607239\n",
      "Epoch [4286/10000], Loss: 0.5609126091003418\n",
      "Epoch [4287/10000], Loss: 0.5609122514724731\n",
      "Epoch [4288/10000], Loss: 0.5609126091003418\n",
      "Epoch [4289/10000], Loss: 0.5609129667282104\n",
      "Epoch [4290/10000], Loss: 0.5609139204025269\n",
      "Epoch [4291/10000], Loss: 0.5609151124954224\n",
      "Epoch [4292/10000], Loss: 0.5609164237976074\n",
      "Epoch [4293/10000], Loss: 0.5609175562858582\n",
      "Epoch [4294/10000], Loss: 0.5609185099601746\n",
      "Epoch [4295/10000], Loss: 0.5609190464019775\n",
      "Epoch [4296/10000], Loss: 0.5609182119369507\n",
      "Epoch [4297/10000], Loss: 0.5609166622161865\n",
      "Epoch [4298/10000], Loss: 0.5609154105186462\n",
      "Epoch [4299/10000], Loss: 0.5609140992164612\n",
      "Epoch [4300/10000], Loss: 0.5609133243560791\n",
      "Epoch [4301/10000], Loss: 0.5609124898910522\n",
      "Epoch [4302/10000], Loss: 0.5609115958213806\n",
      "Epoch [4303/10000], Loss: 0.5609109401702881\n",
      "Epoch [4304/10000], Loss: 0.5609102249145508\n",
      "Epoch [4305/10000], Loss: 0.5609096884727478\n",
      "Epoch [4306/10000], Loss: 0.5609095692634583\n",
      "Epoch [4307/10000], Loss: 0.560908854007721\n",
      "Epoch [4308/10000], Loss: 0.5609085559844971\n",
      "Epoch [4309/10000], Loss: 0.5609084367752075\n",
      "Epoch [4310/10000], Loss: 0.5609084367752075\n",
      "Epoch [4311/10000], Loss: 0.560908854007721\n",
      "Epoch [4312/10000], Loss: 0.5609096884727478\n",
      "Epoch [4313/10000], Loss: 0.5609105825424194\n",
      "Epoch [4314/10000], Loss: 0.5609111785888672\n",
      "Epoch [4315/10000], Loss: 0.5609114766120911\n",
      "Epoch [4316/10000], Loss: 0.5609114766120911\n",
      "Epoch [4317/10000], Loss: 0.5609115958213806\n",
      "Epoch [4318/10000], Loss: 0.560911238193512\n",
      "Epoch [4319/10000], Loss: 0.560910701751709\n",
      "Epoch [4320/10000], Loss: 0.5609101057052612\n",
      "Epoch [4321/10000], Loss: 0.560909628868103\n",
      "Epoch [4322/10000], Loss: 0.560909628868103\n",
      "Epoch [4323/10000], Loss: 0.5609098672866821\n",
      "Epoch [4324/10000], Loss: 0.560910165309906\n",
      "Epoch [4325/10000], Loss: 0.5609098076820374\n",
      "Epoch [4326/10000], Loss: 0.5609093308448792\n",
      "Epoch [4327/10000], Loss: 0.560908317565918\n",
      "Epoch [4328/10000], Loss: 0.5609073042869568\n",
      "Epoch [4329/10000], Loss: 0.5609062910079956\n",
      "Epoch [4330/10000], Loss: 0.5609055757522583\n",
      "Epoch [4331/10000], Loss: 0.5609051585197449\n",
      "Epoch [4332/10000], Loss: 0.5609046816825867\n",
      "Epoch [4333/10000], Loss: 0.560904860496521\n",
      "Epoch [4334/10000], Loss: 0.5609049201011658\n",
      "Epoch [4335/10000], Loss: 0.5609047412872314\n",
      "Epoch [4336/10000], Loss: 0.5609047412872314\n",
      "Epoch [4337/10000], Loss: 0.5609047412872314\n",
      "Epoch [4338/10000], Loss: 0.5609051585197449\n",
      "Epoch [4339/10000], Loss: 0.560905396938324\n",
      "Epoch [4340/10000], Loss: 0.5609054565429688\n",
      "Epoch [4341/10000], Loss: 0.5609053373336792\n",
      "Epoch [4342/10000], Loss: 0.5609050989151001\n",
      "Epoch [4343/10000], Loss: 0.5609040260314941\n",
      "Epoch [4344/10000], Loss: 0.5609034299850464\n",
      "Epoch [4345/10000], Loss: 0.5609032511711121\n",
      "Epoch [4346/10000], Loss: 0.5609025955200195\n",
      "Epoch [4347/10000], Loss: 0.5609024167060852\n",
      "Epoch [4348/10000], Loss: 0.5609022378921509\n",
      "Epoch [4349/10000], Loss: 0.5609028339385986\n",
      "Epoch [4350/10000], Loss: 0.5609027147293091\n",
      "Epoch [4351/10000], Loss: 0.5609027147293091\n",
      "Epoch [4352/10000], Loss: 0.5609030723571777\n",
      "Epoch [4353/10000], Loss: 0.5609027743339539\n",
      "Epoch [4354/10000], Loss: 0.5609022378921509\n",
      "Epoch [4355/10000], Loss: 0.5609023571014404\n",
      "Epoch [4356/10000], Loss: 0.5609021186828613\n",
      "Epoch [4357/10000], Loss: 0.5609021186828613\n",
      "Epoch [4358/10000], Loss: 0.5609022974967957\n",
      "Epoch [4359/10000], Loss: 0.5609028339385986\n",
      "Epoch [4360/10000], Loss: 0.5609039664268494\n",
      "Epoch [4361/10000], Loss: 0.560905396938324\n",
      "Epoch [4362/10000], Loss: 0.5609081983566284\n",
      "Epoch [4363/10000], Loss: 0.560912013053894\n",
      "Epoch [4364/10000], Loss: 0.5609164834022522\n",
      "Epoch [4365/10000], Loss: 0.5609217882156372\n",
      "Epoch [4366/10000], Loss: 0.5609269142150879\n",
      "Epoch [4367/10000], Loss: 0.5609312057495117\n",
      "Epoch [4368/10000], Loss: 0.5609323978424072\n",
      "Epoch [4369/10000], Loss: 0.5609306693077087\n",
      "Epoch [4370/10000], Loss: 0.5609250068664551\n",
      "Epoch [4371/10000], Loss: 0.5609163045883179\n",
      "Epoch [4372/10000], Loss: 0.5609073638916016\n",
      "Epoch [4373/10000], Loss: 0.5609006285667419\n",
      "Epoch [4374/10000], Loss: 0.5608975291252136\n",
      "Epoch [4375/10000], Loss: 0.5608976483345032\n",
      "Epoch [4376/10000], Loss: 0.5609000325202942\n",
      "Epoch [4377/10000], Loss: 0.5609028339385986\n",
      "Epoch [4378/10000], Loss: 0.5609051585197449\n",
      "Epoch [4379/10000], Loss: 0.5609063506126404\n",
      "Epoch [4380/10000], Loss: 0.5609062314033508\n",
      "Epoch [4381/10000], Loss: 0.5609046220779419\n",
      "Epoch [4382/10000], Loss: 0.5609025359153748\n",
      "Epoch [4383/10000], Loss: 0.5609004497528076\n",
      "Epoch [4384/10000], Loss: 0.5608990788459778\n",
      "Epoch [4385/10000], Loss: 0.56089848279953\n",
      "Epoch [4386/10000], Loss: 0.5608981251716614\n",
      "Epoch [4387/10000], Loss: 0.5608978867530823\n",
      "Epoch [4388/10000], Loss: 0.5608972311019897\n",
      "Epoch [4389/10000], Loss: 0.5608966946601868\n",
      "Epoch [4390/10000], Loss: 0.5608967542648315\n",
      "Epoch [4391/10000], Loss: 0.5608962178230286\n",
      "Epoch [4392/10000], Loss: 0.5608963966369629\n",
      "Epoch [4393/10000], Loss: 0.560896635055542\n",
      "Epoch [4394/10000], Loss: 0.5608969926834106\n",
      "Epoch [4395/10000], Loss: 0.5608972311019897\n",
      "Epoch [4396/10000], Loss: 0.5608973503112793\n",
      "Epoch [4397/10000], Loss: 0.5608970522880554\n",
      "Epoch [4398/10000], Loss: 0.560896635055542\n",
      "Epoch [4399/10000], Loss: 0.5608956813812256\n",
      "Epoch [4400/10000], Loss: 0.5608947277069092\n",
      "Epoch [4401/10000], Loss: 0.5608937740325928\n",
      "Epoch [4402/10000], Loss: 0.5608936548233032\n",
      "Epoch [4403/10000], Loss: 0.5608928799629211\n",
      "Epoch [4404/10000], Loss: 0.5608921051025391\n",
      "Epoch [4405/10000], Loss: 0.5608920454978943\n",
      "Epoch [4406/10000], Loss: 0.5608922839164734\n",
      "Epoch [4407/10000], Loss: 0.5608931183815002\n",
      "Epoch [4408/10000], Loss: 0.5608938932418823\n",
      "Epoch [4409/10000], Loss: 0.5608948469161987\n",
      "Epoch [4410/10000], Loss: 0.5608958601951599\n",
      "Epoch [4411/10000], Loss: 0.5608965158462524\n",
      "Epoch [4412/10000], Loss: 0.5608974099159241\n",
      "Epoch [4413/10000], Loss: 0.5608983635902405\n",
      "Epoch [4414/10000], Loss: 0.56089848279953\n",
      "Epoch [4415/10000], Loss: 0.5608978867530823\n",
      "Epoch [4416/10000], Loss: 0.5608963966369629\n",
      "Epoch [4417/10000], Loss: 0.5608947277069092\n",
      "Epoch [4418/10000], Loss: 0.5608936548233032\n",
      "Epoch [4419/10000], Loss: 0.5608930587768555\n",
      "Epoch [4420/10000], Loss: 0.5608927607536316\n",
      "Epoch [4421/10000], Loss: 0.5608928799629211\n",
      "Epoch [4422/10000], Loss: 0.5608929395675659\n",
      "Epoch [4423/10000], Loss: 0.5608933568000793\n",
      "Epoch [4424/10000], Loss: 0.5608936548233032\n",
      "Epoch [4425/10000], Loss: 0.5608943104743958\n",
      "Epoch [4426/10000], Loss: 0.5608945488929749\n",
      "Epoch [4427/10000], Loss: 0.5608947277069092\n",
      "Epoch [4428/10000], Loss: 0.5608943700790405\n",
      "Epoch [4429/10000], Loss: 0.560894250869751\n",
      "Epoch [4430/10000], Loss: 0.5608934760093689\n",
      "Epoch [4431/10000], Loss: 0.5608927607536316\n",
      "Epoch [4432/10000], Loss: 0.5608922243118286\n",
      "Epoch [4433/10000], Loss: 0.5608915686607361\n",
      "Epoch [4434/10000], Loss: 0.5608907341957092\n",
      "Epoch [4435/10000], Loss: 0.5608899593353271\n",
      "Epoch [4436/10000], Loss: 0.5608898997306824\n",
      "Epoch [4437/10000], Loss: 0.5608896017074585\n",
      "Epoch [4438/10000], Loss: 0.5608891844749451\n",
      "Epoch [4439/10000], Loss: 0.5608893632888794\n",
      "Epoch [4440/10000], Loss: 0.5608892440795898\n",
      "Epoch [4441/10000], Loss: 0.5608893632888794\n",
      "Epoch [4442/10000], Loss: 0.5608896017074585\n",
      "Epoch [4443/10000], Loss: 0.5608894228935242\n",
      "Epoch [4444/10000], Loss: 0.560889720916748\n",
      "Epoch [4445/10000], Loss: 0.5608896613121033\n",
      "Epoch [4446/10000], Loss: 0.5608892440795898\n",
      "Epoch [4447/10000], Loss: 0.5608893036842346\n",
      "Epoch [4448/10000], Loss: 0.5608892440795898\n",
      "Epoch [4449/10000], Loss: 0.560889482498169\n",
      "Epoch [4450/10000], Loss: 0.560889482498169\n",
      "Epoch [4451/10000], Loss: 0.560889720916748\n",
      "Epoch [4452/10000], Loss: 0.5608899593353271\n",
      "Epoch [4453/10000], Loss: 0.5608903765678406\n",
      "Epoch [4454/10000], Loss: 0.5608905553817749\n",
      "Epoch [4455/10000], Loss: 0.5608909726142883\n",
      "Epoch [4456/10000], Loss: 0.5608917474746704\n",
      "Epoch [4457/10000], Loss: 0.5608925819396973\n",
      "Epoch [4458/10000], Loss: 0.5608931183815002\n",
      "Epoch [4459/10000], Loss: 0.560893714427948\n",
      "Epoch [4460/10000], Loss: 0.5608946084976196\n",
      "Epoch [4461/10000], Loss: 0.5608948469161987\n",
      "Epoch [4462/10000], Loss: 0.5608950257301331\n",
      "Epoch [4463/10000], Loss: 0.5608954429626465\n",
      "Epoch [4464/10000], Loss: 0.5608958005905151\n",
      "Epoch [4465/10000], Loss: 0.5608959197998047\n",
      "Epoch [4466/10000], Loss: 0.5608961582183838\n",
      "Epoch [4467/10000], Loss: 0.560896098613739\n",
      "Epoch [4468/10000], Loss: 0.5608952045440674\n",
      "Epoch [4469/10000], Loss: 0.5608941316604614\n",
      "Epoch [4470/10000], Loss: 0.560892641544342\n",
      "Epoch [4471/10000], Loss: 0.5608903765678406\n",
      "Epoch [4472/10000], Loss: 0.5608885288238525\n",
      "Epoch [4473/10000], Loss: 0.5608870387077332\n",
      "Epoch [4474/10000], Loss: 0.5608858466148376\n",
      "Epoch [4475/10000], Loss: 0.5608854293823242\n",
      "Epoch [4476/10000], Loss: 0.5608853697776794\n",
      "Epoch [4477/10000], Loss: 0.5608862042427063\n",
      "Epoch [4478/10000], Loss: 0.5608870387077332\n",
      "Epoch [4479/10000], Loss: 0.56088787317276\n",
      "Epoch [4480/10000], Loss: 0.5608887672424316\n",
      "Epoch [4481/10000], Loss: 0.5608891248703003\n",
      "Epoch [4482/10000], Loss: 0.5608897805213928\n",
      "Epoch [4483/10000], Loss: 0.560889482498169\n",
      "Epoch [4484/10000], Loss: 0.5608891248703003\n",
      "Epoch [4485/10000], Loss: 0.5608884692192078\n",
      "Epoch [4486/10000], Loss: 0.5608876943588257\n",
      "Epoch [4487/10000], Loss: 0.5608870387077332\n",
      "Epoch [4488/10000], Loss: 0.5608865022659302\n",
      "Epoch [4489/10000], Loss: 0.5608866214752197\n",
      "Epoch [4490/10000], Loss: 0.5608872771263123\n",
      "Epoch [4491/10000], Loss: 0.5608879327774048\n",
      "Epoch [4492/10000], Loss: 0.5608884692192078\n",
      "Epoch [4493/10000], Loss: 0.5608883500099182\n",
      "Epoch [4494/10000], Loss: 0.5608883500099182\n",
      "Epoch [4495/10000], Loss: 0.5608872771263123\n",
      "Epoch [4496/10000], Loss: 0.5608860850334167\n",
      "Epoch [4497/10000], Loss: 0.5608844757080078\n",
      "Epoch [4498/10000], Loss: 0.5608834624290466\n",
      "Epoch [4499/10000], Loss: 0.5608825087547302\n",
      "Epoch [4500/10000], Loss: 0.5608820915222168\n",
      "Epoch [4501/10000], Loss: 0.5608821511268616\n",
      "Epoch [4502/10000], Loss: 0.5608826875686646\n",
      "Epoch [4503/10000], Loss: 0.5608835220336914\n",
      "Epoch [4504/10000], Loss: 0.5608848929405212\n",
      "Epoch [4505/10000], Loss: 0.5608855485916138\n",
      "Epoch [4506/10000], Loss: 0.5608859062194824\n",
      "Epoch [4507/10000], Loss: 0.5608853697776794\n",
      "Epoch [4508/10000], Loss: 0.5608846545219421\n",
      "Epoch [4509/10000], Loss: 0.5608841776847839\n",
      "Epoch [4510/10000], Loss: 0.5608841776847839\n",
      "Epoch [4511/10000], Loss: 0.5608847737312317\n",
      "Epoch [4512/10000], Loss: 0.5608859062194824\n",
      "Epoch [4513/10000], Loss: 0.5608872771263123\n",
      "Epoch [4514/10000], Loss: 0.5608879327774048\n",
      "Epoch [4515/10000], Loss: 0.5608879327774048\n",
      "Epoch [4516/10000], Loss: 0.5608875155448914\n",
      "Epoch [4517/10000], Loss: 0.5608864426612854\n",
      "Epoch [4518/10000], Loss: 0.5608850121498108\n",
      "Epoch [4519/10000], Loss: 0.5608837008476257\n",
      "Epoch [4520/10000], Loss: 0.5608822107315063\n",
      "Epoch [4521/10000], Loss: 0.5608806014060974\n",
      "Epoch [4522/10000], Loss: 0.5608792304992676\n",
      "Epoch [4523/10000], Loss: 0.5608784556388855\n",
      "Epoch [4524/10000], Loss: 0.5608776807785034\n",
      "Epoch [4525/10000], Loss: 0.5608772039413452\n",
      "Epoch [4526/10000], Loss: 0.5608774423599243\n",
      "Epoch [4527/10000], Loss: 0.5608777403831482\n",
      "Epoch [4528/10000], Loss: 0.5608780384063721\n",
      "Epoch [4529/10000], Loss: 0.5608781576156616\n",
      "Epoch [4530/10000], Loss: 0.5608779191970825\n",
      "Epoch [4531/10000], Loss: 0.5608769059181213\n",
      "Epoch [4532/10000], Loss: 0.5608766674995422\n",
      "Epoch [4533/10000], Loss: 0.5608763098716736\n",
      "Epoch [4534/10000], Loss: 0.5608760714530945\n",
      "Epoch [4535/10000], Loss: 0.5608760118484497\n",
      "Epoch [4536/10000], Loss: 0.5608762502670288\n",
      "Epoch [4537/10000], Loss: 0.5608764290809631\n",
      "Epoch [4538/10000], Loss: 0.5608764290809631\n",
      "Epoch [4539/10000], Loss: 0.5608769655227661\n",
      "Epoch [4540/10000], Loss: 0.5608778595924377\n",
      "Epoch [4541/10000], Loss: 0.5608790516853333\n",
      "Epoch [4542/10000], Loss: 0.560880184173584\n",
      "Epoch [4543/10000], Loss: 0.5608808994293213\n",
      "Epoch [4544/10000], Loss: 0.5608818531036377\n",
      "Epoch [4545/10000], Loss: 0.5608819723129272\n",
      "Epoch [4546/10000], Loss: 0.5608810186386108\n",
      "Epoch [4547/10000], Loss: 0.5608792901039124\n",
      "Epoch [4548/10000], Loss: 0.560877799987793\n",
      "Epoch [4549/10000], Loss: 0.5608765482902527\n",
      "Epoch [4550/10000], Loss: 0.5608769655227661\n",
      "Epoch [4551/10000], Loss: 0.560878336429596\n",
      "Epoch [4552/10000], Loss: 0.5608800649642944\n",
      "Epoch [4553/10000], Loss: 0.5608819127082825\n",
      "Epoch [4554/10000], Loss: 0.5608834624290466\n",
      "Epoch [4555/10000], Loss: 0.5608851313591003\n",
      "Epoch [4556/10000], Loss: 0.5608865022659302\n",
      "Epoch [4557/10000], Loss: 0.5608879327774048\n",
      "Epoch [4558/10000], Loss: 0.5608888864517212\n",
      "Epoch [4559/10000], Loss: 0.5608893632888794\n",
      "Epoch [4560/10000], Loss: 0.5608893036842346\n",
      "Epoch [4561/10000], Loss: 0.5608883500099182\n",
      "Epoch [4562/10000], Loss: 0.5608862042427063\n",
      "Epoch [4563/10000], Loss: 0.560883104801178\n",
      "Epoch [4564/10000], Loss: 0.5608799457550049\n",
      "Epoch [4565/10000], Loss: 0.5608779191970825\n",
      "Epoch [4566/10000], Loss: 0.5608760714530945\n",
      "Epoch [4567/10000], Loss: 0.5608748197555542\n",
      "Epoch [4568/10000], Loss: 0.560874879360199\n",
      "Epoch [4569/10000], Loss: 0.5608759522438049\n",
      "Epoch [4570/10000], Loss: 0.5608769655227661\n",
      "Epoch [4571/10000], Loss: 0.5608779788017273\n",
      "Epoch [4572/10000], Loss: 0.5608779788017273\n",
      "Epoch [4573/10000], Loss: 0.5608770251274109\n",
      "Epoch [4574/10000], Loss: 0.5608750581741333\n",
      "Epoch [4575/10000], Loss: 0.5608729124069214\n",
      "Epoch [4576/10000], Loss: 0.5608713626861572\n",
      "Epoch [4577/10000], Loss: 0.560870349407196\n",
      "Epoch [4578/10000], Loss: 0.5608701705932617\n",
      "Epoch [4579/10000], Loss: 0.5608701705932617\n",
      "Epoch [4580/10000], Loss: 0.5608707666397095\n",
      "Epoch [4581/10000], Loss: 0.5608713626861572\n",
      "Epoch [4582/10000], Loss: 0.5608721971511841\n",
      "Epoch [4583/10000], Loss: 0.5608730316162109\n",
      "Epoch [4584/10000], Loss: 0.5608741044998169\n",
      "Epoch [4585/10000], Loss: 0.5608749389648438\n",
      "Epoch [4586/10000], Loss: 0.5608751773834229\n",
      "Epoch [4587/10000], Loss: 0.560874879360199\n",
      "Epoch [4588/10000], Loss: 0.5608741044998169\n",
      "Epoch [4589/10000], Loss: 0.5608737468719482\n",
      "Epoch [4590/10000], Loss: 0.5608729720115662\n",
      "Epoch [4591/10000], Loss: 0.5608729720115662\n",
      "Epoch [4592/10000], Loss: 0.5608737468719482\n",
      "Epoch [4593/10000], Loss: 0.5608749985694885\n",
      "Epoch [4594/10000], Loss: 0.5608764290809631\n",
      "Epoch [4595/10000], Loss: 0.560878336429596\n",
      "Epoch [4596/10000], Loss: 0.5608803033828735\n",
      "Epoch [4597/10000], Loss: 0.5608822107315063\n",
      "Epoch [4598/10000], Loss: 0.5608840584754944\n",
      "Epoch [4599/10000], Loss: 0.5608848333358765\n",
      "Epoch [4600/10000], Loss: 0.5608835816383362\n",
      "Epoch [4601/10000], Loss: 0.5608811974525452\n",
      "Epoch [4602/10000], Loss: 0.5608788728713989\n",
      "Epoch [4603/10000], Loss: 0.5608762502670288\n",
      "Epoch [4604/10000], Loss: 0.560874342918396\n",
      "Epoch [4605/10000], Loss: 0.5608724355697632\n",
      "Epoch [4606/10000], Loss: 0.5608717799186707\n",
      "Epoch [4607/10000], Loss: 0.5608720183372498\n",
      "Epoch [4608/10000], Loss: 0.5608721375465393\n",
      "Epoch [4609/10000], Loss: 0.5608728528022766\n",
      "Epoch [4610/10000], Loss: 0.56087327003479\n",
      "Epoch [4611/10000], Loss: 0.5608734488487244\n",
      "Epoch [4612/10000], Loss: 0.5608731508255005\n",
      "Epoch [4613/10000], Loss: 0.5608721971511841\n",
      "Epoch [4614/10000], Loss: 0.5608713030815125\n",
      "Epoch [4615/10000], Loss: 0.5608706474304199\n",
      "Epoch [4616/10000], Loss: 0.5608693361282349\n",
      "Epoch [4617/10000], Loss: 0.5608685612678528\n",
      "Epoch [4618/10000], Loss: 0.5608686804771423\n",
      "Epoch [4619/10000], Loss: 0.5608687996864319\n",
      "Epoch [4620/10000], Loss: 0.5608694553375244\n",
      "Epoch [4621/10000], Loss: 0.5608710646629333\n",
      "Epoch [4622/10000], Loss: 0.5608727931976318\n",
      "Epoch [4623/10000], Loss: 0.5608744025230408\n",
      "Epoch [4624/10000], Loss: 0.5608760118484497\n",
      "Epoch [4625/10000], Loss: 0.5608762502670288\n",
      "Epoch [4626/10000], Loss: 0.5608755946159363\n",
      "Epoch [4627/10000], Loss: 0.5608740448951721\n",
      "Epoch [4628/10000], Loss: 0.5608726739883423\n",
      "Epoch [4629/10000], Loss: 0.5608715415000916\n",
      "Epoch [4630/10000], Loss: 0.5608710050582886\n",
      "Epoch [4631/10000], Loss: 0.5608702301979065\n",
      "Epoch [4632/10000], Loss: 0.5608699917793274\n",
      "Epoch [4633/10000], Loss: 0.5608705282211304\n",
      "Epoch [4634/10000], Loss: 0.5608709454536438\n",
      "Epoch [4635/10000], Loss: 0.5608716607093811\n",
      "Epoch [4636/10000], Loss: 0.5608723163604736\n",
      "Epoch [4637/10000], Loss: 0.5608728528022766\n",
      "Epoch [4638/10000], Loss: 0.5608726143836975\n",
      "Epoch [4639/10000], Loss: 0.5608722567558289\n",
      "Epoch [4640/10000], Loss: 0.560872495174408\n",
      "Epoch [4641/10000], Loss: 0.560872495174408\n",
      "Epoch [4642/10000], Loss: 0.5608727335929871\n",
      "Epoch [4643/10000], Loss: 0.5608733892440796\n",
      "Epoch [4644/10000], Loss: 0.5608736872673035\n",
      "Epoch [4645/10000], Loss: 0.5608738660812378\n",
      "Epoch [4646/10000], Loss: 0.5608735680580139\n",
      "Epoch [4647/10000], Loss: 0.5608727931976318\n",
      "Epoch [4648/10000], Loss: 0.5608722567558289\n",
      "Epoch [4649/10000], Loss: 0.560871958732605\n",
      "Epoch [4650/10000], Loss: 0.5608709454536438\n",
      "Epoch [4651/10000], Loss: 0.5608701109886169\n",
      "Epoch [4652/10000], Loss: 0.5608695149421692\n",
      "Epoch [4653/10000], Loss: 0.560869038105011\n",
      "Epoch [4654/10000], Loss: 0.5608685612678528\n",
      "Epoch [4655/10000], Loss: 0.5608680248260498\n",
      "Epoch [4656/10000], Loss: 0.5608677864074707\n",
      "Epoch [4657/10000], Loss: 0.560867965221405\n",
      "Epoch [4658/10000], Loss: 0.5608686804771423\n",
      "Epoch [4659/10000], Loss: 0.5608692765235901\n",
      "Epoch [4660/10000], Loss: 0.5608701109886169\n",
      "Epoch [4661/10000], Loss: 0.560870885848999\n",
      "Epoch [4662/10000], Loss: 0.5608713030815125\n",
      "Epoch [4663/10000], Loss: 0.560871422290802\n",
      "Epoch [4664/10000], Loss: 0.5608710646629333\n",
      "Epoch [4665/10000], Loss: 0.5608701705932617\n",
      "Epoch [4666/10000], Loss: 0.5608693361282349\n",
      "Epoch [4667/10000], Loss: 0.5608687996864319\n",
      "Epoch [4668/10000], Loss: 0.560868501663208\n",
      "Epoch [4669/10000], Loss: 0.560868501663208\n",
      "Epoch [4670/10000], Loss: 0.5608684420585632\n",
      "Epoch [4671/10000], Loss: 0.5608685612678528\n",
      "Epoch [4672/10000], Loss: 0.5608687996864319\n",
      "Epoch [4673/10000], Loss: 0.5608689188957214\n",
      "Epoch [4674/10000], Loss: 0.5608697533607483\n",
      "Epoch [4675/10000], Loss: 0.5608706474304199\n",
      "Epoch [4676/10000], Loss: 0.5608716011047363\n",
      "Epoch [4677/10000], Loss: 0.5608721375465393\n",
      "Epoch [4678/10000], Loss: 0.5608724355697632\n",
      "Epoch [4679/10000], Loss: 0.5608723163604736\n",
      "Epoch [4680/10000], Loss: 0.5608713626861572\n",
      "Epoch [4681/10000], Loss: 0.5608704686164856\n",
      "Epoch [4682/10000], Loss: 0.5608697533607483\n",
      "Epoch [4683/10000], Loss: 0.5608687400817871\n",
      "Epoch [4684/10000], Loss: 0.5608675479888916\n",
      "Epoch [4685/10000], Loss: 0.5608668327331543\n",
      "Epoch [4686/10000], Loss: 0.5608663558959961\n",
      "Epoch [4687/10000], Loss: 0.5608657598495483\n",
      "Epoch [4688/10000], Loss: 0.5608659982681274\n",
      "Epoch [4689/10000], Loss: 0.5608659386634827\n",
      "Epoch [4690/10000], Loss: 0.5608659386634827\n",
      "Epoch [4691/10000], Loss: 0.5608658790588379\n",
      "Epoch [4692/10000], Loss: 0.560866117477417\n",
      "Epoch [4693/10000], Loss: 0.5608665943145752\n",
      "Epoch [4694/10000], Loss: 0.5608672499656677\n",
      "Epoch [4695/10000], Loss: 0.560867965221405\n",
      "Epoch [4696/10000], Loss: 0.5608684420585632\n",
      "Epoch [4697/10000], Loss: 0.5608693957328796\n",
      "Epoch [4698/10000], Loss: 0.5608704090118408\n",
      "Epoch [4699/10000], Loss: 0.5608705878257751\n",
      "Epoch [4700/10000], Loss: 0.5608708262443542\n",
      "Epoch [4701/10000], Loss: 0.5608711242675781\n",
      "Epoch [4702/10000], Loss: 0.5608716011047363\n",
      "Epoch [4703/10000], Loss: 0.5608723759651184\n",
      "Epoch [4704/10000], Loss: 0.56087327003479\n",
      "Epoch [4705/10000], Loss: 0.5608741044998169\n",
      "Epoch [4706/10000], Loss: 0.5608745813369751\n",
      "Epoch [4707/10000], Loss: 0.5608745217323303\n",
      "Epoch [4708/10000], Loss: 0.5608742237091064\n",
      "Epoch [4709/10000], Loss: 0.5608733892440796\n",
      "Epoch [4710/10000], Loss: 0.5608727335929871\n",
      "Epoch [4711/10000], Loss: 0.5608715415000916\n",
      "Epoch [4712/10000], Loss: 0.5608702301979065\n",
      "Epoch [4713/10000], Loss: 0.5608688592910767\n",
      "Epoch [4714/10000], Loss: 0.5608678460121155\n",
      "Epoch [4715/10000], Loss: 0.5608673095703125\n",
      "Epoch [4716/10000], Loss: 0.5608664751052856\n",
      "Epoch [4717/10000], Loss: 0.5608662366867065\n",
      "Epoch [4718/10000], Loss: 0.5608663558959961\n",
      "Epoch [4719/10000], Loss: 0.560866117477417\n",
      "Epoch [4720/10000], Loss: 0.5608658790588379\n",
      "Epoch [4721/10000], Loss: 0.5608654022216797\n",
      "Epoch [4722/10000], Loss: 0.5608651638031006\n",
      "Epoch [4723/10000], Loss: 0.5608653426170349\n",
      "Epoch [4724/10000], Loss: 0.5608656406402588\n",
      "Epoch [4725/10000], Loss: 0.5608668327331543\n",
      "Epoch [4726/10000], Loss: 0.5608682036399841\n",
      "Epoch [4727/10000], Loss: 0.5608692169189453\n",
      "Epoch [4728/10000], Loss: 0.5608692169189453\n",
      "Epoch [4729/10000], Loss: 0.5608687400817871\n",
      "Epoch [4730/10000], Loss: 0.5608670711517334\n",
      "Epoch [4731/10000], Loss: 0.5608649253845215\n",
      "Epoch [4732/10000], Loss: 0.5608631372451782\n",
      "Epoch [4733/10000], Loss: 0.5608621835708618\n",
      "Epoch [4734/10000], Loss: 0.5608615875244141\n",
      "Epoch [4735/10000], Loss: 0.5608611702919006\n",
      "Epoch [4736/10000], Loss: 0.5608609914779663\n",
      "Epoch [4737/10000], Loss: 0.5608609914779663\n",
      "Epoch [4738/10000], Loss: 0.5608612298965454\n",
      "Epoch [4739/10000], Loss: 0.5608619451522827\n",
      "Epoch [4740/10000], Loss: 0.5608630180358887\n",
      "Epoch [4741/10000], Loss: 0.5608644485473633\n",
      "Epoch [4742/10000], Loss: 0.560866117477417\n",
      "Epoch [4743/10000], Loss: 0.5608675479888916\n",
      "Epoch [4744/10000], Loss: 0.5608682036399841\n",
      "Epoch [4745/10000], Loss: 0.5608680844306946\n",
      "Epoch [4746/10000], Loss: 0.5608667731285095\n",
      "Epoch [4747/10000], Loss: 0.5608648061752319\n",
      "Epoch [4748/10000], Loss: 0.5608629584312439\n",
      "Epoch [4749/10000], Loss: 0.5608612895011902\n",
      "Epoch [4750/10000], Loss: 0.5608602166175842\n",
      "Epoch [4751/10000], Loss: 0.5608596801757812\n",
      "Epoch [4752/10000], Loss: 0.5608601570129395\n",
      "Epoch [4753/10000], Loss: 0.5608605146408081\n",
      "Epoch [4754/10000], Loss: 0.5608619451522827\n",
      "Epoch [4755/10000], Loss: 0.5608633756637573\n",
      "Epoch [4756/10000], Loss: 0.5608655214309692\n",
      "Epoch [4757/10000], Loss: 0.5608683824539185\n",
      "Epoch [4758/10000], Loss: 0.5608716607093811\n",
      "Epoch [4759/10000], Loss: 0.560873806476593\n",
      "Epoch [4760/10000], Loss: 0.560875415802002\n",
      "Epoch [4761/10000], Loss: 0.5608753561973572\n",
      "Epoch [4762/10000], Loss: 0.5608748197555542\n",
      "Epoch [4763/10000], Loss: 0.5608736276626587\n",
      "Epoch [4764/10000], Loss: 0.5608717203140259\n",
      "Epoch [4765/10000], Loss: 0.5608693957328796\n",
      "Epoch [4766/10000], Loss: 0.5608673691749573\n",
      "Epoch [4767/10000], Loss: 0.560865044593811\n",
      "Epoch [4768/10000], Loss: 0.5608631372451782\n",
      "Epoch [4769/10000], Loss: 0.5608616471290588\n",
      "Epoch [4770/10000], Loss: 0.5608596801757812\n",
      "Epoch [4771/10000], Loss: 0.560858428478241\n",
      "Epoch [4772/10000], Loss: 0.5608569383621216\n",
      "Epoch [4773/10000], Loss: 0.5608565211296082\n",
      "Epoch [4774/10000], Loss: 0.5608563423156738\n",
      "Epoch [4775/10000], Loss: 0.5608566403388977\n",
      "Epoch [4776/10000], Loss: 0.5608571171760559\n",
      "Epoch [4777/10000], Loss: 0.5608575344085693\n",
      "Epoch [4778/10000], Loss: 0.5608574748039246\n",
      "Epoch [4779/10000], Loss: 0.5608571767807007\n",
      "Epoch [4780/10000], Loss: 0.560856282711029\n",
      "Epoch [4781/10000], Loss: 0.5608552694320679\n",
      "Epoch [4782/10000], Loss: 0.5608543753623962\n",
      "Epoch [4783/10000], Loss: 0.5608540177345276\n",
      "Epoch [4784/10000], Loss: 0.5608534216880798\n",
      "Epoch [4785/10000], Loss: 0.5608528852462769\n",
      "Epoch [4786/10000], Loss: 0.5608528256416321\n",
      "Epoch [4787/10000], Loss: 0.5608528256416321\n",
      "Epoch [4788/10000], Loss: 0.5608532428741455\n",
      "Epoch [4789/10000], Loss: 0.560853898525238\n",
      "Epoch [4790/10000], Loss: 0.5608553290367126\n",
      "Epoch [4791/10000], Loss: 0.5608571171760559\n",
      "Epoch [4792/10000], Loss: 0.5608584880828857\n",
      "Epoch [4793/10000], Loss: 0.5608591437339783\n",
      "Epoch [4794/10000], Loss: 0.560858964920044\n",
      "Epoch [4795/10000], Loss: 0.5608580112457275\n",
      "Epoch [4796/10000], Loss: 0.5608563423156738\n",
      "Epoch [4797/10000], Loss: 0.5608548521995544\n",
      "Epoch [4798/10000], Loss: 0.5608534216880798\n",
      "Epoch [4799/10000], Loss: 0.5608524084091187\n",
      "Epoch [4800/10000], Loss: 0.5608521103858948\n",
      "Epoch [4801/10000], Loss: 0.5608524680137634\n",
      "Epoch [4802/10000], Loss: 0.5608526468276978\n",
      "Epoch [4803/10000], Loss: 0.5608528852462769\n",
      "Epoch [4804/10000], Loss: 0.5608534216880798\n",
      "Epoch [4805/10000], Loss: 0.5608540177345276\n",
      "Epoch [4806/10000], Loss: 0.560854434967041\n",
      "Epoch [4807/10000], Loss: 0.5608552694320679\n",
      "Epoch [4808/10000], Loss: 0.5608554482460022\n",
      "Epoch [4809/10000], Loss: 0.5608559250831604\n",
      "Epoch [4810/10000], Loss: 0.5608562231063843\n",
      "Epoch [4811/10000], Loss: 0.5608565211296082\n",
      "Epoch [4812/10000], Loss: 0.5608566999435425\n",
      "Epoch [4813/10000], Loss: 0.5608564019203186\n",
      "Epoch [4814/10000], Loss: 0.5608561635017395\n",
      "Epoch [4815/10000], Loss: 0.5608556270599365\n",
      "Epoch [4816/10000], Loss: 0.5608554482460022\n",
      "Epoch [4817/10000], Loss: 0.5608556270599365\n",
      "Epoch [4818/10000], Loss: 0.5608558058738708\n",
      "Epoch [4819/10000], Loss: 0.5608559250831604\n",
      "Epoch [4820/10000], Loss: 0.560856282711029\n",
      "Epoch [4821/10000], Loss: 0.5608559250831604\n",
      "Epoch [4822/10000], Loss: 0.5608549118041992\n",
      "Epoch [4823/10000], Loss: 0.5608535408973694\n",
      "Epoch [4824/10000], Loss: 0.5608521699905396\n",
      "Epoch [4825/10000], Loss: 0.5608509182929993\n",
      "Epoch [4826/10000], Loss: 0.5608498454093933\n",
      "Epoch [4827/10000], Loss: 0.5608490705490112\n",
      "Epoch [4828/10000], Loss: 0.5608481764793396\n",
      "Epoch [4829/10000], Loss: 0.560847818851471\n",
      "Epoch [4830/10000], Loss: 0.5608479380607605\n",
      "Epoch [4831/10000], Loss: 0.5608481168746948\n",
      "Epoch [4832/10000], Loss: 0.5608487725257874\n",
      "Epoch [4833/10000], Loss: 0.560849666595459\n",
      "Epoch [4834/10000], Loss: 0.5608501434326172\n",
      "Epoch [4835/10000], Loss: 0.5608510971069336\n",
      "Epoch [4836/10000], Loss: 0.5608518123626709\n",
      "Epoch [4837/10000], Loss: 0.5608528256416321\n",
      "Epoch [4838/10000], Loss: 0.5608539581298828\n",
      "Epoch [4839/10000], Loss: 0.5608551502227783\n",
      "Epoch [4840/10000], Loss: 0.5608553290367126\n",
      "Epoch [4841/10000], Loss: 0.5608554482460022\n",
      "Epoch [4842/10000], Loss: 0.560854971408844\n",
      "Epoch [4843/10000], Loss: 0.5608537197113037\n",
      "Epoch [4844/10000], Loss: 0.5608521103858948\n",
      "Epoch [4845/10000], Loss: 0.5608509182929993\n",
      "Epoch [4846/10000], Loss: 0.5608495473861694\n",
      "Epoch [4847/10000], Loss: 0.5608483552932739\n",
      "Epoch [4848/10000], Loss: 0.5608472228050232\n",
      "Epoch [4849/10000], Loss: 0.5608469247817993\n",
      "Epoch [4850/10000], Loss: 0.5608464479446411\n",
      "Epoch [4851/10000], Loss: 0.5608460307121277\n",
      "Epoch [4852/10000], Loss: 0.5608459711074829\n",
      "Epoch [4853/10000], Loss: 0.5608457922935486\n",
      "Epoch [4854/10000], Loss: 0.5608456134796143\n",
      "Epoch [4855/10000], Loss: 0.5608456134796143\n",
      "Epoch [4856/10000], Loss: 0.5608453154563904\n",
      "Epoch [4857/10000], Loss: 0.5608454942703247\n",
      "Epoch [4858/10000], Loss: 0.5608453154563904\n",
      "Epoch [4859/10000], Loss: 0.5608457922935486\n",
      "Epoch [4860/10000], Loss: 0.5608465075492859\n",
      "Epoch [4861/10000], Loss: 0.560847282409668\n",
      "Epoch [4862/10000], Loss: 0.5608475804328918\n",
      "Epoch [4863/10000], Loss: 0.5608481168746948\n",
      "Epoch [4864/10000], Loss: 0.5608482956886292\n",
      "Epoch [4865/10000], Loss: 0.5608487725257874\n",
      "Epoch [4866/10000], Loss: 0.5608492493629456\n",
      "Epoch [4867/10000], Loss: 0.5608493089675903\n",
      "Epoch [4868/10000], Loss: 0.5608490109443665\n",
      "Epoch [4869/10000], Loss: 0.560848593711853\n",
      "Epoch [4870/10000], Loss: 0.5608481764793396\n",
      "Epoch [4871/10000], Loss: 0.5608484148979187\n",
      "Epoch [4872/10000], Loss: 0.5608489513397217\n",
      "Epoch [4873/10000], Loss: 0.5608494877815247\n",
      "Epoch [4874/10000], Loss: 0.5608505606651306\n",
      "Epoch [4875/10000], Loss: 0.5608518123626709\n",
      "Epoch [4876/10000], Loss: 0.5608533620834351\n",
      "Epoch [4877/10000], Loss: 0.5608553290367126\n",
      "Epoch [4878/10000], Loss: 0.5608574748039246\n",
      "Epoch [4879/10000], Loss: 0.560859739780426\n",
      "Epoch [4880/10000], Loss: 0.5608609318733215\n",
      "Epoch [4881/10000], Loss: 0.5608612298965454\n",
      "Epoch [4882/10000], Loss: 0.5608604550361633\n",
      "Epoch [4883/10000], Loss: 0.560857892036438\n",
      "Epoch [4884/10000], Loss: 0.5608545541763306\n",
      "Epoch [4885/10000], Loss: 0.5608508586883545\n",
      "Epoch [4886/10000], Loss: 0.5608469843864441\n",
      "Epoch [4887/10000], Loss: 0.5608439445495605\n",
      "Epoch [4888/10000], Loss: 0.560841977596283\n",
      "Epoch [4889/10000], Loss: 0.5608412623405457\n",
      "Epoch [4890/10000], Loss: 0.5608413815498352\n",
      "Epoch [4891/10000], Loss: 0.5608421564102173\n",
      "Epoch [4892/10000], Loss: 0.5608432292938232\n",
      "Epoch [4893/10000], Loss: 0.5608446002006531\n",
      "Epoch [4894/10000], Loss: 0.5608458518981934\n",
      "Epoch [4895/10000], Loss: 0.5608473420143127\n",
      "Epoch [4896/10000], Loss: 0.5608484148979187\n",
      "Epoch [4897/10000], Loss: 0.5608479976654053\n",
      "Epoch [4898/10000], Loss: 0.5608473420143127\n",
      "Epoch [4899/10000], Loss: 0.5608452558517456\n",
      "Epoch [4900/10000], Loss: 0.5608434677124023\n",
      "Epoch [4901/10000], Loss: 0.5608415603637695\n",
      "Epoch [4902/10000], Loss: 0.5608405470848083\n",
      "Epoch [4903/10000], Loss: 0.5608396530151367\n",
      "Epoch [4904/10000], Loss: 0.5608394742012024\n",
      "Epoch [4905/10000], Loss: 0.5608400106430054\n",
      "Epoch [4906/10000], Loss: 0.560840368270874\n",
      "Epoch [4907/10000], Loss: 0.5608413219451904\n",
      "Epoch [4908/10000], Loss: 0.5608423352241516\n",
      "Epoch [4909/10000], Loss: 0.5608434677124023\n",
      "Epoch [4910/10000], Loss: 0.5608437657356262\n",
      "Epoch [4911/10000], Loss: 0.5608435273170471\n",
      "Epoch [4912/10000], Loss: 0.5608426928520203\n",
      "Epoch [4913/10000], Loss: 0.5608413219451904\n",
      "Epoch [4914/10000], Loss: 0.5608401894569397\n",
      "Epoch [4915/10000], Loss: 0.5608392357826233\n",
      "Epoch [4916/10000], Loss: 0.5608384013175964\n",
      "Epoch [4917/10000], Loss: 0.5608375072479248\n",
      "Epoch [4918/10000], Loss: 0.5608367323875427\n",
      "Epoch [4919/10000], Loss: 0.5608361959457397\n",
      "Epoch [4920/10000], Loss: 0.5608356595039368\n",
      "Epoch [4921/10000], Loss: 0.5608354210853577\n",
      "Epoch [4922/10000], Loss: 0.5608351826667786\n",
      "Epoch [4923/10000], Loss: 0.5608352422714233\n",
      "Epoch [4924/10000], Loss: 0.5608357191085815\n",
      "Epoch [4925/10000], Loss: 0.560836136341095\n",
      "Epoch [4926/10000], Loss: 0.5608368515968323\n",
      "Epoch [4927/10000], Loss: 0.5608383417129517\n",
      "Epoch [4928/10000], Loss: 0.5608394145965576\n",
      "Epoch [4929/10000], Loss: 0.5608406066894531\n",
      "Epoch [4930/10000], Loss: 0.5608413815498352\n",
      "Epoch [4931/10000], Loss: 0.5608421564102173\n",
      "Epoch [4932/10000], Loss: 0.560841977596283\n",
      "Epoch [4933/10000], Loss: 0.5608415603637695\n",
      "Epoch [4934/10000], Loss: 0.5608407855033875\n",
      "Epoch [4935/10000], Loss: 0.5608401298522949\n",
      "Epoch [4936/10000], Loss: 0.5608386397361755\n",
      "Epoch [4937/10000], Loss: 0.56083744764328\n",
      "Epoch [4938/10000], Loss: 0.5608367919921875\n",
      "Epoch [4939/10000], Loss: 0.5608364343643188\n",
      "Epoch [4940/10000], Loss: 0.5608358383178711\n",
      "Epoch [4941/10000], Loss: 0.5608358979225159\n",
      "Epoch [4942/10000], Loss: 0.5608360171318054\n",
      "Epoch [4943/10000], Loss: 0.5608359575271606\n",
      "Epoch [4944/10000], Loss: 0.5608359575271606\n",
      "Epoch [4945/10000], Loss: 0.5608358383178711\n",
      "Epoch [4946/10000], Loss: 0.5608370304107666\n",
      "Epoch [4947/10000], Loss: 0.5608378052711487\n",
      "Epoch [4948/10000], Loss: 0.5608394145965576\n",
      "Epoch [4949/10000], Loss: 0.5608413219451904\n",
      "Epoch [4950/10000], Loss: 0.5608428716659546\n",
      "Epoch [4951/10000], Loss: 0.5608437061309814\n",
      "Epoch [4952/10000], Loss: 0.5608439445495605\n",
      "Epoch [4953/10000], Loss: 0.5608425140380859\n",
      "Epoch [4954/10000], Loss: 0.5608400106430054\n",
      "Epoch [4955/10000], Loss: 0.5608370304107666\n",
      "Epoch [4956/10000], Loss: 0.5608343482017517\n",
      "Epoch [4957/10000], Loss: 0.560832679271698\n",
      "Epoch [4958/10000], Loss: 0.5608317255973816\n",
      "Epoch [4959/10000], Loss: 0.5608311891555786\n",
      "Epoch [4960/10000], Loss: 0.5608313083648682\n",
      "Epoch [4961/10000], Loss: 0.5608313679695129\n",
      "Epoch [4962/10000], Loss: 0.5608317255973816\n",
      "Epoch [4963/10000], Loss: 0.5608324408531189\n",
      "Epoch [4964/10000], Loss: 0.5608333349227905\n",
      "Epoch [4965/10000], Loss: 0.5608347058296204\n",
      "Epoch [4966/10000], Loss: 0.5608358979225159\n",
      "Epoch [4967/10000], Loss: 0.5608363151550293\n",
      "Epoch [4968/10000], Loss: 0.5608352422714233\n",
      "Epoch [4969/10000], Loss: 0.5608336329460144\n",
      "Epoch [4970/10000], Loss: 0.5608317852020264\n",
      "Epoch [4971/10000], Loss: 0.5608301758766174\n",
      "Epoch [4972/10000], Loss: 0.5608291029930115\n",
      "Epoch [4973/10000], Loss: 0.560828685760498\n",
      "Epoch [4974/10000], Loss: 0.5608288645744324\n",
      "Epoch [4975/10000], Loss: 0.5608289241790771\n",
      "Epoch [4976/10000], Loss: 0.5608295798301697\n",
      "Epoch [4977/10000], Loss: 0.560830295085907\n",
      "Epoch [4978/10000], Loss: 0.5608312487602234\n",
      "Epoch [4979/10000], Loss: 0.5608320832252502\n",
      "Epoch [4980/10000], Loss: 0.5608322620391846\n",
      "Epoch [4981/10000], Loss: 0.5608323216438293\n",
      "Epoch [4982/10000], Loss: 0.5608323812484741\n",
      "Epoch [4983/10000], Loss: 0.5608322024345398\n",
      "Epoch [4984/10000], Loss: 0.5608323216438293\n",
      "Epoch [4985/10000], Loss: 0.5608333349227905\n",
      "Epoch [4986/10000], Loss: 0.5608353018760681\n",
      "Epoch [4987/10000], Loss: 0.5608378052711487\n",
      "Epoch [4988/10000], Loss: 0.5608404278755188\n",
      "Epoch [4989/10000], Loss: 0.560842752456665\n",
      "Epoch [4990/10000], Loss: 0.5608446598052979\n",
      "Epoch [4991/10000], Loss: 0.5608446598052979\n",
      "Epoch [4992/10000], Loss: 0.5608429908752441\n",
      "Epoch [4993/10000], Loss: 0.5608401894569397\n",
      "Epoch [4994/10000], Loss: 0.5608368515968323\n",
      "Epoch [4995/10000], Loss: 0.5608334541320801\n",
      "Epoch [4996/10000], Loss: 0.5608313679695129\n",
      "Epoch [4997/10000], Loss: 0.5608301162719727\n",
      "Epoch [4998/10000], Loss: 0.5608295202255249\n",
      "Epoch [4999/10000], Loss: 0.5608293414115906\n",
      "Epoch [5000/10000], Loss: 0.5608283877372742\n",
      "Epoch [5001/10000], Loss: 0.5608270764350891\n",
      "Epoch [5002/10000], Loss: 0.5608258247375488\n",
      "Epoch [5003/10000], Loss: 0.5608249306678772\n",
      "Epoch [5004/10000], Loss: 0.5608250498771667\n",
      "Epoch [5005/10000], Loss: 0.560825526714325\n",
      "Epoch [5006/10000], Loss: 0.5608263611793518\n",
      "Epoch [5007/10000], Loss: 0.5608276128768921\n",
      "Epoch [5008/10000], Loss: 0.5608280897140503\n",
      "Epoch [5009/10000], Loss: 0.5608285665512085\n",
      "Epoch [5010/10000], Loss: 0.5608277916908264\n",
      "Epoch [5011/10000], Loss: 0.5608260035514832\n",
      "Epoch [5012/10000], Loss: 0.5608243346214294\n",
      "Epoch [5013/10000], Loss: 0.5608228445053101\n",
      "Epoch [5014/10000], Loss: 0.5608220100402832\n",
      "Epoch [5015/10000], Loss: 0.560821533203125\n",
      "Epoch [5016/10000], Loss: 0.5608213543891907\n",
      "Epoch [5017/10000], Loss: 0.5608216524124146\n",
      "Epoch [5018/10000], Loss: 0.560822069644928\n",
      "Epoch [5019/10000], Loss: 0.5608229637145996\n",
      "Epoch [5020/10000], Loss: 0.5608238577842712\n",
      "Epoch [5021/10000], Loss: 0.560824453830719\n",
      "Epoch [5022/10000], Loss: 0.5608252882957458\n",
      "Epoch [5023/10000], Loss: 0.5608252882957458\n",
      "Epoch [5024/10000], Loss: 0.5608251094818115\n",
      "Epoch [5025/10000], Loss: 0.5608248710632324\n",
      "Epoch [5026/10000], Loss: 0.5608246326446533\n",
      "Epoch [5027/10000], Loss: 0.560824453830719\n",
      "Epoch [5028/10000], Loss: 0.560823917388916\n",
      "Epoch [5029/10000], Loss: 0.5608233213424683\n",
      "Epoch [5030/10000], Loss: 0.5608232617378235\n",
      "Epoch [5031/10000], Loss: 0.5608228445053101\n",
      "Epoch [5032/10000], Loss: 0.5608229041099548\n",
      "Epoch [5033/10000], Loss: 0.5608227849006653\n",
      "Epoch [5034/10000], Loss: 0.560822606086731\n",
      "Epoch [5035/10000], Loss: 0.5608232617378235\n",
      "Epoch [5036/10000], Loss: 0.5608239769935608\n",
      "Epoch [5037/10000], Loss: 0.5608240962028503\n",
      "Epoch [5038/10000], Loss: 0.5608241558074951\n",
      "Epoch [5039/10000], Loss: 0.5608241558074951\n",
      "Epoch [5040/10000], Loss: 0.5608240365982056\n",
      "Epoch [5041/10000], Loss: 0.5608237385749817\n",
      "Epoch [5042/10000], Loss: 0.5608239769935608\n",
      "Epoch [5043/10000], Loss: 0.5608245730400085\n",
      "Epoch [5044/10000], Loss: 0.5608251094818115\n",
      "Epoch [5045/10000], Loss: 0.5608262419700623\n",
      "Epoch [5046/10000], Loss: 0.5608269572257996\n",
      "Epoch [5047/10000], Loss: 0.5608277320861816\n",
      "Epoch [5048/10000], Loss: 0.560828447341919\n",
      "Epoch [5049/10000], Loss: 0.5608288049697876\n",
      "Epoch [5050/10000], Loss: 0.5608288645744324\n",
      "Epoch [5051/10000], Loss: 0.5608279705047607\n",
      "Epoch [5052/10000], Loss: 0.5608265995979309\n",
      "Epoch [5053/10000], Loss: 0.5608249306678772\n",
      "Epoch [5054/10000], Loss: 0.5608235001564026\n",
      "Epoch [5055/10000], Loss: 0.5608224868774414\n",
      "Epoch [5056/10000], Loss: 0.5608215928077698\n",
      "Epoch [5057/10000], Loss: 0.5608208775520325\n",
      "Epoch [5058/10000], Loss: 0.5608201026916504\n",
      "Epoch [5059/10000], Loss: 0.5608193278312683\n",
      "Epoch [5060/10000], Loss: 0.5608188509941101\n",
      "Epoch [5061/10000], Loss: 0.5608187913894653\n",
      "Epoch [5062/10000], Loss: 0.5608185529708862\n",
      "Epoch [5063/10000], Loss: 0.5608183145523071\n",
      "Epoch [5064/10000], Loss: 0.5608185529708862\n",
      "Epoch [5065/10000], Loss: 0.560818612575531\n",
      "Epoch [5066/10000], Loss: 0.5608187317848206\n",
      "Epoch [5067/10000], Loss: 0.5608192086219788\n",
      "Epoch [5068/10000], Loss: 0.5608193874359131\n",
      "Epoch [5069/10000], Loss: 0.5608195066452026\n",
      "Epoch [5070/10000], Loss: 0.5608193874359131\n",
      "Epoch [5071/10000], Loss: 0.5608190298080444\n",
      "Epoch [5072/10000], Loss: 0.5608188509941101\n",
      "Epoch [5073/10000], Loss: 0.5608192086219788\n",
      "Epoch [5074/10000], Loss: 0.5608200430870056\n",
      "Epoch [5075/10000], Loss: 0.5608207583427429\n",
      "Epoch [5076/10000], Loss: 0.5608221888542175\n",
      "Epoch [5077/10000], Loss: 0.560823917388916\n",
      "Epoch [5078/10000], Loss: 0.5608247518539429\n",
      "Epoch [5079/10000], Loss: 0.5608251690864563\n",
      "Epoch [5080/10000], Loss: 0.560824990272522\n",
      "Epoch [5081/10000], Loss: 0.5608243346214294\n",
      "Epoch [5082/10000], Loss: 0.5608232617378235\n",
      "Epoch [5083/10000], Loss: 0.5608220100402832\n",
      "Epoch [5084/10000], Loss: 0.5608202219009399\n",
      "Epoch [5085/10000], Loss: 0.560818612575531\n",
      "Epoch [5086/10000], Loss: 0.5608181357383728\n",
      "Epoch [5087/10000], Loss: 0.5608172416687012\n",
      "Epoch [5088/10000], Loss: 0.5608169436454773\n",
      "Epoch [5089/10000], Loss: 0.5608170032501221\n",
      "Epoch [5090/10000], Loss: 0.5608178377151489\n",
      "Epoch [5091/10000], Loss: 0.5608189105987549\n",
      "Epoch [5092/10000], Loss: 0.5608200430870056\n",
      "Epoch [5093/10000], Loss: 0.5608211755752563\n",
      "Epoch [5094/10000], Loss: 0.5608224868774414\n",
      "Epoch [5095/10000], Loss: 0.5608243346214294\n",
      "Epoch [5096/10000], Loss: 0.5608253479003906\n",
      "Epoch [5097/10000], Loss: 0.56082683801651\n",
      "Epoch [5098/10000], Loss: 0.5608279705047607\n",
      "Epoch [5099/10000], Loss: 0.5608285665512085\n",
      "Epoch [5100/10000], Loss: 0.5608296394348145\n",
      "Epoch [5101/10000], Loss: 0.5608305931091309\n",
      "Epoch [5102/10000], Loss: 0.5608314275741577\n",
      "Epoch [5103/10000], Loss: 0.5608320832252502\n",
      "Epoch [5104/10000], Loss: 0.5608320832252502\n",
      "Epoch [5105/10000], Loss: 0.5608309507369995\n",
      "Epoch [5106/10000], Loss: 0.5608285665512085\n",
      "Epoch [5107/10000], Loss: 0.5608260035514832\n",
      "Epoch [5108/10000], Loss: 0.5608227849006653\n",
      "Epoch [5109/10000], Loss: 0.5608198046684265\n",
      "Epoch [5110/10000], Loss: 0.560818076133728\n",
      "Epoch [5111/10000], Loss: 0.5608167052268982\n",
      "Epoch [5112/10000], Loss: 0.5608163475990295\n",
      "Epoch [5113/10000], Loss: 0.5608170628547668\n",
      "Epoch [5114/10000], Loss: 0.5608182549476624\n",
      "Epoch [5115/10000], Loss: 0.5608201026916504\n",
      "Epoch [5116/10000], Loss: 0.5608217716217041\n",
      "Epoch [5117/10000], Loss: 0.5608227252960205\n",
      "Epoch [5118/10000], Loss: 0.560823380947113\n",
      "Epoch [5119/10000], Loss: 0.5608228445053101\n",
      "Epoch [5120/10000], Loss: 0.5608215928077698\n",
      "Epoch [5121/10000], Loss: 0.560819685459137\n",
      "Epoch [5122/10000], Loss: 0.560818076133728\n",
      "Epoch [5123/10000], Loss: 0.5608159303665161\n",
      "Epoch [5124/10000], Loss: 0.5608147978782654\n",
      "Epoch [5125/10000], Loss: 0.5608136653900146\n",
      "Epoch [5126/10000], Loss: 0.5608131289482117\n",
      "Epoch [5127/10000], Loss: 0.5608128309249878\n",
      "Epoch [5128/10000], Loss: 0.5608133673667908\n",
      "Epoch [5129/10000], Loss: 0.5608136057853699\n",
      "Epoch [5130/10000], Loss: 0.5608140230178833\n",
      "Epoch [5131/10000], Loss: 0.5608143210411072\n",
      "Epoch [5132/10000], Loss: 0.5608149170875549\n",
      "Epoch [5133/10000], Loss: 0.5608150362968445\n",
      "Epoch [5134/10000], Loss: 0.5608145594596863\n",
      "Epoch [5135/10000], Loss: 0.5608141422271729\n",
      "Epoch [5136/10000], Loss: 0.5608136653900146\n",
      "Epoch [5137/10000], Loss: 0.5608136057853699\n",
      "Epoch [5138/10000], Loss: 0.5608139038085938\n",
      "Epoch [5139/10000], Loss: 0.5608142018318176\n",
      "Epoch [5140/10000], Loss: 0.5608154535293579\n",
      "Epoch [5141/10000], Loss: 0.5608168244361877\n",
      "Epoch [5142/10000], Loss: 0.5608182549476624\n",
      "Epoch [5143/10000], Loss: 0.5608195066452026\n",
      "Epoch [5144/10000], Loss: 0.5608198046684265\n",
      "Epoch [5145/10000], Loss: 0.5608184337615967\n",
      "Epoch [5146/10000], Loss: 0.5608161091804504\n",
      "Epoch [5147/10000], Loss: 0.5608133673667908\n",
      "Epoch [5148/10000], Loss: 0.5608118176460266\n",
      "Epoch [5149/10000], Loss: 0.560810923576355\n",
      "Epoch [5150/10000], Loss: 0.5608102083206177\n",
      "Epoch [5151/10000], Loss: 0.5608102083206177\n",
      "Epoch [5152/10000], Loss: 0.5608102679252625\n",
      "Epoch [5153/10000], Loss: 0.5608107447624207\n",
      "Epoch [5154/10000], Loss: 0.5608108639717102\n",
      "Epoch [5155/10000], Loss: 0.5608116984367371\n",
      "Epoch [5156/10000], Loss: 0.5608128309249878\n",
      "Epoch [5157/10000], Loss: 0.560813844203949\n",
      "Epoch [5158/10000], Loss: 0.5608148574829102\n",
      "Epoch [5159/10000], Loss: 0.5608155131340027\n",
      "Epoch [5160/10000], Loss: 0.560815691947937\n",
      "Epoch [5161/10000], Loss: 0.5608159303665161\n",
      "Epoch [5162/10000], Loss: 0.5608158111572266\n",
      "Epoch [5163/10000], Loss: 0.5608153343200684\n",
      "Epoch [5164/10000], Loss: 0.5608142018318176\n",
      "Epoch [5165/10000], Loss: 0.5608130693435669\n",
      "Epoch [5166/10000], Loss: 0.5608121752738953\n",
      "Epoch [5167/10000], Loss: 0.5608118772506714\n",
      "Epoch [5168/10000], Loss: 0.5608118772506714\n",
      "Epoch [5169/10000], Loss: 0.5608122944831848\n",
      "Epoch [5170/10000], Loss: 0.5608130097389221\n",
      "Epoch [5171/10000], Loss: 0.5608139038085938\n",
      "Epoch [5172/10000], Loss: 0.5608145594596863\n",
      "Epoch [5173/10000], Loss: 0.5608163475990295\n",
      "Epoch [5174/10000], Loss: 0.560818076133728\n",
      "Epoch [5175/10000], Loss: 0.5608199238777161\n",
      "Epoch [5176/10000], Loss: 0.5608222484588623\n",
      "Epoch [5177/10000], Loss: 0.5608248710632324\n",
      "Epoch [5178/10000], Loss: 0.5608279705047607\n",
      "Epoch [5179/10000], Loss: 0.5608301162719727\n",
      "Epoch [5180/10000], Loss: 0.5608315467834473\n",
      "Epoch [5181/10000], Loss: 0.5608300566673279\n",
      "Epoch [5182/10000], Loss: 0.5608262419700623\n",
      "Epoch [5183/10000], Loss: 0.5608208775520325\n",
      "Epoch [5184/10000], Loss: 0.560815691947937\n",
      "Epoch [5185/10000], Loss: 0.5608119368553162\n",
      "Epoch [5186/10000], Loss: 0.5608101487159729\n",
      "Epoch [5187/10000], Loss: 0.5608099102973938\n",
      "Epoch [5188/10000], Loss: 0.5608116984367371\n",
      "Epoch [5189/10000], Loss: 0.5608136653900146\n",
      "Epoch [5190/10000], Loss: 0.5608150362968445\n",
      "Epoch [5191/10000], Loss: 0.5608147978782654\n",
      "Epoch [5192/10000], Loss: 0.5608131885528564\n",
      "Epoch [5193/10000], Loss: 0.5608108639717102\n",
      "Epoch [5194/10000], Loss: 0.5608090758323669\n",
      "Epoch [5195/10000], Loss: 0.5608081221580505\n",
      "Epoch [5196/10000], Loss: 0.5608075261116028\n",
      "Epoch [5197/10000], Loss: 0.5608075261116028\n",
      "Epoch [5198/10000], Loss: 0.5608086585998535\n",
      "Epoch [5199/10000], Loss: 0.560810387134552\n",
      "Epoch [5200/10000], Loss: 0.5608115792274475\n",
      "Epoch [5201/10000], Loss: 0.5608124136924744\n",
      "Epoch [5202/10000], Loss: 0.5608123540878296\n",
      "Epoch [5203/10000], Loss: 0.5608106255531311\n",
      "Epoch [5204/10000], Loss: 0.560808002948761\n",
      "Epoch [5205/10000], Loss: 0.5608060359954834\n",
      "Epoch [5206/10000], Loss: 0.5608043670654297\n",
      "Epoch [5207/10000], Loss: 0.5608034133911133\n",
      "Epoch [5208/10000], Loss: 0.5608034729957581\n",
      "Epoch [5209/10000], Loss: 0.5608037114143372\n",
      "Epoch [5210/10000], Loss: 0.5608041882514954\n",
      "Epoch [5211/10000], Loss: 0.5608055591583252\n",
      "Epoch [5212/10000], Loss: 0.5608066320419312\n",
      "Epoch [5213/10000], Loss: 0.5608069896697998\n",
      "Epoch [5214/10000], Loss: 0.5608070492744446\n",
      "Epoch [5215/10000], Loss: 0.5608066320419312\n",
      "Epoch [5216/10000], Loss: 0.56080561876297\n",
      "Epoch [5217/10000], Loss: 0.5608042478561401\n",
      "Epoch [5218/10000], Loss: 0.560803234577179\n",
      "Epoch [5219/10000], Loss: 0.5608025789260864\n",
      "Epoch [5220/10000], Loss: 0.5608025193214417\n",
      "Epoch [5221/10000], Loss: 0.5608023405075073\n",
      "Epoch [5222/10000], Loss: 0.5608023405075073\n",
      "Epoch [5223/10000], Loss: 0.5608025789260864\n",
      "Epoch [5224/10000], Loss: 0.5608029961585999\n",
      "Epoch [5225/10000], Loss: 0.5608037114143372\n",
      "Epoch [5226/10000], Loss: 0.5608044862747192\n",
      "Epoch [5227/10000], Loss: 0.5608053207397461\n",
      "Epoch [5228/10000], Loss: 0.5608058571815491\n",
      "Epoch [5229/10000], Loss: 0.560806155204773\n",
      "Epoch [5230/10000], Loss: 0.5608062744140625\n",
      "Epoch [5231/10000], Loss: 0.5608058571815491\n",
      "Epoch [5232/10000], Loss: 0.5608054995536804\n",
      "Epoch [5233/10000], Loss: 0.5608055591583252\n",
      "Epoch [5234/10000], Loss: 0.5608053803443909\n",
      "Epoch [5235/10000], Loss: 0.5608053207397461\n",
      "Epoch [5236/10000], Loss: 0.560806155204773\n",
      "Epoch [5237/10000], Loss: 0.5608068108558655\n",
      "Epoch [5238/10000], Loss: 0.560808002948761\n",
      "Epoch [5239/10000], Loss: 0.5608097910881042\n",
      "Epoch [5240/10000], Loss: 0.5608116984367371\n",
      "Epoch [5241/10000], Loss: 0.5608133673667908\n",
      "Epoch [5242/10000], Loss: 0.5608137845993042\n",
      "Epoch [5243/10000], Loss: 0.5608128309249878\n",
      "Epoch [5244/10000], Loss: 0.5608118772506714\n",
      "Epoch [5245/10000], Loss: 0.5608113408088684\n",
      "Epoch [5246/10000], Loss: 0.5608105063438416\n",
      "Epoch [5247/10000], Loss: 0.5608091950416565\n",
      "Epoch [5248/10000], Loss: 0.5608079433441162\n",
      "Epoch [5249/10000], Loss: 0.5608064532279968\n",
      "Epoch [5250/10000], Loss: 0.560804545879364\n",
      "Epoch [5251/10000], Loss: 0.5608029961585999\n",
      "Epoch [5252/10000], Loss: 0.5608014464378357\n",
      "Epoch [5253/10000], Loss: 0.5608004927635193\n",
      "Epoch [5254/10000], Loss: 0.5607995986938477\n",
      "Epoch [5255/10000], Loss: 0.560799241065979\n",
      "Epoch [5256/10000], Loss: 0.5607995390892029\n",
      "Epoch [5257/10000], Loss: 0.5607999563217163\n",
      "Epoch [5258/10000], Loss: 0.5608004927635193\n",
      "Epoch [5259/10000], Loss: 0.5608012080192566\n",
      "Epoch [5260/10000], Loss: 0.5608017444610596\n",
      "Epoch [5261/10000], Loss: 0.5608016848564148\n",
      "Epoch [5262/10000], Loss: 0.560801088809967\n",
      "Epoch [5263/10000], Loss: 0.5608000159263611\n",
      "Epoch [5264/10000], Loss: 0.5607989430427551\n",
      "Epoch [5265/10000], Loss: 0.5607978701591492\n",
      "Epoch [5266/10000], Loss: 0.560797393321991\n",
      "Epoch [5267/10000], Loss: 0.5607973337173462\n",
      "Epoch [5268/10000], Loss: 0.5607969164848328\n",
      "Epoch [5269/10000], Loss: 0.5607972145080566\n",
      "Epoch [5270/10000], Loss: 0.5607972741127014\n",
      "Epoch [5271/10000], Loss: 0.5607978701591492\n",
      "Epoch [5272/10000], Loss: 0.5607988238334656\n",
      "Epoch [5273/10000], Loss: 0.5607998371124268\n",
      "Epoch [5274/10000], Loss: 0.5608012080192566\n",
      "Epoch [5275/10000], Loss: 0.5608027577400208\n",
      "Epoch [5276/10000], Loss: 0.5608044862747192\n",
      "Epoch [5277/10000], Loss: 0.5608065724372864\n",
      "Epoch [5278/10000], Loss: 0.5608079433441162\n",
      "Epoch [5279/10000], Loss: 0.5608084797859192\n",
      "Epoch [5280/10000], Loss: 0.560808002948761\n",
      "Epoch [5281/10000], Loss: 0.5608065724372864\n",
      "Epoch [5282/10000], Loss: 0.560804545879364\n",
      "Epoch [5283/10000], Loss: 0.5608028769493103\n",
      "Epoch [5284/10000], Loss: 0.5608018040657043\n",
      "Epoch [5285/10000], Loss: 0.5608014464378357\n",
      "Epoch [5286/10000], Loss: 0.5608018040657043\n",
      "Epoch [5287/10000], Loss: 0.5608019232749939\n",
      "Epoch [5288/10000], Loss: 0.5608021020889282\n",
      "Epoch [5289/10000], Loss: 0.5608020424842834\n",
      "Epoch [5290/10000], Loss: 0.56080162525177\n",
      "Epoch [5291/10000], Loss: 0.5608000159263611\n",
      "Epoch [5292/10000], Loss: 0.560798704624176\n",
      "Epoch [5293/10000], Loss: 0.5607976317405701\n",
      "Epoch [5294/10000], Loss: 0.5607966780662537\n",
      "Epoch [5295/10000], Loss: 0.5607959032058716\n",
      "Epoch [5296/10000], Loss: 0.5607954859733582\n",
      "Epoch [5297/10000], Loss: 0.5607951283454895\n",
      "Epoch [5298/10000], Loss: 0.5607947111129761\n",
      "Epoch [5299/10000], Loss: 0.5607946515083313\n",
      "Epoch [5300/10000], Loss: 0.5607945919036865\n",
      "Epoch [5301/10000], Loss: 0.5607943534851074\n",
      "Epoch [5302/10000], Loss: 0.5607946515083313\n",
      "Epoch [5303/10000], Loss: 0.5607950091362\n",
      "Epoch [5304/10000], Loss: 0.5607954859733582\n",
      "Epoch [5305/10000], Loss: 0.5607965588569641\n",
      "Epoch [5306/10000], Loss: 0.5607974529266357\n",
      "Epoch [5307/10000], Loss: 0.5607986450195312\n",
      "Epoch [5308/10000], Loss: 0.5608000755310059\n",
      "Epoch [5309/10000], Loss: 0.5608002543449402\n",
      "Epoch [5310/10000], Loss: 0.5608002543449402\n",
      "Epoch [5311/10000], Loss: 0.5607995986938477\n",
      "Epoch [5312/10000], Loss: 0.5607987642288208\n",
      "Epoch [5313/10000], Loss: 0.5607979893684387\n",
      "Epoch [5314/10000], Loss: 0.5607980489730835\n",
      "Epoch [5315/10000], Loss: 0.5607984066009521\n",
      "Epoch [5316/10000], Loss: 0.560799241065979\n",
      "Epoch [5317/10000], Loss: 0.5608008503913879\n",
      "Epoch [5318/10000], Loss: 0.5608025789260864\n",
      "Epoch [5319/10000], Loss: 0.5608049631118774\n",
      "Epoch [5320/10000], Loss: 0.5608071088790894\n",
      "Epoch [5321/10000], Loss: 0.5608093738555908\n",
      "Epoch [5322/10000], Loss: 0.5608109831809998\n",
      "Epoch [5323/10000], Loss: 0.5608124732971191\n",
      "Epoch [5324/10000], Loss: 0.5608119964599609\n",
      "Epoch [5325/10000], Loss: 0.5608099699020386\n",
      "Epoch [5326/10000], Loss: 0.5608065128326416\n",
      "Epoch [5327/10000], Loss: 0.5608028173446655\n",
      "Epoch [5328/10000], Loss: 0.5607997179031372\n",
      "Epoch [5329/10000], Loss: 0.560797393321991\n",
      "Epoch [5330/10000], Loss: 0.5607963800430298\n",
      "Epoch [5331/10000], Loss: 0.5607958436012268\n",
      "Epoch [5332/10000], Loss: 0.5607957243919373\n",
      "Epoch [5333/10000], Loss: 0.5607965588569641\n",
      "Epoch [5334/10000], Loss: 0.5607972741127014\n",
      "Epoch [5335/10000], Loss: 0.5607975721359253\n",
      "Epoch [5336/10000], Loss: 0.5607978105545044\n",
      "Epoch [5337/10000], Loss: 0.5607980489730835\n",
      "Epoch [5338/10000], Loss: 0.5607975721359253\n",
      "Epoch [5339/10000], Loss: 0.5607971549034119\n",
      "Epoch [5340/10000], Loss: 0.5607969760894775\n",
      "Epoch [5341/10000], Loss: 0.5607967376708984\n",
      "Epoch [5342/10000], Loss: 0.5607974529266357\n",
      "Epoch [5343/10000], Loss: 0.5607982873916626\n",
      "Epoch [5344/10000], Loss: 0.5607990622520447\n",
      "Epoch [5345/10000], Loss: 0.5607991218566895\n",
      "Epoch [5346/10000], Loss: 0.5607986450195312\n",
      "Epoch [5347/10000], Loss: 0.5607974529266357\n",
      "Epoch [5348/10000], Loss: 0.5607962012290955\n",
      "Epoch [5349/10000], Loss: 0.5607957243919373\n",
      "Epoch [5350/10000], Loss: 0.5607948303222656\n",
      "Epoch [5351/10000], Loss: 0.560794472694397\n",
      "Epoch [5352/10000], Loss: 0.560793936252594\n",
      "Epoch [5353/10000], Loss: 0.5607938766479492\n",
      "Epoch [5354/10000], Loss: 0.5607940554618835\n",
      "Epoch [5355/10000], Loss: 0.5607942938804626\n",
      "Epoch [5356/10000], Loss: 0.5607948303222656\n",
      "Epoch [5357/10000], Loss: 0.5607955455780029\n",
      "Epoch [5358/10000], Loss: 0.5607964992523193\n",
      "Epoch [5359/10000], Loss: 0.5607981085777283\n",
      "Epoch [5360/10000], Loss: 0.5608003735542297\n",
      "Epoch [5361/10000], Loss: 0.5608019232749939\n",
      "Epoch [5362/10000], Loss: 0.5608034729957581\n",
      "Epoch [5363/10000], Loss: 0.5608039498329163\n",
      "Epoch [5364/10000], Loss: 0.5608038306236267\n",
      "Epoch [5365/10000], Loss: 0.5608028769493103\n",
      "Epoch [5366/10000], Loss: 0.5608013272285461\n",
      "Epoch [5367/10000], Loss: 0.560800313949585\n",
      "Epoch [5368/10000], Loss: 0.5607991218566895\n",
      "Epoch [5369/10000], Loss: 0.5607978105545044\n",
      "Epoch [5370/10000], Loss: 0.5607966184616089\n",
      "Epoch [5371/10000], Loss: 0.5607962608337402\n",
      "Epoch [5372/10000], Loss: 0.5607962012290955\n",
      "Epoch [5373/10000], Loss: 0.5607962012290955\n",
      "Epoch [5374/10000], Loss: 0.5607965588569641\n",
      "Epoch [5375/10000], Loss: 0.5607970952987671\n",
      "Epoch [5376/10000], Loss: 0.5607981085777283\n",
      "Epoch [5377/10000], Loss: 0.5607995390892029\n",
      "Epoch [5378/10000], Loss: 0.5608013868331909\n",
      "Epoch [5379/10000], Loss: 0.5608026385307312\n",
      "Epoch [5380/10000], Loss: 0.5608029961585999\n",
      "Epoch [5381/10000], Loss: 0.5608018040657043\n",
      "Epoch [5382/10000], Loss: 0.5608002543449402\n",
      "Epoch [5383/10000], Loss: 0.5607980489730835\n",
      "Epoch [5384/10000], Loss: 0.5607965588569641\n",
      "Epoch [5385/10000], Loss: 0.5607956051826477\n",
      "Epoch [5386/10000], Loss: 0.560795247554779\n",
      "Epoch [5387/10000], Loss: 0.5607954263687134\n",
      "Epoch [5388/10000], Loss: 0.5607960224151611\n",
      "Epoch [5389/10000], Loss: 0.560796856880188\n",
      "Epoch [5390/10000], Loss: 0.5607972145080566\n",
      "Epoch [5391/10000], Loss: 0.5607975721359253\n",
      "Epoch [5392/10000], Loss: 0.5607975125312805\n",
      "Epoch [5393/10000], Loss: 0.560797929763794\n",
      "Epoch [5394/10000], Loss: 0.5607980489730835\n",
      "Epoch [5395/10000], Loss: 0.5607974529266357\n",
      "Epoch [5396/10000], Loss: 0.5607964992523193\n",
      "Epoch [5397/10000], Loss: 0.5607953667640686\n",
      "Epoch [5398/10000], Loss: 0.5607946515083313\n",
      "Epoch [5399/10000], Loss: 0.5607941746711731\n",
      "Epoch [5400/10000], Loss: 0.5607933402061462\n",
      "Epoch [5401/10000], Loss: 0.5607929229736328\n",
      "Epoch [5402/10000], Loss: 0.5607931017875671\n",
      "Epoch [5403/10000], Loss: 0.5607928037643433\n",
      "Epoch [5404/10000], Loss: 0.5607928037643433\n",
      "Epoch [5405/10000], Loss: 0.5607924461364746\n",
      "Epoch [5406/10000], Loss: 0.5607924461364746\n",
      "Epoch [5407/10000], Loss: 0.5607925653457642\n",
      "Epoch [5408/10000], Loss: 0.5607929229736328\n",
      "Epoch [5409/10000], Loss: 0.5607937574386597\n",
      "Epoch [5410/10000], Loss: 0.5607950687408447\n",
      "Epoch [5411/10000], Loss: 0.5607965588569641\n",
      "Epoch [5412/10000], Loss: 0.5607982873916626\n",
      "Epoch [5413/10000], Loss: 0.5607999563217163\n",
      "Epoch [5414/10000], Loss: 0.5608012080192566\n",
      "Epoch [5415/10000], Loss: 0.5608016848564148\n",
      "Epoch [5416/10000], Loss: 0.5608018040657043\n",
      "Epoch [5417/10000], Loss: 0.5608031153678894\n",
      "Epoch [5418/10000], Loss: 0.5608051419258118\n",
      "Epoch [5419/10000], Loss: 0.5608073472976685\n",
      "Epoch [5420/10000], Loss: 0.5608101487159729\n",
      "Epoch [5421/10000], Loss: 0.5608136653900146\n",
      "Epoch [5422/10000], Loss: 0.5608169436454773\n",
      "Epoch [5423/10000], Loss: 0.5608185529708862\n",
      "Epoch [5424/10000], Loss: 0.5608171820640564\n",
      "Epoch [5425/10000], Loss: 0.560814619064331\n",
      "Epoch [5426/10000], Loss: 0.5608096718788147\n",
      "Epoch [5427/10000], Loss: 0.5608037114143372\n",
      "Epoch [5428/10000], Loss: 0.5607988834381104\n",
      "Epoch [5429/10000], Loss: 0.5607959032058716\n",
      "Epoch [5430/10000], Loss: 0.5607946515083313\n",
      "Epoch [5431/10000], Loss: 0.5607950091362\n",
      "Epoch [5432/10000], Loss: 0.5607962608337402\n",
      "Epoch [5433/10000], Loss: 0.5607976913452148\n",
      "Epoch [5434/10000], Loss: 0.5607982873916626\n",
      "Epoch [5435/10000], Loss: 0.5607976913452148\n",
      "Epoch [5436/10000], Loss: 0.5607964992523193\n",
      "Epoch [5437/10000], Loss: 0.5607951283454895\n",
      "Epoch [5438/10000], Loss: 0.5607935786247253\n",
      "Epoch [5439/10000], Loss: 0.5607925057411194\n",
      "Epoch [5440/10000], Loss: 0.5607922673225403\n",
      "Epoch [5441/10000], Loss: 0.5607928037643433\n",
      "Epoch [5442/10000], Loss: 0.5607942938804626\n",
      "Epoch [5443/10000], Loss: 0.5607959628105164\n",
      "Epoch [5444/10000], Loss: 0.5607975721359253\n",
      "Epoch [5445/10000], Loss: 0.5607982277870178\n",
      "Epoch [5446/10000], Loss: 0.5607980489730835\n",
      "Epoch [5447/10000], Loss: 0.5607969164848328\n",
      "Epoch [5448/10000], Loss: 0.5607950091362\n",
      "Epoch [5449/10000], Loss: 0.5607938766479492\n",
      "Epoch [5450/10000], Loss: 0.5607931017875671\n",
      "Epoch [5451/10000], Loss: 0.5607925057411194\n",
      "Epoch [5452/10000], Loss: 0.5607928037643433\n",
      "Epoch [5453/10000], Loss: 0.5607934594154358\n",
      "Epoch [5454/10000], Loss: 0.5607944130897522\n",
      "Epoch [5455/10000], Loss: 0.5607950687408447\n",
      "Epoch [5456/10000], Loss: 0.5607953071594238\n",
      "Epoch [5457/10000], Loss: 0.5607946515083313\n",
      "Epoch [5458/10000], Loss: 0.5607937574386597\n",
      "Epoch [5459/10000], Loss: 0.5607930421829224\n",
      "Epoch [5460/10000], Loss: 0.5607925653457642\n",
      "Epoch [5461/10000], Loss: 0.5607924461364746\n",
      "Epoch [5462/10000], Loss: 0.5607926845550537\n",
      "Epoch [5463/10000], Loss: 0.5607931017875671\n",
      "Epoch [5464/10000], Loss: 0.5607938766479492\n",
      "Epoch [5465/10000], Loss: 0.5607945322990417\n",
      "Epoch [5466/10000], Loss: 0.5607951283454895\n",
      "Epoch [5467/10000], Loss: 0.5607945322990417\n",
      "Epoch [5468/10000], Loss: 0.5607938766479492\n",
      "Epoch [5469/10000], Loss: 0.5607931017875671\n",
      "Epoch [5470/10000], Loss: 0.5607923269271851\n",
      "Epoch [5471/10000], Loss: 0.5607925653457642\n",
      "Epoch [5472/10000], Loss: 0.5607929825782776\n",
      "Epoch [5473/10000], Loss: 0.5607935786247253\n",
      "Epoch [5474/10000], Loss: 0.5607941150665283\n",
      "Epoch [5475/10000], Loss: 0.5607948303222656\n",
      "Epoch [5476/10000], Loss: 0.5607951879501343\n",
      "Epoch [5477/10000], Loss: 0.5607951283454895\n",
      "Epoch [5478/10000], Loss: 0.5607945919036865\n",
      "Epoch [5479/10000], Loss: 0.5607937574386597\n",
      "Epoch [5480/10000], Loss: 0.560792863368988\n",
      "Epoch [5481/10000], Loss: 0.5607924461364746\n",
      "Epoch [5482/10000], Loss: 0.560792088508606\n",
      "Epoch [5483/10000], Loss: 0.5607917904853821\n",
      "Epoch [5484/10000], Loss: 0.5607919096946716\n",
      "Epoch [5485/10000], Loss: 0.5607922673225403\n",
      "Epoch [5486/10000], Loss: 0.5607934594154358\n",
      "Epoch [5487/10000], Loss: 0.5607945919036865\n",
      "Epoch [5488/10000], Loss: 0.5607958436012268\n",
      "Epoch [5489/10000], Loss: 0.5607965588569641\n",
      "Epoch [5490/10000], Loss: 0.5607966780662537\n",
      "Epoch [5491/10000], Loss: 0.5607963800430298\n",
      "Epoch [5492/10000], Loss: 0.560796320438385\n",
      "Epoch [5493/10000], Loss: 0.5607962608337402\n",
      "Epoch [5494/10000], Loss: 0.5607962608337402\n",
      "Epoch [5495/10000], Loss: 0.5607960820198059\n",
      "Epoch [5496/10000], Loss: 0.5607964992523193\n",
      "Epoch [5497/10000], Loss: 0.5607969164848328\n",
      "Epoch [5498/10000], Loss: 0.5607976913452148\n",
      "Epoch [5499/10000], Loss: 0.5607981085777283\n",
      "Epoch [5500/10000], Loss: 0.5607986450195312\n",
      "Epoch [5501/10000], Loss: 0.5607991218566895\n",
      "Epoch [5502/10000], Loss: 0.5607998371124268\n",
      "Epoch [5503/10000], Loss: 0.5608005523681641\n",
      "Epoch [5504/10000], Loss: 0.5608006119728088\n",
      "Epoch [5505/10000], Loss: 0.5607998371124268\n",
      "Epoch [5506/10000], Loss: 0.5607988238334656\n",
      "Epoch [5507/10000], Loss: 0.5607965588569641\n",
      "Epoch [5508/10000], Loss: 0.5607945322990417\n",
      "Epoch [5509/10000], Loss: 0.5607931613922119\n",
      "Epoch [5510/10000], Loss: 0.5607918500900269\n",
      "Epoch [5511/10000], Loss: 0.5607913732528687\n",
      "Epoch [5512/10000], Loss: 0.5607913136482239\n",
      "Epoch [5513/10000], Loss: 0.5607918500900269\n",
      "Epoch [5514/10000], Loss: 0.5607929229736328\n",
      "Epoch [5515/10000], Loss: 0.5607945919036865\n",
      "Epoch [5516/10000], Loss: 0.560796320438385\n",
      "Epoch [5517/10000], Loss: 0.5607975721359253\n",
      "Epoch [5518/10000], Loss: 0.5607979893684387\n",
      "Epoch [5519/10000], Loss: 0.5607969164848328\n",
      "Epoch [5520/10000], Loss: 0.5607951283454895\n",
      "Epoch [5521/10000], Loss: 0.5607929825782776\n",
      "Epoch [5522/10000], Loss: 0.5607914924621582\n",
      "Epoch [5523/10000], Loss: 0.5607905387878418\n",
      "Epoch [5524/10000], Loss: 0.5607901215553284\n",
      "Epoch [5525/10000], Loss: 0.5607897043228149\n",
      "Epoch [5526/10000], Loss: 0.5607893466949463\n",
      "Epoch [5527/10000], Loss: 0.5607892274856567\n",
      "Epoch [5528/10000], Loss: 0.5607896447181702\n",
      "Epoch [5529/10000], Loss: 0.5607903599739075\n",
      "Epoch [5530/10000], Loss: 0.5607911348342896\n",
      "Epoch [5531/10000], Loss: 0.5607917308807373\n",
      "Epoch [5532/10000], Loss: 0.560792863368988\n",
      "Epoch [5533/10000], Loss: 0.560793936252594\n",
      "Epoch [5534/10000], Loss: 0.5607942342758179\n",
      "Epoch [5535/10000], Loss: 0.5607945322990417\n",
      "Epoch [5536/10000], Loss: 0.5607942342758179\n",
      "Epoch [5537/10000], Loss: 0.5607936382293701\n",
      "Epoch [5538/10000], Loss: 0.5607927441596985\n",
      "Epoch [5539/10000], Loss: 0.5607922673225403\n",
      "Epoch [5540/10000], Loss: 0.5607919096946716\n",
      "Epoch [5541/10000], Loss: 0.5607913732528687\n",
      "Epoch [5542/10000], Loss: 0.560791015625\n",
      "Epoch [5543/10000], Loss: 0.5607905387878418\n",
      "Epoch [5544/10000], Loss: 0.5607900619506836\n",
      "Epoch [5545/10000], Loss: 0.5607900619506836\n",
      "Epoch [5546/10000], Loss: 0.5607903003692627\n",
      "Epoch [5547/10000], Loss: 0.5607900619506836\n",
      "Epoch [5548/10000], Loss: 0.5607903599739075\n",
      "Epoch [5549/10000], Loss: 0.5607909560203552\n",
      "Epoch [5550/10000], Loss: 0.5607918500900269\n",
      "Epoch [5551/10000], Loss: 0.560793399810791\n",
      "Epoch [5552/10000], Loss: 0.5607957243919373\n",
      "Epoch [5553/10000], Loss: 0.5607982277870178\n",
      "Epoch [5554/10000], Loss: 0.56080162525177\n",
      "Epoch [5555/10000], Loss: 0.5608055591583252\n",
      "Epoch [5556/10000], Loss: 0.5608092546463013\n",
      "Epoch [5557/10000], Loss: 0.5608126521110535\n",
      "Epoch [5558/10000], Loss: 0.5608149766921997\n",
      "Epoch [5559/10000], Loss: 0.5608159899711609\n",
      "Epoch [5560/10000], Loss: 0.5608136057853699\n",
      "Epoch [5561/10000], Loss: 0.5608101487159729\n",
      "Epoch [5562/10000], Loss: 0.5608053207397461\n",
      "Epoch [5563/10000], Loss: 0.560799777507782\n",
      "Epoch [5564/10000], Loss: 0.560794472694397\n",
      "Epoch [5565/10000], Loss: 0.5607911348342896\n",
      "Epoch [5566/10000], Loss: 0.5607898235321045\n",
      "Epoch [5567/10000], Loss: 0.5607904195785522\n",
      "Epoch [5568/10000], Loss: 0.560791552066803\n",
      "Epoch [5569/10000], Loss: 0.5607929229736328\n",
      "Epoch [5570/10000], Loss: 0.5607934594154358\n",
      "Epoch [5571/10000], Loss: 0.5607937574386597\n",
      "Epoch [5572/10000], Loss: 0.5607929229736328\n",
      "Epoch [5573/10000], Loss: 0.5607919692993164\n",
      "Epoch [5574/10000], Loss: 0.5607913732528687\n",
      "Epoch [5575/10000], Loss: 0.5607913136482239\n",
      "Epoch [5576/10000], Loss: 0.5607914924621582\n",
      "Epoch [5577/10000], Loss: 0.5607922077178955\n",
      "Epoch [5578/10000], Loss: 0.5607931017875671\n",
      "Epoch [5579/10000], Loss: 0.560793399810791\n",
      "Epoch [5580/10000], Loss: 0.5607934594154358\n",
      "Epoch [5581/10000], Loss: 0.5607929229736328\n",
      "Epoch [5582/10000], Loss: 0.5607916116714478\n",
      "Epoch [5583/10000], Loss: 0.5607904195785522\n",
      "Epoch [5584/10000], Loss: 0.5607895851135254\n",
      "Epoch [5585/10000], Loss: 0.5607889294624329\n",
      "Epoch [5586/10000], Loss: 0.5607885718345642\n",
      "Epoch [5587/10000], Loss: 0.5607883334159851\n",
      "Epoch [5588/10000], Loss: 0.5607883334159851\n",
      "Epoch [5589/10000], Loss: 0.5607880353927612\n",
      "Epoch [5590/10000], Loss: 0.5607882738113403\n",
      "Epoch [5591/10000], Loss: 0.5607884526252747\n",
      "Epoch [5592/10000], Loss: 0.560788631439209\n",
      "Epoch [5593/10000], Loss: 0.5607900023460388\n",
      "Epoch [5594/10000], Loss: 0.560791015625\n",
      "Epoch [5595/10000], Loss: 0.5607922077178955\n",
      "Epoch [5596/10000], Loss: 0.560793399810791\n",
      "Epoch [5597/10000], Loss: 0.5607941746711731\n",
      "Epoch [5598/10000], Loss: 0.5607938170433044\n",
      "Epoch [5599/10000], Loss: 0.5607924461364746\n",
      "Epoch [5600/10000], Loss: 0.5607912540435791\n",
      "Epoch [5601/10000], Loss: 0.5607900619506836\n",
      "Epoch [5602/10000], Loss: 0.5607897043228149\n",
      "Epoch [5603/10000], Loss: 0.5607894659042358\n",
      "Epoch [5604/10000], Loss: 0.5607894062995911\n",
      "Epoch [5605/10000], Loss: 0.5607898235321045\n",
      "Epoch [5606/10000], Loss: 0.5607900023460388\n",
      "Epoch [5607/10000], Loss: 0.5607900619506836\n",
      "Epoch [5608/10000], Loss: 0.5607908368110657\n",
      "Epoch [5609/10000], Loss: 0.5607908368110657\n",
      "Epoch [5610/10000], Loss: 0.5607912540435791\n",
      "Epoch [5611/10000], Loss: 0.5607916712760925\n",
      "Epoch [5612/10000], Loss: 0.560792088508606\n",
      "Epoch [5613/10000], Loss: 0.5607931017875671\n",
      "Epoch [5614/10000], Loss: 0.560793936252594\n",
      "Epoch [5615/10000], Loss: 0.5607950091362\n",
      "Epoch [5616/10000], Loss: 0.5607950091362\n",
      "Epoch [5617/10000], Loss: 0.5607941746711731\n",
      "Epoch [5618/10000], Loss: 0.5607924461364746\n",
      "Epoch [5619/10000], Loss: 0.5607907772064209\n",
      "Epoch [5620/10000], Loss: 0.5607890486717224\n",
      "Epoch [5621/10000], Loss: 0.560788094997406\n",
      "Epoch [5622/10000], Loss: 0.5607877969741821\n",
      "Epoch [5623/10000], Loss: 0.5607874989509583\n",
      "Epoch [5624/10000], Loss: 0.5607876181602478\n",
      "Epoch [5625/10000], Loss: 0.5607878565788269\n",
      "Epoch [5626/10000], Loss: 0.5607878565788269\n",
      "Epoch [5627/10000], Loss: 0.5607877969741821\n",
      "Epoch [5628/10000], Loss: 0.5607880353927612\n",
      "Epoch [5629/10000], Loss: 0.5607887506484985\n",
      "Epoch [5630/10000], Loss: 0.5607894659042358\n",
      "Epoch [5631/10000], Loss: 0.5607903003692627\n",
      "Epoch [5632/10000], Loss: 0.5607917308807373\n",
      "Epoch [5633/10000], Loss: 0.5607936382293701\n",
      "Epoch [5634/10000], Loss: 0.5607953071594238\n",
      "Epoch [5635/10000], Loss: 0.560796856880188\n",
      "Epoch [5636/10000], Loss: 0.5607978701591492\n",
      "Epoch [5637/10000], Loss: 0.5607983469963074\n",
      "Epoch [5638/10000], Loss: 0.5607988238334656\n",
      "Epoch [5639/10000], Loss: 0.5607997179031372\n",
      "Epoch [5640/10000], Loss: 0.5608001947402954\n",
      "Epoch [5641/10000], Loss: 0.5608008503913879\n",
      "Epoch [5642/10000], Loss: 0.5608014464378357\n",
      "Epoch [5643/10000], Loss: 0.5608020424842834\n",
      "Epoch [5644/10000], Loss: 0.5608016848564148\n",
      "Epoch [5645/10000], Loss: 0.5608008503913879\n",
      "Epoch [5646/10000], Loss: 0.560799777507782\n",
      "Epoch [5647/10000], Loss: 0.5607977509498596\n",
      "Epoch [5648/10000], Loss: 0.5607956051826477\n",
      "Epoch [5649/10000], Loss: 0.5607933402061462\n",
      "Epoch [5650/10000], Loss: 0.5607910752296448\n",
      "Epoch [5651/10000], Loss: 0.5607891082763672\n",
      "Epoch [5652/10000], Loss: 0.560787558555603\n",
      "Epoch [5653/10000], Loss: 0.5607873201370239\n",
      "Epoch [5654/10000], Loss: 0.5607873201370239\n",
      "Epoch [5655/10000], Loss: 0.5607874989509583\n",
      "Epoch [5656/10000], Loss: 0.560787558555603\n",
      "Epoch [5657/10000], Loss: 0.5607877969741821\n",
      "Epoch [5658/10000], Loss: 0.5607879757881165\n",
      "Epoch [5659/10000], Loss: 0.5607884526252747\n",
      "Epoch [5660/10000], Loss: 0.5607888102531433\n",
      "Epoch [5661/10000], Loss: 0.5607897043228149\n",
      "Epoch [5662/10000], Loss: 0.5607903003692627\n",
      "Epoch [5663/10000], Loss: 0.5607908368110657\n",
      "Epoch [5664/10000], Loss: 0.5607906579971313\n",
      "Epoch [5665/10000], Loss: 0.5607905387878418\n",
      "Epoch [5666/10000], Loss: 0.5607898235321045\n",
      "Epoch [5667/10000], Loss: 0.5607888698577881\n",
      "Epoch [5668/10000], Loss: 0.560788094997406\n",
      "Epoch [5669/10000], Loss: 0.560788094997406\n",
      "Epoch [5670/10000], Loss: 0.5607882142066956\n",
      "Epoch [5671/10000], Loss: 0.560789167881012\n",
      "Epoch [5672/10000], Loss: 0.5607901215553284\n",
      "Epoch [5673/10000], Loss: 0.5607913732528687\n",
      "Epoch [5674/10000], Loss: 0.5607921481132507\n",
      "Epoch [5675/10000], Loss: 0.560792863368988\n",
      "Epoch [5676/10000], Loss: 0.5607925653457642\n",
      "Epoch [5677/10000], Loss: 0.5607919096946716\n",
      "Epoch [5678/10000], Loss: 0.5607907176017761\n",
      "Epoch [5679/10000], Loss: 0.5607894062995911\n",
      "Epoch [5680/10000], Loss: 0.560788094997406\n",
      "Epoch [5681/10000], Loss: 0.5607873797416687\n",
      "Epoch [5682/10000], Loss: 0.5607872009277344\n",
      "Epoch [5683/10000], Loss: 0.5607869625091553\n",
      "Epoch [5684/10000], Loss: 0.5607872009277344\n",
      "Epoch [5685/10000], Loss: 0.5607874393463135\n",
      "Epoch [5686/10000], Loss: 0.5607879757881165\n",
      "Epoch [5687/10000], Loss: 0.5607885122299194\n",
      "Epoch [5688/10000], Loss: 0.5607893466949463\n",
      "Epoch [5689/10000], Loss: 0.5607898235321045\n",
      "Epoch [5690/10000], Loss: 0.5607905983924866\n",
      "Epoch [5691/10000], Loss: 0.5607912540435791\n",
      "Epoch [5692/10000], Loss: 0.5607919096946716\n",
      "Epoch [5693/10000], Loss: 0.5607917308807373\n",
      "Epoch [5694/10000], Loss: 0.5607914924621582\n",
      "Epoch [5695/10000], Loss: 0.5607917904853821\n",
      "Epoch [5696/10000], Loss: 0.5607920289039612\n",
      "Epoch [5697/10000], Loss: 0.560792863368988\n",
      "Epoch [5698/10000], Loss: 0.5607931613922119\n",
      "Epoch [5699/10000], Loss: 0.5607934594154358\n",
      "Epoch [5700/10000], Loss: 0.5607936978340149\n",
      "Epoch [5701/10000], Loss: 0.560793936252594\n",
      "Epoch [5702/10000], Loss: 0.5607934594154358\n",
      "Epoch [5703/10000], Loss: 0.5607931613922119\n",
      "Epoch [5704/10000], Loss: 0.5607924461364746\n",
      "Epoch [5705/10000], Loss: 0.5607919692993164\n",
      "Epoch [5706/10000], Loss: 0.5607916116714478\n",
      "Epoch [5707/10000], Loss: 0.5607920289039612\n",
      "Epoch [5708/10000], Loss: 0.560792863368988\n",
      "Epoch [5709/10000], Loss: 0.560793936252594\n",
      "Epoch [5710/10000], Loss: 0.5607945919036865\n",
      "Epoch [5711/10000], Loss: 0.5607940554618835\n",
      "Epoch [5712/10000], Loss: 0.5607925653457642\n",
      "Epoch [5713/10000], Loss: 0.5607901215553284\n",
      "Epoch [5714/10000], Loss: 0.5607876181602478\n",
      "Epoch [5715/10000], Loss: 0.5607860684394836\n",
      "Epoch [5716/10000], Loss: 0.5607854127883911\n",
      "Epoch [5717/10000], Loss: 0.5607855916023254\n",
      "Epoch [5718/10000], Loss: 0.5607860684394836\n",
      "Epoch [5719/10000], Loss: 0.5607866644859314\n",
      "Epoch [5720/10000], Loss: 0.5607873797416687\n",
      "Epoch [5721/10000], Loss: 0.560788094997406\n",
      "Epoch [5722/10000], Loss: 0.5607889294624329\n",
      "Epoch [5723/10000], Loss: 0.5607896447181702\n",
      "Epoch [5724/10000], Loss: 0.5607908368110657\n",
      "Epoch [5725/10000], Loss: 0.560791552066803\n",
      "Epoch [5726/10000], Loss: 0.5607922077178955\n",
      "Epoch [5727/10000], Loss: 0.5607922673225403\n",
      "Epoch [5728/10000], Loss: 0.5607919692993164\n",
      "Epoch [5729/10000], Loss: 0.5607918500900269\n",
      "Epoch [5730/10000], Loss: 0.5607912540435791\n",
      "Epoch [5731/10000], Loss: 0.5607905983924866\n",
      "Epoch [5732/10000], Loss: 0.5607894659042358\n",
      "Epoch [5733/10000], Loss: 0.5607883334159851\n",
      "Epoch [5734/10000], Loss: 0.5607870221138\n",
      "Epoch [5735/10000], Loss: 0.5607865452766418\n",
      "Epoch [5736/10000], Loss: 0.5607859492301941\n",
      "Epoch [5737/10000], Loss: 0.5607852935791016\n",
      "Epoch [5738/10000], Loss: 0.5607853531837463\n",
      "Epoch [5739/10000], Loss: 0.5607860088348389\n",
      "Epoch [5740/10000], Loss: 0.5607864856719971\n",
      "Epoch [5741/10000], Loss: 0.5607871413230896\n",
      "Epoch [5742/10000], Loss: 0.5607873797416687\n",
      "Epoch [5743/10000], Loss: 0.5607878565788269\n",
      "Epoch [5744/10000], Loss: 0.5607882142066956\n",
      "Epoch [5745/10000], Loss: 0.5607885718345642\n",
      "Epoch [5746/10000], Loss: 0.560788094997406\n",
      "Epoch [5747/10000], Loss: 0.560788094997406\n",
      "Epoch [5748/10000], Loss: 0.5607885718345642\n",
      "Epoch [5749/10000], Loss: 0.5607889294624329\n",
      "Epoch [5750/10000], Loss: 0.5607890486717224\n",
      "Epoch [5751/10000], Loss: 0.5607886910438538\n",
      "Epoch [5752/10000], Loss: 0.5607878565788269\n",
      "Epoch [5753/10000], Loss: 0.5607869029045105\n",
      "Epoch [5754/10000], Loss: 0.5607861280441284\n",
      "Epoch [5755/10000], Loss: 0.5607858896255493\n",
      "Epoch [5756/10000], Loss: 0.5607856512069702\n",
      "Epoch [5757/10000], Loss: 0.560785710811615\n",
      "Epoch [5758/10000], Loss: 0.560785710811615\n",
      "Epoch [5759/10000], Loss: 0.5607861876487732\n",
      "Epoch [5760/10000], Loss: 0.5607864260673523\n",
      "Epoch [5761/10000], Loss: 0.5607870817184448\n",
      "Epoch [5762/10000], Loss: 0.560788094997406\n",
      "Epoch [5763/10000], Loss: 0.5607891082763672\n",
      "Epoch [5764/10000], Loss: 0.5607901215553284\n",
      "Epoch [5765/10000], Loss: 0.5607916116714478\n",
      "Epoch [5766/10000], Loss: 0.5607940554618835\n",
      "Epoch [5767/10000], Loss: 0.5607959032058716\n",
      "Epoch [5768/10000], Loss: 0.5607985258102417\n",
      "Epoch [5769/10000], Loss: 0.5608002543449402\n",
      "Epoch [5770/10000], Loss: 0.5608002543449402\n",
      "Epoch [5771/10000], Loss: 0.5607995986938477\n",
      "Epoch [5772/10000], Loss: 0.5607978701591492\n",
      "Epoch [5773/10000], Loss: 0.5607955455780029\n",
      "Epoch [5774/10000], Loss: 0.5607923269271851\n",
      "Epoch [5775/10000], Loss: 0.5607897639274597\n",
      "Epoch [5776/10000], Loss: 0.5607876181602478\n",
      "Epoch [5777/10000], Loss: 0.5607858896255493\n",
      "Epoch [5778/10000], Loss: 0.5607853531837463\n",
      "Epoch [5779/10000], Loss: 0.5607858300209045\n",
      "Epoch [5780/10000], Loss: 0.5607868432998657\n",
      "Epoch [5781/10000], Loss: 0.5607882142066956\n",
      "Epoch [5782/10000], Loss: 0.5607896447181702\n",
      "Epoch [5783/10000], Loss: 0.5607900619506836\n",
      "Epoch [5784/10000], Loss: 0.5607898235321045\n",
      "Epoch [5785/10000], Loss: 0.5607889890670776\n",
      "Epoch [5786/10000], Loss: 0.5607876181602478\n",
      "Epoch [5787/10000], Loss: 0.5607863068580627\n",
      "Epoch [5788/10000], Loss: 0.5607854723930359\n",
      "Epoch [5789/10000], Loss: 0.5607849955558777\n",
      "Epoch [5790/10000], Loss: 0.5607843399047852\n",
      "Epoch [5791/10000], Loss: 0.5607844591140747\n",
      "Epoch [5792/10000], Loss: 0.5607842803001404\n",
      "Epoch [5793/10000], Loss: 0.5607843399047852\n",
      "Epoch [5794/10000], Loss: 0.560784101486206\n",
      "Epoch [5795/10000], Loss: 0.5607842206954956\n",
      "Epoch [5796/10000], Loss: 0.5607842206954956\n",
      "Epoch [5797/10000], Loss: 0.5607842206954956\n",
      "Epoch [5798/10000], Loss: 0.5607843995094299\n",
      "Epoch [5799/10000], Loss: 0.5607847571372986\n",
      "Epoch [5800/10000], Loss: 0.560784637928009\n",
      "Epoch [5801/10000], Loss: 0.560784637928009\n",
      "Epoch [5802/10000], Loss: 0.5607852935791016\n",
      "Epoch [5803/10000], Loss: 0.5607863068580627\n",
      "Epoch [5804/10000], Loss: 0.5607869029045105\n",
      "Epoch [5805/10000], Loss: 0.5607885122299194\n",
      "Epoch [5806/10000], Loss: 0.560789942741394\n",
      "Epoch [5807/10000], Loss: 0.5607912540435791\n",
      "Epoch [5808/10000], Loss: 0.5607928037643433\n",
      "Epoch [5809/10000], Loss: 0.5607935786247253\n",
      "Epoch [5810/10000], Loss: 0.5607933402061462\n",
      "Epoch [5811/10000], Loss: 0.5607926249504089\n",
      "Epoch [5812/10000], Loss: 0.5607919692993164\n",
      "Epoch [5813/10000], Loss: 0.5607907772064209\n",
      "Epoch [5814/10000], Loss: 0.5607901215553284\n",
      "Epoch [5815/10000], Loss: 0.5607900619506836\n",
      "Epoch [5816/10000], Loss: 0.5607903003692627\n",
      "Epoch [5817/10000], Loss: 0.560790479183197\n",
      "Epoch [5818/10000], Loss: 0.5607905983924866\n",
      "Epoch [5819/10000], Loss: 0.560791015625\n",
      "Epoch [5820/10000], Loss: 0.5607906579971313\n",
      "Epoch [5821/10000], Loss: 0.5607901215553284\n",
      "Epoch [5822/10000], Loss: 0.5607896447181702\n",
      "Epoch [5823/10000], Loss: 0.5607886910438538\n",
      "Epoch [5824/10000], Loss: 0.5607874393463135\n",
      "Epoch [5825/10000], Loss: 0.5607864260673523\n",
      "Epoch [5826/10000], Loss: 0.5607852339744568\n",
      "Epoch [5827/10000], Loss: 0.5607843399047852\n",
      "Epoch [5828/10000], Loss: 0.560783863067627\n",
      "Epoch [5829/10000], Loss: 0.5607836246490479\n",
      "Epoch [5830/10000], Loss: 0.5607833862304688\n",
      "Epoch [5831/10000], Loss: 0.560783863067627\n",
      "Epoch [5832/10000], Loss: 0.5607844591140747\n",
      "Epoch [5833/10000], Loss: 0.5607848167419434\n",
      "Epoch [5834/10000], Loss: 0.5607857704162598\n",
      "Epoch [5835/10000], Loss: 0.5607872605323792\n",
      "Epoch [5836/10000], Loss: 0.5607886910438538\n",
      "Epoch [5837/10000], Loss: 0.5607898831367493\n",
      "Epoch [5838/10000], Loss: 0.5607913136482239\n",
      "Epoch [5839/10000], Loss: 0.5607918500900269\n",
      "Epoch [5840/10000], Loss: 0.5607914328575134\n",
      "Epoch [5841/10000], Loss: 0.5607898831367493\n",
      "Epoch [5842/10000], Loss: 0.5607883334159851\n",
      "Epoch [5843/10000], Loss: 0.5607867240905762\n",
      "Epoch [5844/10000], Loss: 0.5607855916023254\n",
      "Epoch [5845/10000], Loss: 0.5607851147651672\n",
      "Epoch [5846/10000], Loss: 0.560785174369812\n",
      "Epoch [5847/10000], Loss: 0.5607861876487732\n",
      "Epoch [5848/10000], Loss: 0.5607873797416687\n",
      "Epoch [5849/10000], Loss: 0.5607894659042358\n",
      "Epoch [5850/10000], Loss: 0.5607914328575134\n",
      "Epoch [5851/10000], Loss: 0.5607925057411194\n",
      "Epoch [5852/10000], Loss: 0.5607924461364746\n",
      "Epoch [5853/10000], Loss: 0.5607914328575134\n",
      "Epoch [5854/10000], Loss: 0.5607896447181702\n",
      "Epoch [5855/10000], Loss: 0.5607877969741821\n",
      "Epoch [5856/10000], Loss: 0.5607865452766418\n",
      "Epoch [5857/10000], Loss: 0.5607854127883911\n",
      "Epoch [5858/10000], Loss: 0.5607849955558777\n",
      "Epoch [5859/10000], Loss: 0.5607852339744568\n",
      "Epoch [5860/10000], Loss: 0.5607859492301941\n",
      "Epoch [5861/10000], Loss: 0.5607872009277344\n",
      "Epoch [5862/10000], Loss: 0.5607886910438538\n",
      "Epoch [5863/10000], Loss: 0.5607901811599731\n",
      "Epoch [5864/10000], Loss: 0.5607914924621582\n",
      "Epoch [5865/10000], Loss: 0.5607919096946716\n",
      "Epoch [5866/10000], Loss: 0.5607919692993164\n",
      "Epoch [5867/10000], Loss: 0.5607910752296448\n",
      "Epoch [5868/10000], Loss: 0.5607898831367493\n",
      "Epoch [5869/10000], Loss: 0.5607883334159851\n",
      "Epoch [5870/10000], Loss: 0.5607870817184448\n",
      "Epoch [5871/10000], Loss: 0.5607866644859314\n",
      "Epoch [5872/10000], Loss: 0.5607869625091553\n",
      "Epoch [5873/10000], Loss: 0.560787558555603\n",
      "Epoch [5874/10000], Loss: 0.5607882738113403\n",
      "Epoch [5875/10000], Loss: 0.560789167881012\n",
      "Epoch [5876/10000], Loss: 0.5607896447181702\n",
      "Epoch [5877/10000], Loss: 0.560789167881012\n",
      "Epoch [5878/10000], Loss: 0.5607884526252747\n",
      "Epoch [5879/10000], Loss: 0.560787558555603\n",
      "Epoch [5880/10000], Loss: 0.5607864856719971\n",
      "Epoch [5881/10000], Loss: 0.5607854127883911\n",
      "Epoch [5882/10000], Loss: 0.5607849359512329\n",
      "Epoch [5883/10000], Loss: 0.5607844591140747\n",
      "Epoch [5884/10000], Loss: 0.5607840418815613\n",
      "Epoch [5885/10000], Loss: 0.5607839822769165\n",
      "Epoch [5886/10000], Loss: 0.5607847571372986\n",
      "Epoch [5887/10000], Loss: 0.5607854127883911\n",
      "Epoch [5888/10000], Loss: 0.5607869029045105\n",
      "Epoch [5889/10000], Loss: 0.5607881546020508\n",
      "Epoch [5890/10000], Loss: 0.5607889294624329\n",
      "Epoch [5891/10000], Loss: 0.5607892274856567\n",
      "Epoch [5892/10000], Loss: 0.5607892870903015\n",
      "Epoch [5893/10000], Loss: 0.5607889294624329\n",
      "Epoch [5894/10000], Loss: 0.5607882738113403\n",
      "Epoch [5895/10000], Loss: 0.5607870817184448\n",
      "Epoch [5896/10000], Loss: 0.5607861280441284\n",
      "Epoch [5897/10000], Loss: 0.5607856512069702\n",
      "Epoch [5898/10000], Loss: 0.5607854723930359\n",
      "Epoch [5899/10000], Loss: 0.5607854127883911\n",
      "Epoch [5900/10000], Loss: 0.5607855916023254\n",
      "Epoch [5901/10000], Loss: 0.5607865452766418\n",
      "Epoch [5902/10000], Loss: 0.5607869029045105\n",
      "Epoch [5903/10000], Loss: 0.5607877969741821\n",
      "Epoch [5904/10000], Loss: 0.560788631439209\n",
      "Epoch [5905/10000], Loss: 0.5607889294624329\n",
      "Epoch [5906/10000], Loss: 0.5607895255088806\n",
      "Epoch [5907/10000], Loss: 0.560789942741394\n",
      "Epoch [5908/10000], Loss: 0.5607902407646179\n",
      "Epoch [5909/10000], Loss: 0.5607904195785522\n",
      "Epoch [5910/10000], Loss: 0.5607898235321045\n",
      "Epoch [5911/10000], Loss: 0.5607896447181702\n",
      "Epoch [5912/10000], Loss: 0.5607894062995911\n",
      "Epoch [5913/10000], Loss: 0.560789167881012\n",
      "Epoch [5914/10000], Loss: 0.5607887506484985\n",
      "Epoch [5915/10000], Loss: 0.5607878565788269\n",
      "Epoch [5916/10000], Loss: 0.5607871413230896\n",
      "Epoch [5917/10000], Loss: 0.5607863068580627\n",
      "Epoch [5918/10000], Loss: 0.5607858300209045\n",
      "Epoch [5919/10000], Loss: 0.5607848167419434\n",
      "Epoch [5920/10000], Loss: 0.5607843399047852\n",
      "Epoch [5921/10000], Loss: 0.560784637928009\n",
      "Epoch [5922/10000], Loss: 0.5607846975326538\n",
      "Epoch [5923/10000], Loss: 0.5607850551605225\n",
      "Epoch [5924/10000], Loss: 0.560785174369812\n",
      "Epoch [5925/10000], Loss: 0.5607852935791016\n",
      "Epoch [5926/10000], Loss: 0.5607855916023254\n",
      "Epoch [5927/10000], Loss: 0.5607854127883911\n",
      "Epoch [5928/10000], Loss: 0.5607851147651672\n",
      "Epoch [5929/10000], Loss: 0.5607843399047852\n",
      "Epoch [5930/10000], Loss: 0.560783863067627\n",
      "Epoch [5931/10000], Loss: 0.560783326625824\n",
      "Epoch [5932/10000], Loss: 0.5607825517654419\n",
      "Epoch [5933/10000], Loss: 0.5607821941375732\n",
      "Epoch [5934/10000], Loss: 0.5607823133468628\n",
      "Epoch [5935/10000], Loss: 0.5607823133468628\n",
      "Epoch [5936/10000], Loss: 0.5607826113700867\n",
      "Epoch [5937/10000], Loss: 0.5607831478118896\n",
      "Epoch [5938/10000], Loss: 0.5607835650444031\n",
      "Epoch [5939/10000], Loss: 0.5607843995094299\n",
      "Epoch [5940/10000], Loss: 0.560785174369812\n",
      "Epoch [5941/10000], Loss: 0.5607865452766418\n",
      "Epoch [5942/10000], Loss: 0.5607879757881165\n",
      "Epoch [5943/10000], Loss: 0.5607890486717224\n",
      "Epoch [5944/10000], Loss: 0.5607902407646179\n",
      "Epoch [5945/10000], Loss: 0.5607914924621582\n",
      "Epoch [5946/10000], Loss: 0.5607929825782776\n",
      "Epoch [5947/10000], Loss: 0.5607936978340149\n",
      "Epoch [5948/10000], Loss: 0.5607940554618835\n",
      "Epoch [5949/10000], Loss: 0.5607932209968567\n",
      "Epoch [5950/10000], Loss: 0.560791552066803\n",
      "Epoch [5951/10000], Loss: 0.5607898831367493\n",
      "Epoch [5952/10000], Loss: 0.5607879757881165\n",
      "Epoch [5953/10000], Loss: 0.5607863068580627\n",
      "Epoch [5954/10000], Loss: 0.5607848167419434\n",
      "Epoch [5955/10000], Loss: 0.5607845187187195\n",
      "Epoch [5956/10000], Loss: 0.5607844591140747\n",
      "Epoch [5957/10000], Loss: 0.560784637928009\n",
      "Epoch [5958/10000], Loss: 0.5607848763465881\n",
      "Epoch [5959/10000], Loss: 0.5607847571372986\n",
      "Epoch [5960/10000], Loss: 0.5607847571372986\n",
      "Epoch [5961/10000], Loss: 0.5607848167419434\n",
      "Epoch [5962/10000], Loss: 0.5607843399047852\n",
      "Epoch [5963/10000], Loss: 0.5607835650444031\n",
      "Epoch [5964/10000], Loss: 0.5607829093933105\n",
      "Epoch [5965/10000], Loss: 0.5607825517654419\n",
      "Epoch [5966/10000], Loss: 0.5607820153236389\n",
      "Epoch [5967/10000], Loss: 0.5607816576957703\n",
      "Epoch [5968/10000], Loss: 0.5607821345329285\n",
      "Epoch [5969/10000], Loss: 0.5607823729515076\n",
      "Epoch [5970/10000], Loss: 0.5607824921607971\n",
      "Epoch [5971/10000], Loss: 0.5607831478118896\n",
      "Epoch [5972/10000], Loss: 0.5607844591140747\n",
      "Epoch [5973/10000], Loss: 0.5607852935791016\n",
      "Epoch [5974/10000], Loss: 0.5607861876487732\n",
      "Epoch [5975/10000], Loss: 0.5607873201370239\n",
      "Epoch [5976/10000], Loss: 0.5607873797416687\n",
      "Epoch [5977/10000], Loss: 0.5607870817184448\n",
      "Epoch [5978/10000], Loss: 0.5607861280441284\n",
      "Epoch [5979/10000], Loss: 0.5607848167419434\n",
      "Epoch [5980/10000], Loss: 0.5607838034629822\n",
      "Epoch [5981/10000], Loss: 0.5607830882072449\n",
      "Epoch [5982/10000], Loss: 0.5607830286026001\n",
      "Epoch [5983/10000], Loss: 0.560784101486206\n",
      "Epoch [5984/10000], Loss: 0.5607855319976807\n",
      "Epoch [5985/10000], Loss: 0.5607873797416687\n",
      "Epoch [5986/10000], Loss: 0.560788631439209\n",
      "Epoch [5987/10000], Loss: 0.5607885718345642\n",
      "Epoch [5988/10000], Loss: 0.5607879757881165\n",
      "Epoch [5989/10000], Loss: 0.5607869625091553\n",
      "Epoch [5990/10000], Loss: 0.5607852935791016\n",
      "Epoch [5991/10000], Loss: 0.5607838034629822\n",
      "Epoch [5992/10000], Loss: 0.5607829689979553\n",
      "Epoch [5993/10000], Loss: 0.5607828497886658\n",
      "Epoch [5994/10000], Loss: 0.5607831478118896\n",
      "Epoch [5995/10000], Loss: 0.5607840418815613\n",
      "Epoch [5996/10000], Loss: 0.5607852339744568\n",
      "Epoch [5997/10000], Loss: 0.5607863068580627\n",
      "Epoch [5998/10000], Loss: 0.5607869029045105\n",
      "Epoch [5999/10000], Loss: 0.5607864856719971\n",
      "Epoch [6000/10000], Loss: 0.560786247253418\n",
      "Epoch [6001/10000], Loss: 0.5607860088348389\n",
      "Epoch [6002/10000], Loss: 0.5607853531837463\n",
      "Epoch [6003/10000], Loss: 0.5607849955558777\n",
      "Epoch [6004/10000], Loss: 0.5607845783233643\n",
      "Epoch [6005/10000], Loss: 0.5607844591140747\n",
      "Epoch [6006/10000], Loss: 0.5607847571372986\n",
      "Epoch [6007/10000], Loss: 0.5607853531837463\n",
      "Epoch [6008/10000], Loss: 0.5607855916023254\n",
      "Epoch [6009/10000], Loss: 0.5607855916023254\n",
      "Epoch [6010/10000], Loss: 0.5607859492301941\n",
      "Epoch [6011/10000], Loss: 0.5607858300209045\n",
      "Epoch [6012/10000], Loss: 0.560785710811615\n",
      "Epoch [6013/10000], Loss: 0.560785174369812\n",
      "Epoch [6014/10000], Loss: 0.560784637928009\n",
      "Epoch [6015/10000], Loss: 0.5607841610908508\n",
      "Epoch [6016/10000], Loss: 0.5607837438583374\n",
      "Epoch [6017/10000], Loss: 0.560783326625824\n",
      "Epoch [6018/10000], Loss: 0.5607831478118896\n",
      "Epoch [6019/10000], Loss: 0.5607832670211792\n",
      "Epoch [6020/10000], Loss: 0.560784101486206\n",
      "Epoch [6021/10000], Loss: 0.5607852339744568\n",
      "Epoch [6022/10000], Loss: 0.5607858896255493\n",
      "Epoch [6023/10000], Loss: 0.5607861876487732\n",
      "Epoch [6024/10000], Loss: 0.5607855319976807\n",
      "Epoch [6025/10000], Loss: 0.5607844591140747\n",
      "Epoch [6026/10000], Loss: 0.5607829689979553\n",
      "Epoch [6027/10000], Loss: 0.5607814192771912\n",
      "Epoch [6028/10000], Loss: 0.5607801079750061\n",
      "Epoch [6029/10000], Loss: 0.5607796311378479\n",
      "Epoch [6030/10000], Loss: 0.560779333114624\n",
      "Epoch [6031/10000], Loss: 0.5607789158821106\n",
      "Epoch [6032/10000], Loss: 0.5607796311378479\n",
      "Epoch [6033/10000], Loss: 0.5607807636260986\n",
      "Epoch [6034/10000], Loss: 0.5607816576957703\n",
      "Epoch [6035/10000], Loss: 0.5607823729515076\n",
      "Epoch [6036/10000], Loss: 0.5607826709747314\n",
      "Epoch [6037/10000], Loss: 0.5607825517654419\n",
      "Epoch [6038/10000], Loss: 0.5607818365097046\n",
      "Epoch [6039/10000], Loss: 0.5607811212539673\n",
      "Epoch [6040/10000], Loss: 0.5607807636260986\n",
      "Epoch [6041/10000], Loss: 0.5607808232307434\n",
      "Epoch [6042/10000], Loss: 0.5607810616493225\n",
      "Epoch [6043/10000], Loss: 0.5607821941375732\n",
      "Epoch [6044/10000], Loss: 0.5607836246490479\n",
      "Epoch [6045/10000], Loss: 0.5607855319976807\n",
      "Epoch [6046/10000], Loss: 0.5607874989509583\n",
      "Epoch [6047/10000], Loss: 0.5607897043228149\n",
      "Epoch [6048/10000], Loss: 0.5607916116714478\n",
      "Epoch [6049/10000], Loss: 0.5607932209968567\n",
      "Epoch [6050/10000], Loss: 0.5607945919036865\n",
      "Epoch [6051/10000], Loss: 0.5607946515083313\n",
      "Epoch [6052/10000], Loss: 0.5607936978340149\n",
      "Epoch [6053/10000], Loss: 0.5607917308807373\n",
      "Epoch [6054/10000], Loss: 0.5607896447181702\n",
      "Epoch [6055/10000], Loss: 0.5607872009277344\n",
      "Epoch [6056/10000], Loss: 0.5607844591140747\n",
      "Epoch [6057/10000], Loss: 0.5607826113700867\n",
      "Epoch [6058/10000], Loss: 0.5607808232307434\n",
      "Epoch [6059/10000], Loss: 0.5607797503471375\n",
      "Epoch [6060/10000], Loss: 0.5607790350914001\n",
      "Epoch [6061/10000], Loss: 0.5607781410217285\n",
      "Epoch [6062/10000], Loss: 0.5607775449752808\n",
      "Epoch [6063/10000], Loss: 0.5607771873474121\n",
      "Epoch [6064/10000], Loss: 0.560777485370636\n",
      "Epoch [6065/10000], Loss: 0.5607773661613464\n",
      "Epoch [6066/10000], Loss: 0.5607777833938599\n",
      "Epoch [6067/10000], Loss: 0.5607786774635315\n",
      "Epoch [6068/10000], Loss: 0.5607796907424927\n",
      "Epoch [6069/10000], Loss: 0.5607815384864807\n",
      "Epoch [6070/10000], Loss: 0.560783326625824\n",
      "Epoch [6071/10000], Loss: 0.5607852935791016\n",
      "Epoch [6072/10000], Loss: 0.5607868432998657\n",
      "Epoch [6073/10000], Loss: 0.5607876181602478\n",
      "Epoch [6074/10000], Loss: 0.5607868432998657\n",
      "Epoch [6075/10000], Loss: 0.5607845783233643\n",
      "Epoch [6076/10000], Loss: 0.5607818961143494\n",
      "Epoch [6077/10000], Loss: 0.5607791543006897\n",
      "Epoch [6078/10000], Loss: 0.5607773065567017\n",
      "Epoch [6079/10000], Loss: 0.5607770681381226\n",
      "Epoch [6080/10000], Loss: 0.5607767105102539\n",
      "Epoch [6081/10000], Loss: 0.5607770681381226\n",
      "Epoch [6082/10000], Loss: 0.5607783794403076\n",
      "Epoch [6083/10000], Loss: 0.5607796311378479\n",
      "Epoch [6084/10000], Loss: 0.5607811808586121\n",
      "Epoch [6085/10000], Loss: 0.5607826709747314\n",
      "Epoch [6086/10000], Loss: 0.5607845783233643\n",
      "Epoch [6087/10000], Loss: 0.5607857704162598\n",
      "Epoch [6088/10000], Loss: 0.5607863068580627\n",
      "Epoch [6089/10000], Loss: 0.5607852339744568\n",
      "Epoch [6090/10000], Loss: 0.560783326625824\n",
      "Epoch [6091/10000], Loss: 0.5607808232307434\n",
      "Epoch [6092/10000], Loss: 0.5607791543006897\n",
      "Epoch [6093/10000], Loss: 0.5607779622077942\n",
      "Epoch [6094/10000], Loss: 0.5607780814170837\n",
      "Epoch [6095/10000], Loss: 0.5607790946960449\n",
      "Epoch [6096/10000], Loss: 0.5607801675796509\n",
      "Epoch [6097/10000], Loss: 0.5607823133468628\n",
      "Epoch [6098/10000], Loss: 0.5607831478118896\n",
      "Epoch [6099/10000], Loss: 0.5607828497886658\n",
      "Epoch [6100/10000], Loss: 0.5607814192771912\n",
      "Epoch [6101/10000], Loss: 0.5607797503471375\n",
      "Epoch [6102/10000], Loss: 0.5607782602310181\n",
      "Epoch [6103/10000], Loss: 0.5607772469520569\n",
      "Epoch [6104/10000], Loss: 0.5607770681381226\n",
      "Epoch [6105/10000], Loss: 0.5607770681381226\n",
      "Epoch [6106/10000], Loss: 0.5607773065567017\n",
      "Epoch [6107/10000], Loss: 0.5607785582542419\n",
      "Epoch [6108/10000], Loss: 0.560779869556427\n",
      "Epoch [6109/10000], Loss: 0.5607810020446777\n",
      "Epoch [6110/10000], Loss: 0.5607821941375732\n",
      "Epoch [6111/10000], Loss: 0.5607828497886658\n",
      "Epoch [6112/10000], Loss: 0.5607831478118896\n",
      "Epoch [6113/10000], Loss: 0.5607824325561523\n",
      "Epoch [6114/10000], Loss: 0.5607813596725464\n",
      "Epoch [6115/10000], Loss: 0.5607802867889404\n",
      "Epoch [6116/10000], Loss: 0.5607799291610718\n",
      "Epoch [6117/10000], Loss: 0.5607803463935852\n",
      "Epoch [6118/10000], Loss: 0.5607821345329285\n",
      "Epoch [6119/10000], Loss: 0.5607845783233643\n",
      "Epoch [6120/10000], Loss: 0.5607883930206299\n",
      "Epoch [6121/10000], Loss: 0.5607930421829224\n",
      "Epoch [6122/10000], Loss: 0.5607990622520447\n",
      "Epoch [6123/10000], Loss: 0.5608053207397461\n",
      "Epoch [6124/10000], Loss: 0.5608115792274475\n",
      "Epoch [6125/10000], Loss: 0.5608165264129639\n",
      "Epoch [6126/10000], Loss: 0.5608168840408325\n",
      "Epoch [6127/10000], Loss: 0.5608132481575012\n",
      "Epoch [6128/10000], Loss: 0.5608044266700745\n",
      "Epoch [6129/10000], Loss: 0.5607935786247253\n",
      "Epoch [6130/10000], Loss: 0.5607840418815613\n",
      "Epoch [6131/10000], Loss: 0.5607783794403076\n",
      "Epoch [6132/10000], Loss: 0.5607775449752808\n",
      "Epoch [6133/10000], Loss: 0.56078040599823\n",
      "Epoch [6134/10000], Loss: 0.5607845783233643\n",
      "Epoch [6135/10000], Loss: 0.560788094997406\n",
      "Epoch [6136/10000], Loss: 0.5607901811599731\n",
      "Epoch [6137/10000], Loss: 0.5607901811599731\n",
      "Epoch [6138/10000], Loss: 0.5607877969741821\n",
      "Epoch [6139/10000], Loss: 0.5607848167419434\n",
      "Epoch [6140/10000], Loss: 0.5607814788818359\n",
      "Epoch [6141/10000], Loss: 0.5607790350914001\n",
      "Epoch [6142/10000], Loss: 0.5607777237892151\n",
      "Epoch [6143/10000], Loss: 0.5607773065567017\n",
      "Epoch [6144/10000], Loss: 0.5607783198356628\n",
      "Epoch [6145/10000], Loss: 0.5607795715332031\n",
      "Epoch [6146/10000], Loss: 0.5607803463935852\n",
      "Epoch [6147/10000], Loss: 0.5607813000679016\n",
      "Epoch [6148/10000], Loss: 0.5607816576957703\n",
      "Epoch [6149/10000], Loss: 0.5607814788818359\n",
      "Epoch [6150/10000], Loss: 0.5607805252075195\n",
      "Epoch [6151/10000], Loss: 0.560778796672821\n",
      "Epoch [6152/10000], Loss: 0.5607774257659912\n",
      "Epoch [6153/10000], Loss: 0.5607765913009644\n",
      "Epoch [6154/10000], Loss: 0.5607759952545166\n",
      "Epoch [6155/10000], Loss: 0.5607759356498718\n",
      "Epoch [6156/10000], Loss: 0.5607762932777405\n",
      "Epoch [6157/10000], Loss: 0.560776948928833\n",
      "Epoch [6158/10000], Loss: 0.5607779026031494\n",
      "Epoch [6159/10000], Loss: 0.560779333114624\n",
      "Epoch [6160/10000], Loss: 0.5607800483703613\n",
      "Epoch [6161/10000], Loss: 0.5607801079750061\n",
      "Epoch [6162/10000], Loss: 0.560779869556427\n",
      "Epoch [6163/10000], Loss: 0.5607790946960449\n",
      "Epoch [6164/10000], Loss: 0.5607775449752808\n",
      "Epoch [6165/10000], Loss: 0.56077641248703\n",
      "Epoch [6166/10000], Loss: 0.5607755184173584\n",
      "Epoch [6167/10000], Loss: 0.5607750415802002\n",
      "Epoch [6168/10000], Loss: 0.5607752799987793\n",
      "Epoch [6169/10000], Loss: 0.5607753396034241\n",
      "Epoch [6170/10000], Loss: 0.560775637626648\n",
      "Epoch [6171/10000], Loss: 0.5607761740684509\n",
      "Epoch [6172/10000], Loss: 0.5607772469520569\n",
      "Epoch [6173/10000], Loss: 0.5607781410217285\n",
      "Epoch [6174/10000], Loss: 0.5607796907424927\n",
      "Epoch [6175/10000], Loss: 0.5607815384864807\n",
      "Epoch [6176/10000], Loss: 0.5607833862304688\n",
      "Epoch [6177/10000], Loss: 0.5607846975326538\n",
      "Epoch [6178/10000], Loss: 0.5607843399047852\n",
      "Epoch [6179/10000], Loss: 0.5607830286026001\n",
      "Epoch [6180/10000], Loss: 0.5607810020446777\n",
      "Epoch [6181/10000], Loss: 0.5607792139053345\n",
      "Epoch [6182/10000], Loss: 0.5607783198356628\n",
      "Epoch [6183/10000], Loss: 0.5607779622077942\n",
      "Epoch [6184/10000], Loss: 0.5607777237892151\n",
      "Epoch [6185/10000], Loss: 0.5607781410217285\n",
      "Epoch [6186/10000], Loss: 0.5607783794403076\n",
      "Epoch [6187/10000], Loss: 0.5607787370681763\n",
      "Epoch [6188/10000], Loss: 0.5607791543006897\n",
      "Epoch [6189/10000], Loss: 0.5607796311378479\n",
      "Epoch [6190/10000], Loss: 0.5607790946960449\n",
      "Epoch [6191/10000], Loss: 0.5607784986495972\n",
      "Epoch [6192/10000], Loss: 0.5607779622077942\n",
      "Epoch [6193/10000], Loss: 0.5607776045799255\n",
      "Epoch [6194/10000], Loss: 0.5607779622077942\n",
      "Epoch [6195/10000], Loss: 0.5607781410217285\n",
      "Epoch [6196/10000], Loss: 0.5607782602310181\n",
      "Epoch [6197/10000], Loss: 0.5607783198356628\n",
      "Epoch [6198/10000], Loss: 0.5607782602310181\n",
      "Epoch [6199/10000], Loss: 0.5607783794403076\n",
      "Epoch [6200/10000], Loss: 0.5607784390449524\n",
      "Epoch [6201/10000], Loss: 0.5607784390449524\n",
      "Epoch [6202/10000], Loss: 0.5607785582542419\n",
      "Epoch [6203/10000], Loss: 0.5607786178588867\n",
      "Epoch [6204/10000], Loss: 0.5607789158821106\n",
      "Epoch [6205/10000], Loss: 0.560779333114624\n",
      "Epoch [6206/10000], Loss: 0.5607796311378479\n",
      "Epoch [6207/10000], Loss: 0.5607800483703613\n",
      "Epoch [6208/10000], Loss: 0.5607807636260986\n",
      "Epoch [6209/10000], Loss: 0.5607815384864807\n",
      "Epoch [6210/10000], Loss: 0.5607816576957703\n",
      "Epoch [6211/10000], Loss: 0.5607811808586121\n",
      "Epoch [6212/10000], Loss: 0.5607805848121643\n",
      "Epoch [6213/10000], Loss: 0.5607794523239136\n",
      "Epoch [6214/10000], Loss: 0.5607782006263733\n",
      "Epoch [6215/10000], Loss: 0.5607774257659912\n",
      "Epoch [6216/10000], Loss: 0.5607768297195435\n",
      "Epoch [6217/10000], Loss: 0.5607764720916748\n",
      "Epoch [6218/10000], Loss: 0.5607761740684509\n",
      "Epoch [6219/10000], Loss: 0.5607761740684509\n",
      "Epoch [6220/10000], Loss: 0.5607760548591614\n",
      "Epoch [6221/10000], Loss: 0.5607762336730957\n",
      "Epoch [6222/10000], Loss: 0.5607765316963196\n",
      "Epoch [6223/10000], Loss: 0.5607770681381226\n",
      "Epoch [6224/10000], Loss: 0.5607780814170837\n",
      "Epoch [6225/10000], Loss: 0.5607789754867554\n",
      "Epoch [6226/10000], Loss: 0.5607799887657166\n",
      "Epoch [6227/10000], Loss: 0.5607807040214539\n",
      "Epoch [6228/10000], Loss: 0.5607811212539673\n",
      "Epoch [6229/10000], Loss: 0.5607808232307434\n",
      "Epoch [6230/10000], Loss: 0.5607801079750061\n",
      "Epoch [6231/10000], Loss: 0.5607792735099792\n",
      "Epoch [6232/10000], Loss: 0.5607782602310181\n",
      "Epoch [6233/10000], Loss: 0.5607776045799255\n",
      "Epoch [6234/10000], Loss: 0.5607775449752808\n",
      "Epoch [6235/10000], Loss: 0.5607775449752808\n",
      "Epoch [6236/10000], Loss: 0.5607777237892151\n",
      "Epoch [6237/10000], Loss: 0.5607781410217285\n",
      "Epoch [6238/10000], Loss: 0.5607786774635315\n",
      "Epoch [6239/10000], Loss: 0.5607795715332031\n",
      "Epoch [6240/10000], Loss: 0.5607804656028748\n",
      "Epoch [6241/10000], Loss: 0.5607810020446777\n",
      "Epoch [6242/10000], Loss: 0.5607820153236389\n",
      "Epoch [6243/10000], Loss: 0.560782790184021\n",
      "Epoch [6244/10000], Loss: 0.5607828497886658\n",
      "Epoch [6245/10000], Loss: 0.5607829093933105\n",
      "Epoch [6246/10000], Loss: 0.5607829689979553\n",
      "Epoch [6247/10000], Loss: 0.5607823729515076\n",
      "Epoch [6248/10000], Loss: 0.5607816576957703\n",
      "Epoch [6249/10000], Loss: 0.5607811808586121\n",
      "Epoch [6250/10000], Loss: 0.5607801079750061\n",
      "Epoch [6251/10000], Loss: 0.5607792735099792\n",
      "Epoch [6252/10000], Loss: 0.5607785582542419\n",
      "Epoch [6253/10000], Loss: 0.5607782006263733\n",
      "Epoch [6254/10000], Loss: 0.5607776641845703\n",
      "Epoch [6255/10000], Loss: 0.560777485370636\n",
      "Epoch [6256/10000], Loss: 0.5607772469520569\n",
      "Epoch [6257/10000], Loss: 0.560777485370636\n",
      "Epoch [6258/10000], Loss: 0.560778021812439\n",
      "Epoch [6259/10000], Loss: 0.5607790350914001\n",
      "Epoch [6260/10000], Loss: 0.5607797503471375\n",
      "Epoch [6261/10000], Loss: 0.5607802867889404\n",
      "Epoch [6262/10000], Loss: 0.5607802867889404\n",
      "Epoch [6263/10000], Loss: 0.5607796311378479\n",
      "Epoch [6264/10000], Loss: 0.560778796672821\n",
      "Epoch [6265/10000], Loss: 0.5607774257659912\n",
      "Epoch [6266/10000], Loss: 0.5607768297195435\n",
      "Epoch [6267/10000], Loss: 0.5607763528823853\n",
      "Epoch [6268/10000], Loss: 0.560775637626648\n",
      "Epoch [6269/10000], Loss: 0.5607751607894897\n",
      "Epoch [6270/10000], Loss: 0.5607749223709106\n",
      "Epoch [6271/10000], Loss: 0.5607749819755554\n",
      "Epoch [6272/10000], Loss: 0.5607751607894897\n",
      "Epoch [6273/10000], Loss: 0.5607753992080688\n",
      "Epoch [6274/10000], Loss: 0.5607758164405823\n",
      "Epoch [6275/10000], Loss: 0.5607762932777405\n",
      "Epoch [6276/10000], Loss: 0.5607767701148987\n",
      "Epoch [6277/10000], Loss: 0.5607779026031494\n",
      "Epoch [6278/10000], Loss: 0.5607786774635315\n",
      "Epoch [6279/10000], Loss: 0.5607793927192688\n",
      "Epoch [6280/10000], Loss: 0.5607801079750061\n",
      "Epoch [6281/10000], Loss: 0.5607812404632568\n",
      "Epoch [6282/10000], Loss: 0.560781717300415\n",
      "Epoch [6283/10000], Loss: 0.5607816576957703\n",
      "Epoch [6284/10000], Loss: 0.560780942440033\n",
      "Epoch [6285/10000], Loss: 0.5607808232307434\n",
      "Epoch [6286/10000], Loss: 0.5607805252075195\n",
      "Epoch [6287/10000], Loss: 0.5607808232307434\n",
      "Epoch [6288/10000], Loss: 0.5607810020446777\n",
      "Epoch [6289/10000], Loss: 0.5607814788818359\n",
      "Epoch [6290/10000], Loss: 0.5607818365097046\n",
      "Epoch [6291/10000], Loss: 0.5607826113700867\n",
      "Epoch [6292/10000], Loss: 0.5607836246490479\n",
      "Epoch [6293/10000], Loss: 0.5607847571372986\n",
      "Epoch [6294/10000], Loss: 0.560785710811615\n",
      "Epoch [6295/10000], Loss: 0.5607865452766418\n",
      "Epoch [6296/10000], Loss: 0.5607870221138\n",
      "Epoch [6297/10000], Loss: 0.5607868432998657\n",
      "Epoch [6298/10000], Loss: 0.5607855319976807\n",
      "Epoch [6299/10000], Loss: 0.5607839226722717\n",
      "Epoch [6300/10000], Loss: 0.560782253742218\n",
      "Epoch [6301/10000], Loss: 0.5607802271842957\n",
      "Epoch [6302/10000], Loss: 0.5607781410217285\n",
      "Epoch [6303/10000], Loss: 0.5607771277427673\n",
      "Epoch [6304/10000], Loss: 0.560775876045227\n",
      "Epoch [6305/10000], Loss: 0.5607750415802002\n",
      "Epoch [6306/10000], Loss: 0.5607747435569763\n",
      "Epoch [6307/10000], Loss: 0.5607743263244629\n",
      "Epoch [6308/10000], Loss: 0.5607739686965942\n",
      "Epoch [6309/10000], Loss: 0.5607739090919495\n",
      "Epoch [6310/10000], Loss: 0.5607738494873047\n",
      "Epoch [6311/10000], Loss: 0.5607736706733704\n",
      "Epoch [6312/10000], Loss: 0.5607737302780151\n",
      "Epoch [6313/10000], Loss: 0.5607742071151733\n",
      "Epoch [6314/10000], Loss: 0.5607748031616211\n",
      "Epoch [6315/10000], Loss: 0.5607753396034241\n",
      "Epoch [6316/10000], Loss: 0.5607765913009644\n",
      "Epoch [6317/10000], Loss: 0.5607780814170837\n",
      "Epoch [6318/10000], Loss: 0.5607792735099792\n",
      "Epoch [6319/10000], Loss: 0.5607804656028748\n",
      "Epoch [6320/10000], Loss: 0.5607810616493225\n",
      "Epoch [6321/10000], Loss: 0.560780942440033\n",
      "Epoch [6322/10000], Loss: 0.5607808232307434\n",
      "Epoch [6323/10000], Loss: 0.5607795119285583\n",
      "Epoch [6324/10000], Loss: 0.5607787370681763\n",
      "Epoch [6325/10000], Loss: 0.560778021812439\n",
      "Epoch [6326/10000], Loss: 0.5607775449752808\n",
      "Epoch [6327/10000], Loss: 0.5607778429985046\n",
      "Epoch [6328/10000], Loss: 0.5607783198356628\n",
      "Epoch [6329/10000], Loss: 0.5607788562774658\n",
      "Epoch [6330/10000], Loss: 0.560779333114624\n",
      "Epoch [6331/10000], Loss: 0.5607798099517822\n",
      "Epoch [6332/10000], Loss: 0.5607802271842957\n",
      "Epoch [6333/10000], Loss: 0.5607802867889404\n",
      "Epoch [6334/10000], Loss: 0.5607804656028748\n",
      "Epoch [6335/10000], Loss: 0.5607805252075195\n",
      "Epoch [6336/10000], Loss: 0.5607802867889404\n",
      "Epoch [6337/10000], Loss: 0.5607805848121643\n",
      "Epoch [6338/10000], Loss: 0.5607816576957703\n",
      "Epoch [6339/10000], Loss: 0.5607823729515076\n",
      "Epoch [6340/10000], Loss: 0.5607829689979553\n",
      "Epoch [6341/10000], Loss: 0.5607838034629822\n",
      "Epoch [6342/10000], Loss: 0.560783863067627\n",
      "Epoch [6343/10000], Loss: 0.560784101486206\n",
      "Epoch [6344/10000], Loss: 0.560783326625824\n",
      "Epoch [6345/10000], Loss: 0.5607826113700867\n",
      "Epoch [6346/10000], Loss: 0.5607818365097046\n",
      "Epoch [6347/10000], Loss: 0.560780942440033\n",
      "Epoch [6348/10000], Loss: 0.5607802867889404\n",
      "Epoch [6349/10000], Loss: 0.5607805252075195\n",
      "Epoch [6350/10000], Loss: 0.5607814192771912\n",
      "Epoch [6351/10000], Loss: 0.5607824921607971\n",
      "Epoch [6352/10000], Loss: 0.5607831478118896\n",
      "Epoch [6353/10000], Loss: 0.5607829093933105\n",
      "Epoch [6354/10000], Loss: 0.5607820153236389\n",
      "Epoch [6355/10000], Loss: 0.5607799887657166\n",
      "Epoch [6356/10000], Loss: 0.560777485370636\n",
      "Epoch [6357/10000], Loss: 0.5607754588127136\n",
      "Epoch [6358/10000], Loss: 0.5607746839523315\n",
      "Epoch [6359/10000], Loss: 0.560774028301239\n",
      "Epoch [6360/10000], Loss: 0.5607735514640808\n",
      "Epoch [6361/10000], Loss: 0.5607739686965942\n",
      "Epoch [6362/10000], Loss: 0.5607741475105286\n",
      "Epoch [6363/10000], Loss: 0.560775101184845\n",
      "Epoch [6364/10000], Loss: 0.5607765913009644\n",
      "Epoch [6365/10000], Loss: 0.5607785582542419\n",
      "Epoch [6366/10000], Loss: 0.5607801675796509\n",
      "Epoch [6367/10000], Loss: 0.5607808232307434\n",
      "Epoch [6368/10000], Loss: 0.5607804656028748\n",
      "Epoch [6369/10000], Loss: 0.5607798099517822\n",
      "Epoch [6370/10000], Loss: 0.5607785582542419\n",
      "Epoch [6371/10000], Loss: 0.5607773661613464\n",
      "Epoch [6372/10000], Loss: 0.5607762932777405\n",
      "Epoch [6373/10000], Loss: 0.5607758164405823\n",
      "Epoch [6374/10000], Loss: 0.5607759952545166\n",
      "Epoch [6375/10000], Loss: 0.5607765913009644\n",
      "Epoch [6376/10000], Loss: 0.5607773065567017\n",
      "Epoch [6377/10000], Loss: 0.5607782006263733\n",
      "Epoch [6378/10000], Loss: 0.5607790946960449\n",
      "Epoch [6379/10000], Loss: 0.5607792735099792\n",
      "Epoch [6380/10000], Loss: 0.560779333114624\n",
      "Epoch [6381/10000], Loss: 0.560779333114624\n",
      "Epoch [6382/10000], Loss: 0.5607790350914001\n",
      "Epoch [6383/10000], Loss: 0.5607786178588867\n",
      "Epoch [6384/10000], Loss: 0.5607779622077942\n",
      "Epoch [6385/10000], Loss: 0.5607773065567017\n",
      "Epoch [6386/10000], Loss: 0.5607762336730957\n",
      "Epoch [6387/10000], Loss: 0.5607753992080688\n",
      "Epoch [6388/10000], Loss: 0.560775101184845\n",
      "Epoch [6389/10000], Loss: 0.5607746839523315\n",
      "Epoch [6390/10000], Loss: 0.5607746243476868\n",
      "Epoch [6391/10000], Loss: 0.5607750415802002\n",
      "Epoch [6392/10000], Loss: 0.5607755184173584\n",
      "Epoch [6393/10000], Loss: 0.5607753992080688\n",
      "Epoch [6394/10000], Loss: 0.5607757568359375\n",
      "Epoch [6395/10000], Loss: 0.5607761740684509\n",
      "Epoch [6396/10000], Loss: 0.5607767105102539\n",
      "Epoch [6397/10000], Loss: 0.560777485370636\n",
      "Epoch [6398/10000], Loss: 0.5607779622077942\n",
      "Epoch [6399/10000], Loss: 0.5607783198356628\n",
      "Epoch [6400/10000], Loss: 0.5607787370681763\n",
      "Epoch [6401/10000], Loss: 0.5607791543006897\n",
      "Epoch [6402/10000], Loss: 0.5607788562774658\n",
      "Epoch [6403/10000], Loss: 0.5607789158821106\n",
      "Epoch [6404/10000], Loss: 0.5607792139053345\n",
      "Epoch [6405/10000], Loss: 0.5607795715332031\n",
      "Epoch [6406/10000], Loss: 0.5607797503471375\n",
      "Epoch [6407/10000], Loss: 0.5607798099517822\n",
      "Epoch [6408/10000], Loss: 0.5607795119285583\n",
      "Epoch [6409/10000], Loss: 0.5607795119285583\n",
      "Epoch [6410/10000], Loss: 0.5607789158821106\n",
      "Epoch [6411/10000], Loss: 0.5607786178588867\n",
      "Epoch [6412/10000], Loss: 0.5607784390449524\n",
      "Epoch [6413/10000], Loss: 0.5607781410217285\n",
      "Epoch [6414/10000], Loss: 0.5607780814170837\n",
      "Epoch [6415/10000], Loss: 0.5607777833938599\n",
      "Epoch [6416/10000], Loss: 0.5607779026031494\n",
      "Epoch [6417/10000], Loss: 0.560778021812439\n",
      "Epoch [6418/10000], Loss: 0.5607777237892151\n",
      "Epoch [6419/10000], Loss: 0.5607771873474121\n",
      "Epoch [6420/10000], Loss: 0.5607764720916748\n",
      "Epoch [6421/10000], Loss: 0.5607753992080688\n",
      "Epoch [6422/10000], Loss: 0.5607745051383972\n",
      "Epoch [6423/10000], Loss: 0.5607733726501465\n",
      "Epoch [6424/10000], Loss: 0.5607724785804749\n",
      "Epoch [6425/10000], Loss: 0.5607719421386719\n",
      "Epoch [6426/10000], Loss: 0.5607713460922241\n",
      "Epoch [6427/10000], Loss: 0.5607715249061584\n",
      "Epoch [6428/10000], Loss: 0.5607717633247375\n",
      "Epoch [6429/10000], Loss: 0.5607721209526062\n",
      "Epoch [6430/10000], Loss: 0.5607728362083435\n",
      "Epoch [6431/10000], Loss: 0.5607734322547913\n",
      "Epoch [6432/10000], Loss: 0.5607741475105286\n",
      "Epoch [6433/10000], Loss: 0.5607749223709106\n",
      "Epoch [6434/10000], Loss: 0.5607754588127136\n",
      "Epoch [6435/10000], Loss: 0.5607760548591614\n",
      "Epoch [6436/10000], Loss: 0.56077641248703\n",
      "Epoch [6437/10000], Loss: 0.5607762932777405\n",
      "Epoch [6438/10000], Loss: 0.560775876045227\n",
      "Epoch [6439/10000], Loss: 0.5607751607894897\n",
      "Epoch [6440/10000], Loss: 0.560774028301239\n",
      "Epoch [6441/10000], Loss: 0.5607733130455017\n",
      "Epoch [6442/10000], Loss: 0.5607728362083435\n",
      "Epoch [6443/10000], Loss: 0.560772716999054\n",
      "Epoch [6444/10000], Loss: 0.5607725977897644\n",
      "Epoch [6445/10000], Loss: 0.5607732534408569\n",
      "Epoch [6446/10000], Loss: 0.5607740879058838\n",
      "Epoch [6447/10000], Loss: 0.5607753992080688\n",
      "Epoch [6448/10000], Loss: 0.5607770085334778\n",
      "Epoch [6449/10000], Loss: 0.5607792139053345\n",
      "Epoch [6450/10000], Loss: 0.560780942440033\n",
      "Epoch [6451/10000], Loss: 0.5607819557189941\n",
      "Epoch [6452/10000], Loss: 0.5607819557189941\n",
      "Epoch [6453/10000], Loss: 0.5607814788818359\n",
      "Epoch [6454/10000], Loss: 0.560780942440033\n",
      "Epoch [6455/10000], Loss: 0.5607805252075195\n",
      "Epoch [6456/10000], Loss: 0.5607802271842957\n",
      "Epoch [6457/10000], Loss: 0.5607799291610718\n",
      "Epoch [6458/10000], Loss: 0.5607800483703613\n",
      "Epoch [6459/10000], Loss: 0.5607803463935852\n",
      "Epoch [6460/10000], Loss: 0.5607804656028748\n",
      "Epoch [6461/10000], Loss: 0.5607801675796509\n",
      "Epoch [6462/10000], Loss: 0.5607801675796509\n",
      "Epoch [6463/10000], Loss: 0.5607791543006897\n",
      "Epoch [6464/10000], Loss: 0.5607785582542419\n",
      "Epoch [6465/10000], Loss: 0.5607772469520569\n",
      "Epoch [6466/10000], Loss: 0.560775876045227\n",
      "Epoch [6467/10000], Loss: 0.5607749223709106\n",
      "Epoch [6468/10000], Loss: 0.5607746243476868\n",
      "Epoch [6469/10000], Loss: 0.5607746839523315\n",
      "Epoch [6470/10000], Loss: 0.5607747435569763\n",
      "Epoch [6471/10000], Loss: 0.5607753992080688\n",
      "Epoch [6472/10000], Loss: 0.560775637626648\n",
      "Epoch [6473/10000], Loss: 0.560775637626648\n",
      "Epoch [6474/10000], Loss: 0.5607753396034241\n",
      "Epoch [6475/10000], Loss: 0.5607745051383972\n",
      "Epoch [6476/10000], Loss: 0.560774028301239\n",
      "Epoch [6477/10000], Loss: 0.5607731938362122\n",
      "Epoch [6478/10000], Loss: 0.5607725977897644\n",
      "Epoch [6479/10000], Loss: 0.5607721209526062\n",
      "Epoch [6480/10000], Loss: 0.5607718229293823\n",
      "Epoch [6481/10000], Loss: 0.560771107673645\n",
      "Epoch [6482/10000], Loss: 0.5607708096504211\n",
      "Epoch [6483/10000], Loss: 0.5607708096504211\n",
      "Epoch [6484/10000], Loss: 0.5607706904411316\n",
      "Epoch [6485/10000], Loss: 0.5607708692550659\n",
      "Epoch [6486/10000], Loss: 0.5607714056968689\n",
      "Epoch [6487/10000], Loss: 0.5607725381851196\n",
      "Epoch [6488/10000], Loss: 0.5607734322547913\n",
      "Epoch [6489/10000], Loss: 0.5607748031616211\n",
      "Epoch [6490/10000], Loss: 0.5607756972312927\n",
      "Epoch [6491/10000], Loss: 0.5607767105102539\n",
      "Epoch [6492/10000], Loss: 0.5607770681381226\n",
      "Epoch [6493/10000], Loss: 0.560776948928833\n",
      "Epoch [6494/10000], Loss: 0.5607759356498718\n",
      "Epoch [6495/10000], Loss: 0.5607747435569763\n",
      "Epoch [6496/10000], Loss: 0.5607739686965942\n",
      "Epoch [6497/10000], Loss: 0.5607733130455017\n",
      "Epoch [6498/10000], Loss: 0.5607730746269226\n",
      "Epoch [6499/10000], Loss: 0.5607730150222778\n",
      "Epoch [6500/10000], Loss: 0.5607737302780151\n",
      "Epoch [6501/10000], Loss: 0.560775637626648\n",
      "Epoch [6502/10000], Loss: 0.5607777237892151\n",
      "Epoch [6503/10000], Loss: 0.5607799887657166\n",
      "Epoch [6504/10000], Loss: 0.5607813000679016\n",
      "Epoch [6505/10000], Loss: 0.5607816576957703\n",
      "Epoch [6506/10000], Loss: 0.5607811212539673\n",
      "Epoch [6507/10000], Loss: 0.5607797503471375\n",
      "Epoch [6508/10000], Loss: 0.5607784390449524\n",
      "Epoch [6509/10000], Loss: 0.5607777237892151\n",
      "Epoch [6510/10000], Loss: 0.5607770085334778\n",
      "Epoch [6511/10000], Loss: 0.5607767105102539\n",
      "Epoch [6512/10000], Loss: 0.5607773661613464\n",
      "Epoch [6513/10000], Loss: 0.5607780814170837\n",
      "Epoch [6514/10000], Loss: 0.560778796672821\n",
      "Epoch [6515/10000], Loss: 0.5607789158821106\n",
      "Epoch [6516/10000], Loss: 0.5607789754867554\n",
      "Epoch [6517/10000], Loss: 0.5607786774635315\n",
      "Epoch [6518/10000], Loss: 0.5607779622077942\n",
      "Epoch [6519/10000], Loss: 0.560777485370636\n",
      "Epoch [6520/10000], Loss: 0.5607768297195435\n",
      "Epoch [6521/10000], Loss: 0.560775101184845\n",
      "Epoch [6522/10000], Loss: 0.5607735514640808\n",
      "Epoch [6523/10000], Loss: 0.560772180557251\n",
      "Epoch [6524/10000], Loss: 0.5607712864875793\n",
      "Epoch [6525/10000], Loss: 0.5607708692550659\n",
      "Epoch [6526/10000], Loss: 0.5607706904411316\n",
      "Epoch [6527/10000], Loss: 0.5607702732086182\n",
      "Epoch [6528/10000], Loss: 0.5607703924179077\n",
      "Epoch [6529/10000], Loss: 0.5607701539993286\n",
      "Epoch [6530/10000], Loss: 0.5607698559761047\n",
      "Epoch [6531/10000], Loss: 0.5607699155807495\n",
      "Epoch [6532/10000], Loss: 0.5607696771621704\n",
      "Epoch [6533/10000], Loss: 0.5607702732086182\n",
      "Epoch [6534/10000], Loss: 0.5607708692550659\n",
      "Epoch [6535/10000], Loss: 0.5607717037200928\n",
      "Epoch [6536/10000], Loss: 0.5607721209526062\n",
      "Epoch [6537/10000], Loss: 0.5607728958129883\n",
      "Epoch [6538/10000], Loss: 0.5607738494873047\n",
      "Epoch [6539/10000], Loss: 0.5607748031616211\n",
      "Epoch [6540/10000], Loss: 0.5607753396034241\n",
      "Epoch [6541/10000], Loss: 0.560775101184845\n",
      "Epoch [6542/10000], Loss: 0.560774564743042\n",
      "Epoch [6543/10000], Loss: 0.560773491859436\n",
      "Epoch [6544/10000], Loss: 0.5607724785804749\n",
      "Epoch [6545/10000], Loss: 0.5607718825340271\n",
      "Epoch [6546/10000], Loss: 0.5607717633247375\n",
      "Epoch [6547/10000], Loss: 0.5607725381851196\n",
      "Epoch [6548/10000], Loss: 0.5607736706733704\n",
      "Epoch [6549/10000], Loss: 0.5607753396034241\n",
      "Epoch [6550/10000], Loss: 0.5607776641845703\n",
      "Epoch [6551/10000], Loss: 0.5607811808586121\n",
      "Epoch [6552/10000], Loss: 0.5607846975326538\n",
      "Epoch [6553/10000], Loss: 0.560788631439209\n",
      "Epoch [6554/10000], Loss: 0.5607923269271851\n",
      "Epoch [6555/10000], Loss: 0.5607947707176208\n",
      "Epoch [6556/10000], Loss: 0.5607948303222656\n",
      "Epoch [6557/10000], Loss: 0.560793399810791\n",
      "Epoch [6558/10000], Loss: 0.5607896447181702\n",
      "Epoch [6559/10000], Loss: 0.5607855319976807\n",
      "Epoch [6560/10000], Loss: 0.5607814788818359\n",
      "Epoch [6561/10000], Loss: 0.5607779622077942\n",
      "Epoch [6562/10000], Loss: 0.5607762932777405\n",
      "Epoch [6563/10000], Loss: 0.56077641248703\n",
      "Epoch [6564/10000], Loss: 0.5607773065567017\n",
      "Epoch [6565/10000], Loss: 0.5607779622077942\n",
      "Epoch [6566/10000], Loss: 0.560778021812439\n",
      "Epoch [6567/10000], Loss: 0.560778021812439\n",
      "Epoch [6568/10000], Loss: 0.560777485370636\n",
      "Epoch [6569/10000], Loss: 0.5607772469520569\n",
      "Epoch [6570/10000], Loss: 0.5607768297195435\n",
      "Epoch [6571/10000], Loss: 0.5607765913009644\n",
      "Epoch [6572/10000], Loss: 0.5607768297195435\n",
      "Epoch [6573/10000], Loss: 0.5607765316963196\n",
      "Epoch [6574/10000], Loss: 0.5607765913009644\n",
      "Epoch [6575/10000], Loss: 0.5607763528823853\n",
      "Epoch [6576/10000], Loss: 0.5607755780220032\n",
      "Epoch [6577/10000], Loss: 0.5607743859291077\n",
      "Epoch [6578/10000], Loss: 0.5607731938362122\n",
      "Epoch [6579/10000], Loss: 0.5607723593711853\n",
      "Epoch [6580/10000], Loss: 0.5607718229293823\n",
      "Epoch [6581/10000], Loss: 0.5607717633247375\n",
      "Epoch [6582/10000], Loss: 0.5607723593711853\n",
      "Epoch [6583/10000], Loss: 0.5607730746269226\n",
      "Epoch [6584/10000], Loss: 0.5607737302780151\n",
      "Epoch [6585/10000], Loss: 0.5607739686965942\n",
      "Epoch [6586/10000], Loss: 0.5607736706733704\n",
      "Epoch [6587/10000], Loss: 0.5607730746269226\n",
      "Epoch [6588/10000], Loss: 0.5607726573944092\n",
      "Epoch [6589/10000], Loss: 0.5607721209526062\n",
      "Epoch [6590/10000], Loss: 0.560771644115448\n",
      "Epoch [6591/10000], Loss: 0.5607709288597107\n",
      "Epoch [6592/10000], Loss: 0.5607708096504211\n",
      "Epoch [6593/10000], Loss: 0.5607706308364868\n",
      "Epoch [6594/10000], Loss: 0.5607706904411316\n",
      "Epoch [6595/10000], Loss: 0.5607706904411316\n",
      "Epoch [6596/10000], Loss: 0.5607715249061584\n",
      "Epoch [6597/10000], Loss: 0.5607718229293823\n",
      "Epoch [6598/10000], Loss: 0.560772180557251\n",
      "Epoch [6599/10000], Loss: 0.5607730746269226\n",
      "Epoch [6600/10000], Loss: 0.5607739686965942\n",
      "Epoch [6601/10000], Loss: 0.5607749223709106\n",
      "Epoch [6602/10000], Loss: 0.5607759356498718\n",
      "Epoch [6603/10000], Loss: 0.560775637626648\n",
      "Epoch [6604/10000], Loss: 0.5607748031616211\n",
      "Epoch [6605/10000], Loss: 0.5607741475105286\n",
      "Epoch [6606/10000], Loss: 0.560772716999054\n",
      "Epoch [6607/10000], Loss: 0.5607714056968689\n",
      "Epoch [6608/10000], Loss: 0.5607706904411316\n",
      "Epoch [6609/10000], Loss: 0.5607703328132629\n",
      "Epoch [6610/10000], Loss: 0.5607700347900391\n",
      "Epoch [6611/10000], Loss: 0.5607698559761047\n",
      "Epoch [6612/10000], Loss: 0.5607702136039734\n",
      "Epoch [6613/10000], Loss: 0.5607708692550659\n",
      "Epoch [6614/10000], Loss: 0.5607715845108032\n",
      "Epoch [6615/10000], Loss: 0.5607728362083435\n",
      "Epoch [6616/10000], Loss: 0.5607745051383972\n",
      "Epoch [6617/10000], Loss: 0.5607764720916748\n",
      "Epoch [6618/10000], Loss: 0.5607781410217285\n",
      "Epoch [6619/10000], Loss: 0.560779333114624\n",
      "Epoch [6620/10000], Loss: 0.5607803463935852\n",
      "Epoch [6621/10000], Loss: 0.5607805848121643\n",
      "Epoch [6622/10000], Loss: 0.5607802867889404\n",
      "Epoch [6623/10000], Loss: 0.5607801675796509\n",
      "Epoch [6624/10000], Loss: 0.5607795715332031\n",
      "Epoch [6625/10000], Loss: 0.5607792139053345\n",
      "Epoch [6626/10000], Loss: 0.5607784986495972\n",
      "Epoch [6627/10000], Loss: 0.5607774257659912\n",
      "Epoch [6628/10000], Loss: 0.5607765316963196\n",
      "Epoch [6629/10000], Loss: 0.5607753396034241\n",
      "Epoch [6630/10000], Loss: 0.560774564743042\n",
      "Epoch [6631/10000], Loss: 0.5607738494873047\n",
      "Epoch [6632/10000], Loss: 0.5607733130455017\n",
      "Epoch [6633/10000], Loss: 0.5607731938362122\n",
      "Epoch [6634/10000], Loss: 0.5607730150222778\n",
      "Epoch [6635/10000], Loss: 0.560773491859436\n",
      "Epoch [6636/10000], Loss: 0.5607736706733704\n",
      "Epoch [6637/10000], Loss: 0.5607739686965942\n",
      "Epoch [6638/10000], Loss: 0.5607740879058838\n",
      "Epoch [6639/10000], Loss: 0.5607737898826599\n",
      "Epoch [6640/10000], Loss: 0.5607736110687256\n",
      "Epoch [6641/10000], Loss: 0.5607731342315674\n",
      "Epoch [6642/10000], Loss: 0.5607723593711853\n",
      "Epoch [6643/10000], Loss: 0.5607722401618958\n",
      "Epoch [6644/10000], Loss: 0.5607715249061584\n",
      "Epoch [6645/10000], Loss: 0.5607706904411316\n",
      "Epoch [6646/10000], Loss: 0.5607703328132629\n",
      "Epoch [6647/10000], Loss: 0.5607702136039734\n",
      "Epoch [6648/10000], Loss: 0.5607702136039734\n",
      "Epoch [6649/10000], Loss: 0.5607708096504211\n",
      "Epoch [6650/10000], Loss: 0.560771107673645\n",
      "Epoch [6651/10000], Loss: 0.5607708692550659\n",
      "Epoch [6652/10000], Loss: 0.5607711672782898\n",
      "Epoch [6653/10000], Loss: 0.5607714653015137\n",
      "Epoch [6654/10000], Loss: 0.5607722401618958\n",
      "Epoch [6655/10000], Loss: 0.5607728362083435\n",
      "Epoch [6656/10000], Loss: 0.5607731938362122\n",
      "Epoch [6657/10000], Loss: 0.5607739090919495\n",
      "Epoch [6658/10000], Loss: 0.5607746243476868\n",
      "Epoch [6659/10000], Loss: 0.5607755184173584\n",
      "Epoch [6660/10000], Loss: 0.5607759356498718\n",
      "Epoch [6661/10000], Loss: 0.5607763528823853\n",
      "Epoch [6662/10000], Loss: 0.5607777833938599\n",
      "Epoch [6663/10000], Loss: 0.5607784390449524\n",
      "Epoch [6664/10000], Loss: 0.5607793927192688\n",
      "Epoch [6665/10000], Loss: 0.5607804656028748\n",
      "Epoch [6666/10000], Loss: 0.5607814788818359\n",
      "Epoch [6667/10000], Loss: 0.5607818365097046\n",
      "Epoch [6668/10000], Loss: 0.5607815384864807\n",
      "Epoch [6669/10000], Loss: 0.5607804656028748\n",
      "Epoch [6670/10000], Loss: 0.5607783794403076\n",
      "Epoch [6671/10000], Loss: 0.5607764720916748\n",
      "Epoch [6672/10000], Loss: 0.5607748031616211\n",
      "Epoch [6673/10000], Loss: 0.5607730150222778\n",
      "Epoch [6674/10000], Loss: 0.5607718825340271\n",
      "Epoch [6675/10000], Loss: 0.5607712268829346\n",
      "Epoch [6676/10000], Loss: 0.5607708692550659\n",
      "Epoch [6677/10000], Loss: 0.5607706904411316\n",
      "Epoch [6678/10000], Loss: 0.5607707500457764\n",
      "Epoch [6679/10000], Loss: 0.5607708096504211\n",
      "Epoch [6680/10000], Loss: 0.5607707500457764\n",
      "Epoch [6681/10000], Loss: 0.5607709884643555\n",
      "Epoch [6682/10000], Loss: 0.5607715845108032\n",
      "Epoch [6683/10000], Loss: 0.5607717633247375\n",
      "Epoch [6684/10000], Loss: 0.5607720613479614\n",
      "Epoch [6685/10000], Loss: 0.5607725977897644\n",
      "Epoch [6686/10000], Loss: 0.5607729554176331\n",
      "Epoch [6687/10000], Loss: 0.5607730746269226\n",
      "Epoch [6688/10000], Loss: 0.5607736110687256\n",
      "Epoch [6689/10000], Loss: 0.560773491859436\n",
      "Epoch [6690/10000], Loss: 0.5607733726501465\n",
      "Epoch [6691/10000], Loss: 0.5607733130455017\n",
      "Epoch [6692/10000], Loss: 0.5607733130455017\n",
      "Epoch [6693/10000], Loss: 0.5607727766036987\n",
      "Epoch [6694/10000], Loss: 0.5607724785804749\n",
      "Epoch [6695/10000], Loss: 0.5607722401618958\n",
      "Epoch [6696/10000], Loss: 0.560771644115448\n",
      "Epoch [6697/10000], Loss: 0.5607715845108032\n",
      "Epoch [6698/10000], Loss: 0.5607715845108032\n",
      "Epoch [6699/10000], Loss: 0.5607713460922241\n",
      "Epoch [6700/10000], Loss: 0.5607721209526062\n",
      "Epoch [6701/10000], Loss: 0.5607730150222778\n",
      "Epoch [6702/10000], Loss: 0.5607737302780151\n",
      "Epoch [6703/10000], Loss: 0.560775101184845\n",
      "Epoch [6704/10000], Loss: 0.5607768297195435\n",
      "Epoch [6705/10000], Loss: 0.5607781410217285\n",
      "Epoch [6706/10000], Loss: 0.5607795715332031\n",
      "Epoch [6707/10000], Loss: 0.5607803463935852\n",
      "Epoch [6708/10000], Loss: 0.5607814788818359\n",
      "Epoch [6709/10000], Loss: 0.5607813596725464\n",
      "Epoch [6710/10000], Loss: 0.5607818961143494\n",
      "Epoch [6711/10000], Loss: 0.5607816576957703\n",
      "Epoch [6712/10000], Loss: 0.5607810020446777\n",
      "Epoch [6713/10000], Loss: 0.5607796311378479\n",
      "Epoch [6714/10000], Loss: 0.5607788562774658\n",
      "Epoch [6715/10000], Loss: 0.5607773661613464\n",
      "Epoch [6716/10000], Loss: 0.5607762336730957\n",
      "Epoch [6717/10000], Loss: 0.560774564743042\n",
      "Epoch [6718/10000], Loss: 0.560773491859436\n",
      "Epoch [6719/10000], Loss: 0.5607722401618958\n",
      "Epoch [6720/10000], Loss: 0.5607710480690002\n",
      "Epoch [6721/10000], Loss: 0.5607701539993286\n",
      "Epoch [6722/10000], Loss: 0.5607697367668152\n",
      "Epoch [6723/10000], Loss: 0.5607694983482361\n",
      "Epoch [6724/10000], Loss: 0.56076979637146\n",
      "Epoch [6725/10000], Loss: 0.560771107673645\n",
      "Epoch [6726/10000], Loss: 0.560772180557251\n",
      "Epoch [6727/10000], Loss: 0.5607739090919495\n",
      "Epoch [6728/10000], Loss: 0.560775637626648\n",
      "Epoch [6729/10000], Loss: 0.560777485370636\n",
      "Epoch [6730/10000], Loss: 0.5607783198356628\n",
      "Epoch [6731/10000], Loss: 0.5607780814170837\n",
      "Epoch [6732/10000], Loss: 0.5607770681381226\n",
      "Epoch [6733/10000], Loss: 0.5607755780220032\n",
      "Epoch [6734/10000], Loss: 0.5607741475105286\n",
      "Epoch [6735/10000], Loss: 0.5607728362083435\n",
      "Epoch [6736/10000], Loss: 0.5607717037200928\n",
      "Epoch [6737/10000], Loss: 0.5607709288597107\n",
      "Epoch [6738/10000], Loss: 0.5607706308364868\n",
      "Epoch [6739/10000], Loss: 0.5607702732086182\n",
      "Epoch [6740/10000], Loss: 0.5607700943946838\n",
      "Epoch [6741/10000], Loss: 0.5607703924179077\n",
      "Epoch [6742/10000], Loss: 0.5607707500457764\n",
      "Epoch [6743/10000], Loss: 0.5607713460922241\n",
      "Epoch [6744/10000], Loss: 0.560771644115448\n",
      "Epoch [6745/10000], Loss: 0.5607720017433167\n",
      "Epoch [6746/10000], Loss: 0.5607725381851196\n",
      "Epoch [6747/10000], Loss: 0.560772716999054\n",
      "Epoch [6748/10000], Loss: 0.5607733726501465\n",
      "Epoch [6749/10000], Loss: 0.5607737302780151\n",
      "Epoch [6750/10000], Loss: 0.5607732534408569\n",
      "Epoch [6751/10000], Loss: 0.5607726573944092\n",
      "Epoch [6752/10000], Loss: 0.5607723593711853\n",
      "Epoch [6753/10000], Loss: 0.5607720017433167\n",
      "Epoch [6754/10000], Loss: 0.5607718229293823\n",
      "Epoch [6755/10000], Loss: 0.5607715249061584\n",
      "Epoch [6756/10000], Loss: 0.5607715845108032\n",
      "Epoch [6757/10000], Loss: 0.5607720017433167\n",
      "Epoch [6758/10000], Loss: 0.560772716999054\n",
      "Epoch [6759/10000], Loss: 0.5607736706733704\n",
      "Epoch [6760/10000], Loss: 0.5607750415802002\n",
      "Epoch [6761/10000], Loss: 0.5607763528823853\n",
      "Epoch [6762/10000], Loss: 0.5607777237892151\n",
      "Epoch [6763/10000], Loss: 0.5607786774635315\n",
      "Epoch [6764/10000], Loss: 0.5607788562774658\n",
      "Epoch [6765/10000], Loss: 0.5607791543006897\n",
      "Epoch [6766/10000], Loss: 0.5607793927192688\n",
      "Epoch [6767/10000], Loss: 0.5607792735099792\n",
      "Epoch [6768/10000], Loss: 0.5607790946960449\n",
      "Epoch [6769/10000], Loss: 0.5607790350914001\n",
      "Epoch [6770/10000], Loss: 0.5607784986495972\n",
      "Epoch [6771/10000], Loss: 0.5607782006263733\n",
      "Epoch [6772/10000], Loss: 0.5607779026031494\n",
      "Epoch [6773/10000], Loss: 0.5607771873474121\n",
      "Epoch [6774/10000], Loss: 0.5607763528823853\n",
      "Epoch [6775/10000], Loss: 0.560775101184845\n",
      "Epoch [6776/10000], Loss: 0.5607735514640808\n",
      "Epoch [6777/10000], Loss: 0.5607722401618958\n",
      "Epoch [6778/10000], Loss: 0.5607708692550659\n",
      "Epoch [6779/10000], Loss: 0.5607702136039734\n",
      "Epoch [6780/10000], Loss: 0.56076979637146\n",
      "Epoch [6781/10000], Loss: 0.5607693791389465\n",
      "Epoch [6782/10000], Loss: 0.5607695579528809\n",
      "Epoch [6783/10000], Loss: 0.5607694983482361\n",
      "Epoch [6784/10000], Loss: 0.5607696175575256\n",
      "Epoch [6785/10000], Loss: 0.5607700347900391\n",
      "Epoch [6786/10000], Loss: 0.5607707500457764\n",
      "Epoch [6787/10000], Loss: 0.5607715845108032\n",
      "Epoch [6788/10000], Loss: 0.5607723593711853\n",
      "Epoch [6789/10000], Loss: 0.5607736110687256\n",
      "Epoch [6790/10000], Loss: 0.5607751607894897\n",
      "Epoch [6791/10000], Loss: 0.5607764720916748\n",
      "Epoch [6792/10000], Loss: 0.560778021812439\n",
      "Epoch [6793/10000], Loss: 0.5607792735099792\n",
      "Epoch [6794/10000], Loss: 0.5607795119285583\n",
      "Epoch [6795/10000], Loss: 0.5607786178588867\n",
      "Epoch [6796/10000], Loss: 0.560776948928833\n",
      "Epoch [6797/10000], Loss: 0.5607752203941345\n",
      "Epoch [6798/10000], Loss: 0.5607736706733704\n",
      "Epoch [6799/10000], Loss: 0.5607725381851196\n",
      "Epoch [6800/10000], Loss: 0.5607717633247375\n",
      "Epoch [6801/10000], Loss: 0.5607712864875793\n",
      "Epoch [6802/10000], Loss: 0.5607720613479614\n",
      "Epoch [6803/10000], Loss: 0.5607729554176331\n",
      "Epoch [6804/10000], Loss: 0.5607746839523315\n",
      "Epoch [6805/10000], Loss: 0.5607772469520569\n",
      "Epoch [6806/10000], Loss: 0.5607797503471375\n",
      "Epoch [6807/10000], Loss: 0.5607807636260986\n",
      "Epoch [6808/10000], Loss: 0.5607807040214539\n",
      "Epoch [6809/10000], Loss: 0.560779333114624\n",
      "Epoch [6810/10000], Loss: 0.5607773661613464\n",
      "Epoch [6811/10000], Loss: 0.5607747435569763\n",
      "Epoch [6812/10000], Loss: 0.560772716999054\n",
      "Epoch [6813/10000], Loss: 0.5607714056968689\n",
      "Epoch [6814/10000], Loss: 0.560770571231842\n",
      "Epoch [6815/10000], Loss: 0.5607699155807495\n",
      "Epoch [6816/10000], Loss: 0.5607699751853943\n",
      "Epoch [6817/10000], Loss: 0.5607700347900391\n",
      "Epoch [6818/10000], Loss: 0.5607702732086182\n",
      "Epoch [6819/10000], Loss: 0.5607708096504211\n",
      "Epoch [6820/10000], Loss: 0.560771107673645\n",
      "Epoch [6821/10000], Loss: 0.5607717633247375\n",
      "Epoch [6822/10000], Loss: 0.5607721209526062\n",
      "Epoch [6823/10000], Loss: 0.560772716999054\n",
      "Epoch [6824/10000], Loss: 0.5607731342315674\n",
      "Epoch [6825/10000], Loss: 0.5607734322547913\n",
      "Epoch [6826/10000], Loss: 0.5607736706733704\n",
      "Epoch [6827/10000], Loss: 0.560773491859436\n",
      "Epoch [6828/10000], Loss: 0.5607731342315674\n",
      "Epoch [6829/10000], Loss: 0.5607723593711853\n",
      "Epoch [6830/10000], Loss: 0.5607718229293823\n",
      "Epoch [6831/10000], Loss: 0.5607718229293823\n",
      "Epoch [6832/10000], Loss: 0.5607719421386719\n",
      "Epoch [6833/10000], Loss: 0.5607722401618958\n",
      "Epoch [6834/10000], Loss: 0.5607728362083435\n",
      "Epoch [6835/10000], Loss: 0.5607739090919495\n",
      "Epoch [6836/10000], Loss: 0.5607753992080688\n",
      "Epoch [6837/10000], Loss: 0.5607772469520569\n",
      "Epoch [6838/10000], Loss: 0.5607793927192688\n",
      "Epoch [6839/10000], Loss: 0.5607818365097046\n",
      "Epoch [6840/10000], Loss: 0.5607851147651672\n",
      "Epoch [6841/10000], Loss: 0.5607876181602478\n",
      "Epoch [6842/10000], Loss: 0.5607895255088806\n",
      "Epoch [6843/10000], Loss: 0.5607895255088806\n",
      "Epoch [6844/10000], Loss: 0.5607882738113403\n",
      "Epoch [6845/10000], Loss: 0.5607852935791016\n",
      "Epoch [6846/10000], Loss: 0.5607814192771912\n",
      "Epoch [6847/10000], Loss: 0.5607772469520569\n",
      "Epoch [6848/10000], Loss: 0.5607739090919495\n",
      "Epoch [6849/10000], Loss: 0.5607710480690002\n",
      "Epoch [6850/10000], Loss: 0.5607695579528809\n",
      "Epoch [6851/10000], Loss: 0.5607691407203674\n",
      "Epoch [6852/10000], Loss: 0.56076979637146\n",
      "Epoch [6853/10000], Loss: 0.5607703924179077\n",
      "Epoch [6854/10000], Loss: 0.5607713460922241\n",
      "Epoch [6855/10000], Loss: 0.5607722401618958\n",
      "Epoch [6856/10000], Loss: 0.5607725977897644\n",
      "Epoch [6857/10000], Loss: 0.5607737898826599\n",
      "Epoch [6858/10000], Loss: 0.5607749819755554\n",
      "Epoch [6859/10000], Loss: 0.560775637626648\n",
      "Epoch [6860/10000], Loss: 0.560775637626648\n",
      "Epoch [6861/10000], Loss: 0.5607747435569763\n",
      "Epoch [6862/10000], Loss: 0.5607736110687256\n",
      "Epoch [6863/10000], Loss: 0.5607723593711853\n",
      "Epoch [6864/10000], Loss: 0.5607712864875793\n",
      "Epoch [6865/10000], Loss: 0.5607708096504211\n",
      "Epoch [6866/10000], Loss: 0.5607702732086182\n",
      "Epoch [6867/10000], Loss: 0.5607703924179077\n",
      "Epoch [6868/10000], Loss: 0.5607712864875793\n",
      "Epoch [6869/10000], Loss: 0.5607729554176331\n",
      "Epoch [6870/10000], Loss: 0.560774564743042\n",
      "Epoch [6871/10000], Loss: 0.5607759356498718\n",
      "Epoch [6872/10000], Loss: 0.560775876045227\n",
      "Epoch [6873/10000], Loss: 0.5607747435569763\n",
      "Epoch [6874/10000], Loss: 0.560773491859436\n",
      "Epoch [6875/10000], Loss: 0.5607723593711853\n",
      "Epoch [6876/10000], Loss: 0.5607720017433167\n",
      "Epoch [6877/10000], Loss: 0.5607714056968689\n",
      "Epoch [6878/10000], Loss: 0.5607717037200928\n",
      "Epoch [6879/10000], Loss: 0.560771644115448\n",
      "Epoch [6880/10000], Loss: 0.560771644115448\n",
      "Epoch [6881/10000], Loss: 0.5607717633247375\n",
      "Epoch [6882/10000], Loss: 0.5607720613479614\n",
      "Epoch [6883/10000], Loss: 0.5607729554176331\n",
      "Epoch [6884/10000], Loss: 0.560773491859436\n",
      "Epoch [6885/10000], Loss: 0.5607726573944092\n",
      "Epoch [6886/10000], Loss: 0.5607720613479614\n",
      "Epoch [6887/10000], Loss: 0.5607712864875793\n",
      "Epoch [6888/10000], Loss: 0.5607704520225525\n",
      "Epoch [6889/10000], Loss: 0.5607702732086182\n",
      "Epoch [6890/10000], Loss: 0.5607699751853943\n",
      "Epoch [6891/10000], Loss: 0.5607701539993286\n",
      "Epoch [6892/10000], Loss: 0.56076979637146\n",
      "Epoch [6893/10000], Loss: 0.5607697367668152\n",
      "Epoch [6894/10000], Loss: 0.5607704520225525\n",
      "Epoch [6895/10000], Loss: 0.5607709884643555\n",
      "Epoch [6896/10000], Loss: 0.5607712864875793\n",
      "Epoch [6897/10000], Loss: 0.5607723593711853\n",
      "Epoch [6898/10000], Loss: 0.5607733726501465\n",
      "Epoch [6899/10000], Loss: 0.5607742071151733\n",
      "Epoch [6900/10000], Loss: 0.5607757568359375\n",
      "Epoch [6901/10000], Loss: 0.5607777237892151\n",
      "Epoch [6902/10000], Loss: 0.5607785582542419\n",
      "Epoch [6903/10000], Loss: 0.5607795119285583\n",
      "Epoch [6904/10000], Loss: 0.5607795715332031\n",
      "Epoch [6905/10000], Loss: 0.5607793927192688\n",
      "Epoch [6906/10000], Loss: 0.5607784986495972\n",
      "Epoch [6907/10000], Loss: 0.560777485370636\n",
      "Epoch [6908/10000], Loss: 0.560775876045227\n",
      "Epoch [6909/10000], Loss: 0.5607752799987793\n",
      "Epoch [6910/10000], Loss: 0.5607743859291077\n",
      "Epoch [6911/10000], Loss: 0.5607739686965942\n",
      "Epoch [6912/10000], Loss: 0.5607738494873047\n",
      "Epoch [6913/10000], Loss: 0.5607739686965942\n",
      "Epoch [6914/10000], Loss: 0.560774564743042\n",
      "Epoch [6915/10000], Loss: 0.5607746243476868\n",
      "Epoch [6916/10000], Loss: 0.5607744455337524\n",
      "Epoch [6917/10000], Loss: 0.560774028301239\n",
      "Epoch [6918/10000], Loss: 0.5607736706733704\n",
      "Epoch [6919/10000], Loss: 0.5607730746269226\n",
      "Epoch [6920/10000], Loss: 0.5607718229293823\n",
      "Epoch [6921/10000], Loss: 0.5607709884643555\n",
      "Epoch [6922/10000], Loss: 0.5607706308364868\n",
      "Epoch [6923/10000], Loss: 0.5607702732086182\n",
      "Epoch [6924/10000], Loss: 0.5607699155807495\n",
      "Epoch [6925/10000], Loss: 0.5607697367668152\n",
      "Epoch [6926/10000], Loss: 0.5607697367668152\n",
      "Epoch [6927/10000], Loss: 0.5607697367668152\n",
      "Epoch [6928/10000], Loss: 0.5607697367668152\n",
      "Epoch [6929/10000], Loss: 0.5607701539993286\n",
      "Epoch [6930/10000], Loss: 0.5607706904411316\n",
      "Epoch [6931/10000], Loss: 0.5607710480690002\n",
      "Epoch [6932/10000], Loss: 0.5607718825340271\n",
      "Epoch [6933/10000], Loss: 0.5607728362083435\n",
      "Epoch [6934/10000], Loss: 0.5607743263244629\n",
      "Epoch [6935/10000], Loss: 0.5607760548591614\n",
      "Epoch [6936/10000], Loss: 0.5607776045799255\n",
      "Epoch [6937/10000], Loss: 0.5607782602310181\n",
      "Epoch [6938/10000], Loss: 0.5607790946960449\n",
      "Epoch [6939/10000], Loss: 0.5607784390449524\n",
      "Epoch [6940/10000], Loss: 0.5607766509056091\n",
      "Epoch [6941/10000], Loss: 0.5607751607894897\n",
      "Epoch [6942/10000], Loss: 0.5607731938362122\n",
      "Epoch [6943/10000], Loss: 0.5607717037200928\n",
      "Epoch [6944/10000], Loss: 0.5607705116271973\n",
      "Epoch [6945/10000], Loss: 0.5607702136039734\n",
      "Epoch [6946/10000], Loss: 0.5607700347900391\n",
      "Epoch [6947/10000], Loss: 0.5607707500457764\n",
      "Epoch [6948/10000], Loss: 0.5607714056968689\n",
      "Epoch [6949/10000], Loss: 0.5607722401618958\n",
      "Epoch [6950/10000], Loss: 0.560773491859436\n",
      "Epoch [6951/10000], Loss: 0.5607742071151733\n",
      "Epoch [6952/10000], Loss: 0.5607755780220032\n",
      "Epoch [6953/10000], Loss: 0.5607765316963196\n",
      "Epoch [6954/10000], Loss: 0.5607767105102539\n",
      "Epoch [6955/10000], Loss: 0.5607767701148987\n",
      "Epoch [6956/10000], Loss: 0.5607760548591614\n",
      "Epoch [6957/10000], Loss: 0.5607751607894897\n",
      "Epoch [6958/10000], Loss: 0.5607746839523315\n",
      "Epoch [6959/10000], Loss: 0.5607742667198181\n",
      "Epoch [6960/10000], Loss: 0.5607737302780151\n",
      "Epoch [6961/10000], Loss: 0.5607736110687256\n",
      "Epoch [6962/10000], Loss: 0.5607738494873047\n",
      "Epoch [6963/10000], Loss: 0.5607743859291077\n",
      "Epoch [6964/10000], Loss: 0.5607746243476868\n",
      "Epoch [6965/10000], Loss: 0.5607740879058838\n",
      "Epoch [6966/10000], Loss: 0.5607725977897644\n",
      "Epoch [6967/10000], Loss: 0.5607714056968689\n",
      "Epoch [6968/10000], Loss: 0.5607706308364868\n",
      "Epoch [6969/10000], Loss: 0.5607700347900391\n",
      "Epoch [6970/10000], Loss: 0.5607694387435913\n",
      "Epoch [6971/10000], Loss: 0.5607694983482361\n",
      "Epoch [6972/10000], Loss: 0.5607696771621704\n",
      "Epoch [6973/10000], Loss: 0.5607697367668152\n",
      "Epoch [6974/10000], Loss: 0.5607701539993286\n",
      "Epoch [6975/10000], Loss: 0.5607708096504211\n",
      "Epoch [6976/10000], Loss: 0.5607718825340271\n",
      "Epoch [6977/10000], Loss: 0.5607721209526062\n",
      "Epoch [6978/10000], Loss: 0.5607723593711853\n",
      "Epoch [6979/10000], Loss: 0.5607728958129883\n",
      "Epoch [6980/10000], Loss: 0.5607732534408569\n",
      "Epoch [6981/10000], Loss: 0.5607728362083435\n",
      "Epoch [6982/10000], Loss: 0.5607724785804749\n",
      "Epoch [6983/10000], Loss: 0.5607718825340271\n",
      "Epoch [6984/10000], Loss: 0.5607712268829346\n",
      "Epoch [6985/10000], Loss: 0.5607704520225525\n",
      "Epoch [6986/10000], Loss: 0.5607701539993286\n",
      "Epoch [6987/10000], Loss: 0.56076979637146\n",
      "Epoch [6988/10000], Loss: 0.56076979637146\n",
      "Epoch [6989/10000], Loss: 0.5607700347900391\n",
      "Epoch [6990/10000], Loss: 0.5607703924179077\n",
      "Epoch [6991/10000], Loss: 0.5607707500457764\n",
      "Epoch [6992/10000], Loss: 0.5607714056968689\n",
      "Epoch [6993/10000], Loss: 0.5607722997665405\n",
      "Epoch [6994/10000], Loss: 0.5607742071151733\n",
      "Epoch [6995/10000], Loss: 0.5607762336730957\n",
      "Epoch [6996/10000], Loss: 0.5607789158821106\n",
      "Epoch [6997/10000], Loss: 0.5607826709747314\n",
      "Epoch [6998/10000], Loss: 0.5607870221138\n",
      "Epoch [6999/10000], Loss: 0.5607914328575134\n",
      "Epoch [7000/10000], Loss: 0.5607956051826477\n",
      "Epoch [7001/10000], Loss: 0.5607972145080566\n",
      "Epoch [7002/10000], Loss: 0.5607962012290955\n",
      "Epoch [7003/10000], Loss: 0.560792088508606\n",
      "Epoch [7004/10000], Loss: 0.5607854723930359\n",
      "Epoch [7005/10000], Loss: 0.560778796672821\n",
      "Epoch [7006/10000], Loss: 0.5607737898826599\n",
      "Epoch [7007/10000], Loss: 0.5607713460922241\n",
      "Epoch [7008/10000], Loss: 0.5607712268829346\n",
      "Epoch [7009/10000], Loss: 0.5607725381851196\n",
      "Epoch [7010/10000], Loss: 0.5607745051383972\n",
      "Epoch [7011/10000], Loss: 0.56077641248703\n",
      "Epoch [7012/10000], Loss: 0.5607776641845703\n",
      "Epoch [7013/10000], Loss: 0.5607783198356628\n",
      "Epoch [7014/10000], Loss: 0.5607782006263733\n",
      "Epoch [7015/10000], Loss: 0.5607771873474121\n",
      "Epoch [7016/10000], Loss: 0.5607760548591614\n",
      "Epoch [7017/10000], Loss: 0.5607743859291077\n",
      "Epoch [7018/10000], Loss: 0.5607734322547913\n",
      "Epoch [7019/10000], Loss: 0.5607726573944092\n",
      "Epoch [7020/10000], Loss: 0.5607721209526062\n",
      "Epoch [7021/10000], Loss: 0.5607721209526062\n",
      "Epoch [7022/10000], Loss: 0.5607719421386719\n",
      "Epoch [7023/10000], Loss: 0.5607721209526062\n",
      "Epoch [7024/10000], Loss: 0.5607720017433167\n",
      "Epoch [7025/10000], Loss: 0.5607708692550659\n",
      "Epoch [7026/10000], Loss: 0.5607708096504211\n",
      "Epoch [7027/10000], Loss: 0.5607708096504211\n",
      "Epoch [7028/10000], Loss: 0.560771107673645\n",
      "Epoch [7029/10000], Loss: 0.5607713460922241\n",
      "Epoch [7030/10000], Loss: 0.560771644115448\n",
      "Epoch [7031/10000], Loss: 0.5607722997665405\n",
      "Epoch [7032/10000], Loss: 0.5607725381851196\n",
      "Epoch [7033/10000], Loss: 0.560773491859436\n",
      "Epoch [7034/10000], Loss: 0.5607743859291077\n",
      "Epoch [7035/10000], Loss: 0.5607743263244629\n",
      "Epoch [7036/10000], Loss: 0.5607742667198181\n",
      "Epoch [7037/10000], Loss: 0.5607737302780151\n",
      "Epoch [7038/10000], Loss: 0.5607730150222778\n",
      "Epoch [7039/10000], Loss: 0.5607723593711853\n",
      "Epoch [7040/10000], Loss: 0.5607712864875793\n",
      "Epoch [7041/10000], Loss: 0.5607708096504211\n",
      "Epoch [7042/10000], Loss: 0.5607704520225525\n",
      "Epoch [7043/10000], Loss: 0.5607699751853943\n",
      "Epoch [7044/10000], Loss: 0.5607697367668152\n",
      "Epoch [7045/10000], Loss: 0.5607694387435913\n",
      "Epoch [7046/10000], Loss: 0.5607694387435913\n",
      "Epoch [7047/10000], Loss: 0.5607690215110779\n",
      "Epoch [7048/10000], Loss: 0.5607688426971436\n",
      "Epoch [7049/10000], Loss: 0.5607692003250122\n",
      "Epoch [7050/10000], Loss: 0.5607689619064331\n",
      "Epoch [7051/10000], Loss: 0.5607693195343018\n",
      "Epoch [7052/10000], Loss: 0.5607696175575256\n",
      "Epoch [7053/10000], Loss: 0.5607699155807495\n",
      "Epoch [7054/10000], Loss: 0.5607700347900391\n",
      "Epoch [7055/10000], Loss: 0.5607703924179077\n",
      "Epoch [7056/10000], Loss: 0.5607709884643555\n",
      "Epoch [7057/10000], Loss: 0.5607714653015137\n",
      "Epoch [7058/10000], Loss: 0.560772180557251\n",
      "Epoch [7059/10000], Loss: 0.5607722401618958\n",
      "Epoch [7060/10000], Loss: 0.560772716999054\n",
      "Epoch [7061/10000], Loss: 0.5607730746269226\n",
      "Epoch [7062/10000], Loss: 0.5607738494873047\n",
      "Epoch [7063/10000], Loss: 0.5607749819755554\n",
      "Epoch [7064/10000], Loss: 0.560775876045227\n",
      "Epoch [7065/10000], Loss: 0.5607767701148987\n",
      "Epoch [7066/10000], Loss: 0.5607773065567017\n",
      "Epoch [7067/10000], Loss: 0.5607773065567017\n",
      "Epoch [7068/10000], Loss: 0.5607767105102539\n",
      "Epoch [7069/10000], Loss: 0.5607757568359375\n",
      "Epoch [7070/10000], Loss: 0.560775101184845\n",
      "Epoch [7071/10000], Loss: 0.5607741475105286\n",
      "Epoch [7072/10000], Loss: 0.560773491859436\n",
      "Epoch [7073/10000], Loss: 0.5607727766036987\n",
      "Epoch [7074/10000], Loss: 0.560772180557251\n",
      "Epoch [7075/10000], Loss: 0.560772180557251\n",
      "Epoch [7076/10000], Loss: 0.560771644115448\n",
      "Epoch [7077/10000], Loss: 0.5607714056968689\n",
      "Epoch [7078/10000], Loss: 0.5607712864875793\n",
      "Epoch [7079/10000], Loss: 0.5607711672782898\n",
      "Epoch [7080/10000], Loss: 0.5607709884643555\n",
      "Epoch [7081/10000], Loss: 0.5607713460922241\n",
      "Epoch [7082/10000], Loss: 0.5607715845108032\n",
      "Epoch [7083/10000], Loss: 0.5607717633247375\n",
      "Epoch [7084/10000], Loss: 0.560771644115448\n",
      "Epoch [7085/10000], Loss: 0.5607719421386719\n",
      "Epoch [7086/10000], Loss: 0.5607720017433167\n",
      "Epoch [7087/10000], Loss: 0.5607718825340271\n",
      "Epoch [7088/10000], Loss: 0.5607712268829346\n",
      "Epoch [7089/10000], Loss: 0.5607707500457764\n",
      "Epoch [7090/10000], Loss: 0.5607703924179077\n",
      "Epoch [7091/10000], Loss: 0.5607699155807495\n",
      "Epoch [7092/10000], Loss: 0.5607697367668152\n",
      "Epoch [7093/10000], Loss: 0.5607697367668152\n",
      "Epoch [7094/10000], Loss: 0.5607697367668152\n",
      "Epoch [7095/10000], Loss: 0.5607698559761047\n",
      "Epoch [7096/10000], Loss: 0.5607700943946838\n",
      "Epoch [7097/10000], Loss: 0.5607708692550659\n",
      "Epoch [7098/10000], Loss: 0.5607718229293823\n",
      "Epoch [7099/10000], Loss: 0.5607726573944092\n",
      "Epoch [7100/10000], Loss: 0.5607739090919495\n",
      "Epoch [7101/10000], Loss: 0.5607748627662659\n",
      "Epoch [7102/10000], Loss: 0.560775101184845\n",
      "Epoch [7103/10000], Loss: 0.5607746839523315\n",
      "Epoch [7104/10000], Loss: 0.5607731342315674\n",
      "Epoch [7105/10000], Loss: 0.5607717037200928\n",
      "Epoch [7106/10000], Loss: 0.5607703328132629\n",
      "Epoch [7107/10000], Loss: 0.5607694387435913\n",
      "Epoch [7108/10000], Loss: 0.5607690811157227\n",
      "Epoch [7109/10000], Loss: 0.560768723487854\n",
      "Epoch [7110/10000], Loss: 0.5607690215110779\n",
      "Epoch [7111/10000], Loss: 0.5607695579528809\n",
      "Epoch [7112/10000], Loss: 0.5607703924179077\n",
      "Epoch [7113/10000], Loss: 0.5607714653015137\n",
      "Epoch [7114/10000], Loss: 0.5607733726501465\n",
      "Epoch [7115/10000], Loss: 0.5607759356498718\n",
      "Epoch [7116/10000], Loss: 0.5607792139053345\n",
      "Epoch [7117/10000], Loss: 0.5607823729515076\n",
      "Epoch [7118/10000], Loss: 0.5607854723930359\n",
      "Epoch [7119/10000], Loss: 0.5607884526252747\n",
      "Epoch [7120/10000], Loss: 0.5607909560203552\n",
      "Epoch [7121/10000], Loss: 0.5607918500900269\n",
      "Epoch [7122/10000], Loss: 0.5607914924621582\n",
      "Epoch [7123/10000], Loss: 0.5607892870903015\n",
      "Epoch [7124/10000], Loss: 0.5607856512069702\n",
      "Epoch [7125/10000], Loss: 0.5607812404632568\n",
      "Epoch [7126/10000], Loss: 0.5607772469520569\n",
      "Epoch [7127/10000], Loss: 0.560774028301239\n",
      "Epoch [7128/10000], Loss: 0.5607724785804749\n",
      "Epoch [7129/10000], Loss: 0.5607712864875793\n",
      "Epoch [7130/10000], Loss: 0.5607710480690002\n",
      "Epoch [7131/10000], Loss: 0.5607715249061584\n",
      "Epoch [7132/10000], Loss: 0.5607725977897644\n",
      "Epoch [7133/10000], Loss: 0.5607739686965942\n",
      "Epoch [7134/10000], Loss: 0.5607748031616211\n",
      "Epoch [7135/10000], Loss: 0.5607744455337524\n",
      "Epoch [7136/10000], Loss: 0.5607736706733704\n",
      "Epoch [7137/10000], Loss: 0.5607721209526062\n",
      "Epoch [7138/10000], Loss: 0.560771107673645\n",
      "Epoch [7139/10000], Loss: 0.5607706904411316\n",
      "Epoch [7140/10000], Loss: 0.5607704520225525\n",
      "Epoch [7141/10000], Loss: 0.5607709288597107\n",
      "Epoch [7142/10000], Loss: 0.5607713460922241\n",
      "Epoch [7143/10000], Loss: 0.5607720613479614\n",
      "Epoch [7144/10000], Loss: 0.5607728958129883\n",
      "Epoch [7145/10000], Loss: 0.5607739686965942\n",
      "Epoch [7146/10000], Loss: 0.5607744455337524\n",
      "Epoch [7147/10000], Loss: 0.5607743263244629\n",
      "Epoch [7148/10000], Loss: 0.5607732534408569\n",
      "Epoch [7149/10000], Loss: 0.5607725381851196\n",
      "Epoch [7150/10000], Loss: 0.5607718229293823\n",
      "Epoch [7151/10000], Loss: 0.5607711672782898\n",
      "Epoch [7152/10000], Loss: 0.5607712268829346\n",
      "Epoch [7153/10000], Loss: 0.5607708692550659\n",
      "Epoch [7154/10000], Loss: 0.5607702136039734\n",
      "Epoch [7155/10000], Loss: 0.5607699155807495\n",
      "Epoch [7156/10000], Loss: 0.5607695579528809\n",
      "Epoch [7157/10000], Loss: 0.5607691407203674\n",
      "Epoch [7158/10000], Loss: 0.5607689023017883\n",
      "Epoch [7159/10000], Loss: 0.5607686042785645\n",
      "Epoch [7160/10000], Loss: 0.5607683658599854\n",
      "Epoch [7161/10000], Loss: 0.5607684254646301\n",
      "Epoch [7162/10000], Loss: 0.5607684254646301\n",
      "Epoch [7163/10000], Loss: 0.5607684850692749\n",
      "Epoch [7164/10000], Loss: 0.5607693791389465\n",
      "Epoch [7165/10000], Loss: 0.5607704520225525\n",
      "Epoch [7166/10000], Loss: 0.5607718229293823\n",
      "Epoch [7167/10000], Loss: 0.560773491859436\n",
      "Epoch [7168/10000], Loss: 0.5607746243476868\n",
      "Epoch [7169/10000], Loss: 0.5607753992080688\n",
      "Epoch [7170/10000], Loss: 0.5607751607894897\n",
      "Epoch [7171/10000], Loss: 0.560774028301239\n",
      "Epoch [7172/10000], Loss: 0.5607728958129883\n",
      "Epoch [7173/10000], Loss: 0.5607718825340271\n",
      "Epoch [7174/10000], Loss: 0.5607718825340271\n",
      "Epoch [7175/10000], Loss: 0.5607726573944092\n",
      "Epoch [7176/10000], Loss: 0.5607733130455017\n",
      "Epoch [7177/10000], Loss: 0.5607746243476868\n",
      "Epoch [7178/10000], Loss: 0.5607761144638062\n",
      "Epoch [7179/10000], Loss: 0.5607768893241882\n",
      "Epoch [7180/10000], Loss: 0.5607773065567017\n",
      "Epoch [7181/10000], Loss: 0.5607775449752808\n",
      "Epoch [7182/10000], Loss: 0.560776948928833\n",
      "Epoch [7183/10000], Loss: 0.5607762932777405\n",
      "Epoch [7184/10000], Loss: 0.5607751607894897\n",
      "Epoch [7185/10000], Loss: 0.5607737898826599\n",
      "Epoch [7186/10000], Loss: 0.5607727766036987\n",
      "Epoch [7187/10000], Loss: 0.5607721209526062\n",
      "Epoch [7188/10000], Loss: 0.5607718825340271\n",
      "Epoch [7189/10000], Loss: 0.5607720017433167\n",
      "Epoch [7190/10000], Loss: 0.5607724785804749\n",
      "Epoch [7191/10000], Loss: 0.5607725977897644\n",
      "Epoch [7192/10000], Loss: 0.5607729554176331\n",
      "Epoch [7193/10000], Loss: 0.5607730150222778\n",
      "Epoch [7194/10000], Loss: 0.5607724785804749\n",
      "Epoch [7195/10000], Loss: 0.560771107673645\n",
      "Epoch [7196/10000], Loss: 0.5607704520225525\n",
      "Epoch [7197/10000], Loss: 0.5607702136039734\n",
      "Epoch [7198/10000], Loss: 0.5607699751853943\n",
      "Epoch [7199/10000], Loss: 0.5607702732086182\n",
      "Epoch [7200/10000], Loss: 0.5607709288597107\n",
      "Epoch [7201/10000], Loss: 0.5607714056968689\n",
      "Epoch [7202/10000], Loss: 0.5607722401618958\n",
      "Epoch [7203/10000], Loss: 0.5607733130455017\n",
      "Epoch [7204/10000], Loss: 0.5607737898826599\n",
      "Epoch [7205/10000], Loss: 0.5607736110687256\n",
      "Epoch [7206/10000], Loss: 0.5607739090919495\n",
      "Epoch [7207/10000], Loss: 0.5607735514640808\n",
      "Epoch [7208/10000], Loss: 0.5607725381851196\n",
      "Epoch [7209/10000], Loss: 0.5607717633247375\n",
      "Epoch [7210/10000], Loss: 0.5607711672782898\n",
      "Epoch [7211/10000], Loss: 0.5607706308364868\n",
      "Epoch [7212/10000], Loss: 0.5607704520225525\n",
      "Epoch [7213/10000], Loss: 0.5607706308364868\n",
      "Epoch [7214/10000], Loss: 0.5607706904411316\n",
      "Epoch [7215/10000], Loss: 0.560771644115448\n",
      "Epoch [7216/10000], Loss: 0.5607732534408569\n",
      "Epoch [7217/10000], Loss: 0.5607758164405823\n",
      "Epoch [7218/10000], Loss: 0.5607786178588867\n",
      "Epoch [7219/10000], Loss: 0.5607818961143494\n",
      "Epoch [7220/10000], Loss: 0.5607857704162598\n",
      "Epoch [7221/10000], Loss: 0.5607885122299194\n",
      "Epoch [7222/10000], Loss: 0.5607897043228149\n",
      "Epoch [7223/10000], Loss: 0.5607893466949463\n",
      "Epoch [7224/10000], Loss: 0.5607870221138\n",
      "Epoch [7225/10000], Loss: 0.5607833862304688\n",
      "Epoch [7226/10000], Loss: 0.5607797503471375\n",
      "Epoch [7227/10000], Loss: 0.5607759356498718\n",
      "Epoch [7228/10000], Loss: 0.5607730150222778\n",
      "Epoch [7229/10000], Loss: 0.5607708096504211\n",
      "Epoch [7230/10000], Loss: 0.5607693195343018\n",
      "Epoch [7231/10000], Loss: 0.560769259929657\n",
      "Epoch [7232/10000], Loss: 0.5607694387435913\n",
      "Epoch [7233/10000], Loss: 0.5607702136039734\n",
      "Epoch [7234/10000], Loss: 0.5607714653015137\n",
      "Epoch [7235/10000], Loss: 0.5607730746269226\n",
      "Epoch [7236/10000], Loss: 0.5607746243476868\n",
      "Epoch [7237/10000], Loss: 0.5607761144638062\n",
      "Epoch [7238/10000], Loss: 0.5607768893241882\n",
      "Epoch [7239/10000], Loss: 0.5607770085334778\n",
      "Epoch [7240/10000], Loss: 0.5607764720916748\n",
      "Epoch [7241/10000], Loss: 0.5607750415802002\n",
      "Epoch [7242/10000], Loss: 0.560773491859436\n",
      "Epoch [7243/10000], Loss: 0.5607721209526062\n",
      "Epoch [7244/10000], Loss: 0.560771107673645\n",
      "Epoch [7245/10000], Loss: 0.5607701539993286\n",
      "Epoch [7246/10000], Loss: 0.5607699155807495\n",
      "Epoch [7247/10000], Loss: 0.56076979637146\n",
      "Epoch [7248/10000], Loss: 0.5607700347900391\n",
      "Epoch [7249/10000], Loss: 0.5607709288597107\n",
      "Epoch [7250/10000], Loss: 0.5607708692550659\n",
      "Epoch [7251/10000], Loss: 0.5607709288597107\n",
      "Epoch [7252/10000], Loss: 0.5607715845108032\n",
      "Epoch [7253/10000], Loss: 0.5607718229293823\n",
      "Epoch [7254/10000], Loss: 0.5607718229293823\n",
      "Epoch [7255/10000], Loss: 0.5607713460922241\n",
      "Epoch [7256/10000], Loss: 0.5607702732086182\n",
      "Epoch [7257/10000], Loss: 0.56076979637146\n",
      "Epoch [7258/10000], Loss: 0.56076979637146\n",
      "Epoch [7259/10000], Loss: 0.560769259929657\n",
      "Epoch [7260/10000], Loss: 0.5607693195343018\n",
      "Epoch [7261/10000], Loss: 0.5607699751853943\n",
      "Epoch [7262/10000], Loss: 0.5607700943946838\n",
      "Epoch [7263/10000], Loss: 0.5607711672782898\n",
      "Epoch [7264/10000], Loss: 0.5607718229293823\n",
      "Epoch [7265/10000], Loss: 0.5607721209526062\n",
      "Epoch [7266/10000], Loss: 0.5607730746269226\n",
      "Epoch [7267/10000], Loss: 0.560773491859436\n",
      "Epoch [7268/10000], Loss: 0.5607731342315674\n",
      "Epoch [7269/10000], Loss: 0.560772716999054\n",
      "Epoch [7270/10000], Loss: 0.5607725381851196\n",
      "Epoch [7271/10000], Loss: 0.5607723593711853\n",
      "Epoch [7272/10000], Loss: 0.5607722401618958\n",
      "Epoch [7273/10000], Loss: 0.5607724785804749\n",
      "Epoch [7274/10000], Loss: 0.5607729554176331\n",
      "Epoch [7275/10000], Loss: 0.5607737898826599\n",
      "Epoch [7276/10000], Loss: 0.5607742071151733\n",
      "Epoch [7277/10000], Loss: 0.5607744455337524\n",
      "Epoch [7278/10000], Loss: 0.5607746243476868\n",
      "Epoch [7279/10000], Loss: 0.5607743263244629\n",
      "Epoch [7280/10000], Loss: 0.560774028301239\n",
      "Epoch [7281/10000], Loss: 0.5607737302780151\n",
      "Epoch [7282/10000], Loss: 0.5607731938362122\n",
      "Epoch [7283/10000], Loss: 0.5607725977897644\n",
      "Epoch [7284/10000], Loss: 0.5607720017433167\n",
      "Epoch [7285/10000], Loss: 0.5607715845108032\n",
      "Epoch [7286/10000], Loss: 0.5607713460922241\n",
      "Epoch [7287/10000], Loss: 0.5607714653015137\n",
      "Epoch [7288/10000], Loss: 0.5607722997665405\n",
      "Epoch [7289/10000], Loss: 0.5607727766036987\n",
      "Epoch [7290/10000], Loss: 0.5607730746269226\n",
      "Epoch [7291/10000], Loss: 0.5607726573944092\n",
      "Epoch [7292/10000], Loss: 0.5607720613479614\n",
      "Epoch [7293/10000], Loss: 0.5607714653015137\n",
      "Epoch [7294/10000], Loss: 0.5607709288597107\n",
      "Epoch [7295/10000], Loss: 0.5607703924179077\n",
      "Epoch [7296/10000], Loss: 0.5607699751853943\n",
      "Epoch [7297/10000], Loss: 0.5607699155807495\n",
      "Epoch [7298/10000], Loss: 0.5607703924179077\n",
      "Epoch [7299/10000], Loss: 0.5607708692550659\n",
      "Epoch [7300/10000], Loss: 0.5607718229293823\n",
      "Epoch [7301/10000], Loss: 0.5607733726501465\n",
      "Epoch [7302/10000], Loss: 0.560775101184845\n",
      "Epoch [7303/10000], Loss: 0.5607762336730957\n",
      "Epoch [7304/10000], Loss: 0.5607767105102539\n",
      "Epoch [7305/10000], Loss: 0.5607767105102539\n",
      "Epoch [7306/10000], Loss: 0.5607759952545166\n",
      "Epoch [7307/10000], Loss: 0.5607746243476868\n",
      "Epoch [7308/10000], Loss: 0.5607730150222778\n",
      "Epoch [7309/10000], Loss: 0.560771644115448\n",
      "Epoch [7310/10000], Loss: 0.5607706904411316\n",
      "Epoch [7311/10000], Loss: 0.5607699751853943\n",
      "Epoch [7312/10000], Loss: 0.560769259929657\n",
      "Epoch [7313/10000], Loss: 0.5607689023017883\n",
      "Epoch [7314/10000], Loss: 0.5607690811157227\n",
      "Epoch [7315/10000], Loss: 0.5607690811157227\n",
      "Epoch [7316/10000], Loss: 0.5607699751853943\n",
      "Epoch [7317/10000], Loss: 0.5607708096504211\n",
      "Epoch [7318/10000], Loss: 0.5607709288597107\n",
      "Epoch [7319/10000], Loss: 0.5607719421386719\n",
      "Epoch [7320/10000], Loss: 0.5607722997665405\n",
      "Epoch [7321/10000], Loss: 0.5607722997665405\n",
      "Epoch [7322/10000], Loss: 0.560772180557251\n",
      "Epoch [7323/10000], Loss: 0.5607722401618958\n",
      "Epoch [7324/10000], Loss: 0.5607724785804749\n",
      "Epoch [7325/10000], Loss: 0.5607728958129883\n",
      "Epoch [7326/10000], Loss: 0.5607733130455017\n",
      "Epoch [7327/10000], Loss: 0.5607743859291077\n",
      "Epoch [7328/10000], Loss: 0.5607755184173584\n",
      "Epoch [7329/10000], Loss: 0.5607767105102539\n",
      "Epoch [7330/10000], Loss: 0.5607783198356628\n",
      "Epoch [7331/10000], Loss: 0.560779869556427\n",
      "Epoch [7332/10000], Loss: 0.5607808828353882\n",
      "Epoch [7333/10000], Loss: 0.5607816576957703\n",
      "Epoch [7334/10000], Loss: 0.5607823133468628\n",
      "Epoch [7335/10000], Loss: 0.5607820749282837\n",
      "Epoch [7336/10000], Loss: 0.560780942440033\n",
      "Epoch [7337/10000], Loss: 0.5607790350914001\n",
      "Epoch [7338/10000], Loss: 0.5607767105102539\n",
      "Epoch [7339/10000], Loss: 0.5607742071151733\n",
      "Epoch [7340/10000], Loss: 0.5607720613479614\n",
      "Epoch [7341/10000], Loss: 0.5607705116271973\n",
      "Epoch [7342/10000], Loss: 0.5607696175575256\n",
      "Epoch [7343/10000], Loss: 0.5607695579528809\n",
      "Epoch [7344/10000], Loss: 0.5607702136039734\n",
      "Epoch [7345/10000], Loss: 0.5607713460922241\n",
      "Epoch [7346/10000], Loss: 0.5607726573944092\n",
      "Epoch [7347/10000], Loss: 0.5607748031616211\n",
      "Epoch [7348/10000], Loss: 0.5607765316963196\n",
      "Epoch [7349/10000], Loss: 0.5607778429985046\n",
      "Epoch [7350/10000], Loss: 0.5607776641845703\n",
      "Epoch [7351/10000], Loss: 0.5607759952545166\n",
      "Epoch [7352/10000], Loss: 0.5607738494873047\n",
      "Epoch [7353/10000], Loss: 0.5607720613479614\n",
      "Epoch [7354/10000], Loss: 0.5607708096504211\n",
      "Epoch [7355/10000], Loss: 0.56076979637146\n",
      "Epoch [7356/10000], Loss: 0.5607689619064331\n",
      "Epoch [7357/10000], Loss: 0.5607689619064331\n",
      "Epoch [7358/10000], Loss: 0.5607696771621704\n",
      "Epoch [7359/10000], Loss: 0.5607699155807495\n",
      "Epoch [7360/10000], Loss: 0.5607704520225525\n",
      "Epoch [7361/10000], Loss: 0.560771107673645\n",
      "Epoch [7362/10000], Loss: 0.5607713460922241\n",
      "Epoch [7363/10000], Loss: 0.5607715845108032\n",
      "Epoch [7364/10000], Loss: 0.5607715249061584\n",
      "Epoch [7365/10000], Loss: 0.5607710480690002\n",
      "Epoch [7366/10000], Loss: 0.5607706308364868\n",
      "Epoch [7367/10000], Loss: 0.5607701539993286\n",
      "Epoch [7368/10000], Loss: 0.5607696175575256\n",
      "Epoch [7369/10000], Loss: 0.5607687830924988\n",
      "Epoch [7370/10000], Loss: 0.5607692003250122\n",
      "Epoch [7371/10000], Loss: 0.5607696771621704\n",
      "Epoch [7372/10000], Loss: 0.5607706904411316\n",
      "Epoch [7373/10000], Loss: 0.5607720017433167\n",
      "Epoch [7374/10000], Loss: 0.5607739090919495\n",
      "Epoch [7375/10000], Loss: 0.5607760548591614\n",
      "Epoch [7376/10000], Loss: 0.5607786178588867\n",
      "Epoch [7377/10000], Loss: 0.5607811212539673\n",
      "Epoch [7378/10000], Loss: 0.5607821345329285\n",
      "Epoch [7379/10000], Loss: 0.5607811808586121\n",
      "Epoch [7380/10000], Loss: 0.560779333114624\n",
      "Epoch [7381/10000], Loss: 0.5607766509056091\n",
      "Epoch [7382/10000], Loss: 0.5607742667198181\n",
      "Epoch [7383/10000], Loss: 0.5607728958129883\n",
      "Epoch [7384/10000], Loss: 0.5607721209526062\n",
      "Epoch [7385/10000], Loss: 0.5607719421386719\n",
      "Epoch [7386/10000], Loss: 0.5607722401618958\n",
      "Epoch [7387/10000], Loss: 0.5607730746269226\n",
      "Epoch [7388/10000], Loss: 0.5607738494873047\n",
      "Epoch [7389/10000], Loss: 0.5607737898826599\n",
      "Epoch [7390/10000], Loss: 0.5607737302780151\n",
      "Epoch [7391/10000], Loss: 0.5607731938362122\n",
      "Epoch [7392/10000], Loss: 0.5607719421386719\n",
      "Epoch [7393/10000], Loss: 0.5607707500457764\n",
      "Epoch [7394/10000], Loss: 0.56076979637146\n",
      "Epoch [7395/10000], Loss: 0.560769259929657\n",
      "Epoch [7396/10000], Loss: 0.5607688426971436\n",
      "Epoch [7397/10000], Loss: 0.5607684850692749\n",
      "Epoch [7398/10000], Loss: 0.5607683658599854\n",
      "Epoch [7399/10000], Loss: 0.5607685446739197\n",
      "Epoch [7400/10000], Loss: 0.5607684850692749\n",
      "Epoch [7401/10000], Loss: 0.5607684850692749\n",
      "Epoch [7402/10000], Loss: 0.5607685446739197\n",
      "Epoch [7403/10000], Loss: 0.5607690215110779\n",
      "Epoch [7404/10000], Loss: 0.560769259929657\n",
      "Epoch [7405/10000], Loss: 0.5607696771621704\n",
      "Epoch [7406/10000], Loss: 0.5607704520225525\n",
      "Epoch [7407/10000], Loss: 0.5607714056968689\n",
      "Epoch [7408/10000], Loss: 0.5607721209526062\n",
      "Epoch [7409/10000], Loss: 0.5607725977897644\n",
      "Epoch [7410/10000], Loss: 0.5607725381851196\n",
      "Epoch [7411/10000], Loss: 0.5607718825340271\n",
      "Epoch [7412/10000], Loss: 0.5607711672782898\n",
      "Epoch [7413/10000], Loss: 0.5607703924179077\n",
      "Epoch [7414/10000], Loss: 0.5607704520225525\n",
      "Epoch [7415/10000], Loss: 0.5607710480690002\n",
      "Epoch [7416/10000], Loss: 0.5607719421386719\n",
      "Epoch [7417/10000], Loss: 0.560772716999054\n",
      "Epoch [7418/10000], Loss: 0.560773491859436\n",
      "Epoch [7419/10000], Loss: 0.5607748031616211\n",
      "Epoch [7420/10000], Loss: 0.5607760548591614\n",
      "Epoch [7421/10000], Loss: 0.5607777833938599\n",
      "Epoch [7422/10000], Loss: 0.5607795119285583\n",
      "Epoch [7423/10000], Loss: 0.5607815980911255\n",
      "Epoch [7424/10000], Loss: 0.5607830882072449\n",
      "Epoch [7425/10000], Loss: 0.560784101486206\n",
      "Epoch [7426/10000], Loss: 0.5607853531837463\n",
      "Epoch [7427/10000], Loss: 0.5607860684394836\n",
      "Epoch [7428/10000], Loss: 0.5607855916023254\n",
      "Epoch [7429/10000], Loss: 0.5607838034629822\n",
      "Epoch [7430/10000], Loss: 0.5607814788818359\n",
      "Epoch [7431/10000], Loss: 0.5607790946960449\n",
      "Epoch [7432/10000], Loss: 0.5607763528823853\n",
      "Epoch [7433/10000], Loss: 0.5607741475105286\n",
      "Epoch [7434/10000], Loss: 0.560772180557251\n",
      "Epoch [7435/10000], Loss: 0.5607709288597107\n",
      "Epoch [7436/10000], Loss: 0.5607700347900391\n",
      "Epoch [7437/10000], Loss: 0.5607693195343018\n",
      "Epoch [7438/10000], Loss: 0.560768723487854\n",
      "Epoch [7439/10000], Loss: 0.5607690811157227\n",
      "Epoch [7440/10000], Loss: 0.5607702136039734\n",
      "Epoch [7441/10000], Loss: 0.560771107673645\n",
      "Epoch [7442/10000], Loss: 0.560772180557251\n",
      "Epoch [7443/10000], Loss: 0.5607725381851196\n",
      "Epoch [7444/10000], Loss: 0.5607731938362122\n",
      "Epoch [7445/10000], Loss: 0.5607737898826599\n",
      "Epoch [7446/10000], Loss: 0.5607743263244629\n",
      "Epoch [7447/10000], Loss: 0.5607739686965942\n",
      "Epoch [7448/10000], Loss: 0.5607737898826599\n",
      "Epoch [7449/10000], Loss: 0.5607731938362122\n",
      "Epoch [7450/10000], Loss: 0.560771644115448\n",
      "Epoch [7451/10000], Loss: 0.5607700347900391\n",
      "Epoch [7452/10000], Loss: 0.5607694387435913\n",
      "Epoch [7453/10000], Loss: 0.5607692003250122\n",
      "Epoch [7454/10000], Loss: 0.5607690811157227\n",
      "Epoch [7455/10000], Loss: 0.5607693791389465\n",
      "Epoch [7456/10000], Loss: 0.5607696175575256\n",
      "Epoch [7457/10000], Loss: 0.5607695579528809\n",
      "Epoch [7458/10000], Loss: 0.5607698559761047\n",
      "Epoch [7459/10000], Loss: 0.56076979637146\n",
      "Epoch [7460/10000], Loss: 0.5607702732086182\n",
      "Epoch [7461/10000], Loss: 0.5607703924179077\n",
      "Epoch [7462/10000], Loss: 0.560770571231842\n",
      "Epoch [7463/10000], Loss: 0.5607709288597107\n",
      "Epoch [7464/10000], Loss: 0.5607717633247375\n",
      "Epoch [7465/10000], Loss: 0.5607721209526062\n",
      "Epoch [7466/10000], Loss: 0.5607724785804749\n",
      "Epoch [7467/10000], Loss: 0.5607725977897644\n",
      "Epoch [7468/10000], Loss: 0.5607730150222778\n",
      "Epoch [7469/10000], Loss: 0.5607732534408569\n",
      "Epoch [7470/10000], Loss: 0.560773491859436\n",
      "Epoch [7471/10000], Loss: 0.5607736110687256\n",
      "Epoch [7472/10000], Loss: 0.5607733726501465\n",
      "Epoch [7473/10000], Loss: 0.5607735514640808\n",
      "Epoch [7474/10000], Loss: 0.5607735514640808\n",
      "Epoch [7475/10000], Loss: 0.560774028301239\n",
      "Epoch [7476/10000], Loss: 0.5607736110687256\n",
      "Epoch [7477/10000], Loss: 0.5607736110687256\n",
      "Epoch [7478/10000], Loss: 0.5607742071151733\n",
      "Epoch [7479/10000], Loss: 0.560774564743042\n",
      "Epoch [7480/10000], Loss: 0.5607753992080688\n",
      "Epoch [7481/10000], Loss: 0.5607761144638062\n",
      "Epoch [7482/10000], Loss: 0.5607767105102539\n",
      "Epoch [7483/10000], Loss: 0.5607771873474121\n",
      "Epoch [7484/10000], Loss: 0.560776948928833\n",
      "Epoch [7485/10000], Loss: 0.5607760548591614\n",
      "Epoch [7486/10000], Loss: 0.5607749223709106\n",
      "Epoch [7487/10000], Loss: 0.5607736706733704\n",
      "Epoch [7488/10000], Loss: 0.5607723593711853\n",
      "Epoch [7489/10000], Loss: 0.5607715845108032\n",
      "Epoch [7490/10000], Loss: 0.5607709884643555\n",
      "Epoch [7491/10000], Loss: 0.5607708096504211\n",
      "Epoch [7492/10000], Loss: 0.5607708096504211\n",
      "Epoch [7493/10000], Loss: 0.5607711672782898\n",
      "Epoch [7494/10000], Loss: 0.560771107673645\n",
      "Epoch [7495/10000], Loss: 0.5607707500457764\n",
      "Epoch [7496/10000], Loss: 0.5607709288597107\n",
      "Epoch [7497/10000], Loss: 0.5607709288597107\n",
      "Epoch [7498/10000], Loss: 0.5607711672782898\n",
      "Epoch [7499/10000], Loss: 0.5607715249061584\n",
      "Epoch [7500/10000], Loss: 0.560771107673645\n",
      "Epoch [7501/10000], Loss: 0.5607706308364868\n",
      "Epoch [7502/10000], Loss: 0.5607702136039734\n",
      "Epoch [7503/10000], Loss: 0.5607699155807495\n",
      "Epoch [7504/10000], Loss: 0.5607704520225525\n",
      "Epoch [7505/10000], Loss: 0.5607706904411316\n",
      "Epoch [7506/10000], Loss: 0.5607708096504211\n",
      "Epoch [7507/10000], Loss: 0.5607708096504211\n",
      "Epoch [7508/10000], Loss: 0.5607708096504211\n",
      "Epoch [7509/10000], Loss: 0.5607708096504211\n",
      "Epoch [7510/10000], Loss: 0.560771107673645\n",
      "Epoch [7511/10000], Loss: 0.5607715845108032\n",
      "Epoch [7512/10000], Loss: 0.5607723593711853\n",
      "Epoch [7513/10000], Loss: 0.5607725977897644\n",
      "Epoch [7514/10000], Loss: 0.5607727766036987\n",
      "Epoch [7515/10000], Loss: 0.5607726573944092\n",
      "Epoch [7516/10000], Loss: 0.5607728362083435\n",
      "Epoch [7517/10000], Loss: 0.5607725381851196\n",
      "Epoch [7518/10000], Loss: 0.5607722401618958\n",
      "Epoch [7519/10000], Loss: 0.5607717633247375\n",
      "Epoch [7520/10000], Loss: 0.5607708692550659\n",
      "Epoch [7521/10000], Loss: 0.5607700347900391\n",
      "Epoch [7522/10000], Loss: 0.5607697367668152\n",
      "Epoch [7523/10000], Loss: 0.5607697367668152\n",
      "Epoch [7524/10000], Loss: 0.5607699751853943\n",
      "Epoch [7525/10000], Loss: 0.560770571231842\n",
      "Epoch [7526/10000], Loss: 0.5607710480690002\n",
      "Epoch [7527/10000], Loss: 0.5607718229293823\n",
      "Epoch [7528/10000], Loss: 0.5607725381851196\n",
      "Epoch [7529/10000], Loss: 0.5607737302780151\n",
      "Epoch [7530/10000], Loss: 0.5607753992080688\n",
      "Epoch [7531/10000], Loss: 0.5607765316963196\n",
      "Epoch [7532/10000], Loss: 0.5607775449752808\n",
      "Epoch [7533/10000], Loss: 0.5607781410217285\n",
      "Epoch [7534/10000], Loss: 0.5607786774635315\n",
      "Epoch [7535/10000], Loss: 0.5607790946960449\n",
      "Epoch [7536/10000], Loss: 0.560779869556427\n",
      "Epoch [7537/10000], Loss: 0.5607814192771912\n",
      "Epoch [7538/10000], Loss: 0.5607828497886658\n",
      "Epoch [7539/10000], Loss: 0.5607842206954956\n",
      "Epoch [7540/10000], Loss: 0.5607846975326538\n",
      "Epoch [7541/10000], Loss: 0.5607843399047852\n",
      "Epoch [7542/10000], Loss: 0.5607835054397583\n",
      "Epoch [7543/10000], Loss: 0.5607816576957703\n",
      "Epoch [7544/10000], Loss: 0.5607786178588867\n",
      "Epoch [7545/10000], Loss: 0.5607755184173584\n",
      "Epoch [7546/10000], Loss: 0.5607727766036987\n",
      "Epoch [7547/10000], Loss: 0.5607706904411316\n",
      "Epoch [7548/10000], Loss: 0.5607704520225525\n",
      "Epoch [7549/10000], Loss: 0.5607708692550659\n",
      "Epoch [7550/10000], Loss: 0.5607722401618958\n",
      "Epoch [7551/10000], Loss: 0.5607733130455017\n",
      "Epoch [7552/10000], Loss: 0.560774028301239\n",
      "Epoch [7553/10000], Loss: 0.5607735514640808\n",
      "Epoch [7554/10000], Loss: 0.5607728958129883\n",
      "Epoch [7555/10000], Loss: 0.560771107673645\n",
      "Epoch [7556/10000], Loss: 0.5607697367668152\n",
      "Epoch [7557/10000], Loss: 0.5607683658599854\n",
      "Epoch [7558/10000], Loss: 0.5607679486274719\n",
      "Epoch [7559/10000], Loss: 0.5607677102088928\n",
      "Epoch [7560/10000], Loss: 0.5607677698135376\n",
      "Epoch [7561/10000], Loss: 0.5607682466506958\n",
      "Epoch [7562/10000], Loss: 0.5607690215110779\n",
      "Epoch [7563/10000], Loss: 0.5607695579528809\n",
      "Epoch [7564/10000], Loss: 0.5607700347900391\n",
      "Epoch [7565/10000], Loss: 0.5607700943946838\n",
      "Epoch [7566/10000], Loss: 0.560770571231842\n",
      "Epoch [7567/10000], Loss: 0.5607705116271973\n",
      "Epoch [7568/10000], Loss: 0.5607706308364868\n",
      "Epoch [7569/10000], Loss: 0.5607706904411316\n",
      "Epoch [7570/10000], Loss: 0.5607703328132629\n",
      "Epoch [7571/10000], Loss: 0.5607700943946838\n",
      "Epoch [7572/10000], Loss: 0.56076979637146\n",
      "Epoch [7573/10000], Loss: 0.5607700943946838\n",
      "Epoch [7574/10000], Loss: 0.5607702732086182\n",
      "Epoch [7575/10000], Loss: 0.5607707500457764\n",
      "Epoch [7576/10000], Loss: 0.5607714056968689\n",
      "Epoch [7577/10000], Loss: 0.5607721209526062\n",
      "Epoch [7578/10000], Loss: 0.5607731342315674\n",
      "Epoch [7579/10000], Loss: 0.5607735514640808\n",
      "Epoch [7580/10000], Loss: 0.5607743263244629\n",
      "Epoch [7581/10000], Loss: 0.5607749223709106\n",
      "Epoch [7582/10000], Loss: 0.5607758164405823\n",
      "Epoch [7583/10000], Loss: 0.5607756972312927\n",
      "Epoch [7584/10000], Loss: 0.5607752799987793\n",
      "Epoch [7585/10000], Loss: 0.5607744455337524\n",
      "Epoch [7586/10000], Loss: 0.5607731342315674\n",
      "Epoch [7587/10000], Loss: 0.560771644115448\n",
      "Epoch [7588/10000], Loss: 0.5607704520225525\n",
      "Epoch [7589/10000], Loss: 0.5607694983482361\n",
      "Epoch [7590/10000], Loss: 0.5607690811157227\n",
      "Epoch [7591/10000], Loss: 0.5607684850692749\n",
      "Epoch [7592/10000], Loss: 0.5607679486274719\n",
      "Epoch [7593/10000], Loss: 0.5607678890228271\n",
      "Epoch [7594/10000], Loss: 0.5607680082321167\n",
      "Epoch [7595/10000], Loss: 0.5607685446739197\n",
      "Epoch [7596/10000], Loss: 0.5607688426971436\n",
      "Epoch [7597/10000], Loss: 0.5607700347900391\n",
      "Epoch [7598/10000], Loss: 0.5607708692550659\n",
      "Epoch [7599/10000], Loss: 0.5607720017433167\n",
      "Epoch [7600/10000], Loss: 0.5607734322547913\n",
      "Epoch [7601/10000], Loss: 0.5607750415802002\n",
      "Epoch [7602/10000], Loss: 0.5607768893241882\n",
      "Epoch [7603/10000], Loss: 0.5607783794403076\n",
      "Epoch [7604/10000], Loss: 0.5607805848121643\n",
      "Epoch [7605/10000], Loss: 0.5607823729515076\n",
      "Epoch [7606/10000], Loss: 0.5607837438583374\n",
      "Epoch [7607/10000], Loss: 0.5607845187187195\n",
      "Epoch [7608/10000], Loss: 0.560784637928009\n",
      "Epoch [7609/10000], Loss: 0.5607845187187195\n",
      "Epoch [7610/10000], Loss: 0.5607835650444031\n",
      "Epoch [7611/10000], Loss: 0.5607814788818359\n",
      "Epoch [7612/10000], Loss: 0.5607792735099792\n",
      "Epoch [7613/10000], Loss: 0.5607767701148987\n",
      "Epoch [7614/10000], Loss: 0.5607748031616211\n",
      "Epoch [7615/10000], Loss: 0.560774028301239\n",
      "Epoch [7616/10000], Loss: 0.5607738494873047\n",
      "Epoch [7617/10000], Loss: 0.560774028301239\n",
      "Epoch [7618/10000], Loss: 0.5607743263244629\n",
      "Epoch [7619/10000], Loss: 0.5607742071151733\n",
      "Epoch [7620/10000], Loss: 0.5607736110687256\n",
      "Epoch [7621/10000], Loss: 0.5607718825340271\n",
      "Epoch [7622/10000], Loss: 0.56076979637146\n",
      "Epoch [7623/10000], Loss: 0.5607686638832092\n",
      "Epoch [7624/10000], Loss: 0.5607680082321167\n",
      "Epoch [7625/10000], Loss: 0.560767650604248\n",
      "Epoch [7626/10000], Loss: 0.560767412185669\n",
      "Epoch [7627/10000], Loss: 0.560767650604248\n",
      "Epoch [7628/10000], Loss: 0.5607678890228271\n",
      "Epoch [7629/10000], Loss: 0.5607687830924988\n",
      "Epoch [7630/10000], Loss: 0.5607694983482361\n",
      "Epoch [7631/10000], Loss: 0.5607708692550659\n",
      "Epoch [7632/10000], Loss: 0.5607720017433167\n",
      "Epoch [7633/10000], Loss: 0.5607730746269226\n",
      "Epoch [7634/10000], Loss: 0.5607737302780151\n",
      "Epoch [7635/10000], Loss: 0.5607742071151733\n",
      "Epoch [7636/10000], Loss: 0.5607739090919495\n",
      "Epoch [7637/10000], Loss: 0.5607738494873047\n",
      "Epoch [7638/10000], Loss: 0.5607739090919495\n",
      "Epoch [7639/10000], Loss: 0.5607739686965942\n",
      "Epoch [7640/10000], Loss: 0.5607736110687256\n",
      "Epoch [7641/10000], Loss: 0.5607737302780151\n",
      "Epoch [7642/10000], Loss: 0.5607738494873047\n",
      "Epoch [7643/10000], Loss: 0.5607738494873047\n",
      "Epoch [7644/10000], Loss: 0.5607729554176331\n",
      "Epoch [7645/10000], Loss: 0.5607725381851196\n",
      "Epoch [7646/10000], Loss: 0.5607720017433167\n",
      "Epoch [7647/10000], Loss: 0.5607714653015137\n",
      "Epoch [7648/10000], Loss: 0.5607715249061584\n",
      "Epoch [7649/10000], Loss: 0.560771644115448\n",
      "Epoch [7650/10000], Loss: 0.5607725381851196\n",
      "Epoch [7651/10000], Loss: 0.5607736706733704\n",
      "Epoch [7652/10000], Loss: 0.5607752799987793\n",
      "Epoch [7653/10000], Loss: 0.5607767701148987\n",
      "Epoch [7654/10000], Loss: 0.5607777237892151\n",
      "Epoch [7655/10000], Loss: 0.5607771277427673\n",
      "Epoch [7656/10000], Loss: 0.5607747435569763\n",
      "Epoch [7657/10000], Loss: 0.5607718229293823\n",
      "Epoch [7658/10000], Loss: 0.5607690811157227\n",
      "Epoch [7659/10000], Loss: 0.5607678890228271\n",
      "Epoch [7660/10000], Loss: 0.5607672929763794\n",
      "Epoch [7661/10000], Loss: 0.5607673525810242\n",
      "Epoch [7662/10000], Loss: 0.560767412185669\n",
      "Epoch [7663/10000], Loss: 0.5607675313949585\n",
      "Epoch [7664/10000], Loss: 0.5607678890228271\n",
      "Epoch [7665/10000], Loss: 0.5607685446739197\n",
      "Epoch [7666/10000], Loss: 0.5607693791389465\n",
      "Epoch [7667/10000], Loss: 0.5607700347900391\n",
      "Epoch [7668/10000], Loss: 0.5607713460922241\n",
      "Epoch [7669/10000], Loss: 0.5607728362083435\n",
      "Epoch [7670/10000], Loss: 0.5607738494873047\n",
      "Epoch [7671/10000], Loss: 0.5607751607894897\n",
      "Epoch [7672/10000], Loss: 0.5607758164405823\n",
      "Epoch [7673/10000], Loss: 0.5607762932777405\n",
      "Epoch [7674/10000], Loss: 0.5607759952545166\n",
      "Epoch [7675/10000], Loss: 0.560775876045227\n",
      "Epoch [7676/10000], Loss: 0.5607755184173584\n",
      "Epoch [7677/10000], Loss: 0.5607751607894897\n",
      "Epoch [7678/10000], Loss: 0.5607748031616211\n",
      "Epoch [7679/10000], Loss: 0.5607744455337524\n",
      "Epoch [7680/10000], Loss: 0.5607737898826599\n",
      "Epoch [7681/10000], Loss: 0.5607728958129883\n",
      "Epoch [7682/10000], Loss: 0.5607717633247375\n",
      "Epoch [7683/10000], Loss: 0.5607714056968689\n",
      "Epoch [7684/10000], Loss: 0.5607712864875793\n",
      "Epoch [7685/10000], Loss: 0.5607720017433167\n",
      "Epoch [7686/10000], Loss: 0.5607734322547913\n",
      "Epoch [7687/10000], Loss: 0.560775101184845\n",
      "Epoch [7688/10000], Loss: 0.5607764720916748\n",
      "Epoch [7689/10000], Loss: 0.5607762932777405\n",
      "Epoch [7690/10000], Loss: 0.5607751607894897\n",
      "Epoch [7691/10000], Loss: 0.5607732534408569\n",
      "Epoch [7692/10000], Loss: 0.5607712864875793\n",
      "Epoch [7693/10000], Loss: 0.5607699155807495\n",
      "Epoch [7694/10000], Loss: 0.560769259929657\n",
      "Epoch [7695/10000], Loss: 0.5607693195343018\n",
      "Epoch [7696/10000], Loss: 0.5607696771621704\n",
      "Epoch [7697/10000], Loss: 0.5607705116271973\n",
      "Epoch [7698/10000], Loss: 0.5607720017433167\n",
      "Epoch [7699/10000], Loss: 0.5607731342315674\n",
      "Epoch [7700/10000], Loss: 0.5607740879058838\n",
      "Epoch [7701/10000], Loss: 0.5607739686965942\n",
      "Epoch [7702/10000], Loss: 0.5607729554176331\n",
      "Epoch [7703/10000], Loss: 0.5607719421386719\n",
      "Epoch [7704/10000], Loss: 0.560770571231842\n",
      "Epoch [7705/10000], Loss: 0.5607696175575256\n",
      "Epoch [7706/10000], Loss: 0.5607692003250122\n",
      "Epoch [7707/10000], Loss: 0.5607688426971436\n",
      "Epoch [7708/10000], Loss: 0.5607693195343018\n",
      "Epoch [7709/10000], Loss: 0.56076979637146\n",
      "Epoch [7710/10000], Loss: 0.5607705116271973\n",
      "Epoch [7711/10000], Loss: 0.5607710480690002\n",
      "Epoch [7712/10000], Loss: 0.5607708096504211\n",
      "Epoch [7713/10000], Loss: 0.5607710480690002\n",
      "Epoch [7714/10000], Loss: 0.5607713460922241\n",
      "Epoch [7715/10000], Loss: 0.5607717633247375\n",
      "Epoch [7716/10000], Loss: 0.5607725381851196\n",
      "Epoch [7717/10000], Loss: 0.5607733130455017\n",
      "Epoch [7718/10000], Loss: 0.5607739090919495\n",
      "Epoch [7719/10000], Loss: 0.5607740879058838\n",
      "Epoch [7720/10000], Loss: 0.5607744455337524\n",
      "Epoch [7721/10000], Loss: 0.5607755184173584\n",
      "Epoch [7722/10000], Loss: 0.5607768297195435\n",
      "Epoch [7723/10000], Loss: 0.5607785582542419\n",
      "Epoch [7724/10000], Loss: 0.56078040599823\n",
      "Epoch [7725/10000], Loss: 0.5607818961143494\n",
      "Epoch [7726/10000], Loss: 0.5607833862304688\n",
      "Epoch [7727/10000], Loss: 0.5607841610908508\n",
      "Epoch [7728/10000], Loss: 0.5607842206954956\n",
      "Epoch [7729/10000], Loss: 0.5607829689979553\n",
      "Epoch [7730/10000], Loss: 0.5607802271842957\n",
      "Epoch [7731/10000], Loss: 0.5607764720916748\n",
      "Epoch [7732/10000], Loss: 0.5607732534408569\n",
      "Epoch [7733/10000], Loss: 0.5607707500457764\n",
      "Epoch [7734/10000], Loss: 0.5607692003250122\n",
      "Epoch [7735/10000], Loss: 0.5607686042785645\n",
      "Epoch [7736/10000], Loss: 0.5607681274414062\n",
      "Epoch [7737/10000], Loss: 0.5607683062553406\n",
      "Epoch [7738/10000], Loss: 0.5607687830924988\n",
      "Epoch [7739/10000], Loss: 0.5607699751853943\n",
      "Epoch [7740/10000], Loss: 0.5607712268829346\n",
      "Epoch [7741/10000], Loss: 0.5607721209526062\n",
      "Epoch [7742/10000], Loss: 0.5607735514640808\n",
      "Epoch [7743/10000], Loss: 0.5607746243476868\n",
      "Epoch [7744/10000], Loss: 0.5607750415802002\n",
      "Epoch [7745/10000], Loss: 0.5607750415802002\n",
      "Epoch [7746/10000], Loss: 0.5607744455337524\n",
      "Epoch [7747/10000], Loss: 0.5607739090919495\n",
      "Epoch [7748/10000], Loss: 0.5607730150222778\n",
      "Epoch [7749/10000], Loss: 0.5607721209526062\n",
      "Epoch [7750/10000], Loss: 0.5607717633247375\n",
      "Epoch [7751/10000], Loss: 0.5607708692550659\n",
      "Epoch [7752/10000], Loss: 0.5607703924179077\n",
      "Epoch [7753/10000], Loss: 0.5607700347900391\n",
      "Epoch [7754/10000], Loss: 0.5607701539993286\n",
      "Epoch [7755/10000], Loss: 0.5607703924179077\n",
      "Epoch [7756/10000], Loss: 0.5607705116271973\n",
      "Epoch [7757/10000], Loss: 0.5607706308364868\n",
      "Epoch [7758/10000], Loss: 0.5607699155807495\n",
      "Epoch [7759/10000], Loss: 0.5607696175575256\n",
      "Epoch [7760/10000], Loss: 0.56076979637146\n",
      "Epoch [7761/10000], Loss: 0.5607694983482361\n",
      "Epoch [7762/10000], Loss: 0.560769259929657\n",
      "Epoch [7763/10000], Loss: 0.5607694983482361\n",
      "Epoch [7764/10000], Loss: 0.5607690811157227\n",
      "Epoch [7765/10000], Loss: 0.5607685446739197\n",
      "Epoch [7766/10000], Loss: 0.5607680678367615\n",
      "Epoch [7767/10000], Loss: 0.5607677698135376\n",
      "Epoch [7768/10000], Loss: 0.5607673525810242\n",
      "Epoch [7769/10000], Loss: 0.5607669949531555\n",
      "Epoch [7770/10000], Loss: 0.5607669949531555\n",
      "Epoch [7771/10000], Loss: 0.5607673525810242\n",
      "Epoch [7772/10000], Loss: 0.5607675313949585\n",
      "Epoch [7773/10000], Loss: 0.5607680678367615\n",
      "Epoch [7774/10000], Loss: 0.5607688426971436\n",
      "Epoch [7775/10000], Loss: 0.5607700347900391\n",
      "Epoch [7776/10000], Loss: 0.5607718825340271\n",
      "Epoch [7777/10000], Loss: 0.5607737898826599\n",
      "Epoch [7778/10000], Loss: 0.5607759356498718\n",
      "Epoch [7779/10000], Loss: 0.5607773065567017\n",
      "Epoch [7780/10000], Loss: 0.5607779622077942\n",
      "Epoch [7781/10000], Loss: 0.5607779622077942\n",
      "Epoch [7782/10000], Loss: 0.5607771277427673\n",
      "Epoch [7783/10000], Loss: 0.5607757568359375\n",
      "Epoch [7784/10000], Loss: 0.5607741475105286\n",
      "Epoch [7785/10000], Loss: 0.5607728958129883\n",
      "Epoch [7786/10000], Loss: 0.5607722401618958\n",
      "Epoch [7787/10000], Loss: 0.5607718229293823\n",
      "Epoch [7788/10000], Loss: 0.5607717633247375\n",
      "Epoch [7789/10000], Loss: 0.5607723593711853\n",
      "Epoch [7790/10000], Loss: 0.5607727766036987\n",
      "Epoch [7791/10000], Loss: 0.5607736110687256\n",
      "Epoch [7792/10000], Loss: 0.5607743263244629\n",
      "Epoch [7793/10000], Loss: 0.560774564743042\n",
      "Epoch [7794/10000], Loss: 0.5607736706733704\n",
      "Epoch [7795/10000], Loss: 0.560772716999054\n",
      "Epoch [7796/10000], Loss: 0.5607714653015137\n",
      "Epoch [7797/10000], Loss: 0.5607700347900391\n",
      "Epoch [7798/10000], Loss: 0.5607687830924988\n",
      "Epoch [7799/10000], Loss: 0.5607680082321167\n",
      "Epoch [7800/10000], Loss: 0.560767650604248\n",
      "Epoch [7801/10000], Loss: 0.5607675909996033\n",
      "Epoch [7802/10000], Loss: 0.5607681274414062\n",
      "Epoch [7803/10000], Loss: 0.5607685446739197\n",
      "Epoch [7804/10000], Loss: 0.5607692003250122\n",
      "Epoch [7805/10000], Loss: 0.5607702136039734\n",
      "Epoch [7806/10000], Loss: 0.5607701539993286\n",
      "Epoch [7807/10000], Loss: 0.5607704520225525\n",
      "Epoch [7808/10000], Loss: 0.5607706308364868\n",
      "Epoch [7809/10000], Loss: 0.560770571231842\n",
      "Epoch [7810/10000], Loss: 0.5607712864875793\n",
      "Epoch [7811/10000], Loss: 0.560771644115448\n",
      "Epoch [7812/10000], Loss: 0.5607720017433167\n",
      "Epoch [7813/10000], Loss: 0.5607725381851196\n",
      "Epoch [7814/10000], Loss: 0.5607731938362122\n",
      "Epoch [7815/10000], Loss: 0.5607739686965942\n",
      "Epoch [7816/10000], Loss: 0.560775101184845\n",
      "Epoch [7817/10000], Loss: 0.560775876045227\n",
      "Epoch [7818/10000], Loss: 0.5607763528823853\n",
      "Epoch [7819/10000], Loss: 0.5607763528823853\n",
      "Epoch [7820/10000], Loss: 0.5607767701148987\n",
      "Epoch [7821/10000], Loss: 0.5607767105102539\n",
      "Epoch [7822/10000], Loss: 0.5607767105102539\n",
      "Epoch [7823/10000], Loss: 0.5607768297195435\n",
      "Epoch [7824/10000], Loss: 0.5607764720916748\n",
      "Epoch [7825/10000], Loss: 0.5607757568359375\n",
      "Epoch [7826/10000], Loss: 0.5607751607894897\n",
      "Epoch [7827/10000], Loss: 0.5607740879058838\n",
      "Epoch [7828/10000], Loss: 0.5607730150222778\n",
      "Epoch [7829/10000], Loss: 0.5607718229293823\n",
      "Epoch [7830/10000], Loss: 0.560770571231842\n",
      "Epoch [7831/10000], Loss: 0.5607699751853943\n",
      "Epoch [7832/10000], Loss: 0.5607694983482361\n",
      "Epoch [7833/10000], Loss: 0.56076979637146\n",
      "Epoch [7834/10000], Loss: 0.5607703924179077\n",
      "Epoch [7835/10000], Loss: 0.5607709884643555\n",
      "Epoch [7836/10000], Loss: 0.5607720613479614\n",
      "Epoch [7837/10000], Loss: 0.5607728362083435\n",
      "Epoch [7838/10000], Loss: 0.560773491859436\n",
      "Epoch [7839/10000], Loss: 0.5607736706733704\n",
      "Epoch [7840/10000], Loss: 0.5607728958129883\n",
      "Epoch [7841/10000], Loss: 0.5607718229293823\n",
      "Epoch [7842/10000], Loss: 0.5607705116271973\n",
      "Epoch [7843/10000], Loss: 0.56076979637146\n",
      "Epoch [7844/10000], Loss: 0.5607686638832092\n",
      "Epoch [7845/10000], Loss: 0.5607683658599854\n",
      "Epoch [7846/10000], Loss: 0.5607687830924988\n",
      "Epoch [7847/10000], Loss: 0.560769259929657\n",
      "Epoch [7848/10000], Loss: 0.5607701539993286\n",
      "Epoch [7849/10000], Loss: 0.5607715845108032\n",
      "Epoch [7850/10000], Loss: 0.5607726573944092\n",
      "Epoch [7851/10000], Loss: 0.5607735514640808\n",
      "Epoch [7852/10000], Loss: 0.5607739686965942\n",
      "Epoch [7853/10000], Loss: 0.5607743859291077\n",
      "Epoch [7854/10000], Loss: 0.5607743263244629\n",
      "Epoch [7855/10000], Loss: 0.560774564743042\n",
      "Epoch [7856/10000], Loss: 0.5607743859291077\n",
      "Epoch [7857/10000], Loss: 0.5607736110687256\n",
      "Epoch [7858/10000], Loss: 0.5607728958129883\n",
      "Epoch [7859/10000], Loss: 0.5607725977897644\n",
      "Epoch [7860/10000], Loss: 0.5607722401618958\n",
      "Epoch [7861/10000], Loss: 0.5607722997665405\n",
      "Epoch [7862/10000], Loss: 0.5607725977897644\n",
      "Epoch [7863/10000], Loss: 0.5607724189758301\n",
      "Epoch [7864/10000], Loss: 0.5607720613479614\n",
      "Epoch [7865/10000], Loss: 0.5607722997665405\n",
      "Epoch [7866/10000], Loss: 0.560772716999054\n",
      "Epoch [7867/10000], Loss: 0.560773491859436\n",
      "Epoch [7868/10000], Loss: 0.5607739686965942\n",
      "Epoch [7869/10000], Loss: 0.5607736706733704\n",
      "Epoch [7870/10000], Loss: 0.5607730746269226\n",
      "Epoch [7871/10000], Loss: 0.5607722401618958\n",
      "Epoch [7872/10000], Loss: 0.5607714056968689\n",
      "Epoch [7873/10000], Loss: 0.5607709288597107\n",
      "Epoch [7874/10000], Loss: 0.5607702136039734\n",
      "Epoch [7875/10000], Loss: 0.5607694983482361\n",
      "Epoch [7876/10000], Loss: 0.560769259929657\n",
      "Epoch [7877/10000], Loss: 0.5607686042785645\n",
      "Epoch [7878/10000], Loss: 0.5607678890228271\n",
      "Epoch [7879/10000], Loss: 0.560767412185669\n",
      "Epoch [7880/10000], Loss: 0.5607674717903137\n",
      "Epoch [7881/10000], Loss: 0.560767650604248\n",
      "Epoch [7882/10000], Loss: 0.5607680082321167\n",
      "Epoch [7883/10000], Loss: 0.5607681274414062\n",
      "Epoch [7884/10000], Loss: 0.560768723487854\n",
      "Epoch [7885/10000], Loss: 0.5607696175575256\n",
      "Epoch [7886/10000], Loss: 0.5607708096504211\n",
      "Epoch [7887/10000], Loss: 0.5607722401618958\n",
      "Epoch [7888/10000], Loss: 0.5607732534408569\n",
      "Epoch [7889/10000], Loss: 0.5607739686965942\n",
      "Epoch [7890/10000], Loss: 0.5607737898826599\n",
      "Epoch [7891/10000], Loss: 0.5607736706733704\n",
      "Epoch [7892/10000], Loss: 0.5607730150222778\n",
      "Epoch [7893/10000], Loss: 0.5607725381851196\n",
      "Epoch [7894/10000], Loss: 0.5607723593711853\n",
      "Epoch [7895/10000], Loss: 0.5607725977897644\n",
      "Epoch [7896/10000], Loss: 0.5607730746269226\n",
      "Epoch [7897/10000], Loss: 0.5607732534408569\n",
      "Epoch [7898/10000], Loss: 0.5607743859291077\n",
      "Epoch [7899/10000], Loss: 0.5607760548591614\n",
      "Epoch [7900/10000], Loss: 0.5607776045799255\n",
      "Epoch [7901/10000], Loss: 0.560779333114624\n",
      "Epoch [7902/10000], Loss: 0.5607811808586121\n",
      "Epoch [7903/10000], Loss: 0.5607829689979553\n",
      "Epoch [7904/10000], Loss: 0.5607838034629822\n",
      "Epoch [7905/10000], Loss: 0.5607834458351135\n",
      "Epoch [7906/10000], Loss: 0.5607814788818359\n",
      "Epoch [7907/10000], Loss: 0.5607789158821106\n",
      "Epoch [7908/10000], Loss: 0.5607753396034241\n",
      "Epoch [7909/10000], Loss: 0.5607724189758301\n",
      "Epoch [7910/10000], Loss: 0.560770571231842\n",
      "Epoch [7911/10000], Loss: 0.5607696771621704\n",
      "Epoch [7912/10000], Loss: 0.5607697367668152\n",
      "Epoch [7913/10000], Loss: 0.5607712268829346\n",
      "Epoch [7914/10000], Loss: 0.5607736706733704\n",
      "Epoch [7915/10000], Loss: 0.5607757568359375\n",
      "Epoch [7916/10000], Loss: 0.5607757568359375\n",
      "Epoch [7917/10000], Loss: 0.5607739090919495\n",
      "Epoch [7918/10000], Loss: 0.5607715249061584\n",
      "Epoch [7919/10000], Loss: 0.5607695579528809\n",
      "Epoch [7920/10000], Loss: 0.5607681274414062\n",
      "Epoch [7921/10000], Loss: 0.5607679486274719\n",
      "Epoch [7922/10000], Loss: 0.5607688426971436\n",
      "Epoch [7923/10000], Loss: 0.5607700347900391\n",
      "Epoch [7924/10000], Loss: 0.5607713460922241\n",
      "Epoch [7925/10000], Loss: 0.5607726573944092\n",
      "Epoch [7926/10000], Loss: 0.5607735514640808\n",
      "Epoch [7927/10000], Loss: 0.5607737898826599\n",
      "Epoch [7928/10000], Loss: 0.5607733130455017\n",
      "Epoch [7929/10000], Loss: 0.5607724189758301\n",
      "Epoch [7930/10000], Loss: 0.5607714056968689\n",
      "Epoch [7931/10000], Loss: 0.5607702732086182\n",
      "Epoch [7932/10000], Loss: 0.560769259929657\n",
      "Epoch [7933/10000], Loss: 0.5607686042785645\n",
      "Epoch [7934/10000], Loss: 0.5607683658599854\n",
      "Epoch [7935/10000], Loss: 0.5607684850692749\n",
      "Epoch [7936/10000], Loss: 0.5607688426971436\n",
      "Epoch [7937/10000], Loss: 0.560769259929657\n",
      "Epoch [7938/10000], Loss: 0.56076979637146\n",
      "Epoch [7939/10000], Loss: 0.5607699751853943\n",
      "Epoch [7940/10000], Loss: 0.5607697367668152\n",
      "Epoch [7941/10000], Loss: 0.560769259929657\n",
      "Epoch [7942/10000], Loss: 0.5607689619064331\n",
      "Epoch [7943/10000], Loss: 0.5607686042785645\n",
      "Epoch [7944/10000], Loss: 0.5607686042785645\n",
      "Epoch [7945/10000], Loss: 0.5607684850692749\n",
      "Epoch [7946/10000], Loss: 0.5607683658599854\n",
      "Epoch [7947/10000], Loss: 0.5607685446739197\n",
      "Epoch [7948/10000], Loss: 0.5607680082321167\n",
      "Epoch [7949/10000], Loss: 0.5607679486274719\n",
      "Epoch [7950/10000], Loss: 0.5607682466506958\n",
      "Epoch [7951/10000], Loss: 0.5607687830924988\n",
      "Epoch [7952/10000], Loss: 0.5607694983482361\n",
      "Epoch [7953/10000], Loss: 0.5607704520225525\n",
      "Epoch [7954/10000], Loss: 0.560771644115448\n",
      "Epoch [7955/10000], Loss: 0.5607718825340271\n",
      "Epoch [7956/10000], Loss: 0.5607720017433167\n",
      "Epoch [7957/10000], Loss: 0.560772180557251\n",
      "Epoch [7958/10000], Loss: 0.5607718825340271\n",
      "Epoch [7959/10000], Loss: 0.5607720613479614\n",
      "Epoch [7960/10000], Loss: 0.5607720613479614\n",
      "Epoch [7961/10000], Loss: 0.560772180557251\n",
      "Epoch [7962/10000], Loss: 0.5607727766036987\n",
      "Epoch [7963/10000], Loss: 0.5607728958129883\n",
      "Epoch [7964/10000], Loss: 0.5607733130455017\n",
      "Epoch [7965/10000], Loss: 0.5607737302780151\n",
      "Epoch [7966/10000], Loss: 0.5607744455337524\n",
      "Epoch [7967/10000], Loss: 0.5607750415802002\n",
      "Epoch [7968/10000], Loss: 0.5607751607894897\n",
      "Epoch [7969/10000], Loss: 0.5607757568359375\n",
      "Epoch [7970/10000], Loss: 0.5607755780220032\n",
      "Epoch [7971/10000], Loss: 0.5607757568359375\n",
      "Epoch [7972/10000], Loss: 0.5607753992080688\n",
      "Epoch [7973/10000], Loss: 0.5607749819755554\n",
      "Epoch [7974/10000], Loss: 0.5607752799987793\n",
      "Epoch [7975/10000], Loss: 0.5607753396034241\n",
      "Epoch [7976/10000], Loss: 0.5607758164405823\n",
      "Epoch [7977/10000], Loss: 0.5607753992080688\n",
      "Epoch [7978/10000], Loss: 0.560775101184845\n",
      "Epoch [7979/10000], Loss: 0.5607744455337524\n",
      "Epoch [7980/10000], Loss: 0.5607731938362122\n",
      "Epoch [7981/10000], Loss: 0.560771644115448\n",
      "Epoch [7982/10000], Loss: 0.5607706308364868\n",
      "Epoch [7983/10000], Loss: 0.56076979637146\n",
      "Epoch [7984/10000], Loss: 0.5607688426971436\n",
      "Epoch [7985/10000], Loss: 0.560768723487854\n",
      "Epoch [7986/10000], Loss: 0.560768723487854\n",
      "Epoch [7987/10000], Loss: 0.560768723487854\n",
      "Epoch [7988/10000], Loss: 0.5607690811157227\n",
      "Epoch [7989/10000], Loss: 0.5607697367668152\n",
      "Epoch [7990/10000], Loss: 0.5607699155807495\n",
      "Epoch [7991/10000], Loss: 0.5607702732086182\n",
      "Epoch [7992/10000], Loss: 0.5607711672782898\n",
      "Epoch [7993/10000], Loss: 0.5607715845108032\n",
      "Epoch [7994/10000], Loss: 0.560771644115448\n",
      "Epoch [7995/10000], Loss: 0.5607717037200928\n",
      "Epoch [7996/10000], Loss: 0.5607715249061584\n",
      "Epoch [7997/10000], Loss: 0.5607710480690002\n",
      "Epoch [7998/10000], Loss: 0.5607710480690002\n",
      "Epoch [7999/10000], Loss: 0.560771107673645\n",
      "Epoch [8000/10000], Loss: 0.5607712268829346\n",
      "Epoch [8001/10000], Loss: 0.5607718229293823\n",
      "Epoch [8002/10000], Loss: 0.5607725977897644\n",
      "Epoch [8003/10000], Loss: 0.5607729554176331\n",
      "Epoch [8004/10000], Loss: 0.560773491859436\n",
      "Epoch [8005/10000], Loss: 0.5607742071151733\n",
      "Epoch [8006/10000], Loss: 0.5607743263244629\n",
      "Epoch [8007/10000], Loss: 0.5607741475105286\n",
      "Epoch [8008/10000], Loss: 0.5607738494873047\n",
      "Epoch [8009/10000], Loss: 0.5607731342315674\n",
      "Epoch [8010/10000], Loss: 0.5607725977897644\n",
      "Epoch [8011/10000], Loss: 0.5607712864875793\n",
      "Epoch [8012/10000], Loss: 0.5607701539993286\n",
      "Epoch [8013/10000], Loss: 0.5607696771621704\n",
      "Epoch [8014/10000], Loss: 0.5607689619064331\n",
      "Epoch [8015/10000], Loss: 0.5607683062553406\n",
      "Epoch [8016/10000], Loss: 0.5607681274414062\n",
      "Epoch [8017/10000], Loss: 0.5607680678367615\n",
      "Epoch [8018/10000], Loss: 0.560767650604248\n",
      "Epoch [8019/10000], Loss: 0.5607678890228271\n",
      "Epoch [8020/10000], Loss: 0.5607683062553406\n",
      "Epoch [8021/10000], Loss: 0.560768723487854\n",
      "Epoch [8022/10000], Loss: 0.5607693791389465\n",
      "Epoch [8023/10000], Loss: 0.5607702732086182\n",
      "Epoch [8024/10000], Loss: 0.560771107673645\n",
      "Epoch [8025/10000], Loss: 0.560771644115448\n",
      "Epoch [8026/10000], Loss: 0.5607718229293823\n",
      "Epoch [8027/10000], Loss: 0.560771107673645\n",
      "Epoch [8028/10000], Loss: 0.5607699155807495\n",
      "Epoch [8029/10000], Loss: 0.5607687830924988\n",
      "Epoch [8030/10000], Loss: 0.5607683062553406\n",
      "Epoch [8031/10000], Loss: 0.5607678294181824\n",
      "Epoch [8032/10000], Loss: 0.5607683062553406\n",
      "Epoch [8033/10000], Loss: 0.5607683062553406\n",
      "Epoch [8034/10000], Loss: 0.5607687830924988\n",
      "Epoch [8035/10000], Loss: 0.5607699155807495\n",
      "Epoch [8036/10000], Loss: 0.5607710480690002\n",
      "Epoch [8037/10000], Loss: 0.5607714056968689\n",
      "Epoch [8038/10000], Loss: 0.5607722401618958\n",
      "Epoch [8039/10000], Loss: 0.5607725977897644\n",
      "Epoch [8040/10000], Loss: 0.5607721209526062\n",
      "Epoch [8041/10000], Loss: 0.5607711672782898\n",
      "Epoch [8042/10000], Loss: 0.5607699751853943\n",
      "Epoch [8043/10000], Loss: 0.5607692003250122\n",
      "Epoch [8044/10000], Loss: 0.5607690215110779\n",
      "Epoch [8045/10000], Loss: 0.560769259929657\n",
      "Epoch [8046/10000], Loss: 0.5607693195343018\n",
      "Epoch [8047/10000], Loss: 0.5607699155807495\n",
      "Epoch [8048/10000], Loss: 0.5607713460922241\n",
      "Epoch [8049/10000], Loss: 0.5607724189758301\n",
      "Epoch [8050/10000], Loss: 0.5607739686965942\n",
      "Epoch [8051/10000], Loss: 0.5607746243476868\n",
      "Epoch [8052/10000], Loss: 0.5607739090919495\n",
      "Epoch [8053/10000], Loss: 0.5607725381851196\n",
      "Epoch [8054/10000], Loss: 0.5607718825340271\n",
      "Epoch [8055/10000], Loss: 0.5607717633247375\n",
      "Epoch [8056/10000], Loss: 0.5607722401618958\n",
      "Epoch [8057/10000], Loss: 0.560773491859436\n",
      "Epoch [8058/10000], Loss: 0.5607758164405823\n",
      "Epoch [8059/10000], Loss: 0.5607784390449524\n",
      "Epoch [8060/10000], Loss: 0.5607817769050598\n",
      "Epoch [8061/10000], Loss: 0.5607846975326538\n",
      "Epoch [8062/10000], Loss: 0.5607872605323792\n",
      "Epoch [8063/10000], Loss: 0.5607888102531433\n",
      "Epoch [8064/10000], Loss: 0.5607894062995911\n",
      "Epoch [8065/10000], Loss: 0.5607879757881165\n",
      "Epoch [8066/10000], Loss: 0.5607854127883911\n",
      "Epoch [8067/10000], Loss: 0.5607810616493225\n",
      "Epoch [8068/10000], Loss: 0.5607768297195435\n",
      "Epoch [8069/10000], Loss: 0.560772716999054\n",
      "Epoch [8070/10000], Loss: 0.56076979637146\n",
      "Epoch [8071/10000], Loss: 0.5607685446739197\n",
      "Epoch [8072/10000], Loss: 0.5607683658599854\n",
      "Epoch [8073/10000], Loss: 0.560768723487854\n",
      "Epoch [8074/10000], Loss: 0.5607695579528809\n",
      "Epoch [8075/10000], Loss: 0.5607708096504211\n",
      "Epoch [8076/10000], Loss: 0.560771644115448\n",
      "Epoch [8077/10000], Loss: 0.560772716999054\n",
      "Epoch [8078/10000], Loss: 0.5607730150222778\n",
      "Epoch [8079/10000], Loss: 0.5607727766036987\n",
      "Epoch [8080/10000], Loss: 0.5607715249061584\n",
      "Epoch [8081/10000], Loss: 0.5607703924179077\n",
      "Epoch [8082/10000], Loss: 0.5607688426971436\n",
      "Epoch [8083/10000], Loss: 0.5607680082321167\n",
      "Epoch [8084/10000], Loss: 0.5607672929763794\n",
      "Epoch [8085/10000], Loss: 0.5607669949531555\n",
      "Epoch [8086/10000], Loss: 0.5607675909996033\n",
      "Epoch [8087/10000], Loss: 0.5607682466506958\n",
      "Epoch [8088/10000], Loss: 0.5607693195343018\n",
      "Epoch [8089/10000], Loss: 0.5607704520225525\n",
      "Epoch [8090/10000], Loss: 0.5607718229293823\n",
      "Epoch [8091/10000], Loss: 0.5607725977897644\n",
      "Epoch [8092/10000], Loss: 0.560773491859436\n",
      "Epoch [8093/10000], Loss: 0.5607735514640808\n",
      "Epoch [8094/10000], Loss: 0.5607729554176331\n",
      "Epoch [8095/10000], Loss: 0.560771644115448\n",
      "Epoch [8096/10000], Loss: 0.5607702136039734\n",
      "Epoch [8097/10000], Loss: 0.5607692003250122\n",
      "Epoch [8098/10000], Loss: 0.5607683062553406\n",
      "Epoch [8099/10000], Loss: 0.5607680082321167\n",
      "Epoch [8100/10000], Loss: 0.560767650604248\n",
      "Epoch [8101/10000], Loss: 0.5607684254646301\n",
      "Epoch [8102/10000], Loss: 0.5607697367668152\n",
      "Epoch [8103/10000], Loss: 0.5607708096504211\n",
      "Epoch [8104/10000], Loss: 0.5607725381851196\n",
      "Epoch [8105/10000], Loss: 0.5607733726501465\n",
      "Epoch [8106/10000], Loss: 0.5607736706733704\n",
      "Epoch [8107/10000], Loss: 0.5607730746269226\n",
      "Epoch [8108/10000], Loss: 0.5607717633247375\n",
      "Epoch [8109/10000], Loss: 0.5607702732086182\n",
      "Epoch [8110/10000], Loss: 0.5607690215110779\n",
      "Epoch [8111/10000], Loss: 0.5607684850692749\n",
      "Epoch [8112/10000], Loss: 0.5607679486274719\n",
      "Epoch [8113/10000], Loss: 0.5607677698135376\n",
      "Epoch [8114/10000], Loss: 0.5607677698135376\n",
      "Epoch [8115/10000], Loss: 0.560767650604248\n",
      "Epoch [8116/10000], Loss: 0.5607675909996033\n",
      "Epoch [8117/10000], Loss: 0.5607680082321167\n",
      "Epoch [8118/10000], Loss: 0.5607685446739197\n",
      "Epoch [8119/10000], Loss: 0.5607694983482361\n",
      "Epoch [8120/10000], Loss: 0.5607710480690002\n",
      "Epoch [8121/10000], Loss: 0.5607723593711853\n",
      "Epoch [8122/10000], Loss: 0.5607731342315674\n",
      "Epoch [8123/10000], Loss: 0.5607746243476868\n",
      "Epoch [8124/10000], Loss: 0.5607751607894897\n",
      "Epoch [8125/10000], Loss: 0.5607743263244629\n",
      "Epoch [8126/10000], Loss: 0.560772716999054\n",
      "Epoch [8127/10000], Loss: 0.5607708096504211\n",
      "Epoch [8128/10000], Loss: 0.5607692003250122\n",
      "Epoch [8129/10000], Loss: 0.5607680082321167\n",
      "Epoch [8130/10000], Loss: 0.560767412185669\n",
      "Epoch [8131/10000], Loss: 0.5607669949531555\n",
      "Epoch [8132/10000], Loss: 0.5607671141624451\n",
      "Epoch [8133/10000], Loss: 0.5607672929763794\n",
      "Epoch [8134/10000], Loss: 0.5607675313949585\n",
      "Epoch [8135/10000], Loss: 0.560768187046051\n",
      "Epoch [8136/10000], Loss: 0.5607685446739197\n",
      "Epoch [8137/10000], Loss: 0.5607693791389465\n",
      "Epoch [8138/10000], Loss: 0.5607694387435913\n",
      "Epoch [8139/10000], Loss: 0.5607690811157227\n",
      "Epoch [8140/10000], Loss: 0.5607695579528809\n",
      "Epoch [8141/10000], Loss: 0.5607702732086182\n",
      "Epoch [8142/10000], Loss: 0.5607706308364868\n",
      "Epoch [8143/10000], Loss: 0.5607711672782898\n",
      "Epoch [8144/10000], Loss: 0.5607718229293823\n",
      "Epoch [8145/10000], Loss: 0.5607720613479614\n",
      "Epoch [8146/10000], Loss: 0.5607712268829346\n",
      "Epoch [8147/10000], Loss: 0.5607702732086182\n",
      "Epoch [8148/10000], Loss: 0.5607694387435913\n",
      "Epoch [8149/10000], Loss: 0.5607686042785645\n",
      "Epoch [8150/10000], Loss: 0.5607683062553406\n",
      "Epoch [8151/10000], Loss: 0.5607684254646301\n",
      "Epoch [8152/10000], Loss: 0.5607689619064331\n",
      "Epoch [8153/10000], Loss: 0.5607699751853943\n",
      "Epoch [8154/10000], Loss: 0.5607711672782898\n",
      "Epoch [8155/10000], Loss: 0.5607730150222778\n",
      "Epoch [8156/10000], Loss: 0.5607750415802002\n",
      "Epoch [8157/10000], Loss: 0.560776948928833\n",
      "Epoch [8158/10000], Loss: 0.5607776641845703\n",
      "Epoch [8159/10000], Loss: 0.5607780814170837\n",
      "Epoch [8160/10000], Loss: 0.5607774257659912\n",
      "Epoch [8161/10000], Loss: 0.5607766509056091\n",
      "Epoch [8162/10000], Loss: 0.5607761144638062\n",
      "Epoch [8163/10000], Loss: 0.5607761144638062\n",
      "Epoch [8164/10000], Loss: 0.56077641248703\n",
      "Epoch [8165/10000], Loss: 0.56077641248703\n",
      "Epoch [8166/10000], Loss: 0.5607767105102539\n",
      "Epoch [8167/10000], Loss: 0.560776948928833\n",
      "Epoch [8168/10000], Loss: 0.5607758164405823\n",
      "Epoch [8169/10000], Loss: 0.5607737898826599\n",
      "Epoch [8170/10000], Loss: 0.560771644115448\n",
      "Epoch [8171/10000], Loss: 0.5607705116271973\n",
      "Epoch [8172/10000], Loss: 0.5607689619064331\n",
      "Epoch [8173/10000], Loss: 0.5607675313949585\n",
      "Epoch [8174/10000], Loss: 0.5607664585113525\n",
      "Epoch [8175/10000], Loss: 0.5607659816741943\n",
      "Epoch [8176/10000], Loss: 0.5607655644416809\n",
      "Epoch [8177/10000], Loss: 0.5607657432556152\n",
      "Epoch [8178/10000], Loss: 0.5607655644416809\n",
      "Epoch [8179/10000], Loss: 0.5607659816741943\n",
      "Epoch [8180/10000], Loss: 0.560766339302063\n",
      "Epoch [8181/10000], Loss: 0.5607669353485107\n",
      "Epoch [8182/10000], Loss: 0.5607675313949585\n",
      "Epoch [8183/10000], Loss: 0.5607683062553406\n",
      "Epoch [8184/10000], Loss: 0.5607693791389465\n",
      "Epoch [8185/10000], Loss: 0.5607704520225525\n",
      "Epoch [8186/10000], Loss: 0.5607720613479614\n",
      "Epoch [8187/10000], Loss: 0.5607736110687256\n",
      "Epoch [8188/10000], Loss: 0.5607753396034241\n",
      "Epoch [8189/10000], Loss: 0.5607764720916748\n",
      "Epoch [8190/10000], Loss: 0.5607770085334778\n",
      "Epoch [8191/10000], Loss: 0.5607775449752808\n",
      "Epoch [8192/10000], Loss: 0.5607767105102539\n",
      "Epoch [8193/10000], Loss: 0.5607753396034241\n",
      "Epoch [8194/10000], Loss: 0.5607739686965942\n",
      "Epoch [8195/10000], Loss: 0.5607728362083435\n",
      "Epoch [8196/10000], Loss: 0.5607720017433167\n",
      "Epoch [8197/10000], Loss: 0.560771107673645\n",
      "Epoch [8198/10000], Loss: 0.5607702732086182\n",
      "Epoch [8199/10000], Loss: 0.5607702732086182\n",
      "Epoch [8200/10000], Loss: 0.5607703328132629\n",
      "Epoch [8201/10000], Loss: 0.5607702732086182\n",
      "Epoch [8202/10000], Loss: 0.5607700943946838\n",
      "Epoch [8203/10000], Loss: 0.5607697367668152\n",
      "Epoch [8204/10000], Loss: 0.560769259929657\n",
      "Epoch [8205/10000], Loss: 0.5607686638832092\n",
      "Epoch [8206/10000], Loss: 0.5607681274414062\n",
      "Epoch [8207/10000], Loss: 0.5607677102088928\n",
      "Epoch [8208/10000], Loss: 0.5607674717903137\n",
      "Epoch [8209/10000], Loss: 0.5607671141624451\n",
      "Epoch [8210/10000], Loss: 0.5607670545578003\n",
      "Epoch [8211/10000], Loss: 0.5607670545578003\n",
      "Epoch [8212/10000], Loss: 0.5607672929763794\n",
      "Epoch [8213/10000], Loss: 0.5607672929763794\n",
      "Epoch [8214/10000], Loss: 0.5607679486274719\n",
      "Epoch [8215/10000], Loss: 0.5607685446739197\n",
      "Epoch [8216/10000], Loss: 0.5607690811157227\n",
      "Epoch [8217/10000], Loss: 0.5607696771621704\n",
      "Epoch [8218/10000], Loss: 0.5607700943946838\n",
      "Epoch [8219/10000], Loss: 0.5607701539993286\n",
      "Epoch [8220/10000], Loss: 0.5607703924179077\n",
      "Epoch [8221/10000], Loss: 0.5607700347900391\n",
      "Epoch [8222/10000], Loss: 0.5607701539993286\n",
      "Epoch [8223/10000], Loss: 0.5607697367668152\n",
      "Epoch [8224/10000], Loss: 0.56076979637146\n",
      "Epoch [8225/10000], Loss: 0.5607700347900391\n",
      "Epoch [8226/10000], Loss: 0.5607706308364868\n",
      "Epoch [8227/10000], Loss: 0.5607713460922241\n",
      "Epoch [8228/10000], Loss: 0.5607721209526062\n",
      "Epoch [8229/10000], Loss: 0.5607730746269226\n",
      "Epoch [8230/10000], Loss: 0.5607739090919495\n",
      "Epoch [8231/10000], Loss: 0.5607743263244629\n",
      "Epoch [8232/10000], Loss: 0.5607752203941345\n",
      "Epoch [8233/10000], Loss: 0.560775637626648\n",
      "Epoch [8234/10000], Loss: 0.560775876045227\n",
      "Epoch [8235/10000], Loss: 0.5607758164405823\n",
      "Epoch [8236/10000], Loss: 0.5607761740684509\n",
      "Epoch [8237/10000], Loss: 0.5607762932777405\n",
      "Epoch [8238/10000], Loss: 0.5607755780220032\n",
      "Epoch [8239/10000], Loss: 0.5607744455337524\n",
      "Epoch [8240/10000], Loss: 0.560772716999054\n",
      "Epoch [8241/10000], Loss: 0.5607709288597107\n",
      "Epoch [8242/10000], Loss: 0.5607694387435913\n",
      "Epoch [8243/10000], Loss: 0.5607678294181824\n",
      "Epoch [8244/10000], Loss: 0.5607666373252869\n",
      "Epoch [8245/10000], Loss: 0.5607659816741943\n",
      "Epoch [8246/10000], Loss: 0.5607657432556152\n",
      "Epoch [8247/10000], Loss: 0.5607655644416809\n",
      "Epoch [8248/10000], Loss: 0.5607656240463257\n",
      "Epoch [8249/10000], Loss: 0.5607656836509705\n",
      "Epoch [8250/10000], Loss: 0.5607662200927734\n",
      "Epoch [8251/10000], Loss: 0.5607662200927734\n",
      "Epoch [8252/10000], Loss: 0.5607661008834839\n",
      "Epoch [8253/10000], Loss: 0.5607664585113525\n",
      "Epoch [8254/10000], Loss: 0.5607669353485107\n",
      "Epoch [8255/10000], Loss: 0.560767650604248\n",
      "Epoch [8256/10000], Loss: 0.560768187046051\n",
      "Epoch [8257/10000], Loss: 0.5607694387435913\n",
      "Epoch [8258/10000], Loss: 0.5607706904411316\n",
      "Epoch [8259/10000], Loss: 0.5607720613479614\n",
      "Epoch [8260/10000], Loss: 0.560773491859436\n",
      "Epoch [8261/10000], Loss: 0.560774564743042\n",
      "Epoch [8262/10000], Loss: 0.560775101184845\n",
      "Epoch [8263/10000], Loss: 0.5607743859291077\n",
      "Epoch [8264/10000], Loss: 0.5607728362083435\n",
      "Epoch [8265/10000], Loss: 0.5607711672782898\n",
      "Epoch [8266/10000], Loss: 0.5607694983482361\n",
      "Epoch [8267/10000], Loss: 0.5607680678367615\n",
      "Epoch [8268/10000], Loss: 0.5607668161392212\n",
      "Epoch [8269/10000], Loss: 0.5607664585113525\n",
      "Epoch [8270/10000], Loss: 0.5607659816741943\n",
      "Epoch [8271/10000], Loss: 0.560766339302063\n",
      "Epoch [8272/10000], Loss: 0.5607671141624451\n",
      "Epoch [8273/10000], Loss: 0.5607683658599854\n",
      "Epoch [8274/10000], Loss: 0.5607700943946838\n",
      "Epoch [8275/10000], Loss: 0.5607714056968689\n",
      "Epoch [8276/10000], Loss: 0.5607720017433167\n",
      "Epoch [8277/10000], Loss: 0.5607723593711853\n",
      "Epoch [8278/10000], Loss: 0.5607718229293823\n",
      "Epoch [8279/10000], Loss: 0.5607715845108032\n",
      "Epoch [8280/10000], Loss: 0.5607712864875793\n",
      "Epoch [8281/10000], Loss: 0.5607709288597107\n",
      "Epoch [8282/10000], Loss: 0.5607705116271973\n",
      "Epoch [8283/10000], Loss: 0.5607700347900391\n",
      "Epoch [8284/10000], Loss: 0.5607696771621704\n",
      "Epoch [8285/10000], Loss: 0.5607698559761047\n",
      "Epoch [8286/10000], Loss: 0.5607703924179077\n",
      "Epoch [8287/10000], Loss: 0.5607711672782898\n",
      "Epoch [8288/10000], Loss: 0.5607718229293823\n",
      "Epoch [8289/10000], Loss: 0.5607717633247375\n",
      "Epoch [8290/10000], Loss: 0.5607718229293823\n",
      "Epoch [8291/10000], Loss: 0.560771644115448\n",
      "Epoch [8292/10000], Loss: 0.5607714653015137\n",
      "Epoch [8293/10000], Loss: 0.5607709288597107\n",
      "Epoch [8294/10000], Loss: 0.5607708692550659\n",
      "Epoch [8295/10000], Loss: 0.5607709288597107\n",
      "Epoch [8296/10000], Loss: 0.5607712864875793\n",
      "Epoch [8297/10000], Loss: 0.5607719421386719\n",
      "Epoch [8298/10000], Loss: 0.5607724189758301\n",
      "Epoch [8299/10000], Loss: 0.5607731342315674\n",
      "Epoch [8300/10000], Loss: 0.5607735514640808\n",
      "Epoch [8301/10000], Loss: 0.5607738494873047\n",
      "Epoch [8302/10000], Loss: 0.5607739686965942\n",
      "Epoch [8303/10000], Loss: 0.5607739090919495\n",
      "Epoch [8304/10000], Loss: 0.5607730746269226\n",
      "Epoch [8305/10000], Loss: 0.560771644115448\n",
      "Epoch [8306/10000], Loss: 0.5607703924179077\n",
      "Epoch [8307/10000], Loss: 0.560769259929657\n",
      "Epoch [8308/10000], Loss: 0.5607686042785645\n",
      "Epoch [8309/10000], Loss: 0.5607684850692749\n",
      "Epoch [8310/10000], Loss: 0.5607683062553406\n",
      "Epoch [8311/10000], Loss: 0.5607689619064331\n",
      "Epoch [8312/10000], Loss: 0.5607696175575256\n",
      "Epoch [8313/10000], Loss: 0.5607702732086182\n",
      "Epoch [8314/10000], Loss: 0.5607713460922241\n",
      "Epoch [8315/10000], Loss: 0.5607725977897644\n",
      "Epoch [8316/10000], Loss: 0.5607736706733704\n",
      "Epoch [8317/10000], Loss: 0.560774564743042\n",
      "Epoch [8318/10000], Loss: 0.5607749223709106\n",
      "Epoch [8319/10000], Loss: 0.5607753992080688\n",
      "Epoch [8320/10000], Loss: 0.5607761144638062\n",
      "Epoch [8321/10000], Loss: 0.560776948928833\n",
      "Epoch [8322/10000], Loss: 0.5607773065567017\n",
      "Epoch [8323/10000], Loss: 0.5607772469520569\n",
      "Epoch [8324/10000], Loss: 0.5607767701148987\n",
      "Epoch [8325/10000], Loss: 0.5607760548591614\n",
      "Epoch [8326/10000], Loss: 0.560774028301239\n",
      "Epoch [8327/10000], Loss: 0.5607720613479614\n",
      "Epoch [8328/10000], Loss: 0.5607700943946838\n",
      "Epoch [8329/10000], Loss: 0.5607685446739197\n",
      "Epoch [8330/10000], Loss: 0.5607673525810242\n",
      "Epoch [8331/10000], Loss: 0.5607671737670898\n",
      "Epoch [8332/10000], Loss: 0.5607671141624451\n",
      "Epoch [8333/10000], Loss: 0.5607677698135376\n",
      "Epoch [8334/10000], Loss: 0.5607690811157227\n",
      "Epoch [8335/10000], Loss: 0.5607702732086182\n",
      "Epoch [8336/10000], Loss: 0.5607712864875793\n",
      "Epoch [8337/10000], Loss: 0.5607712864875793\n",
      "Epoch [8338/10000], Loss: 0.5607706308364868\n",
      "Epoch [8339/10000], Loss: 0.5607692003250122\n",
      "Epoch [8340/10000], Loss: 0.5607678890228271\n",
      "Epoch [8341/10000], Loss: 0.5607667565345764\n",
      "Epoch [8342/10000], Loss: 0.5607657432556152\n",
      "Epoch [8343/10000], Loss: 0.5607652068138123\n",
      "Epoch [8344/10000], Loss: 0.5607649683952332\n",
      "Epoch [8345/10000], Loss: 0.5607650279998779\n",
      "Epoch [8346/10000], Loss: 0.5607655048370361\n",
      "Epoch [8347/10000], Loss: 0.5607657432556152\n",
      "Epoch [8348/10000], Loss: 0.5607664585113525\n",
      "Epoch [8349/10000], Loss: 0.5607677102088928\n",
      "Epoch [8350/10000], Loss: 0.5607691407203674\n",
      "Epoch [8351/10000], Loss: 0.5607708692550659\n",
      "Epoch [8352/10000], Loss: 0.560772716999054\n",
      "Epoch [8353/10000], Loss: 0.5607733130455017\n",
      "Epoch [8354/10000], Loss: 0.5607732534408569\n",
      "Epoch [8355/10000], Loss: 0.5607730150222778\n",
      "Epoch [8356/10000], Loss: 0.5607727766036987\n",
      "Epoch [8357/10000], Loss: 0.5607724189758301\n",
      "Epoch [8358/10000], Loss: 0.5607723593711853\n",
      "Epoch [8359/10000], Loss: 0.5607722997665405\n",
      "Epoch [8360/10000], Loss: 0.5607724785804749\n",
      "Epoch [8361/10000], Loss: 0.5607736706733704\n",
      "Epoch [8362/10000], Loss: 0.5607748031616211\n",
      "Epoch [8363/10000], Loss: 0.5607754588127136\n",
      "Epoch [8364/10000], Loss: 0.5607753992080688\n",
      "Epoch [8365/10000], Loss: 0.5607740879058838\n",
      "Epoch [8366/10000], Loss: 0.5607729554176331\n",
      "Epoch [8367/10000], Loss: 0.5607708692550659\n",
      "Epoch [8368/10000], Loss: 0.5607690215110779\n",
      "Epoch [8369/10000], Loss: 0.5607677102088928\n",
      "Epoch [8370/10000], Loss: 0.560766875743866\n",
      "Epoch [8371/10000], Loss: 0.56076580286026\n",
      "Epoch [8372/10000], Loss: 0.560765266418457\n",
      "Epoch [8373/10000], Loss: 0.5607652068138123\n",
      "Epoch [8374/10000], Loss: 0.560765266418457\n",
      "Epoch [8375/10000], Loss: 0.5607659220695496\n",
      "Epoch [8376/10000], Loss: 0.5607665181159973\n",
      "Epoch [8377/10000], Loss: 0.560767412185669\n",
      "Epoch [8378/10000], Loss: 0.5607680678367615\n",
      "Epoch [8379/10000], Loss: 0.5607686042785645\n",
      "Epoch [8380/10000], Loss: 0.5607688426971436\n",
      "Epoch [8381/10000], Loss: 0.5607697367668152\n",
      "Epoch [8382/10000], Loss: 0.5607699155807495\n",
      "Epoch [8383/10000], Loss: 0.5607696175575256\n",
      "Epoch [8384/10000], Loss: 0.5607689023017883\n",
      "Epoch [8385/10000], Loss: 0.5607680082321167\n",
      "Epoch [8386/10000], Loss: 0.5607671141624451\n",
      "Epoch [8387/10000], Loss: 0.5607670545578003\n",
      "Epoch [8388/10000], Loss: 0.5607671737670898\n",
      "Epoch [8389/10000], Loss: 0.5607678294181824\n",
      "Epoch [8390/10000], Loss: 0.5607687830924988\n",
      "Epoch [8391/10000], Loss: 0.5607699155807495\n",
      "Epoch [8392/10000], Loss: 0.5607713460922241\n",
      "Epoch [8393/10000], Loss: 0.560772716999054\n",
      "Epoch [8394/10000], Loss: 0.560774564743042\n",
      "Epoch [8395/10000], Loss: 0.5607758164405823\n",
      "Epoch [8396/10000], Loss: 0.5607763528823853\n",
      "Epoch [8397/10000], Loss: 0.5607761740684509\n",
      "Epoch [8398/10000], Loss: 0.560775637626648\n",
      "Epoch [8399/10000], Loss: 0.5607749223709106\n",
      "Epoch [8400/10000], Loss: 0.5607739686965942\n",
      "Epoch [8401/10000], Loss: 0.5607732534408569\n",
      "Epoch [8402/10000], Loss: 0.5607729554176331\n",
      "Epoch [8403/10000], Loss: 0.5607730746269226\n",
      "Epoch [8404/10000], Loss: 0.5607733726501465\n",
      "Epoch [8405/10000], Loss: 0.5607733726501465\n",
      "Epoch [8406/10000], Loss: 0.560772716999054\n",
      "Epoch [8407/10000], Loss: 0.5607715249061584\n",
      "Epoch [8408/10000], Loss: 0.5607699155807495\n",
      "Epoch [8409/10000], Loss: 0.5607687830924988\n",
      "Epoch [8410/10000], Loss: 0.5607686042785645\n",
      "Epoch [8411/10000], Loss: 0.5607683062553406\n",
      "Epoch [8412/10000], Loss: 0.5607684850692749\n",
      "Epoch [8413/10000], Loss: 0.5607687830924988\n",
      "Epoch [8414/10000], Loss: 0.5607694387435913\n",
      "Epoch [8415/10000], Loss: 0.5607702732086182\n",
      "Epoch [8416/10000], Loss: 0.5607706904411316\n",
      "Epoch [8417/10000], Loss: 0.560770571231842\n",
      "Epoch [8418/10000], Loss: 0.56076979637146\n",
      "Epoch [8419/10000], Loss: 0.560768723487854\n",
      "Epoch [8420/10000], Loss: 0.5607678294181824\n",
      "Epoch [8421/10000], Loss: 0.5607666969299316\n",
      "Epoch [8422/10000], Loss: 0.5607662200927734\n",
      "Epoch [8423/10000], Loss: 0.5607663989067078\n",
      "Epoch [8424/10000], Loss: 0.5607664585113525\n",
      "Epoch [8425/10000], Loss: 0.5607667565345764\n",
      "Epoch [8426/10000], Loss: 0.5607671737670898\n",
      "Epoch [8427/10000], Loss: 0.5607672929763794\n",
      "Epoch [8428/10000], Loss: 0.5607680082321167\n",
      "Epoch [8429/10000], Loss: 0.5607686638832092\n",
      "Epoch [8430/10000], Loss: 0.5607695579528809\n",
      "Epoch [8431/10000], Loss: 0.5607708096504211\n",
      "Epoch [8432/10000], Loss: 0.5607718229293823\n",
      "Epoch [8433/10000], Loss: 0.5607725977897644\n",
      "Epoch [8434/10000], Loss: 0.560773491859436\n",
      "Epoch [8435/10000], Loss: 0.5607746839523315\n",
      "Epoch [8436/10000], Loss: 0.5607755184173584\n",
      "Epoch [8437/10000], Loss: 0.5607764720916748\n",
      "Epoch [8438/10000], Loss: 0.56077641248703\n",
      "Epoch [8439/10000], Loss: 0.5607766509056091\n",
      "Epoch [8440/10000], Loss: 0.5607768893241882\n",
      "Epoch [8441/10000], Loss: 0.5607768893241882\n",
      "Epoch [8442/10000], Loss: 0.5607770681381226\n",
      "Epoch [8443/10000], Loss: 0.560776948928833\n",
      "Epoch [8444/10000], Loss: 0.56077641248703\n",
      "Epoch [8445/10000], Loss: 0.5607753396034241\n",
      "Epoch [8446/10000], Loss: 0.5607742667198181\n",
      "Epoch [8447/10000], Loss: 0.5607725381851196\n",
      "Epoch [8448/10000], Loss: 0.5607714653015137\n",
      "Epoch [8449/10000], Loss: 0.5607701539993286\n",
      "Epoch [8450/10000], Loss: 0.5607684254646301\n",
      "Epoch [8451/10000], Loss: 0.5607673525810242\n",
      "Epoch [8452/10000], Loss: 0.5607666373252869\n",
      "Epoch [8453/10000], Loss: 0.5607659220695496\n",
      "Epoch [8454/10000], Loss: 0.5607656836509705\n",
      "Epoch [8455/10000], Loss: 0.5607653260231018\n",
      "Epoch [8456/10000], Loss: 0.5607649683952332\n",
      "Epoch [8457/10000], Loss: 0.5607648491859436\n",
      "Epoch [8458/10000], Loss: 0.5607650279998779\n",
      "Epoch [8459/10000], Loss: 0.5607650876045227\n",
      "Epoch [8460/10000], Loss: 0.5607656836509705\n",
      "Epoch [8461/10000], Loss: 0.5607666969299316\n",
      "Epoch [8462/10000], Loss: 0.5607678294181824\n",
      "Epoch [8463/10000], Loss: 0.5607687830924988\n",
      "Epoch [8464/10000], Loss: 0.5607699751853943\n",
      "Epoch [8465/10000], Loss: 0.5607710480690002\n",
      "Epoch [8466/10000], Loss: 0.5607711672782898\n",
      "Epoch [8467/10000], Loss: 0.5607708692550659\n",
      "Epoch [8468/10000], Loss: 0.5607706904411316\n",
      "Epoch [8469/10000], Loss: 0.5607702732086182\n",
      "Epoch [8470/10000], Loss: 0.5607701539993286\n",
      "Epoch [8471/10000], Loss: 0.5607702136039734\n",
      "Epoch [8472/10000], Loss: 0.5607708096504211\n",
      "Epoch [8473/10000], Loss: 0.5607714056968689\n",
      "Epoch [8474/10000], Loss: 0.560772180557251\n",
      "Epoch [8475/10000], Loss: 0.560772716999054\n",
      "Epoch [8476/10000], Loss: 0.5607727766036987\n",
      "Epoch [8477/10000], Loss: 0.5607730150222778\n",
      "Epoch [8478/10000], Loss: 0.5607722997665405\n",
      "Epoch [8479/10000], Loss: 0.560771644115448\n",
      "Epoch [8480/10000], Loss: 0.560770571231842\n",
      "Epoch [8481/10000], Loss: 0.56076979637146\n",
      "Epoch [8482/10000], Loss: 0.5607695579528809\n",
      "Epoch [8483/10000], Loss: 0.5607697367668152\n",
      "Epoch [8484/10000], Loss: 0.5607696771621704\n",
      "Epoch [8485/10000], Loss: 0.5607705116271973\n",
      "Epoch [8486/10000], Loss: 0.5607709288597107\n",
      "Epoch [8487/10000], Loss: 0.560771107673645\n",
      "Epoch [8488/10000], Loss: 0.560771107673645\n",
      "Epoch [8489/10000], Loss: 0.5607704520225525\n",
      "Epoch [8490/10000], Loss: 0.5607690215110779\n",
      "Epoch [8491/10000], Loss: 0.5607678294181824\n",
      "Epoch [8492/10000], Loss: 0.5607671737670898\n",
      "Epoch [8493/10000], Loss: 0.5607665181159973\n",
      "Epoch [8494/10000], Loss: 0.5607665181159973\n",
      "Epoch [8495/10000], Loss: 0.5607672929763794\n",
      "Epoch [8496/10000], Loss: 0.5607678890228271\n",
      "Epoch [8497/10000], Loss: 0.5607690215110779\n",
      "Epoch [8498/10000], Loss: 0.5607695579528809\n",
      "Epoch [8499/10000], Loss: 0.5607701539993286\n",
      "Epoch [8500/10000], Loss: 0.5607701539993286\n",
      "Epoch [8501/10000], Loss: 0.5607696771621704\n",
      "Epoch [8502/10000], Loss: 0.5607690811157227\n",
      "Epoch [8503/10000], Loss: 0.5607688426971436\n",
      "Epoch [8504/10000], Loss: 0.560768723487854\n",
      "Epoch [8505/10000], Loss: 0.5607692003250122\n",
      "Epoch [8506/10000], Loss: 0.5607700347900391\n",
      "Epoch [8507/10000], Loss: 0.5607709288597107\n",
      "Epoch [8508/10000], Loss: 0.5607712864875793\n",
      "Epoch [8509/10000], Loss: 0.5607718229293823\n",
      "Epoch [8510/10000], Loss: 0.5607720017433167\n",
      "Epoch [8511/10000], Loss: 0.560771644115448\n",
      "Epoch [8512/10000], Loss: 0.5607708692550659\n",
      "Epoch [8513/10000], Loss: 0.56076979637146\n",
      "Epoch [8514/10000], Loss: 0.5607685446739197\n",
      "Epoch [8515/10000], Loss: 0.5607675313949585\n",
      "Epoch [8516/10000], Loss: 0.5607671141624451\n",
      "Epoch [8517/10000], Loss: 0.5607666373252869\n",
      "Epoch [8518/10000], Loss: 0.5607666969299316\n",
      "Epoch [8519/10000], Loss: 0.5607672929763794\n",
      "Epoch [8520/10000], Loss: 0.5607680678367615\n",
      "Epoch [8521/10000], Loss: 0.5607689023017883\n",
      "Epoch [8522/10000], Loss: 0.5607693791389465\n",
      "Epoch [8523/10000], Loss: 0.5607693195343018\n",
      "Epoch [8524/10000], Loss: 0.5607690215110779\n",
      "Epoch [8525/10000], Loss: 0.5607684850692749\n",
      "Epoch [8526/10000], Loss: 0.5607689619064331\n",
      "Epoch [8527/10000], Loss: 0.5607693195343018\n",
      "Epoch [8528/10000], Loss: 0.5607701539993286\n",
      "Epoch [8529/10000], Loss: 0.5607717633247375\n",
      "Epoch [8530/10000], Loss: 0.5607736706733704\n",
      "Epoch [8531/10000], Loss: 0.5607760548591614\n",
      "Epoch [8532/10000], Loss: 0.5607783198356628\n",
      "Epoch [8533/10000], Loss: 0.5607804656028748\n",
      "Epoch [8534/10000], Loss: 0.5607824325561523\n",
      "Epoch [8535/10000], Loss: 0.5607840418815613\n",
      "Epoch [8536/10000], Loss: 0.5607855916023254\n",
      "Epoch [8537/10000], Loss: 0.5607864260673523\n",
      "Epoch [8538/10000], Loss: 0.5607859492301941\n",
      "Epoch [8539/10000], Loss: 0.5607850551605225\n",
      "Epoch [8540/10000], Loss: 0.5607824325561523\n",
      "Epoch [8541/10000], Loss: 0.5607783794403076\n",
      "Epoch [8542/10000], Loss: 0.5607736706733704\n",
      "Epoch [8543/10000], Loss: 0.5607696175575256\n",
      "Epoch [8544/10000], Loss: 0.5607669949531555\n",
      "Epoch [8545/10000], Loss: 0.5607656836509705\n",
      "Epoch [8546/10000], Loss: 0.5607667565345764\n",
      "Epoch [8547/10000], Loss: 0.5607685446739197\n",
      "Epoch [8548/10000], Loss: 0.5607708096504211\n",
      "Epoch [8549/10000], Loss: 0.5607733726501465\n",
      "Epoch [8550/10000], Loss: 0.5607749223709106\n",
      "Epoch [8551/10000], Loss: 0.5607750415802002\n",
      "Epoch [8552/10000], Loss: 0.5607739686965942\n",
      "Epoch [8553/10000], Loss: 0.5607720017433167\n",
      "Epoch [8554/10000], Loss: 0.5607701539993286\n",
      "Epoch [8555/10000], Loss: 0.5607684850692749\n",
      "Epoch [8556/10000], Loss: 0.5607672333717346\n",
      "Epoch [8557/10000], Loss: 0.5607669353485107\n",
      "Epoch [8558/10000], Loss: 0.560767412185669\n",
      "Epoch [8559/10000], Loss: 0.5607683658599854\n",
      "Epoch [8560/10000], Loss: 0.5607695579528809\n",
      "Epoch [8561/10000], Loss: 0.5607708096504211\n",
      "Epoch [8562/10000], Loss: 0.5607712864875793\n",
      "Epoch [8563/10000], Loss: 0.5607712864875793\n",
      "Epoch [8564/10000], Loss: 0.5607708692550659\n",
      "Epoch [8565/10000], Loss: 0.5607699155807495\n",
      "Epoch [8566/10000], Loss: 0.5607686638832092\n",
      "Epoch [8567/10000], Loss: 0.5607671737670898\n",
      "Epoch [8568/10000], Loss: 0.5607662796974182\n",
      "Epoch [8569/10000], Loss: 0.5607656240463257\n",
      "Epoch [8570/10000], Loss: 0.560765266418457\n",
      "Epoch [8571/10000], Loss: 0.560765266418457\n",
      "Epoch [8572/10000], Loss: 0.5607656240463257\n",
      "Epoch [8573/10000], Loss: 0.5607658624649048\n",
      "Epoch [8574/10000], Loss: 0.5607663989067078\n",
      "Epoch [8575/10000], Loss: 0.5607672929763794\n",
      "Epoch [8576/10000], Loss: 0.5607684254646301\n",
      "Epoch [8577/10000], Loss: 0.56076979637146\n",
      "Epoch [8578/10000], Loss: 0.5607708692550659\n",
      "Epoch [8579/10000], Loss: 0.5607709288597107\n",
      "Epoch [8580/10000], Loss: 0.5607706308364868\n",
      "Epoch [8581/10000], Loss: 0.5607703924179077\n",
      "Epoch [8582/10000], Loss: 0.5607700943946838\n",
      "Epoch [8583/10000], Loss: 0.56076979637146\n",
      "Epoch [8584/10000], Loss: 0.5607699751853943\n",
      "Epoch [8585/10000], Loss: 0.5607701539993286\n",
      "Epoch [8586/10000], Loss: 0.5607702732086182\n",
      "Epoch [8587/10000], Loss: 0.5607699155807495\n",
      "Epoch [8588/10000], Loss: 0.5607697367668152\n",
      "Epoch [8589/10000], Loss: 0.5607699751853943\n",
      "Epoch [8590/10000], Loss: 0.5607697367668152\n",
      "Epoch [8591/10000], Loss: 0.5607690811157227\n",
      "Epoch [8592/10000], Loss: 0.5607681274414062\n",
      "Epoch [8593/10000], Loss: 0.560767412185669\n",
      "Epoch [8594/10000], Loss: 0.5607670545578003\n",
      "Epoch [8595/10000], Loss: 0.5607671737670898\n",
      "Epoch [8596/10000], Loss: 0.5607674717903137\n",
      "Epoch [8597/10000], Loss: 0.5607681274414062\n",
      "Epoch [8598/10000], Loss: 0.560768723487854\n",
      "Epoch [8599/10000], Loss: 0.5607689023017883\n",
      "Epoch [8600/10000], Loss: 0.5607684254646301\n",
      "Epoch [8601/10000], Loss: 0.5607681274414062\n",
      "Epoch [8602/10000], Loss: 0.5607680082321167\n",
      "Epoch [8603/10000], Loss: 0.5607677698135376\n",
      "Epoch [8604/10000], Loss: 0.560767412185669\n",
      "Epoch [8605/10000], Loss: 0.5607675313949585\n",
      "Epoch [8606/10000], Loss: 0.5607671141624451\n",
      "Epoch [8607/10000], Loss: 0.5607677698135376\n",
      "Epoch [8608/10000], Loss: 0.5607689619064331\n",
      "Epoch [8609/10000], Loss: 0.5607700347900391\n",
      "Epoch [8610/10000], Loss: 0.5607720613479614\n",
      "Epoch [8611/10000], Loss: 0.5607736706733704\n",
      "Epoch [8612/10000], Loss: 0.5607750415802002\n",
      "Epoch [8613/10000], Loss: 0.5607760548591614\n",
      "Epoch [8614/10000], Loss: 0.5607766509056091\n",
      "Epoch [8615/10000], Loss: 0.5607762336730957\n",
      "Epoch [8616/10000], Loss: 0.5607751607894897\n",
      "Epoch [8617/10000], Loss: 0.5607730746269226\n",
      "Epoch [8618/10000], Loss: 0.5607706308364868\n",
      "Epoch [8619/10000], Loss: 0.5607687830924988\n",
      "Epoch [8620/10000], Loss: 0.5607675909996033\n",
      "Epoch [8621/10000], Loss: 0.560767412185669\n",
      "Epoch [8622/10000], Loss: 0.5607675909996033\n",
      "Epoch [8623/10000], Loss: 0.5607679486274719\n",
      "Epoch [8624/10000], Loss: 0.5607692003250122\n",
      "Epoch [8625/10000], Loss: 0.5607706904411316\n",
      "Epoch [8626/10000], Loss: 0.5607718229293823\n",
      "Epoch [8627/10000], Loss: 0.5607722997665405\n",
      "Epoch [8628/10000], Loss: 0.5607720613479614\n",
      "Epoch [8629/10000], Loss: 0.5607707500457764\n",
      "Epoch [8630/10000], Loss: 0.5607694983482361\n",
      "Epoch [8631/10000], Loss: 0.5607683062553406\n",
      "Epoch [8632/10000], Loss: 0.5607672929763794\n",
      "Epoch [8633/10000], Loss: 0.5607665777206421\n",
      "Epoch [8634/10000], Loss: 0.5607665181159973\n",
      "Epoch [8635/10000], Loss: 0.5607666373252869\n",
      "Epoch [8636/10000], Loss: 0.5607668161392212\n",
      "Epoch [8637/10000], Loss: 0.5607670545578003\n",
      "Epoch [8638/10000], Loss: 0.5607675313949585\n",
      "Epoch [8639/10000], Loss: 0.5607678294181824\n",
      "Epoch [8640/10000], Loss: 0.5607683658599854\n",
      "Epoch [8641/10000], Loss: 0.5607680678367615\n",
      "Epoch [8642/10000], Loss: 0.5607678890228271\n",
      "Epoch [8643/10000], Loss: 0.5607677102088928\n",
      "Epoch [8644/10000], Loss: 0.5607675313949585\n",
      "Epoch [8645/10000], Loss: 0.5607677698135376\n",
      "Epoch [8646/10000], Loss: 0.5607682466506958\n",
      "Epoch [8647/10000], Loss: 0.5607690215110779\n",
      "Epoch [8648/10000], Loss: 0.560770571231842\n",
      "Epoch [8649/10000], Loss: 0.5607726573944092\n",
      "Epoch [8650/10000], Loss: 0.5607753396034241\n",
      "Epoch [8651/10000], Loss: 0.5607772469520569\n",
      "Epoch [8652/10000], Loss: 0.560779333114624\n",
      "Epoch [8653/10000], Loss: 0.5607811808586121\n",
      "Epoch [8654/10000], Loss: 0.5607824325561523\n",
      "Epoch [8655/10000], Loss: 0.5607828497886658\n",
      "Epoch [8656/10000], Loss: 0.5607824325561523\n",
      "Epoch [8657/10000], Loss: 0.5607805252075195\n",
      "Epoch [8658/10000], Loss: 0.5607780814170837\n",
      "Epoch [8659/10000], Loss: 0.5607749223709106\n",
      "Epoch [8660/10000], Loss: 0.5607721209526062\n",
      "Epoch [8661/10000], Loss: 0.5607699751853943\n",
      "Epoch [8662/10000], Loss: 0.5607681274414062\n",
      "Epoch [8663/10000], Loss: 0.5607674717903137\n",
      "Epoch [8664/10000], Loss: 0.5607667565345764\n",
      "Epoch [8665/10000], Loss: 0.5607668161392212\n",
      "Epoch [8666/10000], Loss: 0.560767412185669\n",
      "Epoch [8667/10000], Loss: 0.5607681274414062\n",
      "Epoch [8668/10000], Loss: 0.5607680678367615\n",
      "Epoch [8669/10000], Loss: 0.5607685446739197\n",
      "Epoch [8670/10000], Loss: 0.5607690215110779\n",
      "Epoch [8671/10000], Loss: 0.5607690811157227\n",
      "Epoch [8672/10000], Loss: 0.5607688426971436\n",
      "Epoch [8673/10000], Loss: 0.5607692003250122\n",
      "Epoch [8674/10000], Loss: 0.5607696175575256\n",
      "Epoch [8675/10000], Loss: 0.5607699751853943\n",
      "Epoch [8676/10000], Loss: 0.56076979637146\n",
      "Epoch [8677/10000], Loss: 0.5607699751853943\n",
      "Epoch [8678/10000], Loss: 0.5607697367668152\n",
      "Epoch [8679/10000], Loss: 0.5607693195343018\n",
      "Epoch [8680/10000], Loss: 0.5607688426971436\n",
      "Epoch [8681/10000], Loss: 0.5607678294181824\n",
      "Epoch [8682/10000], Loss: 0.5607666373252869\n",
      "Epoch [8683/10000], Loss: 0.5607663989067078\n",
      "Epoch [8684/10000], Loss: 0.5607659220695496\n",
      "Epoch [8685/10000], Loss: 0.5607653260231018\n",
      "Epoch [8686/10000], Loss: 0.5607653856277466\n",
      "Epoch [8687/10000], Loss: 0.5607653260231018\n",
      "Epoch [8688/10000], Loss: 0.5607655644416809\n",
      "Epoch [8689/10000], Loss: 0.5607660412788391\n",
      "Epoch [8690/10000], Loss: 0.5607664585113525\n",
      "Epoch [8691/10000], Loss: 0.5607670545578003\n",
      "Epoch [8692/10000], Loss: 0.5607681274414062\n",
      "Epoch [8693/10000], Loss: 0.5607696771621704\n",
      "Epoch [8694/10000], Loss: 0.5607709884643555\n",
      "Epoch [8695/10000], Loss: 0.5607714056968689\n",
      "Epoch [8696/10000], Loss: 0.5607714056968689\n",
      "Epoch [8697/10000], Loss: 0.5607712268829346\n",
      "Epoch [8698/10000], Loss: 0.5607699751853943\n",
      "Epoch [8699/10000], Loss: 0.5607693791389465\n",
      "Epoch [8700/10000], Loss: 0.5607683658599854\n",
      "Epoch [8701/10000], Loss: 0.5607678294181824\n",
      "Epoch [8702/10000], Loss: 0.5607678890228271\n",
      "Epoch [8703/10000], Loss: 0.5607681274414062\n",
      "Epoch [8704/10000], Loss: 0.5607683658599854\n",
      "Epoch [8705/10000], Loss: 0.5607684850692749\n",
      "Epoch [8706/10000], Loss: 0.5607684850692749\n",
      "Epoch [8707/10000], Loss: 0.5607675909996033\n",
      "Epoch [8708/10000], Loss: 0.5607666373252869\n",
      "Epoch [8709/10000], Loss: 0.56076580286026\n",
      "Epoch [8710/10000], Loss: 0.5607656836509705\n",
      "Epoch [8711/10000], Loss: 0.560765266418457\n",
      "Epoch [8712/10000], Loss: 0.5607651472091675\n",
      "Epoch [8713/10000], Loss: 0.560765266418457\n",
      "Epoch [8714/10000], Loss: 0.5607656836509705\n",
      "Epoch [8715/10000], Loss: 0.5607663989067078\n",
      "Epoch [8716/10000], Loss: 0.560767650604248\n",
      "Epoch [8717/10000], Loss: 0.5607692003250122\n",
      "Epoch [8718/10000], Loss: 0.5607708692550659\n",
      "Epoch [8719/10000], Loss: 0.560772716999054\n",
      "Epoch [8720/10000], Loss: 0.5607746839523315\n",
      "Epoch [8721/10000], Loss: 0.5607753992080688\n",
      "Epoch [8722/10000], Loss: 0.5607763528823853\n",
      "Epoch [8723/10000], Loss: 0.5607766509056091\n",
      "Epoch [8724/10000], Loss: 0.5607774257659912\n",
      "Epoch [8725/10000], Loss: 0.560776948928833\n",
      "Epoch [8726/10000], Loss: 0.5607762932777405\n",
      "Epoch [8727/10000], Loss: 0.5607758164405823\n",
      "Epoch [8728/10000], Loss: 0.560775876045227\n",
      "Epoch [8729/10000], Loss: 0.5607762932777405\n",
      "Epoch [8730/10000], Loss: 0.5607770681381226\n",
      "Epoch [8731/10000], Loss: 0.5607786178588867\n",
      "Epoch [8732/10000], Loss: 0.5607804656028748\n",
      "Epoch [8733/10000], Loss: 0.5607815384864807\n",
      "Epoch [8734/10000], Loss: 0.5607810020446777\n",
      "Epoch [8735/10000], Loss: 0.5607788562774658\n",
      "Epoch [8736/10000], Loss: 0.5607749819755554\n",
      "Epoch [8737/10000], Loss: 0.5607708096504211\n",
      "Epoch [8738/10000], Loss: 0.5607678294181824\n",
      "Epoch [8739/10000], Loss: 0.5607659816741943\n",
      "Epoch [8740/10000], Loss: 0.5607646107673645\n",
      "Epoch [8741/10000], Loss: 0.5607647895812988\n",
      "Epoch [8742/10000], Loss: 0.5607658624649048\n",
      "Epoch [8743/10000], Loss: 0.5607671737670898\n",
      "Epoch [8744/10000], Loss: 0.5607687830924988\n",
      "Epoch [8745/10000], Loss: 0.560770571231842\n",
      "Epoch [8746/10000], Loss: 0.5607720613479614\n",
      "Epoch [8747/10000], Loss: 0.5607730746269226\n",
      "Epoch [8748/10000], Loss: 0.5607734322547913\n",
      "Epoch [8749/10000], Loss: 0.560772716999054\n",
      "Epoch [8750/10000], Loss: 0.5607712864875793\n",
      "Epoch [8751/10000], Loss: 0.5607700943946838\n",
      "Epoch [8752/10000], Loss: 0.5607690215110779\n",
      "Epoch [8753/10000], Loss: 0.5607681274414062\n",
      "Epoch [8754/10000], Loss: 0.5607677102088928\n",
      "Epoch [8755/10000], Loss: 0.5607679486274719\n",
      "Epoch [8756/10000], Loss: 0.5607678294181824\n",
      "Epoch [8757/10000], Loss: 0.560767412185669\n",
      "Epoch [8758/10000], Loss: 0.5607666969299316\n",
      "Epoch [8759/10000], Loss: 0.5607662796974182\n",
      "Epoch [8760/10000], Loss: 0.5607662200927734\n",
      "Epoch [8761/10000], Loss: 0.5607661604881287\n",
      "Epoch [8762/10000], Loss: 0.560766339302063\n",
      "Epoch [8763/10000], Loss: 0.5607671141624451\n",
      "Epoch [8764/10000], Loss: 0.5607680678367615\n",
      "Epoch [8765/10000], Loss: 0.5607689619064331\n",
      "Epoch [8766/10000], Loss: 0.5607700943946838\n",
      "Epoch [8767/10000], Loss: 0.5607709884643555\n",
      "Epoch [8768/10000], Loss: 0.5607717633247375\n",
      "Epoch [8769/10000], Loss: 0.560772716999054\n",
      "Epoch [8770/10000], Loss: 0.560773491859436\n",
      "Epoch [8771/10000], Loss: 0.5607739686965942\n",
      "Epoch [8772/10000], Loss: 0.5607743263244629\n",
      "Epoch [8773/10000], Loss: 0.560774028301239\n",
      "Epoch [8774/10000], Loss: 0.5607736706733704\n",
      "Epoch [8775/10000], Loss: 0.5607733130455017\n",
      "Epoch [8776/10000], Loss: 0.5607721209526062\n",
      "Epoch [8777/10000], Loss: 0.5607706904411316\n",
      "Epoch [8778/10000], Loss: 0.5607697367668152\n",
      "Epoch [8779/10000], Loss: 0.5607691407203674\n",
      "Epoch [8780/10000], Loss: 0.5607684254646301\n",
      "Epoch [8781/10000], Loss: 0.5607684850692749\n",
      "Epoch [8782/10000], Loss: 0.5607683658599854\n",
      "Epoch [8783/10000], Loss: 0.5607683658599854\n",
      "Epoch [8784/10000], Loss: 0.560768187046051\n",
      "Epoch [8785/10000], Loss: 0.5607680678367615\n",
      "Epoch [8786/10000], Loss: 0.5607671737670898\n",
      "Epoch [8787/10000], Loss: 0.5607666373252869\n",
      "Epoch [8788/10000], Loss: 0.5607661604881287\n",
      "Epoch [8789/10000], Loss: 0.5607657432556152\n",
      "Epoch [8790/10000], Loss: 0.5607654452323914\n",
      "Epoch [8791/10000], Loss: 0.5607656836509705\n",
      "Epoch [8792/10000], Loss: 0.5607662796974182\n",
      "Epoch [8793/10000], Loss: 0.5607671737670898\n",
      "Epoch [8794/10000], Loss: 0.5607683658599854\n",
      "Epoch [8795/10000], Loss: 0.5607698559761047\n",
      "Epoch [8796/10000], Loss: 0.560771644115448\n",
      "Epoch [8797/10000], Loss: 0.5607729554176331\n",
      "Epoch [8798/10000], Loss: 0.5607738494873047\n",
      "Epoch [8799/10000], Loss: 0.5607739686965942\n",
      "Epoch [8800/10000], Loss: 0.5607722401618958\n",
      "Epoch [8801/10000], Loss: 0.5607698559761047\n",
      "Epoch [8802/10000], Loss: 0.560767650604248\n",
      "Epoch [8803/10000], Loss: 0.5607662796974182\n",
      "Epoch [8804/10000], Loss: 0.5607656240463257\n",
      "Epoch [8805/10000], Loss: 0.5607652068138123\n",
      "Epoch [8806/10000], Loss: 0.560764729976654\n",
      "Epoch [8807/10000], Loss: 0.560764491558075\n",
      "Epoch [8808/10000], Loss: 0.560764491558075\n",
      "Epoch [8809/10000], Loss: 0.5607647895812988\n",
      "Epoch [8810/10000], Loss: 0.5607655048370361\n",
      "Epoch [8811/10000], Loss: 0.5607663989067078\n",
      "Epoch [8812/10000], Loss: 0.5607674717903137\n",
      "Epoch [8813/10000], Loss: 0.5607692003250122\n",
      "Epoch [8814/10000], Loss: 0.5607713460922241\n",
      "Epoch [8815/10000], Loss: 0.5607730150222778\n",
      "Epoch [8816/10000], Loss: 0.5607739090919495\n",
      "Epoch [8817/10000], Loss: 0.5607736110687256\n",
      "Epoch [8818/10000], Loss: 0.5607717037200928\n",
      "Epoch [8819/10000], Loss: 0.56076979637146\n",
      "Epoch [8820/10000], Loss: 0.5607682466506958\n",
      "Epoch [8821/10000], Loss: 0.5607673525810242\n",
      "Epoch [8822/10000], Loss: 0.5607673525810242\n",
      "Epoch [8823/10000], Loss: 0.5607680678367615\n",
      "Epoch [8824/10000], Loss: 0.5607690811157227\n",
      "Epoch [8825/10000], Loss: 0.5607706308364868\n",
      "Epoch [8826/10000], Loss: 0.5607726573944092\n",
      "Epoch [8827/10000], Loss: 0.5607752203941345\n",
      "Epoch [8828/10000], Loss: 0.5607781410217285\n",
      "Epoch [8829/10000], Loss: 0.5607800483703613\n",
      "Epoch [8830/10000], Loss: 0.5607806444168091\n",
      "Epoch [8831/10000], Loss: 0.5607810020446777\n",
      "Epoch [8832/10000], Loss: 0.5607796311378479\n",
      "Epoch [8833/10000], Loss: 0.560778021812439\n",
      "Epoch [8834/10000], Loss: 0.560776948928833\n",
      "Epoch [8835/10000], Loss: 0.5607762336730957\n",
      "Epoch [8836/10000], Loss: 0.5607760548591614\n",
      "Epoch [8837/10000], Loss: 0.5607765316963196\n",
      "Epoch [8838/10000], Loss: 0.5607772469520569\n",
      "Epoch [8839/10000], Loss: 0.5607763528823853\n",
      "Epoch [8840/10000], Loss: 0.5607741475105286\n",
      "Epoch [8841/10000], Loss: 0.560771107673645\n",
      "Epoch [8842/10000], Loss: 0.5607683658599854\n",
      "Epoch [8843/10000], Loss: 0.5607665181159973\n",
      "Epoch [8844/10000], Loss: 0.5607656836509705\n",
      "Epoch [8845/10000], Loss: 0.56076580286026\n",
      "Epoch [8846/10000], Loss: 0.560766339302063\n",
      "Epoch [8847/10000], Loss: 0.5607675313949585\n",
      "Epoch [8848/10000], Loss: 0.5607689619064331\n",
      "Epoch [8849/10000], Loss: 0.5607704520225525\n",
      "Epoch [8850/10000], Loss: 0.5607715845108032\n",
      "Epoch [8851/10000], Loss: 0.5607721209526062\n",
      "Epoch [8852/10000], Loss: 0.5607714653015137\n",
      "Epoch [8853/10000], Loss: 0.5607709288597107\n",
      "Epoch [8854/10000], Loss: 0.5607703924179077\n",
      "Epoch [8855/10000], Loss: 0.560770571231842\n",
      "Epoch [8856/10000], Loss: 0.560770571231842\n",
      "Epoch [8857/10000], Loss: 0.5607713460922241\n",
      "Epoch [8858/10000], Loss: 0.5607714056968689\n",
      "Epoch [8859/10000], Loss: 0.5607704520225525\n",
      "Epoch [8860/10000], Loss: 0.5607696771621704\n",
      "Epoch [8861/10000], Loss: 0.5607683658599854\n",
      "Epoch [8862/10000], Loss: 0.5607673525810242\n",
      "Epoch [8863/10000], Loss: 0.5607660412788391\n",
      "Epoch [8864/10000], Loss: 0.560765266418457\n",
      "Epoch [8865/10000], Loss: 0.5607652068138123\n",
      "Epoch [8866/10000], Loss: 0.5607647895812988\n",
      "Epoch [8867/10000], Loss: 0.5607645511627197\n",
      "Epoch [8868/10000], Loss: 0.5607644319534302\n",
      "Epoch [8869/10000], Loss: 0.5607643723487854\n",
      "Epoch [8870/10000], Loss: 0.560764491558075\n",
      "Epoch [8871/10000], Loss: 0.560765266418457\n",
      "Epoch [8872/10000], Loss: 0.5607656836509705\n",
      "Epoch [8873/10000], Loss: 0.5607664585113525\n",
      "Epoch [8874/10000], Loss: 0.5607669949531555\n",
      "Epoch [8875/10000], Loss: 0.5607682466506958\n",
      "Epoch [8876/10000], Loss: 0.5607699751853943\n",
      "Epoch [8877/10000], Loss: 0.5607714056968689\n",
      "Epoch [8878/10000], Loss: 0.5607732534408569\n",
      "Epoch [8879/10000], Loss: 0.5607748627662659\n",
      "Epoch [8880/10000], Loss: 0.5607757568359375\n",
      "Epoch [8881/10000], Loss: 0.5607759356498718\n",
      "Epoch [8882/10000], Loss: 0.5607759952545166\n",
      "Epoch [8883/10000], Loss: 0.5607760548591614\n",
      "Epoch [8884/10000], Loss: 0.5607758164405823\n",
      "Epoch [8885/10000], Loss: 0.560775101184845\n",
      "Epoch [8886/10000], Loss: 0.5607736110687256\n",
      "Epoch [8887/10000], Loss: 0.5607728958129883\n",
      "Epoch [8888/10000], Loss: 0.5607724785804749\n",
      "Epoch [8889/10000], Loss: 0.560772716999054\n",
      "Epoch [8890/10000], Loss: 0.5607725977897644\n",
      "Epoch [8891/10000], Loss: 0.5607720613479614\n",
      "Epoch [8892/10000], Loss: 0.5607706308364868\n",
      "Epoch [8893/10000], Loss: 0.5607690215110779\n",
      "Epoch [8894/10000], Loss: 0.5607678294181824\n",
      "Epoch [8895/10000], Loss: 0.5607671141624451\n",
      "Epoch [8896/10000], Loss: 0.5607669353485107\n",
      "Epoch [8897/10000], Loss: 0.5607665181159973\n",
      "Epoch [8898/10000], Loss: 0.5607659220695496\n",
      "Epoch [8899/10000], Loss: 0.5607659816741943\n",
      "Epoch [8900/10000], Loss: 0.5607659220695496\n",
      "Epoch [8901/10000], Loss: 0.5607661604881287\n",
      "Epoch [8902/10000], Loss: 0.5607665181159973\n",
      "Epoch [8903/10000], Loss: 0.5607671141624451\n",
      "Epoch [8904/10000], Loss: 0.5607673525810242\n",
      "Epoch [8905/10000], Loss: 0.560767412185669\n",
      "Epoch [8906/10000], Loss: 0.5607678294181824\n",
      "Epoch [8907/10000], Loss: 0.5607683658599854\n",
      "Epoch [8908/10000], Loss: 0.5607690215110779\n",
      "Epoch [8909/10000], Loss: 0.5607694983482361\n",
      "Epoch [8910/10000], Loss: 0.5607703328132629\n",
      "Epoch [8911/10000], Loss: 0.5607715249061584\n",
      "Epoch [8912/10000], Loss: 0.5607733130455017\n",
      "Epoch [8913/10000], Loss: 0.5607751607894897\n",
      "Epoch [8914/10000], Loss: 0.5607765913009644\n",
      "Epoch [8915/10000], Loss: 0.5607768893241882\n",
      "Epoch [8916/10000], Loss: 0.5607755780220032\n",
      "Epoch [8917/10000], Loss: 0.5607733726501465\n",
      "Epoch [8918/10000], Loss: 0.5607709288597107\n",
      "Epoch [8919/10000], Loss: 0.5607690811157227\n",
      "Epoch [8920/10000], Loss: 0.5607675313949585\n",
      "Epoch [8921/10000], Loss: 0.5607669949531555\n",
      "Epoch [8922/10000], Loss: 0.5607675909996033\n",
      "Epoch [8923/10000], Loss: 0.5607683062553406\n",
      "Epoch [8924/10000], Loss: 0.5607689023017883\n",
      "Epoch [8925/10000], Loss: 0.5607695579528809\n",
      "Epoch [8926/10000], Loss: 0.5607702136039734\n",
      "Epoch [8927/10000], Loss: 0.5607703924179077\n",
      "Epoch [8928/10000], Loss: 0.5607702136039734\n",
      "Epoch [8929/10000], Loss: 0.5607697367668152\n",
      "Epoch [8930/10000], Loss: 0.5607696771621704\n",
      "Epoch [8931/10000], Loss: 0.5607688426971436\n",
      "Epoch [8932/10000], Loss: 0.5607686042785645\n",
      "Epoch [8933/10000], Loss: 0.5607683658599854\n",
      "Epoch [8934/10000], Loss: 0.560768723487854\n",
      "Epoch [8935/10000], Loss: 0.5607690811157227\n",
      "Epoch [8936/10000], Loss: 0.5607694983482361\n",
      "Epoch [8937/10000], Loss: 0.5607697367668152\n",
      "Epoch [8938/10000], Loss: 0.5607702136039734\n",
      "Epoch [8939/10000], Loss: 0.5607700943946838\n",
      "Epoch [8940/10000], Loss: 0.5607699751853943\n",
      "Epoch [8941/10000], Loss: 0.5607692003250122\n",
      "Epoch [8942/10000], Loss: 0.5607683658599854\n",
      "Epoch [8943/10000], Loss: 0.5607675909996033\n",
      "Epoch [8944/10000], Loss: 0.5607671141624451\n",
      "Epoch [8945/10000], Loss: 0.5607670545578003\n",
      "Epoch [8946/10000], Loss: 0.5607675313949585\n",
      "Epoch [8947/10000], Loss: 0.5607678294181824\n",
      "Epoch [8948/10000], Loss: 0.5607683062553406\n",
      "Epoch [8949/10000], Loss: 0.5607690811157227\n",
      "Epoch [8950/10000], Loss: 0.5607694983482361\n",
      "Epoch [8951/10000], Loss: 0.5607694387435913\n",
      "Epoch [8952/10000], Loss: 0.5607694983482361\n",
      "Epoch [8953/10000], Loss: 0.5607693791389465\n",
      "Epoch [8954/10000], Loss: 0.5607692003250122\n",
      "Epoch [8955/10000], Loss: 0.5607685446739197\n",
      "Epoch [8956/10000], Loss: 0.560767650604248\n",
      "Epoch [8957/10000], Loss: 0.5607664585113525\n",
      "Epoch [8958/10000], Loss: 0.5607662796974182\n",
      "Epoch [8959/10000], Loss: 0.5607660412788391\n",
      "Epoch [8960/10000], Loss: 0.5607657432556152\n",
      "Epoch [8961/10000], Loss: 0.5607659816741943\n",
      "Epoch [8962/10000], Loss: 0.5607661604881287\n",
      "Epoch [8963/10000], Loss: 0.5607664585113525\n",
      "Epoch [8964/10000], Loss: 0.5607671737670898\n",
      "Epoch [8965/10000], Loss: 0.5607684850692749\n",
      "Epoch [8966/10000], Loss: 0.5607702136039734\n",
      "Epoch [8967/10000], Loss: 0.5607718229293823\n",
      "Epoch [8968/10000], Loss: 0.5607731938362122\n",
      "Epoch [8969/10000], Loss: 0.5607744455337524\n",
      "Epoch [8970/10000], Loss: 0.560775637626648\n",
      "Epoch [8971/10000], Loss: 0.5607765913009644\n",
      "Epoch [8972/10000], Loss: 0.5607777833938599\n",
      "Epoch [8973/10000], Loss: 0.5607790350914001\n",
      "Epoch [8974/10000], Loss: 0.5607807040214539\n",
      "Epoch [8975/10000], Loss: 0.5607820749282837\n",
      "Epoch [8976/10000], Loss: 0.560783326625824\n",
      "Epoch [8977/10000], Loss: 0.5607843399047852\n",
      "Epoch [8978/10000], Loss: 0.5607836842536926\n",
      "Epoch [8979/10000], Loss: 0.5607817769050598\n",
      "Epoch [8980/10000], Loss: 0.560778021812439\n",
      "Epoch [8981/10000], Loss: 0.5607736110687256\n",
      "Epoch [8982/10000], Loss: 0.5607692003250122\n",
      "Epoch [8983/10000], Loss: 0.5607664585113525\n",
      "Epoch [8984/10000], Loss: 0.5607649683952332\n",
      "Epoch [8985/10000], Loss: 0.560764729976654\n",
      "Epoch [8986/10000], Loss: 0.5607657432556152\n",
      "Epoch [8987/10000], Loss: 0.5607673525810242\n",
      "Epoch [8988/10000], Loss: 0.5607692003250122\n",
      "Epoch [8989/10000], Loss: 0.5607704520225525\n",
      "Epoch [8990/10000], Loss: 0.5607707500457764\n",
      "Epoch [8991/10000], Loss: 0.5607699751853943\n",
      "Epoch [8992/10000], Loss: 0.5607686638832092\n",
      "Epoch [8993/10000], Loss: 0.5607672333717346\n",
      "Epoch [8994/10000], Loss: 0.5607662796974182\n",
      "Epoch [8995/10000], Loss: 0.5607654452323914\n",
      "Epoch [8996/10000], Loss: 0.5607648491859436\n",
      "Epoch [8997/10000], Loss: 0.5607654452323914\n",
      "Epoch [8998/10000], Loss: 0.5607660412788391\n",
      "Epoch [8999/10000], Loss: 0.5607671737670898\n",
      "Epoch [9000/10000], Loss: 0.5607690215110779\n",
      "Epoch [9001/10000], Loss: 0.5607702732086182\n",
      "Epoch [9002/10000], Loss: 0.5607718825340271\n",
      "Epoch [9003/10000], Loss: 0.5607727766036987\n",
      "Epoch [9004/10000], Loss: 0.5607730150222778\n",
      "Epoch [9005/10000], Loss: 0.5607722997665405\n",
      "Epoch [9006/10000], Loss: 0.560771107673645\n",
      "Epoch [9007/10000], Loss: 0.5607695579528809\n",
      "Epoch [9008/10000], Loss: 0.5607683658599854\n",
      "Epoch [9009/10000], Loss: 0.5607680678367615\n",
      "Epoch [9010/10000], Loss: 0.5607678294181824\n",
      "Epoch [9011/10000], Loss: 0.560767412185669\n",
      "Epoch [9012/10000], Loss: 0.5607675313949585\n",
      "Epoch [9013/10000], Loss: 0.5607677102088928\n",
      "Epoch [9014/10000], Loss: 0.560767650604248\n",
      "Epoch [9015/10000], Loss: 0.5607670545578003\n",
      "Epoch [9016/10000], Loss: 0.5607670545578003\n",
      "Epoch [9017/10000], Loss: 0.5607671737670898\n",
      "Epoch [9018/10000], Loss: 0.5607680082321167\n",
      "Epoch [9019/10000], Loss: 0.5607689619064331\n",
      "Epoch [9020/10000], Loss: 0.5607697367668152\n",
      "Epoch [9021/10000], Loss: 0.5607708096504211\n",
      "Epoch [9022/10000], Loss: 0.5607714056968689\n",
      "Epoch [9023/10000], Loss: 0.5607719421386719\n",
      "Epoch [9024/10000], Loss: 0.5607722401618958\n",
      "Epoch [9025/10000], Loss: 0.5607722401618958\n",
      "Epoch [9026/10000], Loss: 0.5607722401618958\n",
      "Epoch [9027/10000], Loss: 0.560771644115448\n",
      "Epoch [9028/10000], Loss: 0.5607708692550659\n",
      "Epoch [9029/10000], Loss: 0.5607696771621704\n",
      "Epoch [9030/10000], Loss: 0.560768723487854\n",
      "Epoch [9031/10000], Loss: 0.5607680678367615\n",
      "Epoch [9032/10000], Loss: 0.5607675313949585\n",
      "Epoch [9033/10000], Loss: 0.5607672333717346\n",
      "Epoch [9034/10000], Loss: 0.5607670545578003\n",
      "Epoch [9035/10000], Loss: 0.5607672929763794\n",
      "Epoch [9036/10000], Loss: 0.5607672333717346\n",
      "Epoch [9037/10000], Loss: 0.5607670545578003\n",
      "Epoch [9038/10000], Loss: 0.5607669949531555\n",
      "Epoch [9039/10000], Loss: 0.5607673525810242\n",
      "Epoch [9040/10000], Loss: 0.5607673525810242\n",
      "Epoch [9041/10000], Loss: 0.5607678890228271\n",
      "Epoch [9042/10000], Loss: 0.5607689023017883\n",
      "Epoch [9043/10000], Loss: 0.5607702136039734\n",
      "Epoch [9044/10000], Loss: 0.5607714653015137\n",
      "Epoch [9045/10000], Loss: 0.5607723593711853\n",
      "Epoch [9046/10000], Loss: 0.5607731938362122\n",
      "Epoch [9047/10000], Loss: 0.5607738494873047\n",
      "Epoch [9048/10000], Loss: 0.5607739686965942\n",
      "Epoch [9049/10000], Loss: 0.5607742071151733\n",
      "Epoch [9050/10000], Loss: 0.5607744455337524\n",
      "Epoch [9051/10000], Loss: 0.5607744455337524\n",
      "Epoch [9052/10000], Loss: 0.5607744455337524\n",
      "Epoch [9053/10000], Loss: 0.5607739686965942\n",
      "Epoch [9054/10000], Loss: 0.5607734322547913\n",
      "Epoch [9055/10000], Loss: 0.5607724785804749\n",
      "Epoch [9056/10000], Loss: 0.5607715845108032\n",
      "Epoch [9057/10000], Loss: 0.5607706904411316\n",
      "Epoch [9058/10000], Loss: 0.5607700943946838\n",
      "Epoch [9059/10000], Loss: 0.5607697367668152\n",
      "Epoch [9060/10000], Loss: 0.560769259929657\n",
      "Epoch [9061/10000], Loss: 0.5607689619064331\n",
      "Epoch [9062/10000], Loss: 0.560769259929657\n",
      "Epoch [9063/10000], Loss: 0.5607696175575256\n",
      "Epoch [9064/10000], Loss: 0.5607696771621704\n",
      "Epoch [9065/10000], Loss: 0.5607697367668152\n",
      "Epoch [9066/10000], Loss: 0.5607693195343018\n",
      "Epoch [9067/10000], Loss: 0.5607686042785645\n",
      "Epoch [9068/10000], Loss: 0.5607680678367615\n",
      "Epoch [9069/10000], Loss: 0.5607671141624451\n",
      "Epoch [9070/10000], Loss: 0.5607662796974182\n",
      "Epoch [9071/10000], Loss: 0.56076580286026\n",
      "Epoch [9072/10000], Loss: 0.5607652068138123\n",
      "Epoch [9073/10000], Loss: 0.5607648491859436\n",
      "Epoch [9074/10000], Loss: 0.5607648491859436\n",
      "Epoch [9075/10000], Loss: 0.5607645511627197\n",
      "Epoch [9076/10000], Loss: 0.5607644319534302\n",
      "Epoch [9077/10000], Loss: 0.5607645511627197\n",
      "Epoch [9078/10000], Loss: 0.5607646107673645\n",
      "Epoch [9079/10000], Loss: 0.5607650876045227\n",
      "Epoch [9080/10000], Loss: 0.5607656836509705\n",
      "Epoch [9081/10000], Loss: 0.5607669353485107\n",
      "Epoch [9082/10000], Loss: 0.560768723487854\n",
      "Epoch [9083/10000], Loss: 0.5607704520225525\n",
      "Epoch [9084/10000], Loss: 0.5607720613479614\n",
      "Epoch [9085/10000], Loss: 0.5607733726501465\n",
      "Epoch [9086/10000], Loss: 0.5607739686965942\n",
      "Epoch [9087/10000], Loss: 0.5607736706733704\n",
      "Epoch [9088/10000], Loss: 0.5607739090919495\n",
      "Epoch [9089/10000], Loss: 0.5607739686965942\n",
      "Epoch [9090/10000], Loss: 0.5607745051383972\n",
      "Epoch [9091/10000], Loss: 0.5607760548591614\n",
      "Epoch [9092/10000], Loss: 0.5607772469520569\n",
      "Epoch [9093/10000], Loss: 0.5607785582542419\n",
      "Epoch [9094/10000], Loss: 0.5607793927192688\n",
      "Epoch [9095/10000], Loss: 0.5607795715332031\n",
      "Epoch [9096/10000], Loss: 0.5607788562774658\n",
      "Epoch [9097/10000], Loss: 0.5607773065567017\n",
      "Epoch [9098/10000], Loss: 0.5607748031616211\n",
      "Epoch [9099/10000], Loss: 0.5607722997665405\n",
      "Epoch [9100/10000], Loss: 0.5607706308364868\n",
      "Epoch [9101/10000], Loss: 0.5607689619064331\n",
      "Epoch [9102/10000], Loss: 0.5607681274414062\n",
      "Epoch [9103/10000], Loss: 0.5607678294181824\n",
      "Epoch [9104/10000], Loss: 0.5607680082321167\n",
      "Epoch [9105/10000], Loss: 0.5607678890228271\n",
      "Epoch [9106/10000], Loss: 0.5607672333717346\n",
      "Epoch [9107/10000], Loss: 0.5607669949531555\n",
      "Epoch [9108/10000], Loss: 0.5607660412788391\n",
      "Epoch [9109/10000], Loss: 0.5607656836509705\n",
      "Epoch [9110/10000], Loss: 0.56076580286026\n",
      "Epoch [9111/10000], Loss: 0.5607661604881287\n",
      "Epoch [9112/10000], Loss: 0.5607666969299316\n",
      "Epoch [9113/10000], Loss: 0.5607679486274719\n",
      "Epoch [9114/10000], Loss: 0.5607697367668152\n",
      "Epoch [9115/10000], Loss: 0.5607722997665405\n",
      "Epoch [9116/10000], Loss: 0.5607741475105286\n",
      "Epoch [9117/10000], Loss: 0.5607753992080688\n",
      "Epoch [9118/10000], Loss: 0.5607743263244629\n",
      "Epoch [9119/10000], Loss: 0.5607718229293823\n",
      "Epoch [9120/10000], Loss: 0.5607687830924988\n",
      "Epoch [9121/10000], Loss: 0.5607669353485107\n",
      "Epoch [9122/10000], Loss: 0.5607657432556152\n",
      "Epoch [9123/10000], Loss: 0.5607657432556152\n",
      "Epoch [9124/10000], Loss: 0.5607663989067078\n",
      "Epoch [9125/10000], Loss: 0.5607670545578003\n",
      "Epoch [9126/10000], Loss: 0.5607680678367615\n",
      "Epoch [9127/10000], Loss: 0.560769259929657\n",
      "Epoch [9128/10000], Loss: 0.5607696771621704\n",
      "Epoch [9129/10000], Loss: 0.5607697367668152\n",
      "Epoch [9130/10000], Loss: 0.5607701539993286\n",
      "Epoch [9131/10000], Loss: 0.5607701539993286\n",
      "Epoch [9132/10000], Loss: 0.5607695579528809\n",
      "Epoch [9133/10000], Loss: 0.5607692003250122\n",
      "Epoch [9134/10000], Loss: 0.5607689023017883\n",
      "Epoch [9135/10000], Loss: 0.5607683658599854\n",
      "Epoch [9136/10000], Loss: 0.560768187046051\n",
      "Epoch [9137/10000], Loss: 0.5607680082321167\n",
      "Epoch [9138/10000], Loss: 0.560767650604248\n",
      "Epoch [9139/10000], Loss: 0.5607669949531555\n",
      "Epoch [9140/10000], Loss: 0.5607661008834839\n",
      "Epoch [9141/10000], Loss: 0.560765266418457\n",
      "Epoch [9142/10000], Loss: 0.5607648491859436\n",
      "Epoch [9143/10000], Loss: 0.5607649683952332\n",
      "Epoch [9144/10000], Loss: 0.5607650876045227\n",
      "Epoch [9145/10000], Loss: 0.5607659816741943\n",
      "Epoch [9146/10000], Loss: 0.5607669949531555\n",
      "Epoch [9147/10000], Loss: 0.5607681274414062\n",
      "Epoch [9148/10000], Loss: 0.5607700347900391\n",
      "Epoch [9149/10000], Loss: 0.5607720613479614\n",
      "Epoch [9150/10000], Loss: 0.5607743263244629\n",
      "Epoch [9151/10000], Loss: 0.5607753992080688\n",
      "Epoch [9152/10000], Loss: 0.5607754588127136\n",
      "Epoch [9153/10000], Loss: 0.560774564743042\n",
      "Epoch [9154/10000], Loss: 0.5607724189758301\n",
      "Epoch [9155/10000], Loss: 0.5607707500457764\n",
      "Epoch [9156/10000], Loss: 0.5607701539993286\n",
      "Epoch [9157/10000], Loss: 0.5607703924179077\n",
      "Epoch [9158/10000], Loss: 0.5607711672782898\n",
      "Epoch [9159/10000], Loss: 0.5607730150222778\n",
      "Epoch [9160/10000], Loss: 0.5607759356498718\n",
      "Epoch [9161/10000], Loss: 0.5607793927192688\n",
      "Epoch [9162/10000], Loss: 0.5607829093933105\n",
      "Epoch [9163/10000], Loss: 0.5607855916023254\n",
      "Epoch [9164/10000], Loss: 0.5607861280441284\n",
      "Epoch [9165/10000], Loss: 0.5607846975326538\n",
      "Epoch [9166/10000], Loss: 0.5607825517654419\n",
      "Epoch [9167/10000], Loss: 0.5607792139053345\n",
      "Epoch [9168/10000], Loss: 0.5607763528823853\n",
      "Epoch [9169/10000], Loss: 0.5607744455337524\n",
      "Epoch [9170/10000], Loss: 0.5607730746269226\n",
      "Epoch [9171/10000], Loss: 0.5607720613479614\n",
      "Epoch [9172/10000], Loss: 0.560771644115448\n",
      "Epoch [9173/10000], Loss: 0.560771107673645\n",
      "Epoch [9174/10000], Loss: 0.5607706308364868\n",
      "Epoch [9175/10000], Loss: 0.5607694983482361\n",
      "Epoch [9176/10000], Loss: 0.5607680678367615\n",
      "Epoch [9177/10000], Loss: 0.5607674717903137\n",
      "Epoch [9178/10000], Loss: 0.5607673525810242\n",
      "Epoch [9179/10000], Loss: 0.5607678890228271\n",
      "Epoch [9180/10000], Loss: 0.560768723487854\n",
      "Epoch [9181/10000], Loss: 0.560770571231842\n",
      "Epoch [9182/10000], Loss: 0.5607723593711853\n",
      "Epoch [9183/10000], Loss: 0.5607737898826599\n",
      "Epoch [9184/10000], Loss: 0.5607746243476868\n",
      "Epoch [9185/10000], Loss: 0.5607741475105286\n",
      "Epoch [9186/10000], Loss: 0.5607724785804749\n",
      "Epoch [9187/10000], Loss: 0.5607704520225525\n",
      "Epoch [9188/10000], Loss: 0.5607688426971436\n",
      "Epoch [9189/10000], Loss: 0.5607675313949585\n",
      "Epoch [9190/10000], Loss: 0.5607666373252869\n",
      "Epoch [9191/10000], Loss: 0.5607665181159973\n",
      "Epoch [9192/10000], Loss: 0.5607667565345764\n",
      "Epoch [9193/10000], Loss: 0.560767412185669\n",
      "Epoch [9194/10000], Loss: 0.5607682466506958\n",
      "Epoch [9195/10000], Loss: 0.5607686638832092\n",
      "Epoch [9196/10000], Loss: 0.5607685446739197\n",
      "Epoch [9197/10000], Loss: 0.5607677698135376\n",
      "Epoch [9198/10000], Loss: 0.5607672929763794\n",
      "Epoch [9199/10000], Loss: 0.5607666969299316\n",
      "Epoch [9200/10000], Loss: 0.5607666969299316\n",
      "Epoch [9201/10000], Loss: 0.5607668161392212\n",
      "Epoch [9202/10000], Loss: 0.560767412185669\n",
      "Epoch [9203/10000], Loss: 0.5607684254646301\n",
      "Epoch [9204/10000], Loss: 0.5607693791389465\n",
      "Epoch [9205/10000], Loss: 0.5607700347900391\n",
      "Epoch [9206/10000], Loss: 0.5607710480690002\n",
      "Epoch [9207/10000], Loss: 0.5607717633247375\n",
      "Epoch [9208/10000], Loss: 0.5607720613479614\n",
      "Epoch [9209/10000], Loss: 0.5607720017433167\n",
      "Epoch [9210/10000], Loss: 0.5607714653015137\n",
      "Epoch [9211/10000], Loss: 0.5607712268829346\n",
      "Epoch [9212/10000], Loss: 0.5607709288597107\n",
      "Epoch [9213/10000], Loss: 0.5607702136039734\n",
      "Epoch [9214/10000], Loss: 0.5607692003250122\n",
      "Epoch [9215/10000], Loss: 0.560768723487854\n",
      "Epoch [9216/10000], Loss: 0.5607678890228271\n",
      "Epoch [9217/10000], Loss: 0.5607675909996033\n",
      "Epoch [9218/10000], Loss: 0.5607671141624451\n",
      "Epoch [9219/10000], Loss: 0.5607662796974182\n",
      "Epoch [9220/10000], Loss: 0.5607662200927734\n",
      "Epoch [9221/10000], Loss: 0.5607657432556152\n",
      "Epoch [9222/10000], Loss: 0.560765266418457\n",
      "Epoch [9223/10000], Loss: 0.5607648491859436\n",
      "Epoch [9224/10000], Loss: 0.560764491558075\n",
      "Epoch [9225/10000], Loss: 0.5607643723487854\n",
      "Epoch [9226/10000], Loss: 0.5607645511627197\n",
      "Epoch [9227/10000], Loss: 0.5607650876045227\n",
      "Epoch [9228/10000], Loss: 0.5607656240463257\n",
      "Epoch [9229/10000], Loss: 0.5607662796974182\n",
      "Epoch [9230/10000], Loss: 0.5607670545578003\n",
      "Epoch [9231/10000], Loss: 0.560767650604248\n",
      "Epoch [9232/10000], Loss: 0.5607675909996033\n",
      "Epoch [9233/10000], Loss: 0.5607671737670898\n",
      "Epoch [9234/10000], Loss: 0.5607673525810242\n",
      "Epoch [9235/10000], Loss: 0.5607669353485107\n",
      "Epoch [9236/10000], Loss: 0.5607667565345764\n",
      "Epoch [9237/10000], Loss: 0.5607668161392212\n",
      "Epoch [9238/10000], Loss: 0.5607668161392212\n",
      "Epoch [9239/10000], Loss: 0.5607670545578003\n",
      "Epoch [9240/10000], Loss: 0.5607677102088928\n",
      "Epoch [9241/10000], Loss: 0.5607687830924988\n",
      "Epoch [9242/10000], Loss: 0.5607700347900391\n",
      "Epoch [9243/10000], Loss: 0.5607720017433167\n",
      "Epoch [9244/10000], Loss: 0.5607743263244629\n",
      "Epoch [9245/10000], Loss: 0.5607771277427673\n",
      "Epoch [9246/10000], Loss: 0.5607795119285583\n",
      "Epoch [9247/10000], Loss: 0.5607804656028748\n",
      "Epoch [9248/10000], Loss: 0.5607810616493225\n",
      "Epoch [9249/10000], Loss: 0.5607805252075195\n",
      "Epoch [9250/10000], Loss: 0.5607790350914001\n",
      "Epoch [9251/10000], Loss: 0.5607767701148987\n",
      "Epoch [9252/10000], Loss: 0.5607736706733704\n",
      "Epoch [9253/10000], Loss: 0.5607708096504211\n",
      "Epoch [9254/10000], Loss: 0.5607684254646301\n",
      "Epoch [9255/10000], Loss: 0.560766875743866\n",
      "Epoch [9256/10000], Loss: 0.5607661604881287\n",
      "Epoch [9257/10000], Loss: 0.5607659220695496\n",
      "Epoch [9258/10000], Loss: 0.5607658624649048\n",
      "Epoch [9259/10000], Loss: 0.5607659816741943\n",
      "Epoch [9260/10000], Loss: 0.5607660412788391\n",
      "Epoch [9261/10000], Loss: 0.5607659816741943\n",
      "Epoch [9262/10000], Loss: 0.5607662200927734\n",
      "Epoch [9263/10000], Loss: 0.5607666969299316\n",
      "Epoch [9264/10000], Loss: 0.5607673525810242\n",
      "Epoch [9265/10000], Loss: 0.5607678294181824\n",
      "Epoch [9266/10000], Loss: 0.5607678890228271\n",
      "Epoch [9267/10000], Loss: 0.5607682466506958\n",
      "Epoch [9268/10000], Loss: 0.5607683062553406\n",
      "Epoch [9269/10000], Loss: 0.5607683062553406\n",
      "Epoch [9270/10000], Loss: 0.5607685446739197\n",
      "Epoch [9271/10000], Loss: 0.5607685446739197\n",
      "Epoch [9272/10000], Loss: 0.5607680082321167\n",
      "Epoch [9273/10000], Loss: 0.5607678890228271\n",
      "Epoch [9274/10000], Loss: 0.5607675313949585\n",
      "Epoch [9275/10000], Loss: 0.560767412185669\n",
      "Epoch [9276/10000], Loss: 0.5607671141624451\n",
      "Epoch [9277/10000], Loss: 0.5607671737670898\n",
      "Epoch [9278/10000], Loss: 0.5607672929763794\n",
      "Epoch [9279/10000], Loss: 0.5607672929763794\n",
      "Epoch [9280/10000], Loss: 0.5607669353485107\n",
      "Epoch [9281/10000], Loss: 0.5607668161392212\n",
      "Epoch [9282/10000], Loss: 0.5607669353485107\n",
      "Epoch [9283/10000], Loss: 0.5607672929763794\n",
      "Epoch [9284/10000], Loss: 0.5607677102088928\n",
      "Epoch [9285/10000], Loss: 0.560768723487854\n",
      "Epoch [9286/10000], Loss: 0.5607699751853943\n",
      "Epoch [9287/10000], Loss: 0.5607719421386719\n",
      "Epoch [9288/10000], Loss: 0.5607739686965942\n",
      "Epoch [9289/10000], Loss: 0.5607760548591614\n",
      "Epoch [9290/10000], Loss: 0.5607776641845703\n",
      "Epoch [9291/10000], Loss: 0.5607789158821106\n",
      "Epoch [9292/10000], Loss: 0.5607796311378479\n",
      "Epoch [9293/10000], Loss: 0.5607792735099792\n",
      "Epoch [9294/10000], Loss: 0.5607786178588867\n",
      "Epoch [9295/10000], Loss: 0.5607776045799255\n",
      "Epoch [9296/10000], Loss: 0.5607762336730957\n",
      "Epoch [9297/10000], Loss: 0.5607748031616211\n",
      "Epoch [9298/10000], Loss: 0.560772716999054\n",
      "Epoch [9299/10000], Loss: 0.5607703924179077\n",
      "Epoch [9300/10000], Loss: 0.5607686042785645\n",
      "Epoch [9301/10000], Loss: 0.5607672929763794\n",
      "Epoch [9302/10000], Loss: 0.5607661604881287\n",
      "Epoch [9303/10000], Loss: 0.560765266418457\n",
      "Epoch [9304/10000], Loss: 0.5607648491859436\n",
      "Epoch [9305/10000], Loss: 0.5607650876045227\n",
      "Epoch [9306/10000], Loss: 0.5607653260231018\n",
      "Epoch [9307/10000], Loss: 0.5607662796974182\n",
      "Epoch [9308/10000], Loss: 0.5607675313949585\n",
      "Epoch [9309/10000], Loss: 0.5607691407203674\n",
      "Epoch [9310/10000], Loss: 0.5607712864875793\n",
      "Epoch [9311/10000], Loss: 0.5607738494873047\n",
      "Epoch [9312/10000], Loss: 0.5607752203941345\n",
      "Epoch [9313/10000], Loss: 0.5607743263244629\n",
      "Epoch [9314/10000], Loss: 0.5607724189758301\n",
      "Epoch [9315/10000], Loss: 0.5607697367668152\n",
      "Epoch [9316/10000], Loss: 0.5607675313949585\n",
      "Epoch [9317/10000], Loss: 0.5607661604881287\n",
      "Epoch [9318/10000], Loss: 0.5607652068138123\n",
      "Epoch [9319/10000], Loss: 0.5607648491859436\n",
      "Epoch [9320/10000], Loss: 0.5607652068138123\n",
      "Epoch [9321/10000], Loss: 0.5607659816741943\n",
      "Epoch [9322/10000], Loss: 0.5607670545578003\n",
      "Epoch [9323/10000], Loss: 0.560768723487854\n",
      "Epoch [9324/10000], Loss: 0.560770571231842\n",
      "Epoch [9325/10000], Loss: 0.5607720017433167\n",
      "Epoch [9326/10000], Loss: 0.5607724785804749\n",
      "Epoch [9327/10000], Loss: 0.5607722401618958\n",
      "Epoch [9328/10000], Loss: 0.5607718229293823\n",
      "Epoch [9329/10000], Loss: 0.5607708096504211\n",
      "Epoch [9330/10000], Loss: 0.560769259929657\n",
      "Epoch [9331/10000], Loss: 0.5607677698135376\n",
      "Epoch [9332/10000], Loss: 0.5607665777206421\n",
      "Epoch [9333/10000], Loss: 0.5607661008834839\n",
      "Epoch [9334/10000], Loss: 0.5607666969299316\n",
      "Epoch [9335/10000], Loss: 0.5607680082321167\n",
      "Epoch [9336/10000], Loss: 0.5607694387435913\n",
      "Epoch [9337/10000], Loss: 0.5607715249061584\n",
      "Epoch [9338/10000], Loss: 0.5607736706733704\n",
      "Epoch [9339/10000], Loss: 0.5607749819755554\n",
      "Epoch [9340/10000], Loss: 0.5607751607894897\n",
      "Epoch [9341/10000], Loss: 0.560773491859436\n",
      "Epoch [9342/10000], Loss: 0.5607709288597107\n",
      "Epoch [9343/10000], Loss: 0.5607688426971436\n",
      "Epoch [9344/10000], Loss: 0.5607675909996033\n",
      "Epoch [9345/10000], Loss: 0.5607666969299316\n",
      "Epoch [9346/10000], Loss: 0.5607666373252869\n",
      "Epoch [9347/10000], Loss: 0.5607675909996033\n",
      "Epoch [9348/10000], Loss: 0.5607684850692749\n",
      "Epoch [9349/10000], Loss: 0.5607694983482361\n",
      "Epoch [9350/10000], Loss: 0.5607708096504211\n",
      "Epoch [9351/10000], Loss: 0.5607717633247375\n",
      "Epoch [9352/10000], Loss: 0.5607717633247375\n",
      "Epoch [9353/10000], Loss: 0.560771644115448\n",
      "Epoch [9354/10000], Loss: 0.5607706308364868\n",
      "Epoch [9355/10000], Loss: 0.5607693195343018\n",
      "Epoch [9356/10000], Loss: 0.5607683658599854\n",
      "Epoch [9357/10000], Loss: 0.560767412185669\n",
      "Epoch [9358/10000], Loss: 0.5607677102088928\n",
      "Epoch [9359/10000], Loss: 0.5607689619064331\n",
      "Epoch [9360/10000], Loss: 0.5607699751853943\n",
      "Epoch [9361/10000], Loss: 0.5607715845108032\n",
      "Epoch [9362/10000], Loss: 0.5607726573944092\n",
      "Epoch [9363/10000], Loss: 0.5607734322547913\n",
      "Epoch [9364/10000], Loss: 0.5607732534408569\n",
      "Epoch [9365/10000], Loss: 0.5607728362083435\n",
      "Epoch [9366/10000], Loss: 0.560771644115448\n",
      "Epoch [9367/10000], Loss: 0.5607702136039734\n",
      "Epoch [9368/10000], Loss: 0.5607694983482361\n",
      "Epoch [9369/10000], Loss: 0.5607688426971436\n",
      "Epoch [9370/10000], Loss: 0.5607688426971436\n",
      "Epoch [9371/10000], Loss: 0.560768723487854\n",
      "Epoch [9372/10000], Loss: 0.5607686042785645\n",
      "Epoch [9373/10000], Loss: 0.5607684254646301\n",
      "Epoch [9374/10000], Loss: 0.5607682466506958\n",
      "Epoch [9375/10000], Loss: 0.5607682466506958\n",
      "Epoch [9376/10000], Loss: 0.560767650604248\n",
      "Epoch [9377/10000], Loss: 0.5607666969299316\n",
      "Epoch [9378/10000], Loss: 0.5607656836509705\n",
      "Epoch [9379/10000], Loss: 0.5607646107673645\n",
      "Epoch [9380/10000], Loss: 0.5607643723487854\n",
      "Epoch [9381/10000], Loss: 0.5607641339302063\n",
      "Epoch [9382/10000], Loss: 0.5607641339302063\n",
      "Epoch [9383/10000], Loss: 0.5607641339302063\n",
      "Epoch [9384/10000], Loss: 0.5607642531394958\n",
      "Epoch [9385/10000], Loss: 0.5607648491859436\n",
      "Epoch [9386/10000], Loss: 0.5607654452323914\n",
      "Epoch [9387/10000], Loss: 0.5607661604881287\n",
      "Epoch [9388/10000], Loss: 0.5607669949531555\n",
      "Epoch [9389/10000], Loss: 0.5607681274414062\n",
      "Epoch [9390/10000], Loss: 0.560768723487854\n",
      "Epoch [9391/10000], Loss: 0.560768723487854\n",
      "Epoch [9392/10000], Loss: 0.5607686042785645\n",
      "Epoch [9393/10000], Loss: 0.560768187046051\n",
      "Epoch [9394/10000], Loss: 0.5607677698135376\n",
      "Epoch [9395/10000], Loss: 0.560767650604248\n",
      "Epoch [9396/10000], Loss: 0.560767650604248\n",
      "Epoch [9397/10000], Loss: 0.5607678294181824\n",
      "Epoch [9398/10000], Loss: 0.5607686042785645\n",
      "Epoch [9399/10000], Loss: 0.5607700943946838\n",
      "Epoch [9400/10000], Loss: 0.560771644115448\n",
      "Epoch [9401/10000], Loss: 0.560774028301239\n",
      "Epoch [9402/10000], Loss: 0.5607762336730957\n",
      "Epoch [9403/10000], Loss: 0.5607784986495972\n",
      "Epoch [9404/10000], Loss: 0.56078040599823\n",
      "Epoch [9405/10000], Loss: 0.5607813000679016\n",
      "Epoch [9406/10000], Loss: 0.5607808232307434\n",
      "Epoch [9407/10000], Loss: 0.5607795119285583\n",
      "Epoch [9408/10000], Loss: 0.5607774257659912\n",
      "Epoch [9409/10000], Loss: 0.5607741475105286\n",
      "Epoch [9410/10000], Loss: 0.5607714653015137\n",
      "Epoch [9411/10000], Loss: 0.5607690811157227\n",
      "Epoch [9412/10000], Loss: 0.5607673525810242\n",
      "Epoch [9413/10000], Loss: 0.5607669353485107\n",
      "Epoch [9414/10000], Loss: 0.5607667565345764\n",
      "Epoch [9415/10000], Loss: 0.5607666373252869\n",
      "Epoch [9416/10000], Loss: 0.5607669353485107\n",
      "Epoch [9417/10000], Loss: 0.5607672929763794\n",
      "Epoch [9418/10000], Loss: 0.5607669949531555\n",
      "Epoch [9419/10000], Loss: 0.5607663989067078\n",
      "Epoch [9420/10000], Loss: 0.5607656836509705\n",
      "Epoch [9421/10000], Loss: 0.5607650279998779\n",
      "Epoch [9422/10000], Loss: 0.5607643723487854\n",
      "Epoch [9423/10000], Loss: 0.5607643723487854\n",
      "Epoch [9424/10000], Loss: 0.5607646107673645\n",
      "Epoch [9425/10000], Loss: 0.5607650876045227\n",
      "Epoch [9426/10000], Loss: 0.5607658624649048\n",
      "Epoch [9427/10000], Loss: 0.5607670545578003\n",
      "Epoch [9428/10000], Loss: 0.5607689023017883\n",
      "Epoch [9429/10000], Loss: 0.5607706308364868\n",
      "Epoch [9430/10000], Loss: 0.5607713460922241\n",
      "Epoch [9431/10000], Loss: 0.5607719421386719\n",
      "Epoch [9432/10000], Loss: 0.5607706904411316\n",
      "Epoch [9433/10000], Loss: 0.5607686638832092\n",
      "Epoch [9434/10000], Loss: 0.5607665181159973\n",
      "Epoch [9435/10000], Loss: 0.5607652068138123\n",
      "Epoch [9436/10000], Loss: 0.5607643723487854\n",
      "Epoch [9437/10000], Loss: 0.5607640743255615\n",
      "Epoch [9438/10000], Loss: 0.5607642531394958\n",
      "Epoch [9439/10000], Loss: 0.5607643723487854\n",
      "Epoch [9440/10000], Loss: 0.5607649683952332\n",
      "Epoch [9441/10000], Loss: 0.5607659220695496\n",
      "Epoch [9442/10000], Loss: 0.5607661604881287\n",
      "Epoch [9443/10000], Loss: 0.560766875743866\n",
      "Epoch [9444/10000], Loss: 0.5607671141624451\n",
      "Epoch [9445/10000], Loss: 0.5607671737670898\n",
      "Epoch [9446/10000], Loss: 0.5607668161392212\n",
      "Epoch [9447/10000], Loss: 0.5607661604881287\n",
      "Epoch [9448/10000], Loss: 0.5607655644416809\n",
      "Epoch [9449/10000], Loss: 0.5607653856277466\n",
      "Epoch [9450/10000], Loss: 0.5607656836509705\n",
      "Epoch [9451/10000], Loss: 0.560766339302063\n",
      "Epoch [9452/10000], Loss: 0.5607671737670898\n",
      "Epoch [9453/10000], Loss: 0.5607686042785645\n",
      "Epoch [9454/10000], Loss: 0.5607708096504211\n",
      "Epoch [9455/10000], Loss: 0.5607734322547913\n",
      "Epoch [9456/10000], Loss: 0.5607765316963196\n",
      "Epoch [9457/10000], Loss: 0.5607788562774658\n",
      "Epoch [9458/10000], Loss: 0.5607803463935852\n",
      "Epoch [9459/10000], Loss: 0.5607812404632568\n",
      "Epoch [9460/10000], Loss: 0.56078040599823\n",
      "Epoch [9461/10000], Loss: 0.5607788562774658\n",
      "Epoch [9462/10000], Loss: 0.5607767701148987\n",
      "Epoch [9463/10000], Loss: 0.5607742071151733\n",
      "Epoch [9464/10000], Loss: 0.5607709288597107\n",
      "Epoch [9465/10000], Loss: 0.560767412185669\n",
      "Epoch [9466/10000], Loss: 0.560765266418457\n",
      "Epoch [9467/10000], Loss: 0.5607643127441406\n",
      "Epoch [9468/10000], Loss: 0.560763955116272\n",
      "Epoch [9469/10000], Loss: 0.5607641935348511\n",
      "Epoch [9470/10000], Loss: 0.5607644319534302\n",
      "Epoch [9471/10000], Loss: 0.5607647895812988\n",
      "Epoch [9472/10000], Loss: 0.5607655644416809\n",
      "Epoch [9473/10000], Loss: 0.5607658624649048\n",
      "Epoch [9474/10000], Loss: 0.5607667565345764\n",
      "Epoch [9475/10000], Loss: 0.5607670545578003\n",
      "Epoch [9476/10000], Loss: 0.5607671141624451\n",
      "Epoch [9477/10000], Loss: 0.5607677102088928\n",
      "Epoch [9478/10000], Loss: 0.5607685446739197\n",
      "Epoch [9479/10000], Loss: 0.5607692003250122\n",
      "Epoch [9480/10000], Loss: 0.56076979637146\n",
      "Epoch [9481/10000], Loss: 0.5607702136039734\n",
      "Epoch [9482/10000], Loss: 0.5607703924179077\n",
      "Epoch [9483/10000], Loss: 0.5607700943946838\n",
      "Epoch [9484/10000], Loss: 0.5607686042785645\n",
      "Epoch [9485/10000], Loss: 0.5607672929763794\n",
      "Epoch [9486/10000], Loss: 0.5607661604881287\n",
      "Epoch [9487/10000], Loss: 0.5607650279998779\n",
      "Epoch [9488/10000], Loss: 0.5607649683952332\n",
      "Epoch [9489/10000], Loss: 0.56076580286026\n",
      "Epoch [9490/10000], Loss: 0.560766875743866\n",
      "Epoch [9491/10000], Loss: 0.5607678890228271\n",
      "Epoch [9492/10000], Loss: 0.5607690215110779\n",
      "Epoch [9493/10000], Loss: 0.5607697367668152\n",
      "Epoch [9494/10000], Loss: 0.5607694387435913\n",
      "Epoch [9495/10000], Loss: 0.5607685446739197\n",
      "Epoch [9496/10000], Loss: 0.5607675909996033\n",
      "Epoch [9497/10000], Loss: 0.5607666969299316\n",
      "Epoch [9498/10000], Loss: 0.5607654452323914\n",
      "Epoch [9499/10000], Loss: 0.5607647895812988\n",
      "Epoch [9500/10000], Loss: 0.5607645511627197\n",
      "Epoch [9501/10000], Loss: 0.5607642531394958\n",
      "Epoch [9502/10000], Loss: 0.5607644319534302\n",
      "Epoch [9503/10000], Loss: 0.5607649683952332\n",
      "Epoch [9504/10000], Loss: 0.5607658624649048\n",
      "Epoch [9505/10000], Loss: 0.5607665777206421\n",
      "Epoch [9506/10000], Loss: 0.5607666969299316\n",
      "Epoch [9507/10000], Loss: 0.5607669353485107\n",
      "Epoch [9508/10000], Loss: 0.5607665181159973\n",
      "Epoch [9509/10000], Loss: 0.5607659220695496\n",
      "Epoch [9510/10000], Loss: 0.5607655048370361\n",
      "Epoch [9511/10000], Loss: 0.5607650876045227\n",
      "Epoch [9512/10000], Loss: 0.5607647895812988\n",
      "Epoch [9513/10000], Loss: 0.560764729976654\n",
      "Epoch [9514/10000], Loss: 0.5607646107673645\n",
      "Epoch [9515/10000], Loss: 0.5607649683952332\n",
      "Epoch [9516/10000], Loss: 0.56076580286026\n",
      "Epoch [9517/10000], Loss: 0.560766875743866\n",
      "Epoch [9518/10000], Loss: 0.5607679486274719\n",
      "Epoch [9519/10000], Loss: 0.5607696175575256\n",
      "Epoch [9520/10000], Loss: 0.5607715249061584\n",
      "Epoch [9521/10000], Loss: 0.5607732534408569\n",
      "Epoch [9522/10000], Loss: 0.5607753992080688\n",
      "Epoch [9523/10000], Loss: 0.5607773065567017\n",
      "Epoch [9524/10000], Loss: 0.5607783198356628\n",
      "Epoch [9525/10000], Loss: 0.5607783198356628\n",
      "Epoch [9526/10000], Loss: 0.5607770085334778\n",
      "Epoch [9527/10000], Loss: 0.5607743263244629\n",
      "Epoch [9528/10000], Loss: 0.5607706308364868\n",
      "Epoch [9529/10000], Loss: 0.5607672929763794\n",
      "Epoch [9530/10000], Loss: 0.5607649683952332\n",
      "Epoch [9531/10000], Loss: 0.5607635378837585\n",
      "Epoch [9532/10000], Loss: 0.5607632398605347\n",
      "Epoch [9533/10000], Loss: 0.5607636570930481\n",
      "Epoch [9534/10000], Loss: 0.5607645511627197\n",
      "Epoch [9535/10000], Loss: 0.5607656836509705\n",
      "Epoch [9536/10000], Loss: 0.5607675909996033\n",
      "Epoch [9537/10000], Loss: 0.5607696771621704\n",
      "Epoch [9538/10000], Loss: 0.5607715249061584\n",
      "Epoch [9539/10000], Loss: 0.560772716999054\n",
      "Epoch [9540/10000], Loss: 0.5607729554176331\n",
      "Epoch [9541/10000], Loss: 0.5607720613479614\n",
      "Epoch [9542/10000], Loss: 0.5607699155807495\n",
      "Epoch [9543/10000], Loss: 0.5607680082321167\n",
      "Epoch [9544/10000], Loss: 0.5607661604881287\n",
      "Epoch [9545/10000], Loss: 0.560765266418457\n",
      "Epoch [9546/10000], Loss: 0.5607647895812988\n",
      "Epoch [9547/10000], Loss: 0.5607646703720093\n",
      "Epoch [9548/10000], Loss: 0.5607643127441406\n",
      "Epoch [9549/10000], Loss: 0.5607643127441406\n",
      "Epoch [9550/10000], Loss: 0.5607651472091675\n",
      "Epoch [9551/10000], Loss: 0.5607663989067078\n",
      "Epoch [9552/10000], Loss: 0.5607682466506958\n",
      "Epoch [9553/10000], Loss: 0.5607699751853943\n",
      "Epoch [9554/10000], Loss: 0.5607718825340271\n",
      "Epoch [9555/10000], Loss: 0.5607729554176331\n",
      "Epoch [9556/10000], Loss: 0.560772716999054\n",
      "Epoch [9557/10000], Loss: 0.5607715249061584\n",
      "Epoch [9558/10000], Loss: 0.5607696771621704\n",
      "Epoch [9559/10000], Loss: 0.5607682466506958\n",
      "Epoch [9560/10000], Loss: 0.5607668161392212\n",
      "Epoch [9561/10000], Loss: 0.5607656836509705\n",
      "Epoch [9562/10000], Loss: 0.5607648491859436\n",
      "Epoch [9563/10000], Loss: 0.5607649087905884\n",
      "Epoch [9564/10000], Loss: 0.5607653260231018\n",
      "Epoch [9565/10000], Loss: 0.560766339302063\n",
      "Epoch [9566/10000], Loss: 0.5607681274414062\n",
      "Epoch [9567/10000], Loss: 0.5607695579528809\n",
      "Epoch [9568/10000], Loss: 0.560770571231842\n",
      "Epoch [9569/10000], Loss: 0.5607709288597107\n",
      "Epoch [9570/10000], Loss: 0.5607706308364868\n",
      "Epoch [9571/10000], Loss: 0.5607704520225525\n",
      "Epoch [9572/10000], Loss: 0.5607708692550659\n",
      "Epoch [9573/10000], Loss: 0.5607711672782898\n",
      "Epoch [9574/10000], Loss: 0.5607720613479614\n",
      "Epoch [9575/10000], Loss: 0.5607732534408569\n",
      "Epoch [9576/10000], Loss: 0.5607749223709106\n",
      "Epoch [9577/10000], Loss: 0.5607766509056091\n",
      "Epoch [9578/10000], Loss: 0.5607790350914001\n",
      "Epoch [9579/10000], Loss: 0.5607807636260986\n",
      "Epoch [9580/10000], Loss: 0.5607820749282837\n",
      "Epoch [9581/10000], Loss: 0.5607818961143494\n",
      "Epoch [9582/10000], Loss: 0.560779869556427\n",
      "Epoch [9583/10000], Loss: 0.5607765913009644\n",
      "Epoch [9584/10000], Loss: 0.5607730746269226\n",
      "Epoch [9585/10000], Loss: 0.56076979637146\n",
      "Epoch [9586/10000], Loss: 0.5607667565345764\n",
      "Epoch [9587/10000], Loss: 0.5607650279998779\n",
      "Epoch [9588/10000], Loss: 0.5607640147209167\n",
      "Epoch [9589/10000], Loss: 0.5607637763023376\n",
      "Epoch [9590/10000], Loss: 0.5607643723487854\n",
      "Epoch [9591/10000], Loss: 0.5607653856277466\n",
      "Epoch [9592/10000], Loss: 0.5607661604881287\n",
      "Epoch [9593/10000], Loss: 0.560766875743866\n",
      "Epoch [9594/10000], Loss: 0.5607679486274719\n",
      "Epoch [9595/10000], Loss: 0.5607686042785645\n",
      "Epoch [9596/10000], Loss: 0.5607693195343018\n",
      "Epoch [9597/10000], Loss: 0.56076979637146\n",
      "Epoch [9598/10000], Loss: 0.5607697367668152\n",
      "Epoch [9599/10000], Loss: 0.5607692003250122\n",
      "Epoch [9600/10000], Loss: 0.5607685446739197\n",
      "Epoch [9601/10000], Loss: 0.5607673525810242\n",
      "Epoch [9602/10000], Loss: 0.5607659816741943\n",
      "Epoch [9603/10000], Loss: 0.5607652068138123\n",
      "Epoch [9604/10000], Loss: 0.5607645511627197\n",
      "Epoch [9605/10000], Loss: 0.5607644319534302\n",
      "Epoch [9606/10000], Loss: 0.5607643723487854\n",
      "Epoch [9607/10000], Loss: 0.5607643723487854\n",
      "Epoch [9608/10000], Loss: 0.560764729976654\n",
      "Epoch [9609/10000], Loss: 0.5607655644416809\n",
      "Epoch [9610/10000], Loss: 0.5607661008834839\n",
      "Epoch [9611/10000], Loss: 0.5607664585113525\n",
      "Epoch [9612/10000], Loss: 0.5607669353485107\n",
      "Epoch [9613/10000], Loss: 0.5607671737670898\n",
      "Epoch [9614/10000], Loss: 0.5607673525810242\n",
      "Epoch [9615/10000], Loss: 0.5607677102088928\n",
      "Epoch [9616/10000], Loss: 0.5607675909996033\n",
      "Epoch [9617/10000], Loss: 0.5607671141624451\n",
      "Epoch [9618/10000], Loss: 0.5607666969299316\n",
      "Epoch [9619/10000], Loss: 0.5607665181159973\n",
      "Epoch [9620/10000], Loss: 0.5607664585113525\n",
      "Epoch [9621/10000], Loss: 0.5607662200927734\n",
      "Epoch [9622/10000], Loss: 0.5607661008834839\n",
      "Epoch [9623/10000], Loss: 0.5607662796974182\n",
      "Epoch [9624/10000], Loss: 0.5607665181159973\n",
      "Epoch [9625/10000], Loss: 0.5607670545578003\n",
      "Epoch [9626/10000], Loss: 0.5607675909996033\n",
      "Epoch [9627/10000], Loss: 0.5607688426971436\n",
      "Epoch [9628/10000], Loss: 0.5607700347900391\n",
      "Epoch [9629/10000], Loss: 0.5607712864875793\n",
      "Epoch [9630/10000], Loss: 0.5607719421386719\n",
      "Epoch [9631/10000], Loss: 0.560772180557251\n",
      "Epoch [9632/10000], Loss: 0.5607714056968689\n",
      "Epoch [9633/10000], Loss: 0.5607709288597107\n",
      "Epoch [9634/10000], Loss: 0.5607697367668152\n",
      "Epoch [9635/10000], Loss: 0.5607690811157227\n",
      "Epoch [9636/10000], Loss: 0.5607683062553406\n",
      "Epoch [9637/10000], Loss: 0.5607673525810242\n",
      "Epoch [9638/10000], Loss: 0.5607662200927734\n",
      "Epoch [9639/10000], Loss: 0.5607655048370361\n",
      "Epoch [9640/10000], Loss: 0.5607650279998779\n",
      "Epoch [9641/10000], Loss: 0.560764729976654\n",
      "Epoch [9642/10000], Loss: 0.5607648491859436\n",
      "Epoch [9643/10000], Loss: 0.5607648491859436\n",
      "Epoch [9644/10000], Loss: 0.5607647895812988\n",
      "Epoch [9645/10000], Loss: 0.5607643127441406\n",
      "Epoch [9646/10000], Loss: 0.5607643127441406\n",
      "Epoch [9647/10000], Loss: 0.5607642531394958\n",
      "Epoch [9648/10000], Loss: 0.5607644319534302\n",
      "Epoch [9649/10000], Loss: 0.5607645511627197\n",
      "Epoch [9650/10000], Loss: 0.5607648491859436\n",
      "Epoch [9651/10000], Loss: 0.5607655048370361\n",
      "Epoch [9652/10000], Loss: 0.5607664585113525\n",
      "Epoch [9653/10000], Loss: 0.5607677102088928\n",
      "Epoch [9654/10000], Loss: 0.5607697367668152\n",
      "Epoch [9655/10000], Loss: 0.5607719421386719\n",
      "Epoch [9656/10000], Loss: 0.5607737302780151\n",
      "Epoch [9657/10000], Loss: 0.5607749223709106\n",
      "Epoch [9658/10000], Loss: 0.5607749819755554\n",
      "Epoch [9659/10000], Loss: 0.5607743859291077\n",
      "Epoch [9660/10000], Loss: 0.5607732534408569\n",
      "Epoch [9661/10000], Loss: 0.5607720613479614\n",
      "Epoch [9662/10000], Loss: 0.5607707500457764\n",
      "Epoch [9663/10000], Loss: 0.5607699155807495\n",
      "Epoch [9664/10000], Loss: 0.5607695579528809\n",
      "Epoch [9665/10000], Loss: 0.5607696175575256\n",
      "Epoch [9666/10000], Loss: 0.5607696771621704\n",
      "Epoch [9667/10000], Loss: 0.560769259929657\n",
      "Epoch [9668/10000], Loss: 0.5607684850692749\n",
      "Epoch [9669/10000], Loss: 0.5607671737670898\n",
      "Epoch [9670/10000], Loss: 0.5607656836509705\n",
      "Epoch [9671/10000], Loss: 0.560764491558075\n",
      "Epoch [9672/10000], Loss: 0.5607638359069824\n",
      "Epoch [9673/10000], Loss: 0.5607636570930481\n",
      "Epoch [9674/10000], Loss: 0.5607636570930481\n",
      "Epoch [9675/10000], Loss: 0.5607638955116272\n",
      "Epoch [9676/10000], Loss: 0.560764729976654\n",
      "Epoch [9677/10000], Loss: 0.5607656240463257\n",
      "Epoch [9678/10000], Loss: 0.560766875743866\n",
      "Epoch [9679/10000], Loss: 0.5607690215110779\n",
      "Epoch [9680/10000], Loss: 0.5607707500457764\n",
      "Epoch [9681/10000], Loss: 0.5607723593711853\n",
      "Epoch [9682/10000], Loss: 0.560773491859436\n",
      "Epoch [9683/10000], Loss: 0.5607741475105286\n",
      "Epoch [9684/10000], Loss: 0.5607737302780151\n",
      "Epoch [9685/10000], Loss: 0.5607722997665405\n",
      "Epoch [9686/10000], Loss: 0.5607694983482361\n",
      "Epoch [9687/10000], Loss: 0.560766875743866\n",
      "Epoch [9688/10000], Loss: 0.5607651472091675\n",
      "Epoch [9689/10000], Loss: 0.5607640743255615\n",
      "Epoch [9690/10000], Loss: 0.560764491558075\n",
      "Epoch [9691/10000], Loss: 0.560764491558075\n",
      "Epoch [9692/10000], Loss: 0.56076580286026\n",
      "Epoch [9693/10000], Loss: 0.560767412185669\n",
      "Epoch [9694/10000], Loss: 0.5607693195343018\n",
      "Epoch [9695/10000], Loss: 0.5607717037200928\n",
      "Epoch [9696/10000], Loss: 0.5607737302780151\n",
      "Epoch [9697/10000], Loss: 0.5607755780220032\n",
      "Epoch [9698/10000], Loss: 0.5607764720916748\n",
      "Epoch [9699/10000], Loss: 0.5607762932777405\n",
      "Epoch [9700/10000], Loss: 0.5607753992080688\n",
      "Epoch [9701/10000], Loss: 0.5607738494873047\n",
      "Epoch [9702/10000], Loss: 0.5607720613479614\n",
      "Epoch [9703/10000], Loss: 0.5607702732086182\n",
      "Epoch [9704/10000], Loss: 0.5607688426971436\n",
      "Epoch [9705/10000], Loss: 0.5607680678367615\n",
      "Epoch [9706/10000], Loss: 0.5607678890228271\n",
      "Epoch [9707/10000], Loss: 0.5607678890228271\n",
      "Epoch [9708/10000], Loss: 0.560768187046051\n",
      "Epoch [9709/10000], Loss: 0.5607686042785645\n",
      "Epoch [9710/10000], Loss: 0.5607696771621704\n",
      "Epoch [9711/10000], Loss: 0.56076979637146\n",
      "Epoch [9712/10000], Loss: 0.56076979637146\n",
      "Epoch [9713/10000], Loss: 0.560769259929657\n",
      "Epoch [9714/10000], Loss: 0.560768187046051\n",
      "Epoch [9715/10000], Loss: 0.5607666969299316\n",
      "Epoch [9716/10000], Loss: 0.5607654452323914\n",
      "Epoch [9717/10000], Loss: 0.5607646107673645\n",
      "Epoch [9718/10000], Loss: 0.5607638359069824\n",
      "Epoch [9719/10000], Loss: 0.5607631206512451\n",
      "Epoch [9720/10000], Loss: 0.560762882232666\n",
      "Epoch [9721/10000], Loss: 0.5607629418373108\n",
      "Epoch [9722/10000], Loss: 0.5607629418373108\n",
      "Epoch [9723/10000], Loss: 0.5607630610466003\n",
      "Epoch [9724/10000], Loss: 0.5607633590698242\n",
      "Epoch [9725/10000], Loss: 0.5607635974884033\n",
      "Epoch [9726/10000], Loss: 0.5607640147209167\n",
      "Epoch [9727/10000], Loss: 0.5607646703720093\n",
      "Epoch [9728/10000], Loss: 0.5607655048370361\n",
      "Epoch [9729/10000], Loss: 0.5607664585113525\n",
      "Epoch [9730/10000], Loss: 0.560767412185669\n",
      "Epoch [9731/10000], Loss: 0.5607682466506958\n",
      "Epoch [9732/10000], Loss: 0.5607687830924988\n",
      "Epoch [9733/10000], Loss: 0.5607686638832092\n",
      "Epoch [9734/10000], Loss: 0.5607680678367615\n",
      "Epoch [9735/10000], Loss: 0.5607674717903137\n",
      "Epoch [9736/10000], Loss: 0.5607669353485107\n",
      "Epoch [9737/10000], Loss: 0.560766339302063\n",
      "Epoch [9738/10000], Loss: 0.5607655048370361\n",
      "Epoch [9739/10000], Loss: 0.5607649087905884\n",
      "Epoch [9740/10000], Loss: 0.5607647895812988\n",
      "Epoch [9741/10000], Loss: 0.5607648491859436\n",
      "Epoch [9742/10000], Loss: 0.5607654452323914\n",
      "Epoch [9743/10000], Loss: 0.5607666969299316\n",
      "Epoch [9744/10000], Loss: 0.5607686042785645\n",
      "Epoch [9745/10000], Loss: 0.5607711672782898\n",
      "Epoch [9746/10000], Loss: 0.5607742667198181\n",
      "Epoch [9747/10000], Loss: 0.5607776641845703\n",
      "Epoch [9748/10000], Loss: 0.5607808828353882\n",
      "Epoch [9749/10000], Loss: 0.5607836842536926\n",
      "Epoch [9750/10000], Loss: 0.5607845187187195\n",
      "Epoch [9751/10000], Loss: 0.560783326625824\n",
      "Epoch [9752/10000], Loss: 0.5607810020446777\n",
      "Epoch [9753/10000], Loss: 0.5607785582542419\n",
      "Epoch [9754/10000], Loss: 0.560775876045227\n",
      "Epoch [9755/10000], Loss: 0.5607729554176331\n",
      "Epoch [9756/10000], Loss: 0.560770571231842\n",
      "Epoch [9757/10000], Loss: 0.5607689619064331\n",
      "Epoch [9758/10000], Loss: 0.5607680082321167\n",
      "Epoch [9759/10000], Loss: 0.5607674717903137\n",
      "Epoch [9760/10000], Loss: 0.5607671737670898\n",
      "Epoch [9761/10000], Loss: 0.560767412185669\n",
      "Epoch [9762/10000], Loss: 0.5607677698135376\n",
      "Epoch [9763/10000], Loss: 0.5607686042785645\n",
      "Epoch [9764/10000], Loss: 0.5607700943946838\n",
      "Epoch [9765/10000], Loss: 0.5607714653015137\n",
      "Epoch [9766/10000], Loss: 0.5607722401618958\n",
      "Epoch [9767/10000], Loss: 0.5607719421386719\n",
      "Epoch [9768/10000], Loss: 0.5607711672782898\n",
      "Epoch [9769/10000], Loss: 0.5607700347900391\n",
      "Epoch [9770/10000], Loss: 0.5607689619064331\n",
      "Epoch [9771/10000], Loss: 0.5607677698135376\n",
      "Epoch [9772/10000], Loss: 0.5607664585113525\n",
      "Epoch [9773/10000], Loss: 0.5607655644416809\n",
      "Epoch [9774/10000], Loss: 0.560764729976654\n",
      "Epoch [9775/10000], Loss: 0.5607646107673645\n",
      "Epoch [9776/10000], Loss: 0.5607649683952332\n",
      "Epoch [9777/10000], Loss: 0.5607655048370361\n",
      "Epoch [9778/10000], Loss: 0.5607662796974182\n",
      "Epoch [9779/10000], Loss: 0.5607670545578003\n",
      "Epoch [9780/10000], Loss: 0.5607675909996033\n",
      "Epoch [9781/10000], Loss: 0.5607678294181824\n",
      "Epoch [9782/10000], Loss: 0.5607680678367615\n",
      "Epoch [9783/10000], Loss: 0.5607675313949585\n",
      "Epoch [9784/10000], Loss: 0.5607663989067078\n",
      "Epoch [9785/10000], Loss: 0.5607653260231018\n",
      "Epoch [9786/10000], Loss: 0.5607649683952332\n",
      "Epoch [9787/10000], Loss: 0.560764729976654\n",
      "Epoch [9788/10000], Loss: 0.5607646107673645\n",
      "Epoch [9789/10000], Loss: 0.560764729976654\n",
      "Epoch [9790/10000], Loss: 0.560765266418457\n",
      "Epoch [9791/10000], Loss: 0.5607654452323914\n",
      "Epoch [9792/10000], Loss: 0.5607661008834839\n",
      "Epoch [9793/10000], Loss: 0.5607666373252869\n",
      "Epoch [9794/10000], Loss: 0.5607671141624451\n",
      "Epoch [9795/10000], Loss: 0.5607678890228271\n",
      "Epoch [9796/10000], Loss: 0.560768723487854\n",
      "Epoch [9797/10000], Loss: 0.5607693195343018\n",
      "Epoch [9798/10000], Loss: 0.5607699751853943\n",
      "Epoch [9799/10000], Loss: 0.560770571231842\n",
      "Epoch [9800/10000], Loss: 0.5607706904411316\n",
      "Epoch [9801/10000], Loss: 0.5607699751853943\n",
      "Epoch [9802/10000], Loss: 0.560769259929657\n",
      "Epoch [9803/10000], Loss: 0.5607683658599854\n",
      "Epoch [9804/10000], Loss: 0.5607677698135376\n",
      "Epoch [9805/10000], Loss: 0.5607669949531555\n",
      "Epoch [9806/10000], Loss: 0.5607665181159973\n",
      "Epoch [9807/10000], Loss: 0.5607666373252869\n",
      "Epoch [9808/10000], Loss: 0.5607664585113525\n",
      "Epoch [9809/10000], Loss: 0.5607665181159973\n",
      "Epoch [9810/10000], Loss: 0.560766875743866\n",
      "Epoch [9811/10000], Loss: 0.560767650604248\n",
      "Epoch [9812/10000], Loss: 0.560767650604248\n",
      "Epoch [9813/10000], Loss: 0.5607677102088928\n",
      "Epoch [9814/10000], Loss: 0.5607674717903137\n",
      "Epoch [9815/10000], Loss: 0.5607671737670898\n",
      "Epoch [9816/10000], Loss: 0.5607672333717346\n",
      "Epoch [9817/10000], Loss: 0.5607669353485107\n",
      "Epoch [9818/10000], Loss: 0.5607664585113525\n",
      "Epoch [9819/10000], Loss: 0.5607661604881287\n",
      "Epoch [9820/10000], Loss: 0.5607664585113525\n",
      "Epoch [9821/10000], Loss: 0.5607666969299316\n",
      "Epoch [9822/10000], Loss: 0.5607670545578003\n",
      "Epoch [9823/10000], Loss: 0.560767412185669\n",
      "Epoch [9824/10000], Loss: 0.5607681274414062\n",
      "Epoch [9825/10000], Loss: 0.5607693195343018\n",
      "Epoch [9826/10000], Loss: 0.560770571231842\n",
      "Epoch [9827/10000], Loss: 0.5607718229293823\n",
      "Epoch [9828/10000], Loss: 0.5607733130455017\n",
      "Epoch [9829/10000], Loss: 0.5607741475105286\n",
      "Epoch [9830/10000], Loss: 0.5607743859291077\n",
      "Epoch [9831/10000], Loss: 0.5607741475105286\n",
      "Epoch [9832/10000], Loss: 0.5607734322547913\n",
      "Epoch [9833/10000], Loss: 0.5607724785804749\n",
      "Epoch [9834/10000], Loss: 0.5607708096504211\n",
      "Epoch [9835/10000], Loss: 0.5607692003250122\n",
      "Epoch [9836/10000], Loss: 0.5607680082321167\n",
      "Epoch [9837/10000], Loss: 0.560766875743866\n",
      "Epoch [9838/10000], Loss: 0.5607663989067078\n",
      "Epoch [9839/10000], Loss: 0.5607659220695496\n",
      "Epoch [9840/10000], Loss: 0.5607652068138123\n",
      "Epoch [9841/10000], Loss: 0.5607647895812988\n",
      "Epoch [9842/10000], Loss: 0.560764491558075\n",
      "Epoch [9843/10000], Loss: 0.5607647895812988\n",
      "Epoch [9844/10000], Loss: 0.560764491558075\n",
      "Epoch [9845/10000], Loss: 0.5607647895812988\n",
      "Epoch [9846/10000], Loss: 0.5607654452323914\n",
      "Epoch [9847/10000], Loss: 0.5607659220695496\n",
      "Epoch [9848/10000], Loss: 0.5607667565345764\n",
      "Epoch [9849/10000], Loss: 0.5607673525810242\n",
      "Epoch [9850/10000], Loss: 0.5607681274414062\n",
      "Epoch [9851/10000], Loss: 0.5607681274414062\n",
      "Epoch [9852/10000], Loss: 0.5607672929763794\n",
      "Epoch [9853/10000], Loss: 0.5607666969299316\n",
      "Epoch [9854/10000], Loss: 0.5607659816741943\n",
      "Epoch [9855/10000], Loss: 0.5607656836509705\n",
      "Epoch [9856/10000], Loss: 0.5607659816741943\n",
      "Epoch [9857/10000], Loss: 0.560766875743866\n",
      "Epoch [9858/10000], Loss: 0.5607674717903137\n",
      "Epoch [9859/10000], Loss: 0.5607684850692749\n",
      "Epoch [9860/10000], Loss: 0.5607699155807495\n",
      "Epoch [9861/10000], Loss: 0.5607706308364868\n",
      "Epoch [9862/10000], Loss: 0.5607714653015137\n",
      "Epoch [9863/10000], Loss: 0.5607722997665405\n",
      "Epoch [9864/10000], Loss: 0.560772716999054\n",
      "Epoch [9865/10000], Loss: 0.560772716999054\n",
      "Epoch [9866/10000], Loss: 0.5607728362083435\n",
      "Epoch [9867/10000], Loss: 0.5607728362083435\n",
      "Epoch [9868/10000], Loss: 0.5607729554176331\n",
      "Epoch [9869/10000], Loss: 0.5607720017433167\n",
      "Epoch [9870/10000], Loss: 0.5607701539993286\n",
      "Epoch [9871/10000], Loss: 0.5607683658599854\n",
      "Epoch [9872/10000], Loss: 0.5607661604881287\n",
      "Epoch [9873/10000], Loss: 0.5607650279998779\n",
      "Epoch [9874/10000], Loss: 0.5607644319534302\n",
      "Epoch [9875/10000], Loss: 0.5607638359069824\n",
      "Epoch [9876/10000], Loss: 0.5607632398605347\n",
      "Epoch [9877/10000], Loss: 0.5607628226280212\n",
      "Epoch [9878/10000], Loss: 0.5607631802558899\n",
      "Epoch [9879/10000], Loss: 0.5607633590698242\n",
      "Epoch [9880/10000], Loss: 0.5607633590698242\n",
      "Epoch [9881/10000], Loss: 0.5607638359069824\n",
      "Epoch [9882/10000], Loss: 0.5607643723487854\n",
      "Epoch [9883/10000], Loss: 0.5607653856277466\n",
      "Epoch [9884/10000], Loss: 0.5607669353485107\n",
      "Epoch [9885/10000], Loss: 0.5607683658599854\n",
      "Epoch [9886/10000], Loss: 0.5607694387435913\n",
      "Epoch [9887/10000], Loss: 0.56076979637146\n",
      "Epoch [9888/10000], Loss: 0.5607694387435913\n",
      "Epoch [9889/10000], Loss: 0.5607687830924988\n",
      "Epoch [9890/10000], Loss: 0.5607678294181824\n",
      "Epoch [9891/10000], Loss: 0.560766339302063\n",
      "Epoch [9892/10000], Loss: 0.5607652068138123\n",
      "Epoch [9893/10000], Loss: 0.560764491558075\n",
      "Epoch [9894/10000], Loss: 0.5607640743255615\n",
      "Epoch [9895/10000], Loss: 0.5607635378837585\n",
      "Epoch [9896/10000], Loss: 0.5607634782791138\n",
      "Epoch [9897/10000], Loss: 0.5607635378837585\n",
      "Epoch [9898/10000], Loss: 0.5607632994651794\n",
      "Epoch [9899/10000], Loss: 0.5607636570930481\n",
      "Epoch [9900/10000], Loss: 0.5607638955116272\n",
      "Epoch [9901/10000], Loss: 0.5607646703720093\n",
      "Epoch [9902/10000], Loss: 0.5607654452323914\n",
      "Epoch [9903/10000], Loss: 0.5607662796974182\n",
      "Epoch [9904/10000], Loss: 0.5607673525810242\n",
      "Epoch [9905/10000], Loss: 0.5607680082321167\n",
      "Epoch [9906/10000], Loss: 0.5607684850692749\n",
      "Epoch [9907/10000], Loss: 0.560768187046051\n",
      "Epoch [9908/10000], Loss: 0.5607670545578003\n",
      "Epoch [9909/10000], Loss: 0.5607660412788391\n",
      "Epoch [9910/10000], Loss: 0.560764729976654\n",
      "Epoch [9911/10000], Loss: 0.5607643127441406\n",
      "Epoch [9912/10000], Loss: 0.5607645511627197\n",
      "Epoch [9913/10000], Loss: 0.5607645511627197\n",
      "Epoch [9914/10000], Loss: 0.5607653260231018\n",
      "Epoch [9915/10000], Loss: 0.5607666969299316\n",
      "Epoch [9916/10000], Loss: 0.5607677698135376\n",
      "Epoch [9917/10000], Loss: 0.560768723487854\n",
      "Epoch [9918/10000], Loss: 0.5607697367668152\n",
      "Epoch [9919/10000], Loss: 0.5607697367668152\n",
      "Epoch [9920/10000], Loss: 0.5607693791389465\n",
      "Epoch [9921/10000], Loss: 0.5607682466506958\n",
      "Epoch [9922/10000], Loss: 0.5607671141624451\n",
      "Epoch [9923/10000], Loss: 0.5607663989067078\n",
      "Epoch [9924/10000], Loss: 0.5607655048370361\n",
      "Epoch [9925/10000], Loss: 0.5607653856277466\n",
      "Epoch [9926/10000], Loss: 0.5607662200927734\n",
      "Epoch [9927/10000], Loss: 0.5607675313949585\n",
      "Epoch [9928/10000], Loss: 0.5607702732086182\n",
      "Epoch [9929/10000], Loss: 0.5607752203941345\n",
      "Epoch [9930/10000], Loss: 0.5607821345329285\n",
      "Epoch [9931/10000], Loss: 0.5607905387878418\n",
      "Epoch [9932/10000], Loss: 0.5607981085777283\n",
      "Epoch [9933/10000], Loss: 0.560805082321167\n",
      "Epoch [9934/10000], Loss: 0.5608096718788147\n",
      "Epoch [9935/10000], Loss: 0.5608115196228027\n",
      "Epoch [9936/10000], Loss: 0.5608081221580505\n",
      "Epoch [9937/10000], Loss: 0.5607998371124268\n",
      "Epoch [9938/10000], Loss: 0.5607869029045105\n",
      "Epoch [9939/10000], Loss: 0.560774564743042\n",
      "Epoch [9940/10000], Loss: 0.5607672929763794\n",
      "Epoch [9941/10000], Loss: 0.5607662796974182\n",
      "Epoch [9942/10000], Loss: 0.5607708096504211\n",
      "Epoch [9943/10000], Loss: 0.5607765316963196\n",
      "Epoch [9944/10000], Loss: 0.5607814788818359\n",
      "Epoch [9945/10000], Loss: 0.5607824325561523\n",
      "Epoch [9946/10000], Loss: 0.560779869556427\n",
      "Epoch [9947/10000], Loss: 0.5607745051383972\n",
      "Epoch [9948/10000], Loss: 0.5607687830924988\n",
      "Epoch [9949/10000], Loss: 0.5607651472091675\n",
      "Epoch [9950/10000], Loss: 0.5607642531394958\n",
      "Epoch [9951/10000], Loss: 0.5607655048370361\n",
      "Epoch [9952/10000], Loss: 0.560767650604248\n",
      "Epoch [9953/10000], Loss: 0.5607692003250122\n",
      "Epoch [9954/10000], Loss: 0.5607693195343018\n",
      "Epoch [9955/10000], Loss: 0.5607681274414062\n",
      "Epoch [9956/10000], Loss: 0.5607668161392212\n",
      "Epoch [9957/10000], Loss: 0.5607658624649048\n",
      "Epoch [9958/10000], Loss: 0.5607659220695496\n",
      "Epoch [9959/10000], Loss: 0.5607664585113525\n",
      "Epoch [9960/10000], Loss: 0.5607666969299316\n",
      "Epoch [9961/10000], Loss: 0.5607665181159973\n",
      "Epoch [9962/10000], Loss: 0.5607659816741943\n",
      "Epoch [9963/10000], Loss: 0.5607650876045227\n",
      "Epoch [9964/10000], Loss: 0.5607640147209167\n",
      "Epoch [9965/10000], Loss: 0.5607631802558899\n",
      "Epoch [9966/10000], Loss: 0.5607631206512451\n",
      "Epoch [9967/10000], Loss: 0.5607635378837585\n",
      "Epoch [9968/10000], Loss: 0.5607642531394958\n",
      "Epoch [9969/10000], Loss: 0.5607647895812988\n",
      "Epoch [9970/10000], Loss: 0.5607653856277466\n",
      "Epoch [9971/10000], Loss: 0.5607650876045227\n",
      "Epoch [9972/10000], Loss: 0.5607643723487854\n",
      "Epoch [9973/10000], Loss: 0.5607635378837585\n",
      "Epoch [9974/10000], Loss: 0.560762882232666\n",
      "Epoch [9975/10000], Loss: 0.5607626438140869\n",
      "Epoch [9976/10000], Loss: 0.5607631206512451\n",
      "Epoch [9977/10000], Loss: 0.5607632994651794\n",
      "Epoch [9978/10000], Loss: 0.5607635378837585\n",
      "Epoch [9979/10000], Loss: 0.560763418674469\n",
      "Epoch [9980/10000], Loss: 0.5607632398605347\n",
      "Epoch [9981/10000], Loss: 0.5607630610466003\n",
      "Epoch [9982/10000], Loss: 0.5607632994651794\n",
      "Epoch [9983/10000], Loss: 0.5607640743255615\n",
      "Epoch [9984/10000], Loss: 0.5607647895812988\n",
      "Epoch [9985/10000], Loss: 0.5607662796974182\n",
      "Epoch [9986/10000], Loss: 0.5607675313949585\n",
      "Epoch [9987/10000], Loss: 0.5607686042785645\n",
      "Epoch [9988/10000], Loss: 0.5607695579528809\n",
      "Epoch [9989/10000], Loss: 0.5607693195343018\n",
      "Epoch [9990/10000], Loss: 0.5607684254646301\n",
      "Epoch [9991/10000], Loss: 0.5607666373252869\n",
      "Epoch [9992/10000], Loss: 0.5607650876045227\n",
      "Epoch [9993/10000], Loss: 0.5607638359069824\n",
      "Epoch [9994/10000], Loss: 0.5607627630233765\n",
      "Epoch [9995/10000], Loss: 0.5607620477676392\n",
      "Epoch [9996/10000], Loss: 0.5607621073722839\n",
      "Epoch [9997/10000], Loss: 0.5607618093490601\n",
      "Epoch [9998/10000], Loss: 0.5607619881629944\n",
      "Epoch [9999/10000], Loss: 0.5607624053955078\n",
      "Epoch [10000/10000], Loss: 0.5607631206512451\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX00lEQVR4nO3deVzUdeI/8NfMwMxwjtwgp/dFHkEaoJlZeK1lbqupoab+Wm/RrHS1LI8ov2nWtlCWx5amVuquFR5onmFZXmV4rgcoICLCgMBwzPv3B/LJEUSOYT7AvJ6PxzzWec/785n35wO7vPZ9fRRCCAEiIiIiK6KUuwFERERElsYARERERFaHAYiIiIisDgMQERERWR0GICIiIrI6DEBERERkdRiAiIiIyOowABEREZHVYQAiIiIiq8MARGQmCoWiWq99+/bV6XvefPNNKBSKWh27b98+s7ShLt/9zTffWPy7m6qqfs/Gjh0rd/Pw+OOPIzg4WO5mEFXKRu4GEDUVhw8fNnm/aNEi7N27Fz/88INJeceOHev0PRMmTED//v1rdezDDz+Mw4cP17kN1HA899xzePnllyuUe3h4yNAaosaDAYjITB599FGT9x4eHlAqlRXK75Wfnw97e/tqf4+fnx/8/Pxq1UZnZ+cHtocajuLiYigUCtjY3P9/qr28vPgzJaoFDoERWVD5kMCBAwcQHh4Oe3t7jBs3DgCwadMmREZGwsfHB3Z2dujQoQPmzJmD27dvm5yjsiGwoKAg/OUvf8GOHTvw8MMPw87ODu3bt8fq1atN6lU2BDZ27Fg4OjriwoULGDhwIBwdHeHv74+XX34ZBoPB5PirV6/iueeeg5OTE5o1a4ZRo0bhl19+gUKhwNq1a81yj06dOoVnnnkGLi4u0Gq16Nq1K/7973+b1DEajVi8eDHatWsHOzs7NGvWDJ07d8YHH3wg1blx4wZeeukl+Pv7Q6PRwMPDAxEREdi9e/cD23Do0CH07dsXTk5OsLe3R3h4OL7//nvp85MnT0KhUGDVqlUVjt2+fTsUCgW2bdsmlZ0/fx4jR46Ep6cnNBoNOnTogH/9618mx5X/bL744gu8/PLL8PX1hUajwYULF6p97+6n/Gf8xx9/oG/fvnBwcICHhwemTp2K/Px8k7qFhYWYO3cuWrRoAbVaDV9fX0yZMgXZ2dkVzvvll18iLCwMjo6OcHR0RNeuXSu9J7/88gt69eoFe3t7tGzZEu+88w6MRqP0eXV+nkTmxh4gIgtLS0vDCy+8gFdffRVvv/02lMqy/x9y/vx5DBw4ENHR0XBwcMCZM2fw7rvv4siRIxWG0Spz8uRJvPzyy5gzZw68vLzw2WefYfz48WjdujUee+yxKo8tLi7G008/jfHjx+Pll1/GgQMHsGjRIuh0OrzxxhsAgNu3b6NPnz7IysrCu+++i9atW2PHjh0YPnx43W/KHWfPnkV4eDg8PT3x4Ycfws3NDevWrcPYsWNx/fp1vPrqqwCApUuX4s0338T8+fPx2GOPobi4GGfOnDH5Ix0VFYVjx45hyZIlaNu2LbKzs3Hs2DHcvHmzyjbs378fTz31FDp37oxVq1ZBo9EgNjYWgwcPxoYNGzB8+HB06dIF3bp1w5o1azB+/HiT49euXQtPT08MHDgQAJCUlITw8HAEBARg2bJl8Pb2xs6dOzF9+nRkZmZiwYIFJsfPnTsXYWFh+Pjjj6FUKuHp6Vlle4UQKCkpqVCuUqlMgnJxcTEGDhyIv//975gzZw4SExOxePFiXLlyBd9++610riFDhmDPnj2YO3cuevXqhd9++w0LFizA4cOHcfjwYWg0GgDAG2+8gUWLFmHo0KF4+eWXodPpcOrUKVy5csWkHenp6Rg1ahRefvllLFiwAFu3bsXcuXPRvHlzjB49GkD1fp5EZieIqF6MGTNGODg4mJT17t1bABB79uyp8lij0SiKi4vF/v37BQBx8uRJ6bMFCxaIe/+rGxgYKLRarbhy5YpUVlBQIFxdXcXf//53qWzv3r0CgNi7d69JOwGIr776yuScAwcOFO3atZPe/+tf/xIAxPbt203q/f3vfxcAxJo1a6q8pvLv/vrrr+9b5/nnnxcajUYkJyeblA8YMEDY29uL7OxsIYQQf/nLX0TXrl2r/D5HR0cRHR1dZZ3KPProo8LT01Pk5uZKZSUlJSI4OFj4+fkJo9EohBDiww8/FADE2bNnpXpZWVlCo9GIl19+WSrr16+f8PPzEzk5OSbfM3XqVKHVakVWVpYQ4s/789hjj1W7rQDu+/riiy+keuU/4w8++MDk+CVLlggA4tChQ0IIIXbs2CEAiKVLl5rU27RpkwAgVq5cKYQQ4uLFi0KlUolRo0ZV2b7y3/eff/7ZpLxjx46iX79+0vvq/DyJzI1DYEQW5uLigieeeKJC+cWLFzFy5Eh4e3tDpVLB1tYWvXv3BgCcPn36geft2rUrAgICpPdarRZt27at8P/IK6NQKDB48GCTss6dO5scu3//fjg5OVWYgD1ixIgHnr+6fvjhB/Tt2xf+/v4m5WPHjkV+fr400bx79+44efIkJk+ejJ07d0Kv11c4V/fu3bF27VosXrwYP/30E4qLix/4/bdv38bPP/+M5557Do6OjlK5SqVCVFQUrl69irNnzwIARo0aBY1GYzL0t2HDBhgMBrz44osAyoaT9uzZg2effRb29vYoKSmRXgMHDkRhYSF++uknkzb89a9/rd7NumPYsGH45ZdfKrzKe6DuNmrUKJP3I0eOBADs3bsXAKSexntXkP3tb3+Dg4MD9uzZAwBISEhAaWkppkyZ8sD2eXt7o3v37iZl9/5uVefnSWRuDEBEFubj41OhLC8vD7169cLPP/+MxYsXY9++ffjll1+wZcsWAEBBQcEDz+vm5lahTKPRVOtYe3t7aLXaCscWFhZK72/evAkvL68Kx1ZWVls3b96s9P40b95c+hwoGyZ677338NNPP2HAgAFwc3ND37598euvv0rHbNq0CWPGjMFnn32GsLAwuLq6YvTo0UhPT7/v99+6dQtCiGq1wdXVFU8//TQ+//xzlJaWAigb/urevTs6deok1S0pKcE///lP2NramrzKA0pmZqbJ91T23VXx8PBAaGhohZerq6tJPRsbmwq/I97e3ibXdPPmTdjY2FRYQaZQKODt7S3Vu3HjBgBUazJ+dX4vq/PzJDI3BiAiC6tsD58ffvgBqampWL16NSZMmIDHHnsMoaGhcHJykqGFlXNzc8P169crlFcVKGrzHWlpaRXKU1NTAQDu7u4Ayv6Yz5o1C8eOHUNWVhY2bNiAlJQU9OvXT5rU6+7ujhUrVuDy5cu4cuUKYmJisGXLlir3x3FxcYFSqaxWGwDgxRdfxLVr15CQkICkpCT88ssvUu9P+flUKhXGjh1baS9NZT01td3j6UFKSkoqzH8q/9mVhxQ3NzeUlJRIAaecEALp6enStZcHpKtXr5qlbdX5eRKZGwMQUQNQ/kevfIJpuU8++USO5lSqd+/eyM3Nxfbt203KN27caLbv6Nu3rxQG7/b555/D3t6+0uXezZo1w3PPPYcpU6YgKysLly9frlAnICAAU6dOxVNPPYVjx47d9/sdHBzQo0cPbNmyxaSHwmg0Yt26dfDz80Pbtm2l8sjISPj6+mLNmjVYs2YNtFqtyZCgvb09+vTpg+PHj6Nz586V9tRU1kNSX9avX2/y/ssvvwRQtjoRKLv/ALBu3TqTeps3b8bt27elzyMjI6FSqRAXF2f2Nlbn50lkDlwFRtQAhIeHw8XFBRMnTsSCBQtga2uL9evX4+TJk3I3TTJmzBi8//77eOGFF7B48WK0bt0a27dvx86dOwFAWs32IPfOeSnXu3dvLFiwAN999x369OmDN954A66urli/fj2+//57LF26FDqdDgAwePBgBAcHIzQ0FB4eHrhy5QpWrFiBwMBAtGnTBjk5OejTpw9GjhyJ9u3bw8nJCb/88gt27NiBoUOHVtm+mJgYPPXUU+jTpw9mz54NtVqN2NhYnDp1Chs2bDDpoVGpVBg9ejSWL18OZ2dnDB06VGpjuQ8++AA9e/ZEr169MGnSJAQFBSE3NxcXLlzAt99+W60VflW5fv16pffU2dnZZMNLtVqNZcuWIS8vD4888oi0CmzAgAHo2bMnAOCpp55Cv3798Nprr0Gv1yMiIkJaBdatWzdERUUBKNt24R//+AcWLVqEgoICjBgxAjqdDklJScjMzMRbb71Vo2t40M+TqF7IPQubqKm63yqwTp06VVo/MTFRhIWFCXt7e+Hh4SEmTJggjh07VmGF1f1WgQ0aNKjCOXv37i169+4tvb/fKrB723m/70lOThZDhw4Vjo6OwsnJSfz1r38V8fHxAoD473//e79bYfLd93uVt+n3338XgwcPFjqdTqjVatGlS5cKK8yWLVsmwsPDhbu7u1Cr1SIgIECMHz9eXL58WQghRGFhoZg4caLo3LmzcHZ2FnZ2dqJdu3ZiwYIF4vbt21W2UwghDh48KJ544gnh4OAg7OzsxKOPPiq+/fbbSuueO3dOuoaEhIRK61y6dEmMGzdO+Pr6CltbW+Hh4SHCw8PF4sWLK9yfqlbJ3auq+xkRESHVK/8Z//bbb+Lxxx8XdnZ2wtXVVUyaNEnk5eWZnLOgoEC89tprIjAwUNja2gofHx8xadIkcevWrQrf//nnn4tHHnlEaLVa4ejoKLp162bys7rf7/uYMWNEYGCg9P5BP0+i+qAQQghLBi4ialrefvttzJ8/H8nJybXeoZrq19ixY/HNN98gLy9P7qYQNRgcAiOiavvoo48AAO3bt0dxcTF++OEHfPjhh3jhhRcYfoioUWEAIqJqs7e3x/vvv4/Lly/DYDAgICAAr732GubPny9304iIaoRDYERERGR1uAyeiIiIrA4DEBEREVkdBiAiIiKyOpwEXQmj0YjU1FQ4OTnV27b0REREZF5CCOTm5qJ58+YP3JyVAagSqampFZ5GTURERI1DSkrKA7fmYACqRPkDKFNSUuDs7Cxza4iIiKg69Ho9/P39q/UgaQagSpQPezk7OzMAERERNTLVmb7CSdBERERkdWQPQLGxsWjRogW0Wi1CQkJw8ODB+9YdO3YsFApFhVenTp1M6m3evBkdO3aERqNBx44dsXXr1vq+DCIiImpEZA1AmzZtQnR0NObNm4fjx4+jV69eGDBgAJKTkyut/8EHHyAtLU16paSkwNXVFX/729+kOocPH8bw4cMRFRWFkydPIioqCsOGDcPPP/9sqcsiIiKiBk7WR2H06NEDDz/8MOLi4qSyDh06YMiQIYiJiXng8f/5z38wdOhQXLp0CYGBgQCA4cOHQ6/XY/v27VK9/v37w8XFBRs2bKhWu/R6PXQ6HXJycjgHiIjIgoxGI4qKiuRuBjVgarX6vkvca/L3W7ZJ0EVFRTh69CjmzJljUh4ZGYnExMRqnWPVqlV48sknpfADlPUAzZw506Rev379sGLFivuex2AwwGAwSO/1en21vp+IiMynqKgIly5dgtFolLsp1IAplUq0aNECarW6TueRLQBlZmaitLQUXl5eJuVeXl5IT09/4PFpaWnYvn07vvzyS5Py9PT0Gp8zJiYGb731Vg1aT0RE5iSEQFpaGlQqFfz9/R+4iR1Zp/KNitPS0hAQEFCnzYplXwZ/b+OFENW6oLVr16JZs2YYMmRInc85d+5czJo1S3pfvo8AERFZRklJCfLz89G8eXPY29vL3RxqwDw8PJCamoqSkhLY2trW+jyyBSB3d3eoVKoKPTMZGRkVenDuJYTA6tWrERUVVaELzNvbu8bn1Gg00Gg0NbwCIiIyl9LSUgCo87AGNX3lvyOlpaV1CkCy9TGq1WqEhIQgISHBpDwhIQHh4eFVHrt//35cuHAB48ePr/BZWFhYhXPu2rXrgeckIiL58fmL9CDm+h2RdQhs1qxZiIqKQmhoKMLCwrBy5UokJydj4sSJAMqGpq5du4bPP//c5LhVq1ahR48eCA4OrnDOGTNm4LHHHsO7776LZ555Bv/973+xe/duHDp0yCLXRERERA2frLPMhg8fjhUrVmDhwoXo2rUrDhw4gPj4eGlVV1paWoU9gXJycrB58+ZKe38AIDw8HBs3bsSaNWvQuXNnrF27Fps2bUKPHj3q/XqIiIjq6vHHH0d0dHS161++fBkKhQInTpyotzY1RbLuA9RQcR8gIiLLKiwsxKVLl6QnAzQGDxqKGTNmDNauXVvj82ZlZcHW1rZaD/QEyubC3LhxA+7u7rCxqb+BncuXL6NFixY4fvw4unbtWm/f8yBV/a40in2ArJGhpBQ3cg1QKRXw0dnJ3RwiIqqDtLQ06d+bNm3CG2+8gbNnz0pldnam/ztfXFxcrUm7rq6uNWqHSqWCt7d3jY6hBvAsMGty6poePd/di+Gf/CR3U4iIqI68vb2ll06ng0KhkN4XFhaiWbNm+Oqrr/D4449Dq9Vi3bp1uHnzJkaMGAE/Pz/Y29vjoYceqvCUgnuHwIKCgvD2229j3LhxcHJyQkBAAFauXCl9fu8Q2L59+6BQKLBnzx6EhobC3t4e4eHhJuEMABYvXgxPT084OTlhwoQJmDNnTp16dgwGA6ZPnw5PT09otVr07NkTv/zyi/T5rVu3MGrUKHh4eMDOzg5t2rTBmjVrAJRtgjl16lT4+PhAq9UiKCioWk+EqAsGIAsq7y0V4KgjEVFVhBDILyqR5WXOmSGvvfYapk+fjtOnT6Nfv34oLCxESEgIvvvuO5w6dQovvfQSoqKiHvi8ymXLliE0NBTHjx/H5MmTMWnSJJw5c6bKY+bNm4dly5bh119/hY2NDcaNGyd9tn79eixZsgTvvvsujh49ioCAAJPHUtXGq6++is2bN+Pf//43jh07htatW6Nfv37IysoCALz++utISkrC9u3bcfr0acTFxcHd3R0A8OGHH2Lbtm346quvcPbsWaxbtw5BQUF1as+DcAjMgspHiznrioioagXFpej4xk5ZvjtpYT/Yq83z5zE6OhpDhw41KZs9e7b072nTpmHHjh34+uuvq1ysM3DgQEyePBlAWah6//33sW/fPrRv3/6+xyxZsgS9e/cGAMyZMweDBg1CYWEhtFot/vnPf2L8+PF48cUXAQBvvPEGdu3ahby8vFpd5+3btxEXF4e1a9diwIABAIBPP/0UCQkJWLVqFV555RUkJyejW7duCA0NBQCTgJOcnIw2bdqgZ8+eUCgUJo+4qi/sAbKg8glzDEBERNah/I99udLSUixZsgSdO3eGm5sbHB0dsWvXrgornu/VuXNn6d/lQ20ZGRnVPsbHxwcApGPOnj2L7t27m9S/931N/O9//0NxcTEiIiKkMltbW3Tv3h2nT58GAEyaNAkbN25E165d8eqrr5o893Ps2LE4ceIE2rVrh+nTp2PXrl21bkt1sQfIgpTc34uIqFrsbFVIWthPtu82FwcHB5P3y5Ytw/vvv48VK1bgoYcegoODA6Kjo1FUVFTlee6dPK1QKB740Ni7jyn/P+B3H1PZY6Nqq/zYqh5FNWDAAFy5cgXff/89du/ejb59+2LKlCl477338PDDD+PSpUvYvn07du/ejWHDhuHJJ5/EN998U+s2PQh7gCxIcWcQzMguICKiKikUCtirbWR51edu1AcPHsQzzzyDF154AV26dEHLli1x/vz5evu++2nXrh2OHDliUvbrr7/W+nytW7eGWq022XS4uLgYv/76Kzp06CCVeXh4YOzYsVi3bh1WrFhhMpnb2dkZw4cPx6effopNmzZh8+bN0vyh+sAeIAuSJkEz/xARWaXWrVtj8+bNSExMhIuLC5YvX4709HSTkGAJ06ZNw//7f/8PoaGhCA8Px6ZNm/Dbb7+hZcuWDzz23tVkANCxY0dMmjQJr7zyClxdXREQEIClS5ciPz9f2rj4jTfeQEhICDp16gSDwYDvvvtOuu73338fPj4+6Nq1K5RKJb7++mt4e3ujWbNmZr3uuzEAyYCrwIiIrNPrr7+OS5cuoV+/frC3t8dLL72EIUOGICcnx6LtGDVqFC5evIjZs2ejsLAQw4YNw9ixYyv0ClXm+eefr1B26dIlvPPOOzAajYiKikJubi5CQ0Oxc+dOuLi4ACh7BujcuXNx+fJl2NnZoVevXti4cSMAwNHREe+++y7Onz8PlUqFRx55BPHx8VAq62+gijtBV6K+doL+IzUHgz48BE8nDY7Me9Js5yUiauwa407QTc1TTz0Fb29vfPHFF3I3pUrcCboRUpavApO5HUREZN3y8/Px8ccfo1+/flCpVNiwYQN2796NhIQEuZtmMQxAFvTnHCBGICIiko9CoUB8fDwWL14Mg8GAdu3aYfPmzXjySesZnWAAsqDyVWDMP0REJCc7Ozvs3r1b7mbIisvgLejPR2EQERGRnBiALOjPR2EwAhERVYb/+0gPYq7fEQYgC1JwEjQRUaVUqrLdlx+0IzJR+e9I+e9MbXEOkAWVD4EZjYxARER3s7Gxgb29PW7cuAFbW9t63f+FGi+j0YgbN27A3t4eNjZ1izAMQBYkDYHJ2goiooZHoVDAx8cHly5dwpUrV+RuDjVgSqUSAQEBdX5kCQOQBSk4C5qI6L7UajXatGnDYTCqklqtNksPIQOQBbEHiIioakqlkjtBk0VwkNWCpJ2gucqBiIhIVgxAFiRNgmb+ISIikhUDkAz4NHgiIiJ5MQBZ0J/PApO3HURERNaOAciCuBEiERFRw8AAZEFKLgMjIiJqEBiALKj8afBGjoERERHJigHIgrgPIhERUcPAAGRBfBo8ERFRw8AAZEnsASIiImoQGIAs6M+doGVuCBERkZVjALKgu59by2EwIiIi+TAAWZD0NHiwF4iIiEhODEAWZNIDJFsriIiIiAHIgu7qAOIQGBERkYwYgCzIZAhMxnYQERFZOwYgC7q7B4i7QRMREcmHAciCTFeBydYMIiIiqyd7AIqNjUWLFi2g1WoREhKCgwcPVlnfYDBg3rx5CAwMhEajQatWrbB69WqTOitWrEC7du1gZ2cHf39/zJw5E4WFhfV5GdVy9xAYERERycdGzi/ftGkToqOjERsbi4iICHzyyScYMGAAkpKSEBAQUOkxw4YNw/Xr17Fq1Sq0bt0aGRkZKCkpkT5fv3495syZg9WrVyM8PBznzp3D2LFjAQDvv/++JS7rvtgDRERE1DDIGoCWL1+O8ePHY8KECQDKem527tyJuLg4xMTEVKi/Y8cO7N+/HxcvXoSrqysAICgoyKTO4cOHERERgZEjR0qfjxgxAkeOHKnfi6kGpckkaCYgIiIiucg2BFZUVISjR48iMjLSpDwyMhKJiYmVHrNt2zaEhoZi6dKl8PX1Rdu2bTF79mwUFBRIdXr27ImjR49KgefixYuIj4/HoEGD7tsWg8EAvV5v8qoPppOg6+UriIiIqBpk6wHKzMxEaWkpvLy8TMq9vLyQnp5e6TEXL17EoUOHoNVqsXXrVmRmZmLy5MnIysqS5gE9//zzuHHjBnr27AkhBEpKSjBp0iTMmTPnvm2JiYnBW2+9Zb6LqwbuA0RERCQf2SdB3zsxWAhx38nCRqMRCoUC69evR/fu3TFw4EAsX74ca9eulXqB9u3bhyVLliA2NhbHjh3Dli1b8N1332HRokX3bcPcuXORk5MjvVJSUsx3gXcx2QixXr6BiIiIqkO2HiB3d3eoVKoKvT0ZGRkVeoXK+fj4wNfXFzqdTirr0KEDhBC4evUq2rRpg9dffx1RUVHSvKKHHnoIt2/fxksvvYR58+ZBqayY+TQaDTQajRmvrnIK8FlgREREDYFsPUBqtRohISFISEgwKU9ISEB4eHilx0RERCA1NRV5eXlS2blz56BUKuHn5wcAyM/PrxByVCoVhBCyDzsp+TAwIiKiBkHWIbBZs2bhs88+w+rVq3H69GnMnDkTycnJmDhxIoCyoanRo0dL9UeOHAk3Nze8+OKLSEpKwoEDB/DKK69g3LhxsLOzAwAMHjwYcXFx2LhxIy5duoSEhAS8/vrrePrpp6FSqWS5znJ3D+1xJ2giIiL5yLoMfvjw4bh58yYWLlyItLQ0BAcHIz4+HoGBgQCAtLQ0JCcnS/UdHR2RkJCAadOmITQ0FG5ubhg2bBgWL14s1Zk/fz4UCgXmz5+Pa9euwcPDA4MHD8aSJUssfn33YgcQERFRw6AQco8LNUB6vR46nQ45OTlwdnY223mFEGgxNx4AcHT+k3BzrP95R0RERNaiJn+/ZV8FZk34NHgiIqKGgQHIwsozEPvdiIiI5MMAZGHlfUAceSQiIpIPA5CFlQ+DMf4QERHJhwHIwv7sAZK1GURERFaNAcjCpDlA7AMiIiKSDQOQhUlDYMw/REREsmEAsrDyITDuBE1ERCQfBiAL4zJ4IiIi+TEAWZjC5IEYREREJAcGIAtjDxAREZH8GIAsTCntA8QEREREJBcGIAv7cxK0rM0gIiKyagxAliYNgTEBERERyYUByMKknaBlbQUREZF1YwCyMG6ESEREJD8GIAtTSqvgmYCIiIjkwgBkYeU9QJwETUREJB8GIAvj0+CJiIjkxwBkYXwaPBERkfwYgCxMGgIzytwQIiIiK8YAZGE2yvI5QOwBIiIikgsDkIWp7gSgEs6CJiIikg0DkIWV9wCVcgyMiIhINgxAFib1AJWyB4iIiEguDEAWZqMsu+WlHAIjIiKSDQOQhXEOEBERkfwYgCzMRlU+B4gBiIiISC4MQBbGHiAiIiL5MQBZGFeBERERyY8ByMKUCvYAERERyY0ByMI4B4iIiEh+DEAWprqzDJ77ABEREcmHAcjCpDlAfBYYERGRbBiALEyl5BAYERGR3BiALMyGy+CJiIhkxwBkYVIPUCmXwRMREcmFAcjC2ANEREQkPwYgC7NRld3yIvYAERERyUb2ABQbG4sWLVpAq9UiJCQEBw8erLK+wWDAvHnzEBgYCI1Gg1atWmH16tUmdbKzszFlyhT4+PhAq9WiQ4cOiI+Pr8/LqDaNzZ0AVMIAREREJBcbOb9806ZNiI6ORmxsLCIiIvDJJ59gwIABSEpKQkBAQKXHDBs2DNevX8eqVavQunVrZGRkoKSkRPq8qKgITz31FDw9PfHNN9/Az88PKSkpcHJystRlVUnNAERERCQ7WQPQ8uXLMX78eEyYMAEAsGLFCuzcuRNxcXGIiYmpUH/Hjh3Yv38/Ll68CFdXVwBAUFCQSZ3Vq1cjKysLiYmJsLW1BQAEBgbW74XUAAMQERGR/GQbAisqKsLRo0cRGRlpUh4ZGYnExMRKj9m2bRtCQ0OxdOlS+Pr6om3btpg9ezYKCgpM6oSFhWHKlCnw8vJCcHAw3n77bZSWlt63LQaDAXq93uRVXzScA0RERCQ72XqAMjMzUVpaCi8vL5NyLy8vpKenV3rMxYsXcejQIWi1WmzduhWZmZmYPHkysrKypHlAFy9exA8//IBRo0YhPj4e58+fx5QpU1BSUoI33nij0vPGxMTgrbfeMu8F3kd5D5ChmAGIiIhILrJPglbceTp6OSFEhbJyRqMRCoUC69evR/fu3TFw4EAsX74ca9eulXqBjEYjPD09sXLlSoSEhOD555/HvHnzEBcXd982zJ07Fzk5OdIrJSXFfBd4D2kIjD1AREREspGtB8jd3R0qlapCb09GRkaFXqFyPj4+8PX1hU6nk8o6dOgAIQSuXr2KNm3awMfHB7a2tlCpVCZ10tPTUVRUBLVaXeG8Go0GGo3GTFdWNY1NWbs4B4iIiEg+svUAqdVqhISEICEhwaQ8ISEB4eHhlR4TERGB1NRU5OXlSWXnzp2DUqmEn5+fVOfChQswGo0mdXx8fCoNP5YmDYExABEREclG1iGwWbNm4bPPPsPq1atx+vRpzJw5E8nJyZg4cSKAsqGp0aNHS/VHjhwJNzc3vPjii0hKSsKBAwfwyiuvYNy4cbCzswMATJo0CTdv3sSMGTNw7tw5fP/993j77bcxZcoUWa7xXmpOgiYiIpKdrMvghw8fjps3b2LhwoVIS0tDcHAw4uPjpWXraWlpSE5Oluo7OjoiISEB06ZNQ2hoKNzc3DBs2DAsXrxYquPv749du3Zh5syZ6Ny5M3x9fTFjxgy89tprFr++yvy5DP7+q9KIiIiofimEEHwo1T30ej10Oh1ycnLg7Oxs1nPv/CMdf//iKLoFNMPWyRFmPTcREZE1q8nfb9lXgVkbPgqDiIhIfgxAFsadoImIiOTHAGRhGu4DREREJDsGIAtTq7gPEBERkdwYgCyM+wARERHJjwHIwjgHiIiISH4MQBbGVWBERETyYwCysLsfhsotmIiIiOTBAGRh5QEI4EowIiIiuTAAWVj5s8AADoMRERHJhQHIwu4OQFwJRkREJA8GIAtTKhWwVSkAsAeIiIhILgxAMtDYcDNEIiIiOTEAyUDNx2EQERHJigFIBuXzgNgDREREJA8GIBn8+TiMUplbQkREZJ0YgGTA54ERERHJiwFIBnwcBhERkbwYgGSgYQ8QERGRrBiAZGCvtgEAFBRxDhAREZEcGIBkYK8u2wfodlGJzC0hIiKyTgxAMigPQOwBIiIikgcDkAzsNWVDYLcNDEBERERyYACSgcOdHqB8DoERERHJggFIBuWToDkHiIiISB4MQDJw0NzpAeIQGBERkSwYgGTAHiAiIiJ5MQDJQOoB4iowIiIiWTAAyaC8B4gBiIiISB4MQDJwKB8CM3AIjIiISA4MQDKwU3MIjIiISE4MQDL4cw4Qe4CIiIjkwAAkgz+HwNgDREREJAcGIBlIzwIrLoXRKGRuDRERkfVhAJKBw51ngQFAHofBiIiILI4BSAZaWxU0NmW3Pie/WObWEBERWR8GIJno7GwBADkFDEBERESWxgAkk/IApGcAIiIisjjZA1BsbCxatGgBrVaLkJAQHDx4sMr6BoMB8+bNQ2BgIDQaDVq1aoXVq1dXWnfjxo1QKBQYMmRIPbS8btgDREREJB+bB1epP5s2bUJ0dDRiY2MRERGBTz75BAMGDEBSUhICAgIqPWbYsGG4fv06Vq1ahdatWyMjIwMlJRUnEl+5cgWzZ89Gr1696vsyaoUBiIiISD6yBqDly5dj/PjxmDBhAgBgxYoV2LlzJ+Li4hATE1Oh/o4dO7B//35cvHgRrq6uAICgoKAK9UpLSzFq1Ci89dZbOHjwILKzs+vzMmqFAYiIiEg+sg2BFRUV4ejRo4iMjDQpj4yMRGJiYqXHbNu2DaGhoVi6dCl8fX3Rtm1bzJ49GwUFBSb1Fi5cCA8PD4wfP77e2l9XzgxAREREspGtBygzMxOlpaXw8vIyKffy8kJ6enqlx1y8eBGHDh2CVqvF1q1bkZmZicmTJyMrK0uaB/Tjjz9i1apVOHHiRLXbYjAYYDAYpPd6vb7mF1RD7AEiIiKSj+yToBUKhcl7IUSFsnJGoxEKhQLr169H9+7dMXDgQCxfvhxr165FQUEBcnNz8cILL+DTTz+Fu7t7tdsQExMDnU4nvfz9/et0TdXBHiAiIiL5yNYD5O7uDpVKVaG3JyMjo0KvUDkfHx/4+vpCp9NJZR06dIAQAlevXsXt27dx+fJlDB48WPrcaDQCAGxsbHD27Fm0atWqwnnnzp2LWbNmSe/1en29hyD2ABEREclHtgCkVqsREhKChIQEPPvss1J5QkICnnnmmUqPiYiIwNdff428vDw4OjoCAM6dOwelUgk/Pz8oFAr8/vvvJsfMnz8fubm5+OCDD+4bajQaDTQajZmurHq4DxAREZF8ZF0FNmvWLERFRSE0NBRhYWFYuXIlkpOTMXHiRABlPTPXrl3D559/DgAYOXIkFi1ahBdffBFvvfUWMjMz8corr2DcuHGws7MDAAQHB5t8R7NmzSotl1sz+7IAdIuPwiAiIrI4WQPQ8OHDcfPmTSxcuBBpaWkIDg5GfHw8AgMDAQBpaWlITk6W6js6OiIhIQHTpk1DaGgo3NzcMGzYMCxevFiuS6g1Nwc1ACDrdpHMLSEiIrI+CiGEkLsRDY1er4dOp0NOTg6cnZ3r5zsKi9H5zV0AgDOL+kNrq6qX7yEiIrIWNfn7LfsqMGvlpLGBWlV2+zPzDA+oTURERObEACQThUIBd8eyYbDMPA6DERERWRIDkIzcHMtWnt1kDxAREZFFMQDJyO1OD9BN9gARERFZFAOQjNzv9ADdYA8QERGRRTEAyYg9QERERPJgAJKRx50eIK4CIyIisiwGIBlJPUC3GYCIiIgsiQFIRh6OWgBAhp4BiIiIyJIYgGTk5Vw2BJauL5S5JURERNalVgEoJSUFV69eld4fOXIE0dHRWLlypdkaZg28dGU9QLmFJcgvKpG5NURERNajVgFo5MiR2Lt3LwAgPT0dTz31FI4cOYJ//OMfWLhwoVkb2JQ5aWxgry57Bth1DoMRERFZTK0C0KlTp9C9e3cAwFdffYXg4GAkJibiyy+/xNq1a83ZviZNoVDA27msFyg9h8NgREREllKrAFRcXAyNpmz+yu7du/H0008DANq3b4+0tDTztc4KeN0JQNc5D4iIiMhiahWAOnXqhI8//hgHDx5EQkIC+vfvDwBITU2Fm5ubWRvY1HnfmQfEidBERESWU6sA9O677+KTTz7B448/jhEjRqBLly4AgG3btklDY1Q9nuUrwTgERkREZDE2tTno8ccfR2ZmJvR6PVxcXKTyl156Cfb29mZrnDUonwOUkcsAREREZCm16gEqKCiAwWCQws+VK1ewYsUKnD17Fp6enmZtYFPHSdBERESWV6sA9Mwzz+Dzzz8HAGRnZ6NHjx5YtmwZhgwZgri4OLM2sKkr3wuIy+CJiIgsp1YB6NixY+jVqxcA4JtvvoGXlxeuXLmCzz//HB9++KFZG9jUed+1CsxoFDK3hoiIyDrUKgDl5+fDyckJALBr1y4MHToUSqUSjz76KK5cuWLWBjZ1Hk4aKBRAiVHg5u0iuZtDRERkFWoVgFq3bo3//Oc/SElJwc6dOxEZGQkAyMjIgLOzs1kb2NTZqpRwcyhbCca9gIiIiCyjVgHojTfewOzZsxEUFITu3bsjLCwMQFlvULdu3czaQGvgrWMAIiIisqRaLYN/7rnn0LNnT6SlpUl7AAFA37598eyzz5qtcdbC21mLU9f03AyRiIjIQmoVgADA29sb3t7euHr1KhQKBXx9fbkJYi15cSk8ERGRRdVqCMxoNGLhwoXQ6XQIDAxEQEAAmjVrhkWLFsFoNJq7jU1e82Z2AIA0BiAiIiKLqFUP0Lx587Bq1Sq88847iIiIgBACP/74I958800UFhZiyZIl5m5nk+ZzZy+g1OwCmVtCRERkHWoVgP7973/js88+k54CDwBdunSBr68vJk+ezABUQz469gARERFZUq2GwLKystC+ffsK5e3bt0dWVladG2Vtmjf7swdICG6GSEREVN9qFYC6dOmCjz76qEL5Rx99hM6dO9e5UdbG+84QmKHEiFv5xTK3hoiIqOmr1RDY0qVLMWjQIOzevRthYWFQKBRITExESkoK4uPjzd3GJk9jo4K7owaZeQakZhfA1UEtd5OIiIiatFr1APXu3Rvnzp3Ds88+i+zsbGRlZWHo0KH4448/sGbNGnO30SrcPQxGRERE9avW+wA1b968wmTnkydP4t///jdWr15d54ZZGx+dFr9dzeFEaCIiIguoVQ8QmV/5SrDUHPYAERER1TcGoAbCt3wzxGz2ABEREdU3BqAGwodzgIiIiCymRnOAhg4dWuXn2dnZdWmLVeNmiERERJZTowCk0+ke+Pno0aPr1CBrVb4KLF1fiFKjgEqpkLlFRERETVeNAhCXuNcfTyctVEoFSo0CN3IN0uaIREREZH6yzwGKjY1FixYtoNVqERISgoMHD1ZZ32AwYN68eQgMDIRGo0GrVq1Mlt1/+umn6NWrF1xcXODi4oInn3wSR44cqe/LqDOVUgEvJw0ArgQjIiKqb7IGoE2bNiE6Ohrz5s3D8ePH0atXLwwYMADJycn3PWbYsGHYs2cPVq1ahbNnz2LDhg0mzyXbt28fRowYgb179+Lw4cMICAhAZGQkrl27ZolLqpPmd1aCcSI0ERFR/VIIGZ++2aNHDzz88MOIi4uTyjp06IAhQ4YgJiamQv0dO3bg+eefx8WLF+Hq6lqt7ygtLYWLiws++uijas9P0uv10Ol0yMnJgbOzc/UuxgymbTiOb0+mYt7ADvh/j7W02PcSERE1BTX5+y1bD1BRURGOHj2KyMhIk/LIyEgkJiZWesy2bdsQGhqKpUuXwtfXF23btsXs2bNRUHD/HpP8/HwUFxdXGZgMBgP0er3JSw7N78z7ucYeICIionpV60dh1FVmZiZKS0vh5eVlUu7l5YX09PRKj7l48SIOHToErVaLrVu3IjMzE5MnT0ZWVtZ9H78xZ84c+Pr64sknn7xvW2JiYvDWW2/V/mLMxM+lbAjs6i0GICIiovok+yRohcJ0ubcQokJZOaPRCIVCgfXr16N79+4YOHAgli9fjrVr11baC7R06VJs2LABW7ZsgVZ7/1VVc+fORU5OjvRKSUmp20XVkp+LPQDg6q18Wb6fiIjIWsjWA+Tu7g6VSlWhtycjI6NCr1A5Hx8f+Pr6muxH1KFDBwghcPXqVbRp00Yqf++99/D2229j9+7d6Ny5c5Vt0Wg00Gg0dbga8/B3/bMHqKogSERERHUjWw+QWq1GSEgIEhISTMoTEhIQHh5e6TERERFITU1FXl6eVHbu3DkolUr4+flJZf/3f/+HRYsWYceOHQgNDa2fC6gH5T1AeYYSZOcXy9waIiKipkvWIbBZs2bhs88+w+rVq3H69GnMnDkTycnJmDhxIoCyoam7V26NHDkSbm5uePHFF5GUlIQDBw7glVdewbhx42BnV9Z7snTpUsyfPx+rV69GUFAQ0tPTkZ6ebhKaGiqtrQrujmU9UZwHREREVH9kDUDDhw/HihUrsHDhQnTt2hUHDhxAfHw8AgMDAQBpaWkmewI5OjoiISEB2dnZCA0NxahRozB48GB8+OGHUp3Y2FgUFRXhueeeg4+Pj/R67733LH59tVE+DJbCeUBERET1RtZ9gBoqufYBAoDpG45j28lUzB3QHn/v3cqi301ERNSYNYp9gKhyd0+EJiIiovrBANTAlE+E5hAYERFR/WEAamD8ywNQFgMQERFRfWEAamDu3QuIiIiIzI8BqIHx0dlBoQAMJUbcyDPI3RwiIqImiQGogVHbKOHjXPbYjpQsToQmIiKqDwxADZCfK58JRkREVJ8YgBogf+mhqOwBIiIiqg8MQA2Qn8ud3aC5EoyIiKheMAA1QP6u3AuIiIioPjEANUD+Ug8Qh8CIiIjqAwNQA1Q+CTo1uwClRu4FREREZG4MQA2Qt7MWtioFSowCaTnsBSIiIjI3BqAGSKVUSPOALmdyHhAREZG5MQA1UEFuDgCASzdvy9wSIiKipocBqIEqD0CXMxmAiIiIzI0BqIFq4V42BHaFPUBERERmxwDUQAW53xkCYw8QERGR2TEANVDlQ2ApWVwKT0REZG4MQA1U82Z2UKuUKCo1IjWbS+GJiIjMiQGogVIpFQhwK5sHxGEwIiIi82IAasCklWCcCE1ERGRWDEANWPlKMPYAERERmRcDUANWvhKMewERERGZFwNQA9ZCGgLj4zCIiIjMiQGoASvvAUrJykdJqVHm1hARETUdDEANmLezFhobJUqMAldvcSk8ERGRuTAANWBKpQItPRwBABcy8mRuDRERUdPBANTAtfUqC0DnMnJlbgkREVHTwQDUwLX1cgIAnL/OHiAiIiJzYQBq4Np43ukBus4eICIiInNhAGrgynuALmTk8aGoREREZsIA1MD5u9pDY6OEocSIlCzuB0RERGQODEANnEqpQGsOgxEREZkVA1AjIE2E5lJ4IiIis2AAagTaeLEHiIiIyJwYgBqBtp5lPUDnuBSeiIjILBiAGoF23mUB6H8ZeSjmM8GIiIjqTPYAFBsbixYtWkCr1SIkJAQHDx6ssr7BYMC8efMQGBgIjUaDVq1aYfXq1SZ1Nm/ejI4dO0Kj0aBjx47YunVrfV5CvfNzsYOT1gZFpUZuiEhERGQGsgagTZs2ITo6GvPmzcPx48fRq1cvDBgwAMnJyfc9ZtiwYdizZw9WrVqFs2fPYsOGDWjfvr30+eHDhzF8+HBERUXh5MmTiIqKwrBhw/Dzzz9b4pLqhUKhQEcfZwDAH6k5MreGiIio8VMIIWTbXa9Hjx54+OGHERcXJ5V16NABQ4YMQUxMTIX6O3bswPPPP4+LFy/C1dW10nMOHz4cer0e27dvl8r69+8PFxcXbNiwoVrt0uv10Ol0yMnJgbOzcw2vqn4s/DYJq3+8hLHhQXjz6U5yN4eIiKjBqcnfb9l6gIqKinD06FFERkaalEdGRiIxMbHSY7Zt24bQ0FAsXboUvr6+aNu2LWbPno2CggKpzuHDhyucs1+/fvc9Z2PRqXnZDzIpVS9zS4iIiBo/G7m+ODMzE6WlpfDy8jIp9/LyQnp6eqXHXLx4EYcOHYJWq8XWrVuRmZmJyZMnIysrS5oHlJ6eXqNzAmXzigwGg/Rer294IaOT750AlKaH0SigVCpkbhEREVHjJfskaIXC9A+5EKJCWTmj0QiFQoH169eje/fuGDhwIJYvX461a9ea9ALV5JwAEBMTA51OJ738/f3rcEX1o5WHI9Q2SuQZSnCFj8QgIiKqE9kCkLu7O1QqVYWemYyMjAo9OOV8fHzg6+sLnU4nlXXo0AFCCFy9ehUA4O3tXaNzAsDcuXORk5MjvVJSUmp7WfXGVqVEhzvL4TkRmoiIqG5kC0BqtRohISFISEgwKU9ISEB4eHilx0RERCA1NRV5eX8uBT937hyUSiX8/PwAAGFhYRXOuWvXrvueEwA0Gg2cnZ1NXg1Rx+Zlwe8PzgMiIiKqE1mHwGbNmoXPPvsMq1evxunTpzFz5kwkJydj4sSJAMp6ZkaPHi3VHzlyJNzc3PDiiy8iKSkJBw4cwCuvvIJx48bBzs4OADBjxgzs2rUL7777Ls6cOYN3330Xu3fvRnR0tByXaFblE6EZgIiIiOpGtknQQNmS9Zs3b2LhwoVIS0tDcHAw4uPjERgYCABIS0sz2RPI0dERCQkJmDZtGkJDQ+Hm5oZhw4Zh8eLFUp3w8HBs3LgR8+fPx+uvv45WrVph06ZN6NGjh8Wvz9ykAHQt54HzmoiIiOj+ZN0HqKFqiPsAAUBhcSmCF+xEiVHg4Kt94O9qL3eTiIiIGoxGsQ8Q1ZzWVoUOd3aEPpGSLW9jiIiIGjEGoEamq38zAMBJBiAiIqJaYwBqZMoDEHuAiIiIao8BqJHpcicAnUrNQXGpUd7GEBERNVIMQI1MS3cHOGltUFhsxNn0XLmbQ0RE1CgxADUySqUCXfyaAQBOXs2WtS1ERESNFQNQI9QtoBkA4OjlW/I2hIiIqJFiAGqEurdwBQD8fClL5pYQERE1TgxAjdDDAS5QKRW4ll2Aq7f4ZHgiIqKaYgBqhBw0NnjIt+zBqD9fZC8QERFRTTEANVI9WpYNgx3hMBgREVGNMQA1Uj2keUA3ZW4JERFR48MA1EiFBrlCqQAu38zHdX2h3M0hIiJqVBiAGilnrS06Ni97MOpPF9kLREREVBMMQI3Yoy3cAACJFxiAiIiIaoIBqBGLaOMOAPjxf5kyt4SIiKhxYQBqxLoHucJGqcDVWwVIvsn9gIiIiKqLAagRc9DY4OEAFwDAoQvsBSIiIqouBqBGLrx12TwgDoMRERFVHwNQI9ezddk8oMQLmTAahcytISIiahwYgBq5Lv7N4KBW4VZ+MZLS9HI3h4iIqFFgAGrkbFVKhLUq6wXaf+6GzK0hIiJqHBiAmoA+7T0AAHvPZMjcEiIiosaBAagJeLydJwDgWPItZOcXydwaIiKiho8BqAnwbWaHdl5OMArgwHmuBiMiInoQBqAm4vE7w2D7OAxGRET0QAxATUSfO8Ng+87d4HJ4IiKiB2AAaiJCAl3gpLFB1u0i/HYtR+7mEBERNWgMQE2ErUqJXm3LlsNzNRgREVHVGICakPLVYPvOMgARERFVhQGoCXm8bdlE6JNXc3Aj1yBza4iIiBouBqAmxNNZi2BfZwDAAe4KTUREdF8MQE1M+WqwvRwGIyIiui8GoCamT/uyALT/3A0UlRhlbg0REVHDxADUxHTxawYPJw1yC0vw4wXuCk1ERFQZBqAmRqVUYECwNwDg+9/TZG4NERFRw8QA1AQNfMgHALDrj3QOgxEREVWCAagJeiTIFR5OGugLS/Dj/zgMRkREdC8GoCbo7mGw+N84DEZERHQv2QNQbGwsWrRoAa1Wi5CQEBw8ePC+dfft2weFQlHhdebMGZN6K1asQLt27WBnZwd/f3/MnDkThYWF9X0pDYo0DJZ0HYaSUplbQ0RE1LDYyPnlmzZtQnR0NGJjYxEREYFPPvkEAwYMQFJSEgICAu573NmzZ+Hs7Cy99/DwkP69fv16zJkzB6tXr0Z4eDjOnTuHsWPHAgDef//9eruWhuaRIFf46LRIyynEntMZUiAiIiIimXuAli9fjvHjx2PChAno0KEDVqxYAX9/f8TFxVV5nKenJ7y9vaWXSqWSPjt8+DAiIiIwcuRIBAUFITIyEiNGjMCvv/5a35fToKiUCgx92BcA8M3RqzK3hoiIqGGRLQAVFRXh6NGjiIyMNCmPjIxEYmJilcd269YNPj4+6Nu3L/bu3WvyWc+ePXH06FEcOXIEAHDx4kXEx8dj0KBB9z2fwWCAXq83eTUFf33YD0DZpogZeusaAiQiIqqKbAEoMzMTpaWl8PLyMin38vJCenp6pcf4+Phg5cqV2Lx5M7Zs2YJ27dqhb9++OHDggFTn+eefx6JFi9CzZ0/Y2tqiVatW6NOnD+bMmXPftsTExECn00kvf39/81ykzFp6OCIk0AWlRoGtx6/J3RwiIqIGQ9Y5QACgUChM3gshKpSVa9euHdq1aye9DwsLQ0pKCt577z089thjAMomSi9ZsgSxsbHo0aMHLly4gBkzZsDHxwevv/56peedO3cuZs2aJb3X6/VNJgT9LcQPR6/cwjdHr+Klx1re994SERFZE9l6gNzd3aFSqSr09mRkZFToFarKo48+ivPnz0vvX3/9dURFRWHChAl46KGH8Oyzz+Ltt99GTEwMjMbKNwXUaDRwdnY2eTUVAzv7QGurxPmMPJy8miN3c4iIiBoE2QKQWq1GSEgIEhISTMoTEhIQHh5e7fMcP34cPj5/rnDKz8+HUml6WSqVCkIICCHq1uhGyFlriwHBZfdn/U9XZG4NERFRwyDrENisWbMQFRWF0NBQhIWFYeXKlUhOTsbEiRMBlA1NXbt2DZ9//jmAsv19goKC0KlTJxQVFWHdunXYvHkzNm/eLJ1z8ODBWL58Obp16yYNgb3++ut4+umnTVaLWZOosEBsPX4N/z2ZitcGtIe7o0buJhEREclK1gA0fPhw3Lx5EwsXLkRaWhqCg4MRHx+PwMBAAEBaWhqSk5Ol+kVFRZg9ezauXbsGOzs7dOrUCd9//z0GDhwo1Zk/fz4UCgXmz5+Pa9euwcPDA4MHD8aSJUssfn0NRTf/Zujip8PJqzn48udkTO/bRu4mERERyUohrHFc6AH0ej10Oh1ycnKazHyg/xy/huhNJ+DhpMHBV/tAa2udvWFERNR01eTvt+yPwiDLGPiQD3x0WtzINeBrboxIRERWjgHISqhtlJjYuxUA4ON9/0NxaeUr4oiIiKwBA5AVGf6IP9wdNbiWXYCtx7gxIhERWS8GICuitVXh74+1BAD8c+95FJWwF4iIiKwTA5CVeeHRQLg7apCSVYCvj6bI3RwiIiJZMABZGTu1ClP6lM0F+uiHCygsLpW5RURERJbHAGSFRnQPgI9Oi7ScQmw8kvzgA4iIiJoYBiArpLVVYeoTrQEAH+39HwqK2AtERETWhQHISv0txB/+rnbIzDPgi58uy90cIiIii2IAslJqGyWmP1H2SIy4ff9DnqFE5hYRERFZDgOQFXu2my9aujvgVn4x/rX3gtzNISIishgGICtmo1Li1f7tAQAf7/8ffryQKXOLiIiILIMByMr1D/bGiO7+EAKYsfE40nMK5W4SERFRvWMAIrzxl05o7+2EzLwiTF5/lDtEExFRk8cARLBTq/DxCyFw0trgWHI2Fn2XJHeTiIiI6hUDEAEAgtwdsGJ4VwDAFz9dwVe/8jEZRETUdDEAkaRvBy9EP1m2NH7+1lM4eiVL5hYRERHVDwYgMjH9iTbo38kbRaVG/P2LY0jNLpC7SURERGbHAEQmlEoFlg3rcmdStAEjP/0J1xiCiIioiWEAogocNDZYNfYR+LnY4fLNfAz7+DAuZOTJ3SwiIiKzYQCiSvk2s8NXfw9DC3cHXMsuwN8+TsTx5FtyN4uIiMgsGIDovpo3s8M3E8PQxU+HW/nFGPnpz9h2MhVCCLmbRkREVCcMQFQlN0cNvvx/j6J3Ww8UFJdi+objGPXZzziZki1304iIiGqNAYgeyEFjg1VjQjG9bxuoVUok/u8mnvnXj5iy/hguZd6Wu3lEREQ1phAcz6hAr9dDp9MhJycHzs7OcjenQUnJysf7u89h6/FrEAKwUSowqkcAZjzZFq4OarmbR0REVqwmf78ZgCrBAPRgp9P0eHfHGew7ewMA4Ky1wfS+bTA6LAhqG3YsEhGR5TEA1REDUPX9eCETi78/jdNpegCAv6sdXugRiOdC/ODmqJG5dUREZE0YgOqIAahmSo0CX/+agvd2nUNmngEAoFYp8Xg7DzzR3hN92nvCy1krcyuJiKipYwCqIwag2skvKsG2E6n48kgyfruaY/JZRx9nKQx19W8GlVIhUyuJiKipYgCqIwaguvsjNQe7kzLww9kM/HY1G3f/lrnY2+LRlm54OMAFD/np0Km5M5y0tvI1loiImgQGoDpiADKvzDwD9p+9gb1nM3Dg3A3oC0sq1PFtZof23k5od9erpbsjJ1QTEVG1MQDVEQNQ/SkpNeJ4SjZ+vXwLx5Nv4dS1HKTmFFZa11alQCsPR3T0cUaHO69gX2c0s+dyeyIiqogBqI4YgCwrO78IZ9NzcfZ6Ls6k5+Jsei7Opeci11CxpwgAAlzt0dlPh4d8dQhyd0ArDwcEuTnARsXeIiIia8YAVEcMQPITQuBadgFOp+XidJoeZ9L1+CNVjys38yutr7ZRoq2XIzp4O6O9jzM6+Dihg7czXLg5IxGR1WAAqiMGoIYrJ78Yv1/Lwcmr2UhK0+NqVj4uZOThdlFppfW9nbVo7+OE4OY6tPRwQJC7A3x0Wrg7amDLHiMioiaFAaiOGIAaF6NRIOVWvtRbdDpNj9PpeqRkFVR5nKuDGq4OajSzs0Uze1vo7NRoZm8LF3tbNLNXw91RAw8nNTydtHBzVMNebWOhKyIiotqoyd9v/i86NXpKpQKBbg4IdHNA/2BvqTy3sBhn08tCUVKaHpcz83Ep8zYy8wwoMQpk3S5C1u2ian+P1lYJV3s1XB3VaGanhqPGBvYaFRzUNvBw0sBHp4WXsxbeOi28nLRwtrOBQsH9joiIGiIGIGqynLS2CA1yRWiQq0m50ShwK78IGbkG3MovQk5+MbILipGdX4zsgrL3N28XITPPgMw8AzL0BhhKjCgsNiI1p/C+q9bupbVVwstZCw9HDXR2tnDU2sBBY1MWnNQq2NmqYKdWQWtb9rK789LaKsveq03LNTZKKLmBJBGRWTAAkdVRKhVwc9RU+1llQgjcLirFrdtFuHm7CFm3DdAXlCDXUIJ8QwluG0qQri9Eut6A6zmFuJ5biOz8YhQWG3HlZv59J27XhsZGCQeNDRzu9Dw53AlTZaHKBo4a1Z3PbeCgVsH+TuAqf1/2n2XHlwcv7spNRNZI9gAUGxuL//u//0NaWho6deqEFStWoFevXpXW3bdvH/r06VOh/PTp02jfvr30Pjs7G/PmzcOWLVtw69YttGjRAsuWLcPAgQPr7Tqo6VIoFHC8EyT8Xe2rdUxhcSky9Aak6wtxM88AfWExcgtLkFtYgvyiEtwuKkVhcdmroKgUhcVGFBTfVVZeXmJEUYlROq+hxAhDSRGybpvv+tQqJTR3ep1slQrYqJSwUSpgo1LARqmESqmAUqmASgEoFWX/VipQVq4oe/3577vK7zlGpVBAqcT9jyk/r0IBxZ3PVUoFFHfKyv5955zKu89R9jNSKhRQANJ3KO6cW2nyn2VtUJTXVfzZBoVCASEESoxl0yK1tipUlg1tVErcW3z3SKcCCtRm5LMmxygqtMBM562nNtT83PVz3pqduT7bXIOfX43OW4PKqL/fo+rS2CjhKeNzImUNQJs2bUJ0dDRiY2MRERGBTz75BAMGDEBSUhICAgLue9zZs2dNJjd5eHhI/y4qKsJTTz0FT09PfPPNN/Dz80NKSgqcnJzq9VqI7qa1VSHAzR4BbtULTFUpNQopFBUWlyK/qBS3DSW4bSjF7aKSO/8uC1VSuaEEeUXlPVR/1su781lB8Z+r5opKjSgqNSK3kh26iYjqy8MBzbBlcoRs3y9rAFq+fDnGjx+PCRMmAABWrFiBnTt3Ii4uDjExMfc9ztPTE82aNav0s9WrVyMrKwuJiYmwtS17vlRgYKDZ205kKSqlQhrWMpdSo4ChpKznqVDqeTKixGhEiVGgpFSgpNSIYqOA0ShQahQwirJXqRF3/VvAKMrmVZXeKfuzPioeU17vzud//ruy8woYjTA9r8A93yEg7pQJAEZRNmRZXl5qvFN+53ulupX8Z6kQUk+TUQgUlRhx7xJZIQSKS6teOFt+DTVR07W4NV26W/O1vg2n/TVdqFzf96a+21PTA2p+vfXX/preS42NqmYHmJlsAaioqAhHjx7FnDlzTMojIyORmJhY5bHdunVDYWEhOnbsiPnz55sMi23btg1hYWGYMmUK/vvf/8LDwwMjR47Ea6+9BpWq8pttMBhgMBik93q9vg5XRtTwqZQK2KttwKeKEJG1km0nuMzMTJSWlsLLy8uk3MvLC+np6ZUe4+Pjg5UrV2Lz5s3YsmUL2rVrh759++LAgQNSnYsXL+Kbb75BaWkp4uPjMX/+fCxbtgxLliy5b1tiYmKg0+mkl7+/v3kukoiIiBok2TZCTE1Nha+vLxITExEWFiaVL1myBF988QXOnDlTrfMMHjwYCoUC27ZtAwC0bdsWhYWFuHTpktTjs3z5cmmidWUq6wHy9/fnRohERESNSKPYCNHd3R0qlapCb09GRkaFXqGqPProo1i3bp303sfHB7a2tibDXR06dEB6ejqKioqgVlfs89doNNBoqrckmoiIiBo/2YbA1Go1QkJCkJCQYFKekJCA8PDwap/n+PHj8PHxkd5HRETgwoULMBr/XDp87tw5+Pj4VBp+iIiIyPrIugps1qxZiIqKQmhoKMLCwrBy5UokJydj4sSJAIC5c+fi2rVr+PzzzwGUrRILCgpCp06dUFRUhHXr1mHz5s3YvHmzdM5Jkybhn//8J2bMmIFp06bh/PnzePvttzF9+nRZrpGIiIgaHlkD0PDhw3Hz5k0sXLgQaWlpCA4ORnx8vLRsPS0tDcnJyVL9oqIizJ49G9euXYOdnR06deqE77//3mSDQ39/f+zatQszZ85E586d4evrixkzZuC1116z+PURERFRw8SnwVeCT4MnIiJqfGry91u2OUBEREREcmEAIiIiIqvDAERERERWhwGIiIiIrA4DEBEREVkdBiAiIiKyOgxAREREZHVk3QixoSrfGkmv18vcEiIiIqqu8r/b1dnikAGoErm5uQDKdpUmIiKixiU3Nxc6na7KOtwJuhJGoxGpqalwcnKCQqEw67n1ej38/f2RkpLCXabrEe+zZfA+Wwbvs+XwXltGfd1nIQRyc3PRvHlzKJVVz/JhD1AllEol/Pz86vU7nJ2d+V8uC+B9tgzeZ8vgfbYc3mvLqI/7/KCen3KcBE1ERERWhwGIiIiIrA4DkIVpNBosWLAAGo1G7qY0abzPlsH7bBm8z5bDe20ZDeE+cxI0ERERWR32ABEREZHVYQAiIiIiq8MARERERFaHAYiIiIisDgOQBcXGxqJFixbQarUICQnBwYMH5W5SgxUTE4NHHnkETk5O8PT0xJAhQ3D27FmTOkIIvPnmm2jevDns7Ozw+OOP448//jCpYzAYMG3aNLi7u8PBwQFPP/00rl69alLn1q1biIqKgk6ng06nQ1RUFLKzs+v7EhukmJgYKBQKREdHS2W8z+Zz7do1vPDCC3Bzc4O9vT26du2Ko0ePSp/zXtddSUkJ5s+fjxYtWsDOzg4tW7bEwoULYTQapTq8zzV34MABDB48GM2bN4dCocB//vMfk88teU+Tk5MxePBgODg4wN3dHdOnT0dRUVHNL0qQRWzcuFHY2tqKTz/9VCQlJYkZM2YIBwcHceXKFbmb1iD169dPrFmzRpw6dUqcOHFCDBo0SAQEBIi8vDypzjvvvCOcnJzE5s2bxe+//y6GDx8ufHx8hF6vl+pMnDhR+Pr6ioSEBHHs2DHRp08f0aVLF1FSUiLV6d+/vwgODhaJiYkiMTFRBAcHi7/85S8Wvd6G4MiRIyIoKEh07txZzJgxQyrnfTaPrKwsERgYKMaOHSt+/vlncenSJbF7925x4cIFqQ7vdd0tXrxYuLm5ie+++05cunRJfP3118LR0VGsWLFCqsP7XHPx8fFi3rx5YvPmzQKA2Lp1q8nnlrqnJSUlIjg4WPTp00ccO3ZMJCQkiObNm4upU6fW+JoYgCyke/fuYuLEiSZl7du3F3PmzJGpRY1LRkaGACD2798vhBDCaDQKb29v8c4770h1CgsLhU6nEx9//LEQQojs7Gxha2srNm7cKNW5du2aUCqVYseOHUIIIZKSkgQA8dNPP0l1Dh8+LACIM2fOWOLSGoTc3FzRpk0bkZCQIHr37i0FIN5n83nttddEz5497/s577V5DBo0SIwbN86kbOjQoeKFF14QQvA+m8O9AciS9zQ+Pl4olUpx7do1qc6GDRuERqMROTk5NboODoFZQFFREY4ePYrIyEiT8sjISCQmJsrUqsYlJycHAODq6goAuHTpEtLT003uqUajQe/evaV7evToURQXF5vUad68OYKDg6U6hw8fhk6nQ48ePaQ6jz76KHQ6nVX9bKZMmYJBgwbhySefNCnnfTafbdu2ITQ0FH/729/g6emJbt264dNPP5U+5702j549e2LPnj04d+4cAODkyZM4dOgQBg4cCID3uT5Y8p4ePnwYwcHBaN68uVSnX79+MBgMJsPJ1cGHoVpAZmYmSktL4eXlZVLu5eWF9PR0mVrVeAghMGvWLPTs2RPBwcEAIN23yu7plStXpDpqtRouLi4V6pQfn56eDk9Pzwrf6enpaTU/m40bN+LYsWP45ZdfKnzG+2w+Fy9eRFxcHGbNmoV//OMfOHLkCKZPnw6NRoPRo0fzXpvJa6+9hpycHLRv3x4qlQqlpaVYsmQJRowYAYC/0/XBkvc0PT29wve4uLhArVbX+L4zAFmQQqEweS+EqFBGFU2dOhW//fYbDh06VOGz2tzTe+tUVt9afjYpKSmYMWMGdu3aBa1We996vM91ZzQaERoairfffhsA0K1bN/zxxx+Ii4vD6NGjpXq813WzadMmrFu3Dl9++SU6deqEEydOIDo6Gs2bN8eYMWOkerzP5mepe2qu+84hMAtwd3eHSqWqkE4zMjIqJFkyNW3aNGzbtg179+6Fn5+fVO7t7Q0AVd5Tb29vFBUV4datW1XWuX79eoXvvXHjhlX8bI4ePYqMjAyEhITAxsYGNjY22L9/Pz788EPY2NhI94D3ue58fHzQsWNHk7IOHTogOTkZAH+nzeWVV17BnDlz8Pzzz+Ohhx5CVFQUZs6ciZiYGAC8z/XBkvfU29u7wvfcunULxcXFNb7vDEAWoFarERISgoSEBJPyhIQEhIeHy9Sqhk0IgalTp2LLli344Ycf0KJFC5PPW7RoAW9vb5N7WlRUhP3790v3NCQkBLa2tiZ10tLScOrUKalOWFgYcnJycOTIEanOzz//jJycHKv42fTt2xe///47Tpw4Ib1CQ0MxatQonDhxAi1btuR9NpOIiIgKWzmcO3cOgYGBAPg7bS75+flQKk3/tKlUKmkZPO+z+VnynoaFheHUqVNIS0uT6uzatQsajQYhISE1a3iNpkxTrZUvg1+1apVISkoS0dHRwsHBQVy+fFnupjVIkyZNEjqdTuzbt0+kpaVJr/z8fKnOO++8I3Q6ndiyZYv4/fffxYgRIypddunn5yd2794tjh07Jp544olKl1127txZHD58WBw+fFg89NBDTXYpa3XcvQpMCN5nczly5IiwsbERS5YsEefPnxfr168X9vb2Yt26dVId3uu6GzNmjPD19ZWWwW/ZskW4u7uLV199VarD+1xzubm54vjx4+L48eMCgFi+fLk4fvy4tJWLpe5p+TL4vn37imPHjondu3cLPz8/LoNv6P71r3+JwMBAoVarxcMPPywt6aaKAFT6WrNmjVTHaDSKBQsWCG9vb6HRaMRjjz0mfv/9d5PzFBQUiKlTpwpXV1dhZ2cn/vKXv4jk5GSTOjdv3hSjRo0STk5OwsnJSYwaNUrcunXLAlfZMN0bgHifzefbb78VwcHBQqPRiPbt24uVK1eafM57XXd6vV7MmDFDBAQECK1WK1q2bCnmzZsnDAaDVIf3ueb27t1b6f8mjxkzRghh2Xt65coVMWjQIGFnZydcXV3F1KlTRWFhYY2vSSGEEDXrMyIiIiJq3DgHiIiIiKwOAxARERFZHQYgIiIisjoMQERERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBERFQNCoUC//nPf+RuBhGZCQMQETV4Y8eOhUKhqPDq37+/3E0jokbKRu4GEBFVR//+/bFmzRqTMo1GI1NriKixYw8QETUKGo0G3t7eJi8XFxcAZcNTcXFxGDBgAOzs7NCiRQt8/fXXJsf//vvveOKJJ2BnZwc3Nze89NJLyMvLM6mzevVqdOrUCRqNBj4+Ppg6darJ55mZmXj22Wdhb2+PNm3aYNu2bfV70URUbxiAiKhJeP311/HXv/4VJ0+exAsvvIARI0bg9OnTAID8/Hz0798fLi4u+OWXX/D1119j9+7dJgEnLi4OU6ZMwUsvvYTff/8d27ZtQ+vWrU2+46233sKwYcPw22+/YeDAgRg1ahSysrIsep1EZCY1fnwqEZGFjRkzRqhUKuHg4GDyWrhwoRBCCABi4sSJJsf06NFDTJo0SQghxMqVK4WLi4vIy8uTPv/++++FUqkU6enpQgghmjdvLubNm3ffNgAQ8+fPl97n5eUJhUIhtm/fbrbrJCLL4RwgImoU+vTpg7i4OJMyV1dX6d9hYWEmn4WFheHEiRMAgNOnT6NLly5wcHCQPo+IiIDRaMTZs2ehUCiQmpqKvn37VtmGzp07S/92cHCAk5MTMjIyantJRCQjBiAiahQcHBwqDEk9iEKhAAAIIaR/V1bHzs6uWueztbWtcKzRaKxRm4ioYeAcICJqEn766acK79u3bw8A6NixI06cOIHbt29Ln//4449QKpVo27YtnJycEBQUhD179li0zUQkH/YAEVGjYDAYkJ6eblJmY2MDd3d3AMDXX3+N0NBQ9OzZE+vXr8eRI0ewatUqAMCoUaOwYMECjBkzBm+++SZu3LiBadOmISoqCl5eXgCAN998ExMnToSnpycGDBiA3Nxc/Pjjj5g2bZplL5SILIIBiIgahR07dsDHx8ekrF27djhz5gyAshVaGzduxOTJk+Ht7Y3169ejY8eOAAB7e3vs3LkTM2bMwCOPPAJ7e3v89a9/xfLly6VzjRkzBoWFhXj//fcxe/ZsuLu747nnnrPcBRKRRSmEEELuRhAR1YVCocDWrVsxZMgQuZtCRI0E5wARERGR1WEAIiIiIqvDOUBE1OhxJJ+Iaoo9QERERGR1GICIiIjI6jAAERERkdVhACIiIiKrwwBEREREVocBiIiIiKwOAxARERFZHQYgIiIisjoMQERERGR1/j/58JvrF5sm6gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "epochs = 10000\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Graficar las métricas durante el entrenamiento\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Training Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69      8732\n",
      "           1       0.49      0.40      0.44      5572\n",
      "\n",
      "    accuracy                           0.60     14304\n",
      "   macro avg       0.57      0.56      0.56     14304\n",
      "weighted avg       0.59      0.60      0.59     14304\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAIhCAYAAAD91lq9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLYUlEQVR4nO3de1xVZd7///eWw1YQdgJyKjI1NQktwwJsyvOBRLKatCxGy7SyNFLLW/uWdhgxp7ID5SnLY1GT2VgZaZmWt6BoMqmROaOmjiBqgGK0IVy/P/q57tmCCiu2oPv19LEeD1nrs9e+9p6p+cz7utaFzTAMQwAAAEAtNarvAQAAAOD8RCMJAAAAS2gkAQAAYAmNJAAAACyhkQQAAIAlNJIAAACwhEYSAAAAltBIAgAAwBIaSQAAAFhCIwmcB7777jvdc889atmypRo3bqymTZvqmmuu0fTp0/Xzzz+79b23bNmirl27yuFwyGaz6eWXX67z97DZbJoyZUqd3/ds5s+fL5vNJpvNpjVr1lS5bhiGLr/8ctlsNnXr1s3Se7zxxhuaP39+rV6zZs2a044JABoS7/oeAIAzmzt3rkaNGqV27drpscceU3R0tCoqKrRp0ybNmjVLWVlZWrZsmdve/95779Xx48eVkZGhZs2a6bLLLqvz98jKytIll1xS5/etqYCAAM2bN69Ks7h27Vr9+9//VkBAgOV7v/HGGwoJCdGwYcNq/JprrrlGWVlZio6Otvy+AHAu0EgCDVhWVpYefPBB9e7dWx999JHsdrt5rXfv3ho3bpwyMzPdOoZt27ZpxIgRSkxMdNt7xMfHu+3eNTF48GAtWbJEr7/+ugIDA83z8+bNU0JCgo4ePXpOxlFRUSGbzabAwMB6/04AoCaY2gYasKlTp8pms2nOnDkuTeRJvr6+Sk5ONn8+ceKEpk+friuuuEJ2u12hoaH6y1/+ov3797u8rlu3boqJiVFOTo5uuOEG+fn5qVWrVpo2bZpOnDgh6f+mfX/77TfNnDnTnAKWpClTpph//28nX7Nnzx7z3OrVq9WtWzcFBwerSZMmuvTSS3Xbbbfpl19+MWuqm9retm2bbr75ZjVr1kyNGzfW1VdfrQULFrjUnJwCfvfdd/XEE08oMjJSgYGB6tWrl3bs2FGzL1nSnXfeKUl69913zXMlJSVaunSp7r333mpf8/TTTysuLk5BQUEKDAzUNddco3nz5skwDLPmsssu0/bt27V27Vrz+zuZ6J4c+6JFizRu3DhdfPHFstvt+te//lVlavvw4cOKiopSly5dVFFRYd7/+++/l7+/v1JSUmr8WQGgLtFIAg1UZWWlVq9erdjYWEVFRdXoNQ8++KAmTJig3r17a/ny5Xr22WeVmZmpLl266PDhwy61BQUFuuuuu3T33Xdr+fLlSkxM1MSJE7V48WJJUv/+/ZWVlSVJ+vOf/6ysrCzz55ras2eP+vfvL19fX7311lvKzMzUtGnT5O/vr/Ly8tO+bseOHerSpYu2b9+uV199VR9++KGio6M1bNgwTZ8+vUr9pEmT9NNPP+nNN9/UnDlztHPnTg0YMECVlZU1GmdgYKD+/Oc/66233jLPvfvuu2rUqJEGDx582s92//336/3339eHH36oW2+9VaNHj9azzz5r1ixbtkytWrVSp06dzO/v1GUIEydO1N69ezVr1ix9/PHHCg0NrfJeISEhysjIUE5OjiZMmCBJ+uWXX3T77bfr0ksv1axZs2r0OQGgzhkAGqSCggJDknHHHXfUqD4vL8+QZIwaNcrl/IYNGwxJxqRJk8xzXbt2NSQZGzZscKmNjo42+vbt63JOkvHQQw+5nJs8ebJR3b8+3n77bUOSsXv3bsMwDOODDz4wJBm5ublnHLskY/LkyebPd9xxh2G32429e/e61CUmJhp+fn5GcXGxYRiG8dVXXxmSjJtuusml7v333zckGVlZWWd835PjzcnJMe+1bds2wzAM49prrzWGDRtmGIZhXHnllUbXrl1Pe5/KykqjoqLCeOaZZ4zg4GDjxIkT5rXTvfbk+914442nvfbVV1+5nH/++ecNScayZcuMoUOHGk2aNDG+++67M35GAHAnEkngAvHVV19JUpWHOq677jq1b99eX375pcv58PBwXXfddS7nOnbsqJ9++qnOxnT11VfL19dXI0eO1IIFC7Rr164avW716tXq2bNnlSR22LBh+uWXX6oko/89vS/9/jkk1eqzdO3aVa1bt9Zbb72lrVu3Kicn57TT2ifH2KtXLzkcDnl5ecnHx0dPPfWUjhw5osLCwhq/72233Vbj2scee0z9+/fXnXfeqQULFui1115Thw4davx6AKhrNJJAAxUSEiI/Pz/t3r27RvVHjhyRJEVERFS5FhkZaV4/KTg4uEqd3W5XWVmZhdFWr3Xr1vriiy8UGhqqhx56SK1bt1br1q31yiuvnPF1R44cOe3nOHn9v536WU6uJ63NZ7HZbLrnnnu0ePFizZo1S23bttUNN9xQbe3GjRvVp08fSb8/Vf+///u/ysnJ0RNPPFHr963uc55pjMOGDdOvv/6q8PBw1kYCqHc0kkAD5eXlpZ49e2rz5s1VHpapzslmKj8/v8q1AwcOKCQkpM7G1rhxY0mS0+l0OX/qOkxJuuGGG/Txxx+rpKRE2dnZSkhIUGpqqjIyMk57/+Dg4NN+Dkl1+ln+27Bhw3T48GHNmjVL99xzz2nrMjIy5OPjo08++USDBg1Sly5d1LlzZ0vvWd1DS6eTn5+vhx56SFdffbWOHDmi8ePHW3pPAKgrNJJAAzZx4kQZhqERI0ZU+3BKRUWFPv74Y0lSjx49JMl8WOaknJwc5eXlqWfPnnU2rpNPHn/33Xcu50+OpTpeXl6Ki4vT66+/Lkn69ttvT1vbs2dPrV692mwcT1q4cKH8/PzctjXOxRdfrMcee0wDBgzQ0KFDT1tns9nk7e0tLy8v81xZWZkWLVpUpbauUt7Kykrdeeedstls+uyzz5SWlqbXXntNH3744R++NwBYxT6SQAOWkJCgmTNnatSoUYqNjdWDDz6oK6+8UhUVFdqyZYvmzJmjmJgYDRgwQO3atdPIkSP12muvqVGjRkpMTNSePXv05JNPKioqSo8++midjeumm25SUFCQhg8frmeeeUbe3t6aP3++9u3b51I3a9YsrV69Wv3799ell16qX3/91XwyulevXqe9/+TJk/XJJ5+oe/fueuqppxQUFKQlS5bo008/1fTp0+VwOOrss5xq2rRpZ63p37+/XnrpJQ0ZMkQjR47UkSNH9MILL1S7RVOHDh2UkZGh9957T61atVLjxo0trWucPHmyvvnmG61cuVLh4eEaN26c1q5dq+HDh6tTp05q2bJlre8JAH8UjSTQwI0YMULXXXedZsyYoeeff14FBQXy8fFR27ZtNWTIED388MNm7cyZM9W6dWvNmzdPr7/+uhwOh/r166e0tLRq10RaFRgYqMzMTKWmpuruu+/WRRddpPvuu0+JiYm67777zLqrr75aK1eu1OTJk1VQUKCmTZsqJiZGy5cvN9cYVqddu3Zav369Jk2apIceekhlZWVq37693n777Vr9hhh36dGjh9566y09//zzGjBggC6++GKNGDFCoaGhGj58uEvt008/rfz8fI0YMULHjh1TixYtXPbZrIlVq1YpLS1NTz75pEuyPH/+fHXq1EmDBw/WunXr5OvrWxcfDwBqzGYY/7V7LgAAAFBDrJEEAACAJTSSAAAAsIRGEgAAAJbQSAIAAMASGkkAAABYQiMJAAAAS2gkAQAAYMkFuSF5k04Pn70IwHmpMOvV+h4CADcJaFx/+ZY7e4eyLeluu3d9I5EEAACAJRdkIgkAAFArNrI1K2gkAQAAbLb6HsF5ifYbAAAAlpBIAgAAMLVtCd8aAAAALCGRBAAAYI2kJSSSAAAAsIREEgAAgDWSlvCtAQAAwBISSQAAANZIWkIjCQAAwNS2JXxrAAAAsIREEgAAgKltS0gkAQAAYAmJJAAAAGskLeFbAwAAgCUkkgAAAKyRtIREEgAAAJaQSAIAALBG0hIaSQAAAKa2LaH9BgAAgCUkkgAAAExtW8K3BgAAAEtIJAEAAEgkLeFbAwAAgCUkkgAAAI14atsKEkkAAABYQiIJAADAGklLaCQBAADYkNwS2m8AAABYQiIJAADA1LYlfGsAAACwhEQSAACANZKWkEgCAADAEhJJAAAA1khawrcGAAAAS0gkAQAAWCNpCY0kAAAAU9uW8K0BAAA0IP/5z3909913Kzg4WH5+frr66qu1efNm87phGJoyZYoiIyPVpEkTdevWTdu3b3e5h9Pp1OjRoxUSEiJ/f38lJydr//79LjVFRUVKSUmRw+GQw+FQSkqKiouLazVWGkkAAACbzX1HLRQVFen666+Xj4+PPvvsM33//fd68cUXddFFF5k106dP10svvaT09HTl5OQoPDxcvXv31rFjx8ya1NRULVu2TBkZGVq3bp1KS0uVlJSkyspKs2bIkCHKzc1VZmamMjMzlZubq5SUlNp9bYZhGLV6xXmgSaeH63sIANykMOvV+h4CADcJaFx/+VaTxBluu3fZZ4/WuPZ//ud/9L//+7/65ptvqr1uGIYiIyOVmpqqCRMmSPo9fQwLC9Pzzz+v+++/XyUlJWrevLkWLVqkwYMHS5IOHDigqKgorVixQn379lVeXp6io6OVnZ2tuLg4SVJ2drYSEhL0ww8/qF27djUaL4kkAACArZHbDqfTqaNHj7ocTqez2mEsX75cnTt31u23367Q0FB16tRJc+fONa/v3r1bBQUF6tOnj3nObrera9euWr9+vSRp8+bNqqiocKmJjIxUTEyMWZOVlSWHw2E2kZIUHx8vh8Nh1tQEjSQAAIAbpaWlmesQTx5paWnV1u7atUszZ85UmzZt9Pnnn+uBBx7QmDFjtHDhQklSQUGBJCksLMzldWFhYea1goIC+fr6qlmzZmesCQ0NrfL+oaGhZk1N8NQ2AACAG7f/mThxosaOHetyzm63V1t74sQJde7cWVOnTpUkderUSdu3b9fMmTP1l7/85b+G6zpewzCqnDvVqTXV1dfkPv+NRBIAAMCN7Ha7AgMDXY7TNZIRERGKjo52Ode+fXvt3btXkhQeHi5JVVLDwsJCM6UMDw9XeXm5ioqKzlhz8ODBKu9/6NChKmnnmdBIAgAAuHGNZG1cf/312rFjh8u5H3/8US1atJAktWzZUuHh4Vq1apV5vby8XGvXrlWXLl0kSbGxsfLx8XGpyc/P17Zt28yahIQElZSUaOPGjWbNhg0bVFJSYtbUBFPbAAAADWRD8kcffVRdunTR1KlTNWjQIG3cuFFz5szRnDlzJP0+HZ2amqqpU6eqTZs2atOmjaZOnSo/Pz8NGTJEkuRwODR8+HCNGzdOwcHBCgoK0vjx49WhQwf16tVL0u8pZ79+/TRixAjNnj1bkjRy5EglJSXV+IltiUYSAACgwbj22mu1bNkyTZw4Uc8884xatmypl19+WXfddZdZ8/jjj6usrEyjRo1SUVGR4uLitHLlSgUEBJg1M2bMkLe3twYNGqSysjL17NlT8+fPl5eXl1mzZMkSjRkzxny6Ozk5Wenp6bUaL/tIAjivsI8kcOGq130kk2e67d5lyx90273rW8PIcQEAAHDeYWobAACggayRPN/wrQEAAMASEkkAAAA3bkh+ISORBAAAgCUkkgAAAKyRtIRGEgAAgKltS2i/AQAAYAmJJAAA8Hg2EklLSCQBAABgCYkkAADweCSS1pBIAgAAwBISSQAAAAJJS0gkAQAAYAmJJAAA8HiskbSGRhIAAHg8GklrmNoGAACAJSSSAADA45FIWkMiCQAAAEtIJAEAgMcjkbSGRBIAAACWkEgCAAAQSFpCIgkAAABLSCQBAIDHY42kNSSSAAAAsIREEgAAeDwSSWtoJAEAgMejkbSGqW0AAABYQiIJAAA8HomkNSSSAAAAsIREEgAAgEDSEhJJAAAAWEIiCQAAPB5rJK0hkQQAAIAlJJIAAMDjkUhaQyMJAAA8Ho2kNUxtAwAAwBISSQAAAAJJS0gkAQAAYAmJJAAA8HiskbSGRBIAAACWkEgCAACPRyJpDYkkAAAALCGRBAAAHo9E0hoSSQAA4PFsNpvbjtqYMmVKldeHh4eb14cNG1blenx8vMs9nE6nRo8erZCQEPn7+ys5OVn79+93qSkqKlJKSoocDoccDodSUlJUXFxc6++NRhIAAKABufLKK5Wfn28eW7dudbner18/l+srVqxwuZ6amqply5YpIyND69atU2lpqZKSklRZWWnWDBkyRLm5ucrMzFRmZqZyc3OVkpJS67EytQ0AANCAZra9vb1dUshT2e32014vKSnRvHnztGjRIvXq1UuStHjxYkVFRemLL75Q3759lZeXp8zMTGVnZysuLk6SNHfuXCUkJGjHjh1q165djcdKIgkAAOBGTqdTR48edTmcTudp63fu3KnIyEi1bNlSd9xxh3bt2uVyfc2aNQoNDVXbtm01YsQIFRYWmtc2b96siooK9enTxzwXGRmpmJgYrV+/XpKUlZUlh8NhNpGSFB8fL4fDYdbUFI0kAADweO5cI5mWlmauRTx5pKWlVTuOuLg4LVy4UJ9//rnmzp2rgoICdenSRUeOHJEkJSYmasmSJVq9erVefPFF5eTkqEePHmZjWlBQIF9fXzVr1szlvmFhYSooKDBrQkNDq7x3aGioWVNTTG0DAAC40cSJEzV27FiXc3a7vdraxMRE8+8dOnRQQkKCWrdurQULFmjs2LEaPHiweT0mJkadO3dWixYt9Omnn+rWW2897RgMw3B58Ke6h4BOrakJGkkAAODx3Ln9j91uP23jeDb+/v7q0KGDdu7cWe31iIgItWjRwrweHh6u8vJyFRUVuaSShYWF6tKli1lz8ODBKvc6dOiQwsLCajU+prYBAAAaKKfTqby8PEVERFR7/ciRI9q3b595PTY2Vj4+Plq1apVZk5+fr23btpmNZEJCgkpKSrRx40azZsOGDSopKTFraopEEgAAeLyGsiH5+PHjNWDAAF166aUqLCzUc889p6NHj2ro0KEqLS3VlClTdNtttykiIkJ79uzRpEmTFBISoltuuUWS5HA4NHz4cI0bN07BwcEKCgrS+PHj1aFDB/Mp7vbt26tfv34aMWKEZs+eLUkaOXKkkpKSavXEtkQjCQAA0GC2/9m/f7/uvPNOHT58WM2bN1d8fLyys7PVokULlZWVaevWrVq4cKGKi4sVERGh7t2767333lNAQIB5jxkzZsjb21uDBg1SWVmZevbsqfnz58vLy8usWbJkicaMGWM+3Z2cnKz09PRaj9dmGIbxxz92w9Kk08P1PQQAblKY9Wp9DwGAmwQ0rr8Vd1EP/8Nt996XfrPb7l3fSCQBAIDHayhT2+cbHrYBAACAJSSSAADA45FIWkMiCQAAAEtIJNEgRDZ36LlHblaf669UE7uPdu4t1INPL9GWvH2SpCfuv0m3971Gl4Q3U3lFpbbk7dWU9I+Vs+0n8x4tLwnRtEdvUUKnVrL7eGvV+jyNff7vKvz5mCTphtg2WvnmI9W+/5/umq7N3+91/wcFPMzb8+boqy9Xac/uXbLbG6vj1Z00OnWcLruspVkze2a6Vmau0MGCAvn4+Kh9dLRGPZyqmI5XmTV/fWayNm7I0uFDhWri56eOV3XSmNRxuqxlK7NmQGJP5R844PL+Q++5T6NTx7n/g+K8RyJpDU9to95dFNBE2Rn/o7U5OzX379+o8OdjahUVop8O/Kzd+w9Lkgb366zComPavf+wmth9NPruHrq1VyfF3Py0DheVyq+xr3Len6itP/5Hz85aIUmaPKq/Ipo7dONfXpRhGPLx9lKQw8/lvZ8alaQece3UPmnKuf7YsIints8vox8coT79blL0lTGqrKzUG6+9rH/960f9/cNP1MTv938eM1d8omZBQbr4kig5f/1V7yxeoC9Wfa6PPv5czYKCJEkffvC+LmvZUuHhkTp6tFizZ76uH3f8oOUrVplbmgxI7KmbB96mgbfdbr6/n5+f/Pz8z/0HhyX1+dT2ZY984rZ773klyW33rm8kkqh34+7prf0FRbp/ymLz3N78n11q3svc5PLzhBc/1D23dFFMm0it2fijEq5upRaRwYq/83kdO/6rJGnk5MXK//pv6nZdW321YYcqfqvUwSPHzHt4ezdS/64dNOu9r9346QDP9trMuS4/T35mqnp3v155edt1Tey1kqR+N7n+j+yj4/9H/1i2VDt37tB1cQmSpFv/PMi8HnnxxRr18CO68/aByj/wH10Sdal5zc/fXyEhzd31cXABI5G0pl7XSO7fv19PPPGEunfvrvbt2ys6Olrdu3fXE088oX379tXn0HAO9e/aQd9+v1dLpt+rn75MU9a7E3TPLaf/FU0+3l4afuv1Kj72i7b++B9Jkt3XW4ZhyFn+m1n3a/lvqqw8oS5Xt672PkldOyrkoqZavDy7bj8QgNMqLf39/8wFBjqqvV5RUa5lS99X04AAtW17RbU1Zb/8ouX/+FAXX3yJwsLDXa4tePtN9bwxXkMG3aJ5c2epoqK8bj8ALlw2Nx4XsHpLJNetW6fExERFRUWpT58+6tOnjwzDUGFhoT766CO99tpr+uyzz3T99def8T5Op1NOp9PlnHGiUrZGXqd5BRqalheHaMTtN+jVxas1fd5KdY5poRcf/7OcFb/pnU/+7/eAJt4Qo4XT7pFfYx8VHD6qpAfSdaT4uCRp49Y9Ol5Wrr8+crOeSl8um2z66yM3y8urkcJDAqt936EDE7QqK0/7Dxafi48JeDzDMPTSC8/r6k6xurxNW5dr36z9SpMmjNevv5YpJKS5Xp81Txc1a+ZS8/f33tGrM15UWdkvuqxlK70+e558fHzN63cMSdEV7aMVGOjQ9m3fKf3VGTrwn/16cspz5+TzAZ6o3tZIXnvttfrTn/6kGTNmVHv90Ucf1bp165STk3PG+0yZMkVPP/20yzmvsGvlE3FdnY0V7lWy8WV9+/1edR/2knnuxcf/rNgrW6jb0BfNc36NfRXePFAhFzXVPbd2Ubdr2+rGlBd0qKhUktQz/gq9OmmwLrs4WCdOGHo/c7OuaBWunG17lJr2vst7Xhx6kXaseEZ3T3hLH32Ze04+J+oGayTPX89PfUbrvlmrN+cvUViYa5JY9ssvOnz4kIqLi7Rs6d+1aeMGzV/8noKCg82a0mPH9PPPR3T48CEtWvC2DhUe1LwF78hut1f7fl9+sVITxj2iL9au10UXNau2Bg1Lfa6RbDV2hdvuveulm9x27/pWb/+Jbdu2TQ888MBpr99///3atm3bWe8zceJElZSUuBzeYbF1OVS4WcHho8rbVeBy7ofdBYoKd/0X/y+/lmvXvsPauHWPHnz6Hf1WeUJD/2sK/MvsH3Rl8tO6tOdEXdL9fzT8yYWKDL1IP/3nSJX3TLk5XkdKjuuTtd+550MBcDE97Tl9veYrzZq7oEoTKUlN/PwUdWkLdeh4tZ56+q/y8vbSPz5a6lLTNCBAl7a4TNfEXqvpL76sPbt366vVX5z2PTt0+P2p7/172ZEBcJd6m9qOiIjQ+vXr1a5du2qvZ2VlKSIi4qz3sdvtVf7fKNPa55es3F1q2yLU5VybS0OrPHBzKptssvtU/a/wyenurte2VWhQU32ydmuVmr8kx+udTzbqt99O/IGRAzgbwzA0Pe05rVn9hWbPW6CLL7mkhq+TysvPvL7RkKGKM9Ts+OF7SVJIcx6+wdnxsI019dZIjh8/Xg888IA2b96s3r17KywsTDabTQUFBVq1apXefPNNvfzyy/U1PJxDry1era/mj9Nj9/bR0lXf6torL9O9t12vh599V9LvU9oT7uurT9duVcHhEgU5/DVy0I26OOwifbjqW/M+Kcnx2rG7QIeKShXXsaVeeOzPem3JV9r5U6HL+3W7rq1aXhKi+R+tP6efE/BEz099RpmffaoXX06Xn7+/Dh8+JElq2jRAjRs3Vtkvv+itN2frxm7dFRLSXCUlxfr7e++q8GCBevXuK0nav3+fVn3+meITrlezZs1UWHhQC96ep8Z2u67/042SpO/+uUVbv/unOl8bp6ZNA/T99q166W/TdGO3HgqPiKy3zw9c6OqtkRw1apSCg4M1Y8YMzZ49W5WVlZIkLy8vxcbGauHChRo0aNBZ7oILwebv92rwuLl6ZnSyJo1M1J7/HNFjf1uqjM9+3/Kn8sQJtbssTHcPiFPwRf76ueQXbdr+k3rdO8NlSrztZaF6ZnSyghx++unAz5o+73O9unh1lfcbNrCLsnL/rR27D56zzwh4qg/ez5Ak3T98qMv5yc9M1YCbb1EjLy/t2b1Lnyz/SMXFRXJcdJGir+yguW8vVuvL20iS7L52bfl2k95dvFBHjx5VcHCwOsV21ryF75prKH19fbXq8880d/YbqigvV3hEpAbedruGDht+bj8wzlsEktY0iA3JKyoqdPjw7xtPh4SEyMfH5w/djw3JgQsXD9sAF676fNjm8vGfue3e/3oh0W33rm8NYkNyHx+fGq2HBAAAcAfWSFrTIBpJAACA+kQfaU29/mYbAAAAnL9IJAEAgMdjatsaEkkAAABYQiIJAAA8HoGkNSSSAAAAsIREEgAAeLxGjYgkrSCRBAAAgCUkkgAAwOOxRtIaGkkAAODx2P7HGqa2AQAAYAmJJAAA8HgEktaQSAIAAMASEkkAAODxWCNpDYkkAAAALCGRBAAAHo9E0hoSSQAAAFhCIgkAADwegaQ1NJIAAMDjMbVtDVPbAAAAsIREEgAAeDwCSWtIJAEAAGAJiSQAAPB4rJG0hkQSAAAAlpBIAgAAj0cgaQ2JJAAAACwhkQQAAB6PNZLWkEgCAADAEhpJAADg8Ww29x21MWXKFNlsNpcjPDzcvG4YhqZMmaLIyEg1adJE3bp10/bt213u4XQ6NXr0aIWEhMjf31/Jycnav3+/S01RUZFSUlLkcDjkcDiUkpKi4uLiWn9vNJIAAMDjndq81eVRW1deeaXy8/PNY+vWrea16dOn66WXXlJ6erpycnIUHh6u3r1769ixY2ZNamqqli1bpoyMDK1bt06lpaVKSkpSZWWlWTNkyBDl5uYqMzNTmZmZys3NVUpKSq3HyhpJAACABsTb29slhTzJMAy9/PLLeuKJJ3TrrbdKkhYsWKCwsDC98847uv/++1VSUqJ58+Zp0aJF6tWrlyRp8eLFioqK0hdffKG+ffsqLy9PmZmZys7OVlxcnCRp7ty5SkhI0I4dO9SuXbsaj5VEEgAAeDx3Tm07nU4dPXrU5XA6nacdy86dOxUZGamWLVvqjjvu0K5duyRJu3fvVkFBgfr06WPW2u12de3aVevXr5ckbd68WRUVFS41kZGRiomJMWuysrLkcDjMJlKS4uPj5XA4zJqaopEEAABwo7S0NHMt4skjLS2t2tq4uDgtXLhQn3/+uebOnauCggJ16dJFR44cUUFBgSQpLCzM5TVhYWHmtYKCAvn6+qpZs2ZnrAkNDa3y3qGhoWZNTTG1DQAAPJ47t/+ZOHGixo4d63LObrdXW5uYmGj+vUOHDkpISFDr1q21YMECxcfHVztWwzDOOv5Ta6qrr8l9TkUiCQAA4EZ2u12BgYEux+kayVP5+/urQ4cO2rlzp7lu8tTUsLCw0Ewpw8PDVV5erqKiojPWHDx4sMp7HTp0qEraeTY0kgAAwOM1lO1/TuV0OpWXl6eIiAi1bNlS4eHhWrVqlXm9vLxca9euVZcuXSRJsbGx8vHxcanJz8/Xtm3bzJqEhASVlJRo48aNZs2GDRtUUlJi1tQUU9sAAAANxPjx4zVgwABdeumlKiws1HPPPaejR49q6NChstlsSk1N1dSpU9WmTRu1adNGU6dOlZ+fn4YMGSJJcjgcGj58uMaNG6fg4GAFBQVp/Pjx6tChg/kUd/v27dWvXz+NGDFCs2fPliSNHDlSSUlJtXpiW6KRBAAAaDC/InH//v268847dfjwYTVv3lzx8fHKzs5WixYtJEmPP/64ysrKNGrUKBUVFSkuLk4rV65UQECAeY8ZM2bI29tbgwYNUllZmXr27Kn58+fLy8vLrFmyZInGjBljPt2dnJys9PT0Wo/XZhiG8Qc/c4PTpNPD9T0EAG5SmPVqfQ8BgJsENK6/FXd/euEbt9173fgb3Hbv+sYaSQAAAFjC1DYAAPB4DWVq+3xDIgkAAABLSCQBAIDHI5G0hkQSAAAAlpBIAgAAj0cgaQ2JJAAAACwhkQQAAB6PNZLW0EgCAACPRx9pDVPbAAAAsIREEgAAeDymtq0hkQQAAIAlJJIAAMDjEUhaQyIJAAAAS0gkAQCAx2tEJGkJiSQAAAAsIZEEAAAej0DSGhpJAADg8dj+xxqmtgEAAGAJiSQAAPB4jQgkLSGRBAAAgCUkkgAAwOOxRtIaEkkAAABYQiIJAAA8HoGkNSSSAAAAsIREEgAAeDybiCStoJEEAAAej+1/rGFqGwAAAJaQSAIAAI/H9j/WkEgCAADAEhJJAADg8QgkrSGRBAAAgCUkkgAAwOM1IpK0hEQSAAAAlpBIAgAAj0cgaQ2NJAAA8Hhs/2MNU9sAAACwhEQSAAB4PAJJa0gkAQAAYAmJJAAA8Hhs/2MNiSQAAAAsIZEEAAAejzzSGhJJAAAAWEIiCQAAPB77SFpDIgkAADxeI5v7jj8iLS1NNptNqamp5rlhw4bJZrO5HPHx8S6vczqdGj16tEJCQuTv76/k5GTt37/fpaaoqEgpKSlyOBxyOBxKSUlRcXFxrcZHIwkAANAA5eTkaM6cOerYsWOVa/369VN+fr55rFixwuV6amqqli1bpoyMDK1bt06lpaVKSkpSZWWlWTNkyBDl5uYqMzNTmZmZys3NVUpKSq3GyNQ2AADweA1taru0tFR33XWX5s6dq+eee67KdbvdrvDw8GpfW1JSonnz5mnRokXq1auXJGnx4sWKiorSF198ob59+yovL0+ZmZnKzs5WXFycJGnu3LlKSEjQjh071K5duxqNk0QSAADAjZxOp44ePepyOJ3OM77moYceUv/+/c1G8FRr1qxRaGio2rZtqxEjRqiwsNC8tnnzZlVUVKhPnz7mucjISMXExGj9+vWSpKysLDkcDrOJlKT4+Hg5HA6zpiZoJAEAgMez2dx3pKWlmesQTx5paWmnHUtGRoa+/fbb09YkJiZqyZIlWr16tV588UXl5OSoR48eZnNaUFAgX19fNWvWzOV1YWFhKigoMGtCQ0Or3Ds0NNSsqQmmtgEAANxo4sSJGjt2rMs5u91ebe2+ffv0yCOPaOXKlWrcuHG1NYMHDzb/HhMTo86dO6tFixb69NNPdeutt552HIZhuEzhVzedf2rN2dBIAgAAj+fONZJ2u/20jeOpNm/erMLCQsXGxprnKisr9fXXXys9PV1Op1NeXl4ur4mIiFCLFi20c+dOSVJ4eLjKy8tVVFTkkkoWFhaqS5cuZs3BgwervP+hQ4cUFhZW489Wo0Zy+fLlNb5hcnJyjWsBAADwf3r27KmtW7e6nLvnnnt0xRVXaMKECVWaSEk6cuSI9u3bp4iICElSbGysfHx8tGrVKg0aNEiSlJ+fr23btmn69OmSpISEBJWUlGjjxo267rrrJEkbNmxQSUmJ2WzWRI0ayYEDB9boZjabzeWxcgAAgPPBH93vsa4EBAQoJibG5Zy/v7+Cg4MVExOj0tJSTZkyRbfddpsiIiK0Z88eTZo0SSEhIbrlllskSQ6HQ8OHD9e4ceMUHBysoKAgjR8/Xh06dDAf3mnfvr369eunESNGaPbs2ZKkkSNHKikpqcZPbEs1bCRPnDhR4xsCAACcbxra9j+n4+Xlpa1bt2rhwoUqLi5WRESEunfvrvfee08BAQFm3YwZM+Tt7a1BgwaprKxMPXv21Pz5810SzSVLlmjMmDHm093JyclKT0+v1XhshmEYdfPRGo4mnR6u7yEAcJPCrFfrewgA3CSgcf1tJnNPxtazF1n09h0d3Hbv+mbpYZvjx49r7dq12rt3r8rLy12ujRkzpk4GBgAAcK6cH3lkw1PrRnLLli266aab9Msvv+j48eMKCgrS4cOH5efnp9DQUBpJAAAAD1HrDPnRRx/VgAED9PPPP6tJkybKzs7WTz/9pNjYWL3wwgvuGCMAAIBbNbLZ3HZcyGrdSObm5mrcuHHy8vKSl5eXnE6noqKiNH36dE2aNMkdYwQAAEADVOtG0sfHx3yyKSwsTHv37pX0+6PmJ/8OAABwPnHnr0i8kNV6jWSnTp20adMmtW3bVt27d9dTTz2lw4cPa9GiRerQ4cJ9KgkAAACuap1ITp061dw5/dlnn1VwcLAefPBBFRYWas6cOXU+QAAAAHez2WxuOy5ktU4kO3fubP69efPmWrFiRZ0OCAAAAOcHS/tIAgAAXEgu8ODQbWrdSLZs2fKMMe2uXbv+0IAAAADOtQt9mx53qXUjmZqa6vJzRUWFtmzZoszMTD322GN1NS4AAAA0cLVuJB955JFqz7/++uvatGnTHx4QAADAuUYgaU2d/Xb0xMRELV26tK5uBwAAgAauzh62+eCDDxQUFFRXtwMAADhnLvRtetzF0obk//1lG4ahgoICHTp0SG+88UadDg4AAAANV60byZtvvtmlkWzUqJGaN2+ubt266YorrqjTwVm1IuPp+h4CADfx8a6zFTkAYOLfLNbUupGcMmWKG4YBAACA802tG3AvLy8VFhZWOX/kyBF5eXnVyaAAAADOJX5FojW1TiQNw6j2vNPplK+v7x8eEAAAwLnW6MLu99ymxo3kq6++Kun3jv3NN99U06ZNzWuVlZX6+uuvG8waSQAAALhfjRvJGTNmSPo9kZw1a5bLNLavr68uu+wyzZo1q+5HCAAA4GYkktbUuJHcvXu3JKl79+768MMP1axZM7cNCgAAAA1frddIfvXVV+4YBwAAQL250B+KcZdaP7X95z//WdOmTaty/m9/+5tuv/32OhkUAAAAGr5aN5Jr165V//79q5zv16+fvv766zoZFAAAwLnUyOa+40JW60aytLS02m1+fHx8dPTo0ToZFAAAABq+WjeSMTExeu+996qcz8jIUHR0dJ0MCgAA4Fyy2dx3XMhq/bDNk08+qdtuu03//ve/1aNHD0nSl19+qXfeeUcffPBBnQ8QAADA3Rpd6B2fm9S6kUxOTtZHH32kqVOn6oMPPlCTJk101VVXafXq1QoMDHTHGAEAANAA1bqRlKT+/fubD9wUFxdryZIlSk1N1T//+U9VVlbW6QABAADcrdZr/SDpD3xvq1ev1t13363IyEilp6frpptu0qZNm+pybAAAAGjAapVI7t+/X/Pnz9dbb72l48ePa9CgQaqoqNDSpUt50AYAAJy3WCJpTY0TyZtuuknR0dH6/vvv9dprr+nAgQN67bXX3Dk2AAAANGA1TiRXrlypMWPG6MEHH1SbNm3cOSYAAIBziqe2ralxIvnNN9/o2LFj6ty5s+Li4pSenq5Dhw65c2wAAABowGrcSCYkJGju3LnKz8/X/fffr4yMDF188cU6ceKEVq1apWPHjrlznAAAAG7DhuTW1PqpbT8/P917771at26dtm7dqnHjxmnatGkKDQ1VcnKyO8YIAADgVvyubWv+0LZJ7dq10/Tp07V//369++67dTUmAAAAnAcsbUh+Ki8vLw0cOFADBw6si9sBAACcUzxsYw0buQMAAMCSOkkkAQAAzmcEktaQSAIAAMASEkkAAODxLvSnq92FRBIAAACW0EgCAACPZ3Pjnz8iLS1NNptNqamp5jnDMDRlyhRFRkaqSZMm6tatm7Zv3+7yOqfTqdGjRyskJET+/v5KTk7W/v37XWqKioqUkpIih8Mhh8OhlJQUFRcX12p8NJIAAMDjNcQNyXNycjRnzhx17NjR5fz06dP10ksvKT09XTk5OQoPD1fv3r1dfstgamqqli1bpoyMDK1bt06lpaVKSkpSZWWlWTNkyBDl5uYqMzNTmZmZys3NVUpKSu2+N+sfDwAAAO5QWlqqu+66S3PnzlWzZs3M84Zh6OWXX9YTTzyhW2+9VTExMVqwYIF++eUXvfPOO5KkkpISzZs3Ty+++KJ69eqlTp06afHixdq6dau++OILSVJeXp4yMzP15ptvKiEhwfxV2J988ol27NhR43HSSAIAAI/nzkTS6XTq6NGjLofT6TzjeB566CH1799fvXr1cjm/e/duFRQUqE+fPuY5u92url27av369ZKkzZs3q6KiwqUmMjJSMTExZk1WVpYcDofi4uLMmvj4eDkcDrOmRt9bjSsBAABQa2lpaeY6xJNHWlraaeszMjL07bffVltTUFAgSQoLC3M5HxYWZl4rKCiQr6+vS5JZXU1oaGiV+4eGhpo1NcH2PwAAwOPZ3Lgj+cSJEzV27FiXc3a7vdraffv26ZFHHtHKlSvVuHHj097z1PEahnHWz3BqTXX1NbnPfyORBAAAcCO73a7AwECX43SN5ObNm1VYWKjY2Fh5e3vL29tba9eu1auvvipvb28ziTw1NSwsLDSvhYeHq7y8XEVFRWesOXjwYJX3P3ToUJW080xoJAEAgMdrKE9t9+zZU1u3blVubq55dO7cWXfddZdyc3PVqlUrhYeHa9WqVeZrysvLtXbtWnXp0kWSFBsbKx8fH5ea/Px8bdu2zaxJSEhQSUmJNm7caNZs2LBBJSUlZk1NMLUNAADQQAQEBCgmJsblnL+/v4KDg83zqampmjp1qtq0aaM2bdpo6tSp8vPz05AhQyRJDodDw4cP17hx4xQcHKygoCCNHz9eHTp0MB/ead++vfr166cRI0Zo9uzZkqSRI0cqKSlJ7dq1q/F4aSQBAIDHc+MSyTr3+OOPq6ysTKNGjVJRUZHi4uK0cuVKBQQEmDUzZsyQt7e3Bg0apLKyMvXs2VPz58+Xl5eXWbNkyRKNGTPGfLo7OTlZ6enptRqLzTAMo24+VsPx1Y4j9T0EAG6S0Dq4vocAwE0a12O89fI3u91279QbWrrt3vWNNZIAAACwhKltAADg8f7IrzL0ZCSSAAAAsIREEgAAeLzz6WGbhoREEgAAAJaQSAIAAI/XSESSVpBIAgAAwBISSQAA4PFYI2kNjSQAAPB4bP9jDVPbAAAAsIREEgAAeLxGzG1bQiIJAAAAS0gkAQCAxyOQtIZEEgAAAJaQSAIAAI/HGklrSCQBAABgCYkkAADweASS1tBIAgAAj8cUrTV8bwAAALCERBIAAHg8G3PblpBIAgAAwBISSQAA4PHII60hkQQAAIAlJJIAAMDjsSG5NSSSAAAAsIREEgAAeDzySGtoJAEAgMdjZtsaprYBAABgCYkkAADweGxIbg2JJAAAACwhkQQAAB6PZM0avjcAAABYQiIJAAA8HmskrSGRBAAAgCUkkgAAwOORR1pDIgkAAABLSCQBAIDHY42kNTSSAADA4zFFaw3fGwAAACwhkQQAAB6PqW1rSCQBAABgCYkkAADweOSR1pBIAgAAwBISSQAA4PFYImkNiSQAAAAsoZEEAAAer5FsbjtqY+bMmerYsaMCAwMVGBiohIQEffbZZ+b1YcOGyWazuRzx8fEu93A6nRo9erRCQkLk7++v5ORk7d+/36WmqKhIKSkpcjgccjgcSklJUXFxsYXvDQAAwMPZbO47auOSSy7RtGnTtGnTJm3atEk9evTQzTffrO3bt5s1/fr1U35+vnmsWLHC5R6pqalatmyZMjIytG7dOpWWliopKUmVlZVmzZAhQ5Sbm6vMzExlZmYqNzdXKSkptf/eDMMwav2qBu6rHUfqewgA3CShdXB9DwGAmzSuxyc3Ptl20G33TooJ+0OvDwoK0t/+9jcNHz5cw4YNU3FxsT766KNqa0tKStS8eXMtWrRIgwcPliQdOHBAUVFRWrFihfr27au8vDxFR0crOztbcXFxkqTs7GwlJCTohx9+ULt27Wo8NhJJAADg8Wxu/ON0OnX06FGXw+l0nnVMlZWVysjI0PHjx5WQkGCeX7NmjUJDQ9W2bVuNGDFChYWF5rXNmzeroqJCffr0Mc9FRkYqJiZG69evlyRlZWXJ4XCYTaQkxcfHy+FwmDU1RSMJAADgRmlpaeZaxJNHWlraaeu3bt2qpk2bym6364EHHtCyZcsUHR0tSUpMTNSSJUu0evVqvfjii8rJyVGPHj3MxrSgoEC+vr5q1qyZyz3DwsJUUFBg1oSGhlZ539DQULOmptj+BwAAeDx3bv8zceJEjR071uWc3W4/bX27du2Um5ur4uJiLV26VEOHDtXatWsVHR1tTldLUkxMjDp37qwWLVro008/1a233nraexqG4fJrIKv7lZCn1tQEjSQAAIAb2e32MzaOp/L19dXll18uSercubNycnL0yiuvaPbs2VVqIyIi1KJFC+3cuVOSFB4ervLychUVFbmkkoWFherSpYtZc/Bg1TWhhw4dUlhY7dZzMrUNAAA8XkPZ/qc6hmGcdk3lkSNHtG/fPkVEREiSYmNj5ePjo1WrVpk1+fn52rZtm9lIJiQkqKSkRBs3bjRrNmzYoJKSErOmpkgkAQAAGohJkyYpMTFRUVFROnbsmDIyMrRmzRplZmaqtLRUU6ZM0W233aaIiAjt2bNHkyZNUkhIiG655RZJksPh0PDhwzVu3DgFBwcrKChI48ePV4cOHdSrVy9JUvv27dWvXz+NGDHCTDlHjhyppKSkWj2xLdFIAgAANJhfkXjw4EGlpKQoPz9fDodDHTt2VGZmpnr37q2ysjJt3bpVCxcuVHFxsSIiItS9e3e99957CggIMO8xY8YMeXt7a9CgQSorK1PPnj01f/58eXl5mTVLlizRmDFjzKe7k5OTlZ6eXuvxso8kgPMK+0gCF6763EdyZd4ht927T/vmbrt3fWONJAAAACxhahsAAHg8Wx08FOOJSCQBAABgCYkkAADweI0IJC0hkQQAAIAlJJIAAMDjsUbSGhJJAAAAWEIiCQAAPF5D2ZD8fEMjCQAAPB5T29YwtQ0AAABLSCQBAIDHY/sfa0gkAQAAYAmJJAAA8HiskbSGRBIAAACWkEgCAACPx/Y/1pBIAgAAwBISSQAA4PEIJK2hkQQAAB6vEXPbljToqe19+/bp3nvvPWON0+nU0aNHXY7ycuc5GiEAAIDnatCN5M8//6wFCxacsSYtLU0Oh8PleGf2y+dmgAAA4IJgc+NxIavXqe3ly5ef8fquXbvOeo+JEydq7NixLueyfir9Q+MCAADA2dVrIzlw4EDZbDYZhnHaGttZ1izY7XbZ7XaXc76+FXUyPgAA4CEu9OjQTep1ajsiIkJLly7ViRMnqj2+/fbb+hweAAAAzqBeG8nY2NgzNotnSysBAADqgs2Nfy5k9Tq1/dhjj+n48eOnvX755Zfrq6++OocjAgAAQE3VayN5ww03nPG6v7+/unbteo5GAwAAPBXbSFrDhuQAAMDj0Uda06D3kQQAAEDDRSIJAABAJGkJiSQAAAAsIZEEAAAe70LfpsddSCQBAABgCYkkAADweGz/Yw2JJAAAACwhkQQAAB6PQNIaGkkAAAA6SUuY2gYAAIAlJJIAAMDjsf2PNSSSAAAAsIREEgAAeDy2/7GGRBIAAACWkEgCAACPRyBpDYkkAAAALCGRBAAAIJK0hEQSAAB4PJsb/9TGzJkz1bFjRwUGBiowMFAJCQn67LPPzOuGYWjKlCmKjIxUkyZN1K1bN23fvt3lHk6nU6NHj1ZISIj8/f2VnJys/fv3u9QUFRUpJSVFDodDDodDKSkpKi4urvX3RiMJAADQQFxyySWaNm2aNm3apE2bNqlHjx66+eabzWZx+vTpeumll5Senq6cnByFh4erd+/eOnbsmHmP1NRULVu2TBkZGVq3bp1KS0uVlJSkyspKs2bIkCHKzc1VZmamMjMzlZubq5SUlFqP12YYhvHHP3bD8tWOI/U9BABuktA6uL6HAMBNGtfjgrut+0vddu8OlzT9Q68PCgrS3/72N917772KjIxUamqqJkyYIOn39DEsLEzPP/+87r//fpWUlKh58+ZatGiRBg8eLEk6cOCAoqKitGLFCvXt21d5eXmKjo5Wdna24uLiJEnZ2dlKSEjQDz/8oHbt2tV4bCSSAAAAbuR0OnX06FGXw+l0nvV1lZWVysjI0PHjx5WQkKDdu3eroKBAffr0MWvsdru6du2q9evXS5I2b96siooKl5rIyEjFxMSYNVlZWXI4HGYTKUnx8fFyOBxmTU3RSAIAAI9nc+ORlpZmrkU8eaSlpZ12LFu3blXTpk1lt9v1wAMPaNmyZYqOjlZBQYEkKSwszKU+LCzMvFZQUCBfX181a9bsjDWhoaFV3jc0NNSsqSme2gYAAHCjiRMnauzYsS7n7Hb7aevbtWun3NxcFRcXa+nSpRo6dKjWrl1rXred8mt4DMOocu5Up9ZUV1+T+5yKRhIAAMCN2//Y7fYzNo6n8vX11eWXXy5J6ty5s3JycvTKK6+Y6yILCgoUERFh1hcWFpopZXh4uMrLy1VUVOSSShYWFqpLly5mzcGDB6u876FDh6qknWfD1DYAAEADZhiGnE6nWrZsqfDwcK1atcq8Vl5errVr15pNYmxsrHx8fFxq8vPztW3bNrMmISFBJSUl2rhxo1mzYcMGlZSUmDU1RSIJAAA8Xm33e3SXSZMmKTExUVFRUTp27JgyMjK0Zs0aZWZmymazKTU1VVOnTlWbNm3Upk0bTZ06VX5+fhoyZIgkyeFwaPjw4Ro3bpyCg4MVFBSk8ePHq0OHDurVq5ckqX379urXr59GjBih2bNnS5JGjhyppKSkWj2xLdFIAgAANBgHDx5USkqK8vPz5XA41LFjR2VmZqp3796SpMcff1xlZWUaNWqUioqKFBcXp5UrVyogIMC8x4wZM+Tt7a1BgwaprKxMPXv21Pz58+Xl5WXWLFmyRGPGjDGf7k5OTlZ6enqtx8s+kgDOK+wjCVy46nMfye8PHHfbvaMj/d127/pGIgkAADxew5jYPv/wsA0AAAAsIZEEAAAgkrSERBIAAACWkEgCAACP11C2/znfkEgCAADAEhJJAADg8Wr5K6bx/yORBAAAgCUkkgAAwOMRSFpDIwkAAEAnaQlT2wAAALCERBIAAHg8tv+xhkQSAAAAlpBIAgAAj8f2P9aQSAIAAMASEkkAAODxCCStIZEEAACAJSSSAAAARJKW0EgCAACPx/Y/1jC1DQAAAEtIJAEAgMdj+x9rSCQBAABgCYkkAADweASS1pBIAgAAwBISSQAAACJJS0gkAQAAYAmJJAAA8HjsI2kNjSQAAPB4bP9jDVPbAAAAsIREEgAAeDwCSWtIJAEAAGAJiSQAAPB4rJG0hkQSAAAAlpBIAgAAsErSEhJJAAAAWEIiCQAAPB5rJK2hkQQAAB6PPtIaprYBAABgCYkkAADweExtW0MiCQAAAEtIJAEAgMezsUrSEhJJAAAAWEIiCQAAQCBpCYkkAAAALKGRBAAAHs/mxqM20tLSdO211yogIEChoaEaOHCgduzY4VIzbNgw2Ww2lyM+Pt6lxul0avTo0QoJCZG/v7+Sk5O1f/9+l5qioiKlpKTI4XDI4XAoJSVFxcXFtRovjSQAAPB4Npv7jtpYu3atHnroIWVnZ2vVqlX67bff1KdPHx0/ftylrl+/fsrPzzePFStWuFxPTU3VsmXLlJGRoXXr1qm0tFRJSUmqrKw0a4YMGaLc3FxlZmYqMzNTubm5SklJqd33ZhiGUbuP2PB9teNIfQ8BgJsktA6u7yEAcJPG9fjkRuGxCrfdOzTAx/JrDx06pNDQUK1du1Y33nijpN8TyeLiYn300UfVvqakpETNmzfXokWLNHjwYEnSgQMHFBUVpRUrVqhv377Ky8tTdHS0srOzFRcXJ0nKzs5WQkKCfvjhB7Vr165G4yORBAAAHs/mxj9Op1NHjx51OZxOZ43GVVJSIkkKCgpyOb9mzRqFhoaqbdu2GjFihAoLC81rmzdvVkVFhfr06WOei4yMVExMjNavXy9JysrKksPhMJtISYqPj5fD4TBraoJGEgAAwI3S0tLMdYgnj7S0tLO+zjAMjR07Vn/6058UExNjnk9MTNSSJUu0evVqvfjii8rJyVGPHj3M5rSgoEC+vr5q1qyZy/3CwsJUUFBg1oSGhlZ5z9DQULOmJtj+BwAAwI3b/0ycOFFjx451OWe328/6uocffljfffed1q1b53L+5HS1JMXExKhz585q0aKFPv30U916662nvZ9hGLL916JNWzULOE+tORsaSQAAADey2+01ahz/2+jRo7V8+XJ9/fXXuuSSS85YGxERoRYtWmjnzp2SpPDwcJWXl6uoqMgllSwsLFSXLl3MmoMHD1a516FDhxQWFlbjcTK1DQAAPF5D2f7HMAw9/PDD+vDDD7V69Wq1bNnyrK85cuSI9u3bp4iICElSbGysfHx8tGrVKrMmPz9f27ZtMxvJhIQElZSUaOPGjWbNhg0bVFJSYtbUBE9tAziv8NQ2cOGqz6e2D5f+5rZ7hzSt+QcbNWqU3nnnHf3jH/9weXLa4XCoSZMmKi0t1ZQpU3TbbbcpIiJCe/bs0aRJk7R3717l5eUpICBAkvTggw/qk08+0fz58xUUFKTx48fryJEj2rx5s7y8vCT9vtbywIEDmj17tiRp5MiRatGihT7++OMaj5dGEsB5hUYSuHDVZyN55Lj7Gslg/5p/sNOtT3z77bc1bNgwlZWVaeDAgdqyZYuKi4sVERGh7t2769lnn1VUVJRZ/+uvv+qxxx7TO++8o7KyMvXs2VNvvPGGS83PP/+sMWPGaPny5ZKk5ORkpaen66KLLqr5eGkkAZxPaCSBC1d9NpI/H688e5FFQf5ebrt3fWONJAAAACzhqW0AAODxavurDPE7EkkAAABYQiMJAAAAS2gkAQAAYAlrJAEAgMdjjaQ1JJIAAACwhEQSAAB4PFutf5khJBpJAAAAprYtYmobAAAAlpBIAgAAj0cgaQ2JJAAAACwhkQQAACCStIREEgAAAJaQSAIAAI/H9j/WkEgCAADAEhJJAADg8dhH0hoSSQAAAFhCIgkAADwegaQ1NJIAAAB0kpYwtQ0AAABLSCQBAIDHY/sfa0gkAQAAYAmJJAAA8Hhs/2MNiSQAAAAssRmGYdT3IACrnE6n0tLSNHHiRNnt9voeDoA6xD/fQMNHI4nz2tGjR+VwOFRSUqLAwMD6Hg6AOsQ/30DDx9Q2AAAALKGRBAAAgCU0kgAAALCERhLnNbvdrsmTJ7MQH7gA8c830PDxsA0AAAAsIZEEAACAJTSSAAAAsIRGEgAAAJbQSAIAAMASGkmc19544w21bNlSjRs3VmxsrL755pv6HhKAP+jrr7/WgAEDFBkZKZvNpo8++qi+hwTgNGgkcd567733lJqaqieeeEJbtmzRDTfcoMTERO3du7e+hwbgDzh+/Liuuuoqpaen1/dQAJwF2//gvBUXF6drrrlGM2fONM+1b99eAwcOVFpaWj2ODEBdsdlsWrZsmQYOHFjfQwFQDRJJnJfKy8u1efNm9enTx+V8nz59tH79+noaFQAAnoVGEuelw4cPq7KyUmFhYS7nw8LCVFBQUE+jAgDAs9BI4rxms9lcfjYMo8o5AADgHjSSOC+FhITIy8urSvpYWFhYJaUEAADuQSOJ85Kvr69iY2O1atUql/OrVq1Sly5d6mlUAAB4Fu/6HgBg1dixY5WSkqLOnTsrISFBc+bM0d69e/XAAw/U99AA/AGlpaX617/+Zf68e/du5ebmKigoSJdeemk9jgzAqdj+B+e1N954Q9OnT1d+fr5iYmI0Y8YM3XjjjfU9LAB/wJo1a9S9e/cq54cOHar58+ef+wEBOC0aSQAAAFjCGkkAAABYQiMJAAAAS2gkAQAAYAmNJAAAACyhkQQAAIAlNJIAAACwhEYSAAAAltBIAgAAwBIaSQAN1pQpU3T11VebPw8bNkwDBw485+PYs2ePbDabcnNzz/l7A0BDRiMJoNaGDRsmm80mm80mHx8ftWrVSuPHj9fx48fd+r6vvPJKjX9FHs0fALifd30PAMD5qV+/fnr77bdVUVGhb775Rvfdd5+OHz+umTNnutRVVFTIx8enTt7T4XDUyX0AAHWDRBKAJXa7XeHh4YqKitKQIUN011136aOPPjKno9966y21atVKdrtdhmGopKREI0eOVGhoqAIDA9WjRw/985//dLnntGnTFBYWpoCAAA0fPly//vqry/VTp7ZPnDih559/XpdffrnsdrsuvfRS/fWvf5UktWzZUpLUqVMn2Ww2devWzXzd22+/rfbt26tx48a64oor9MYbb7i8z8aNG9WpUyc1btxYnTt31pYtW+rwmwOACweJJIA60aRJE1VUVEiS/vWvf+n999/X0qVL5eXlJUnq37+/goKCtGLFCjkcDs2ePVs9e/bUjz/+qKCgIL3//vuaPHmyXn/9dd1www1atGiRXn31VbVq1eq07zlx4kTNnTtXM2bM0J/+9Cfl5+frhx9+kPR7M3jdddfpiy++0JVXXilfX19J0ty5czV58mSlp6erU6dO2rJli0aMGCF/f38NHTpUx48fV1JSknr06KHFixdr9+7deuSRR9z87QHAecoAgFoaOnSocfPNN5s/b9iwwQgODjYGDRpkTJ482fDx8TEKCwvN619++aURGBho/Prrry73ad26tTF79mzDMAwjISHBeOCBB1yux8XFGVdddVW173v06FHDbrcbc+fOrXaMu3fvNiQZW7ZscTkfFRVlvPPOOy7nnn32WSMhIcEwDMOYPXu2ERQUZBw/fty8PnPmzGrvBQCejqltAJZ88sknatq0qRo3bqyEhATdeOONeu211yRJLVq0UPPmzc3azZs3q7S0VMHBwWratKl57N69W//+978lSXl5eUpISHB5j1N//m95eXlyOp3q2bNnjcd86NAh7du3T8OHD3cZx3PPPecyjquuukp+fn41GgcAeDKmtgFY0r17d82cOVM+Pj6KjIx0eaDG39/fpfbEiROKiIjQmjVrqtznoosusvT+TZo0qfVrTpw4Ien36e24uDiXayen4A3DsDQeAPBENJIALPH399fll19eo9prrrlGBQUF8vb21mWXXVZtTfv27ZWdna2//OUv5rns7OzT3rNNmzZq0qSJvvzyS913331Vrp9cE1lZWWmeCwsL08UXX6xdu3bprrvuqva+0dHRWrRokcrKysxm9UzjAABPxtQ2ALfr1auXEhISNHDgQH3++efas2eP1q9fr//3//6fNm3aJEl65JFH9NZbb+mtt97Sjz/+qMmTJ2v79u2nvWfjxo01YcIEPf7441q4cKH+/e9/Kzs7W/PmzZMkhYaGqkmTJsrMzNTBgwdVUlIi6fdNztPS0vTKK6/oxx9/1NatW/X222/rpZdekiQNGTJEjRo10vDhw/X9999rxYoVeuGFF9z8DQHA+YlGEoDb2Ww2rVixQjfeeKPuvfdetW3bVnfccYf27NmjsLAwSdLgwYP11FNPacKECYqNjdVPP/2kBx988Iz3ffLJJzVu3Dg99dRTat++vQYPHqzCwkJJkre3t1599VXNnj1bkZGRuvnmmyVJ9913n958803Nnz9fHTp0UNeuXTV//nxzu6CmTZvq448/1vfff69OnTrpiSee0PPPP+/GbwcAzl82gwVBAAAAsIBEEgAAAJbQSAIAAMASGkkAAABYQiMJAAAAS2gkAQAAYAmNJAAAACyhkQQAAIAlNJIAAACwhEYSAAAAltBIAgAAwBIaSQAAAFjy/wHje4wAyLIKbwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluación en datos de prueba\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(classification_report(y_test_tensor.cpu().numpy(), predicted.cpu().numpy()))\n",
    "\n",
    "# Graficar matriz de confusión\n",
    "cm = confusion_matrix(y_test_tensor.cpu().numpy(), predicted.cpu().numpy())\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=df['readmitted'].unique(), yticklabels=df['readmitted'].unique())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo de googlecolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  patient_nbr             race  gender      age  \\\n",
       "0           0      8222157        Caucasian  Female   [0-10)   \n",
       "1           1     55629189        Caucasian  Female  [10-20)   \n",
       "2           2     86047875  AfricanAmerican  Female  [20-30)   \n",
       "3           3     82442376        Caucasian    Male  [30-40)   \n",
       "4           4     42519267        Caucasian    Male  [40-50)   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  num_lab_procedures  ...  metformin  glimepiride  \\\n",
       "0                 1                  41  ...          0            0   \n",
       "1                 3                  59  ...          0            0   \n",
       "2                 2                  11  ...          0            0   \n",
       "3                 2                  44  ...          0            0   \n",
       "4                 1                  51  ...          0            0   \n",
       "\n",
       "   glipizide  glyburide  pioglitazone rosiglitazone insulin change  \\\n",
       "0          0          0             0             0       0     No   \n",
       "1          0          0             0             0       2     Ch   \n",
       "2          1          0             0             0       0     No   \n",
       "3          0          0             0             0       2     Ch   \n",
       "4          1          0             0             0       1     Ch   \n",
       "\n",
       "   diabetesMed readmitted  \n",
       "0           No         NO  \n",
       "1          Yes        >30  \n",
       "2          Yes         NO  \n",
       "3          Yes         NO  \n",
       "4          Yes         NO  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetic_data_modified.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guille\\AppData\\Local\\Temp\\ipykernel_22728\\3865154589.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df2['readmitted'] = df2['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'readmitted' en binaria (NO = 0; >30 y <30 = 1)\n",
    "df2 = df.copy()\n",
    "df2['readmitted'] = df2['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})\n",
    "df2 = df2.drop(columns=[\"Unnamed: 0\",\"patient_nbr\",], axis=1)\n",
    "\n",
    "# Definir las características (features) y la variable objetivo\n",
    "X = df2.drop('readmitted', axis=1)  # Features\n",
    "y = df2['readmitted']  # Target variable\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "numerical_cols = [\n",
    "    'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    "    'num_medications', 'number_outpatient', 'number_emergency',\n",
    "    'number_inpatient', 'number_diagnoses'\n",
    "]\n",
    "categorical_cols = [\n",
    "    'race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "    'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult',\n",
    "    'metformin', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'change', 'diabetesMed'\n",
    "]\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  precision    recall  f1-score  support\n",
      "0        RandomForest   0.616925  0.634228  0.606828  14304.0\n",
      "1             XGBoost   0.627435  0.642058  0.621645  14304.0\n",
      "2  LogisticRegression   0.625328  0.640450  0.603574  14304.0\n",
      "3        DecisionTree   0.564401  0.561102  0.562611  14304.0\n"
     ]
    }
   ],
   "source": [
    "# Crear un pipeline para cada modelo\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Lista de pipelines de modelos\n",
    "pipelines = [\n",
    "    ('RandomForest', pipeline_rf),\n",
    "    ('XGBoost', pipeline_xgb),\n",
    "    ('LogisticRegression', pipeline_lr),\n",
    "    ('DecisionTree', pipeline_dt)\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada modelo en el pipeline\n",
    "results = {}\n",
    "for name, pipeline in pipelines:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1-score': report['weighted avg']['f1-score'],\n",
    "        'support': report['weighted avg']['support']\n",
    "    }\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.index.name = 'Model'\n",
    "results_df.reset_index(inplace=True)\n",
    "\n",
    "# Mostrar la tabla comparativa\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con balanceo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  precision    recall  f1-score  support\n",
      "0        RandomForest   0.607334  0.607324  0.607311  11414.0\n",
      "1             XGBoost   0.609372  0.609339  0.609317  11414.0\n",
      "2  LogisticRegression   0.607609  0.607587  0.607561  11414.0\n",
      "3        DecisionTree   0.545921  0.545909  0.545859  11414.0\n"
     ]
    }
   ],
   "source": [
    "# Crear un pipeline para cada modelo con manejo de desbalance\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(random_state=42, scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1])))\n",
    "])\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Lista de pipelines de modelos\n",
    "pipelines = [\n",
    "    ('RandomForest', pipeline_rf),\n",
    "    ('XGBoost', pipeline_xgb),\n",
    "    ('LogisticRegression', pipeline_lr),\n",
    "    ('DecisionTree', pipeline_dt)\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada modelo en el pipeline\n",
    "results = {}\n",
    "for name, pipeline in pipelines:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1-score': report['weighted avg']['f1-score'],\n",
    "        'support': report['weighted avg']['support']\n",
    "    }\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.index.name = 'Model'\n",
    "results_df.reset_index(inplace=True)\n",
    "\n",
    "# Mostrar la tabla comparativa\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submuestreo (Undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmitted\n",
      "0    42985\n",
      "1    28533\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readmitted', ylabel='count'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df2.readmitted.value_counts())\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='readmitted', data=df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22684</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22734</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35224</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48169</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71503</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71508</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71513</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71514</th>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71515</th>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57066 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  race  gender      age  admission_type_id  \\\n",
       "22684        Caucasian  Female  [70-80)                  1   \n",
       "22734  AfricanAmerican  Female  [70-80)                  3   \n",
       "1977         Caucasian  Female  [60-70)                  2   \n",
       "35224        Caucasian    Male  [40-50)                  1   \n",
       "48169        Caucasian  Female  [70-80)                  2   \n",
       "...                ...     ...      ...                ...   \n",
       "71503              NaN  Female  [70-80)                  2   \n",
       "71508        Caucasian  Female  [40-50)                  1   \n",
       "71513        Caucasian  Female  [70-80)                  1   \n",
       "71514            Other  Female  [40-50)                  1   \n",
       "71515            Other  Female  [60-70)                  1   \n",
       "\n",
       "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "22684                         6                    7                 2   \n",
       "22734                         1                    1                 4   \n",
       "1977                          1                    4                 2   \n",
       "35224                         1                    7                 2   \n",
       "48169                         1                    1                 4   \n",
       "...                         ...                  ...               ...   \n",
       "71503                         1                    1                 4   \n",
       "71508                         4                    7                14   \n",
       "71513                         1                    7                 9   \n",
       "71514                         1                    7                14   \n",
       "71515                         1                    7                 2   \n",
       "\n",
       "       num_lab_procedures  num_procedures  num_medications  ...  metformin  \\\n",
       "22684                  49               1               15  ...          0   \n",
       "22734                  38               1               18  ...          0   \n",
       "1977                   31               2               21  ...          0   \n",
       "35224                  56               0                2  ...          0   \n",
       "48169                  71               2               13  ...          0   \n",
       "...                   ...             ...              ...  ...        ...   \n",
       "71503                  41               0               13  ...          0   \n",
       "71508                  69               0               16  ...          2   \n",
       "71513                  50               2               33  ...          0   \n",
       "71514                  73               6               26  ...          0   \n",
       "71515                  46               6               17  ...          0   \n",
       "\n",
       "       glimepiride  glipizide glyburide pioglitazone rosiglitazone  insulin  \\\n",
       "22684            0          1         0            0             1        1   \n",
       "22734            0          0         0            0             0        0   \n",
       "1977             1          0         0            0             0        1   \n",
       "35224            0          0         0            0             0        0   \n",
       "48169            0          0         0            0             0        1   \n",
       "...            ...        ...       ...          ...           ...      ...   \n",
       "71503            0          0         0            0             0        1   \n",
       "71508            0          0         1            0             0        3   \n",
       "71513            0          0         2            0             0        1   \n",
       "71514            0          1         0            0             0        2   \n",
       "71515            0          0         0            0             0        1   \n",
       "\n",
       "      change diabetesMed  readmitted  \n",
       "22684     Ch         Yes           0  \n",
       "22734     No          No           0  \n",
       "1977      Ch         Yes           0  \n",
       "35224     No          No           0  \n",
       "48169     Ch         Yes           0  \n",
       "...      ...         ...         ...  \n",
       "71503     Ch         Yes           1  \n",
       "71508     Ch         Yes           1  \n",
       "71513     Ch         Yes           1  \n",
       "71514     Ch         Yes           1  \n",
       "71515     No         Yes           1  \n",
       "\n",
       "[57066 rows x 29 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo: Submuestreo de la clase mayoritaria\n",
    "# Suponiendo que 'df' es tu dataframe original\n",
    "# Separa las clases\n",
    "clase_mayoritaria = df2[df2['readmitted'] == 0]\n",
    "clase_minoritaria = df2[df2['readmitted'] == 1]\n",
    "\n",
    "# Submuestreo de la clase mayoritaria\n",
    "clase_mayoritaria_muestra_reducida = resample(clase_mayoritaria, \n",
    "                                              replace=False,    # Muestras sin reemplazo\n",
    "                                              n_samples=len(clase_minoritaria),    # Igualar número de muestras\n",
    "                                              random_state=42)  # Reproducibilidad\n",
    "\n",
    "# Concatenar las clases submuestreadas\n",
    "df_balanceado = pd.concat([clase_mayoritaria_muestra_reducida, clase_minoritaria])\n",
    "\n",
    "# df_balanceado ahora contiene clases balanceadas\n",
    "df_balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmitted\n",
      "0    28533\n",
      "1    28533\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readmitted', ylabel='count'>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_balanceado.readmitted.value_counts())\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='readmitted', data=df_balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las características (features) y la variable objetivo\n",
    "X = df_balanceado.drop('readmitted', axis=1)  # Features\n",
    "y = df_balanceado['readmitted']  # Target variable\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "numerical_cols = [\n",
    "    'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    "    'num_medications', 'number_outpatient', 'number_emergency',\n",
    "    'number_inpatient', 'number_diagnoses'\n",
    "]\n",
    "categorical_cols = [\n",
    "    'race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "    'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult',\n",
    "    'metformin', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'change', 'diabetesMed'\n",
    "]\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  precision    recall  f1-score  support\n",
      "0        RandomForest   0.605580  0.605572  0.605561  11414.0\n",
      "1             XGBoost   0.610393  0.610391  0.610390  11414.0\n",
      "2  LogisticRegression   0.607607  0.607587  0.607563  11414.0\n",
      "3        DecisionTree   0.545315  0.545295  0.545221  11414.0\n"
     ]
    }
   ],
   "source": [
    "# Crear un pipeline para cada modelo\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Lista de pipelines de modelos\n",
    "pipelines = [\n",
    "    ('RandomForest', pipeline_rf),\n",
    "    ('XGBoost', pipeline_xgb),\n",
    "    ('LogisticRegression', pipeline_lr),\n",
    "    ('DecisionTree', pipeline_dt)\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada modelo en el pipeline\n",
    "results = {}\n",
    "for name, pipeline in pipelines:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1-score': report['weighted avg']['f1-score'],\n",
    "        'support': report['weighted avg']['support']\n",
    "    }\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.index.name = 'Model'\n",
    "results_df.reset_index(inplace=True)\n",
    "\n",
    "# Mostrar la tabla comparativa\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobremuestreo (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8785</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11507</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29359</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85970 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  race  gender      age  admission_type_id  \\\n",
       "0            Caucasian  Female   [0-10)                  6   \n",
       "2      AfricanAmerican  Female  [20-30)                  1   \n",
       "3            Caucasian    Male  [30-40)                  1   \n",
       "4            Caucasian    Male  [40-50)                  1   \n",
       "6            Caucasian    Male  [60-70)                  3   \n",
       "...                ...     ...      ...                ...   \n",
       "8785          Hispanic  Female  [70-80)                  6   \n",
       "11507        Caucasian    Male  [40-50)                  2   \n",
       "29359        Caucasian    Male  [50-60)                  2   \n",
       "9561   AfricanAmerican  Female  [70-80)                  1   \n",
       "10366        Caucasian  Female  [50-60)                  3   \n",
       "\n",
       "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "0                            25                    1                 1   \n",
       "2                             1                    7                 2   \n",
       "3                             1                    7                 2   \n",
       "4                             1                    7                 1   \n",
       "6                             1                    2                 4   \n",
       "...                         ...                  ...               ...   \n",
       "8785                          1                   17                 2   \n",
       "11507                        18                    1                11   \n",
       "29359                         3                    1                 7   \n",
       "9561                         18                    3                 2   \n",
       "10366                        18                    1                 4   \n",
       "\n",
       "       num_lab_procedures  num_procedures  num_medications  ...  metformin  \\\n",
       "0                      41               0                1  ...          0   \n",
       "2                      11               5               13  ...          0   \n",
       "3                      44               1               16  ...          0   \n",
       "4                      51               0                8  ...          0   \n",
       "6                      70               1               21  ...          1   \n",
       "...                   ...             ...              ...  ...        ...   \n",
       "8785                   60               2               14  ...          1   \n",
       "11507                  48               3               17  ...          0   \n",
       "29359                   1               2               21  ...          1   \n",
       "9561                   28               0                5  ...          0   \n",
       "10366                  42               1               11  ...          0   \n",
       "\n",
       "       glimepiride  glipizide glyburide pioglitazone rosiglitazone  insulin  \\\n",
       "0                0          0         0            0             0        0   \n",
       "2                0          1         0            0             0        0   \n",
       "3                0          0         0            0             0        2   \n",
       "4                0          1         0            0             0        1   \n",
       "6                1          0         0            0             0        1   \n",
       "...            ...        ...       ...          ...           ...      ...   \n",
       "8785             0          0         0            1             0        0   \n",
       "11507            0          0         0            0             0        2   \n",
       "29359            1          1         0            0             0        2   \n",
       "9561             0          0         0            0             0        0   \n",
       "10366            0          0         1            0             0        0   \n",
       "\n",
       "      change diabetesMed  readmitted  \n",
       "0         No          No           0  \n",
       "2         No         Yes           0  \n",
       "3         Ch         Yes           0  \n",
       "4         Ch         Yes           0  \n",
       "6         Ch         Yes           0  \n",
       "...      ...         ...         ...  \n",
       "8785      Ch         Yes           1  \n",
       "11507     Ch         Yes           1  \n",
       "29359     Ch         Yes           1  \n",
       "9561      No          No           1  \n",
       "10366     No         Yes           1  \n",
       "\n",
       "[85970 rows x 29 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo: Sobremuestreo de la clase minoritaria\n",
    "clase_minoritaria_sobremuestreada = resample(clase_minoritaria, \n",
    "                                             replace=True,     # Muestras con reemplazo\n",
    "                                             n_samples=len(clase_mayoritaria),    # Igualar número de muestras\n",
    "                                             random_state=42)  # Reproducibilidad\n",
    "\n",
    "# Concatenar las clases sobremuestreadas\n",
    "df_balanceado = pd.concat([clase_mayoritaria, clase_minoritaria_sobremuestreada])\n",
    "\n",
    "# df_balanceado ahora contiene clases balanceadas\n",
    "df_balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmitted\n",
      "0    42985\n",
      "1    42985\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='readmitted', ylabel='count'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_balanceado.readmitted.value_counts())\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='readmitted', data=df_balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las características (features) y la variable objetivo\n",
    "X = df_balanceado.drop('readmitted', axis=1)  # Features\n",
    "y = df_balanceado['readmitted']  # Target variable\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "numerical_cols = [\n",
    "    'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    "    'num_medications', 'number_outpatient', 'number_emergency',\n",
    "    'number_inpatient', 'number_diagnoses'\n",
    "]\n",
    "categorical_cols = [\n",
    "    'race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "    'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult',\n",
    "    'metformin', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'change', 'diabetesMed'\n",
    "]\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [20] in column 4 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, pipeline \u001b[38;5;129;01min\u001b[39;00m pipelines:\n\u001b[0;32m     45\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 46\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     report \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     48\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m: report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m: report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     53\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    505\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:816\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 816\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    664\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    666\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    667\u001b[0m     )\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColumnTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\pipeline.py:933\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m--> 933\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1016\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1015\u001b[0m }\n\u001b[1;32m-> 1016\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1023\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\Nocountry_proyect_01\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:199\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    195\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[0;32m    198\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories [20] in column 4 during transform"
     ]
    }
   ],
   "source": [
    "# Crear un pipeline para cada modelo\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Lista de pipelines de modelos\n",
    "pipelines = [\n",
    "    ('RandomForest', pipeline_rf),\n",
    "    ('XGBoost', pipeline_xgb),\n",
    "    ('LogisticRegression', pipeline_lr),\n",
    "    ('DecisionTree', pipeline_dt)\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada modelo en el pipeline\n",
    "results = {}\n",
    "for name, pipeline in pipelines:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'f1-score': report['weighted avg']['f1-score'],\n",
    "        'support': report['weighted avg']['support']\n",
    "    }\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.index.name = 'Model'\n",
    "results_df.reset_index(inplace=True)\n",
    "\n",
    "# Mostrar la tabla comparativa\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nocountry_proyect_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
